{"1": "Preliminary Report-International Algebraic Language", "2": "Extraction of Roots by Repeated Subtractions for Digital Computers", "3": "Techniques Department on Matrix Program Schemes", "4": "Glossary of Computer Engineering and Programming Terminology", "5": "Two Square-Root Approximations", "6": "The Use of Computers in Inspection Procedures", "7": "Glossary of Computer Engineering and Programming Terminology", "8": "On The Equivalence and Transformation of Program Schemes", "9": "Proposal for an UNCOL", "10": "Glossary of Computer Engineering and Programming Terminology", "11": "The Problem of Programming Communication with", "12": "Error Estimation in Runge-Kutta Procedures", "13": "Glossary of Computer Engineering and Programming Terminology", "14": "The Problem of Programming Communication with", "15": "Recursive Curve Fitting Technique", "16": "Secant Modification of Newton's Method", "17": "On Programming of Arithmetic Operations", "18": "Simple Automatic Coding Systems", "19": "Glossary of Computer Engineering and Programming Terminology", "20": "Accelerating Convergence of Iterative Processes A technique is discussed which, when applied\nto an iterative procedure for the solution of\nan equation, accelerates the rate of convergence if\nthe iteration converges and induces convergence if\nthe iteration diverges.  An illustrative example is given.\n", "21": "Algebraic Formulation of Flow Diagrams", "22": "Unusual Applications Department--Automatic", "23": "Binary and Truth-Function Operations on", "24": "An Improved Decimal Redundancy Check", "25": "General Purpose Programming Systems", "26": "A Subroutine Method for Calculating Logarithms", "27": "Note On Empirical Bounds For Generating Bessel Functions", "28": "Request for Methods or Programs", "29": "Need for an Algorithm", "30": "Algorithm for Analyzing Logical Statements", "31": "IBM 704 Code-Nundrums", "32": "Variable-Width Tables with Binary-Search Facility", "33": "A Programmed Binary Counter For The IBM Type 650 Calculator", "34": "Tables for Automatic Computation", "35": "A Machine Method for Square-Root Computation", "36": "A Queue Network Simulator for the IBM 650 and Burroughs 220", "37": "Impact of Computer Developments", "38": "A Proposed Interpretation in ALGOL", "39": "The Secant Method for Simultaneous Nonlinear Equations  A procedure for the simultaneous solution\nof a system of not-necessarily-linear equations, \na generalization of the secant method for a\nsingle function of one variable, is given.\n", "40": "Fingers or Fists? (The Choice of Decimal or Binary Representation) The binary number system offers many advantages\nover a decimal representation for a high-performance, \ngeneral-purpose computer.  The greater simplicity of\na binary arithmetic unit and the greater compactness \nof binary numbers both contribute directly to arithmetic\nspeed.  Less obvious and perhaps more important \nis the way binary addressing and instruction formats can\nincrease the overall performance.  Binary addresses \nare also essential to certain powerful operations which\nare not practical with decimal instruction formats. \n On the other hand, decimal numbers are essential for\ncommunicating between man and the computer.  In \napplications requiring the processing of a large volume\nof inherently decimal input and output data, \nthe time for decimal-binary conversion needed by a purely\nbinary computer may be significant.  A slower \ndecimal adder may take less time than a fast binary adder\ndoing an addition and two conversions.  A careful \nreview of the significance of decimal and binary addressing\nand both binary and decimal data arithmetic, \nsupplemented by efficient conversion instructions.\n", "41": "Some Notes on Computer Research in Eastern Europe", "42": "A New Method of Computation of Square Roots Without Using Division", "43": "A Technique for Handling Macro Instructions", "44": "RUNCIBLE-Algebraic Translation on a Limited Computer", "45": "Flow Outlining-A Substitute for Flow Charting", "46": "Multiprogramming STRETCH: Feasibility Considerations The tendency towards increased parallelism in\ncomputers is noted.  Exploitation of this parallelism \npresents a number of new problems in machine design\nand in programming systems.  Minimum requirements \nfor successful concurrent execution of several independent\nproblem programs are discussed.  These requirements \nare met in the STRETCH system by a carefully balanced\ncombination of built-in and programmed logic.  \nTechniques are described which place the burden of the\nprogrammed logic on system programs (supervisory \nprogram and compiler) rather than on problem programs.\n", "47": "Russian Visit to U.S. Computers", "48": "Shift-Register Code for Indexing Applications In this communication the use of a shift-register\ncode with n = 10 is described for calling \n64 wireless telemetering stations in a fixed cyclical order.\n A high degree of redundancy is used, permitting \na single-error correcting code (\"minimum-distance-three\"\ncode) with 64 10-bit code words to be employed \nas the station identification code.  Embedding this in\nthe shift-register code with period 1023 permits \nthe code to be employed without punctuation, each of\nthe telemetering station receivers simply putting \nreceived ones and zeros into a shift register.  Each\ntime the given code combination arises identifying \nthe particular station (barring for tuitous error combinations\nof very low probability) it has been called. \n The communication describes the properties and application\nof the code in some detail and the finding \nof the particular example to be employed on URAL, the\nSoviet-built drum computer donated to the Indian \nStatistical Institute by the United Nations\nTechnical Aid Administration (UNTAA).\n", "49": "Scientific and Business Applications (Oracle Curve Plotter)", "50": "Statistical Programs for the IBM 650-Part II", "51": "On the Construction of Micro-Flowcharts", "52": "An Efficient Method for Generating Uniformly Distributed", "53": "Recommendations of the SHARE ALGOL Committee", "54": "SALE, a Simple Algebraic Language for Engineers", "55": "An Algebraic Translator", "56": "Proposed Standard Flow Chart Symbols", "57": "J.E.I.D.A. and Its Computer Center", "58": "LEM-1, Small Size General Purpose Digital The paper examines some of the questions of\ndevelopment and construction of a general purpose \ndigital computer using contactless magnetic (ferrite)\nand capacitive \"DEZU\" (long duration capacitive \nmemory) elements, developed at the Laboratory of Electrical\nModeling VINITYI AN SSSR, under the supervision \nof Professor L.I. Gutenmacher.\n", "59": "Survey of Progress and Trend of Development", "60": "The Alpha Vector Transformation of a System of Linear Constraints", "61": "IBM 709 Tape Matrix Compiler", "62": "Multi-Dimensional Least-Squares Polynomial Curve Fitting", "63": "Octal Diagrams of Binary Conception and This paper dates back the genesis of binary\nconception circa 5000 years ago, and octal diagrams \nabout 4800 years ago, as derived by the Chinese ancients.\n It analyzes the applicability of binary trinities \nof the octal diagrams to modern electronic-digital-computer design logic.\n", "64": "Remarks on ALGOL and Symbol Manipulation ", "65": "ALGOL Sub-Committee Report - Extensions", "66": "A Proposal for a Generalized Card Code for 256 Characters", "67": "Central-European Computers", "68": "The Role of the University in Computers, A study was made of university programs in\nthe United States in the fields of computers, data \nprocessing, operations research, and other closely related\nfields.  University policies, organization, \nadministration, faculties, students, researches, curricula,\nequipment, and financing were investigated. \n An integrated university program is recommended reflecting\nthe conviction that many present activities \nrelated to computers will develop into disciplines and\nas such are the legitimate province of the university \nscholar.  Details on a recommended Graduate\nSchool of \"Computer Sciences\" are given.\n", "69": "Statistical Programs for the IBM 650-Part I A collection is given of brief descriptions\nof statistical programs now in use in university \ncomputing centers which have IBM 650's.\n", "70": "Construction of a Set of Test Matrices This paper develops the equations and properties\nof a set of test matrices which are useful \nin the determination of the accuracy of routines for\nfinding the inverse, determinant and/or eigenvalues \nof a matrix.\n", "71": "Proposal for a Feasible Programming System This paper proposes designing a programming\nfacility (itself involving a digital computer and \na program) which will assist the preparation of large-scale\nreal-time programs.  This facility is to \nbe capable of preparing programs for any of a variety\nof machines having characteristics similar to those \nof the facility's computer.  One of the basic assumptions\nis that there will be enough random-access \nstorage available to avoid the necessity for segmenting\na constructed program in any fashion other than \na trivial one.  While this assumption is somewhat unrealistic,\nit is intended to provide an opportunity \nto concentrate on the other aspects of program construction.\n The programming system should stress the \ndiscovery in source program statements of as many errors\nas possible, before attempting to construct \nan object program.  Among the computer characteristics\nwhich are advocated are a program interrupt scheme, \na large set of characters, and indirect addressing.\n", "72": "An Educational Program in Computing ", "73": "A Real Time Data Assimilator", "74": "A High-Speed Sorting Procedure", "75": "Parameter Estimation for Simple Nonlinear Models", "76": "Binary Conversion, With Fixed Decimal Precision, Of a Decimal Fraction", "77": "On GAT and the Construction of Translators", "78": "Remarks on the Practical Solution of Characteristic Value Problems This paper is concerned with the practical\nsolution of characteristic value problem for an \nordinary differential equation.  It is at once apparent\nthat sequential computers, be they digital or \nanalog, solve initial value problems, rather than boundary\nvalue problems, and some mathematical process \nmust be found to compensate for the machine's inadequacy.\n (Compensating for machine imperfection is, \nof course, the normal activity of the numerical analyst.)\n A number of other papers have applied particular \ndevices to particular problems.  The purpose of this\nnote is to establish a mathematical framework or \nmodel for these practical procedures and thus assist in\nthe use and extension of the ideas in other particular \nproblems.\n", "79": "Programming for a Machine With an Extended", "80": "A Technique for Computing Critical Rotational", "81": "NORC High-Speed Printer", "82": "Handling Identifiers as Internal Symbols in Language Processors Substitution of computer-oriented symbols for\nprogrammer-oriented symbols in language processors \nis examined and a feasible method for doing so is presented.\n", "83": "A Visit to Computation Centers in the Soviet Union", "84": "Survey of Progress and Trend of Development", "85": "Error Analysis in Floating Point Arithmetic", "86": "Survey of Progress and Trend of Development", "87": "A Note on a Method for Generating Points", "88": "An Efficient Method for Generating Uniformly Distributed", "89": "A Routine to Find the Solution of Simultaneous", "90": "Binary Arithmetic for Discretely Variable", "91": "A Mathematical Procedure for Machine Division", "92": "A Checklist of Intelligence for Programming Systems A remarkable variation exists in the degree\nof sophistication of various programming systems. \n A particular manifestation is the jungle of assorted\ndevices for reproducing limited human decision \nprocedures.  An attempt is made here to begin a systematic\nclassification of the various devices for \neducating the computer to take over the decision-making\nfunctions of one or many human operators, both \nthose that have been demonstrated feasible to date and\nthose that are highly desirable for the future.\n", "93": "From Formulas to Computer Oriented Language A technique is shown for enabling a computer\nto translate simple algebraic formulas into a \nthree address computer code.\n", "94": "An Iterative Method for Fitting the Logistic Curve An iterative method is given for finding a\nlogistic curve of best least squares fit to a set \nof two-dimensional points.\n", "95": "Elimination of Special Functions from Differential Equations A set of ordinary differential equations which\ncontains mathematical functions requiring the \nuse of subroutines for numerical solution by electronic\ncomputer, tabular data for numerical solution \nby hand calculation or function generators when analog\nmethods are applied can sometimes be expanded \nto an equivalent set of equations which do not contain\nthe functions.  This is practical if these functions \nsatisfy sufficiently simple differential equations. \nThus among those functions which can be eliminated \nby this procedure are the trigonometric, inverse trigonometric,\nexponential, and many other transcendental \nfunctions.\n", "96": "On Computing Radiation Integrals The relative merit and cost of four ways of\nevaluating typical radiation integrals containing \nspherical Bessel functions are investigated.  These methods\nare desk machine evaluation of a finite series, \nintegration of the appropriate differential equation\nby a Reeves Electronic Analog Computer and by a \nLitton 40 IBM 704 computer.  Results are generally applicable\nto equations separated from a Helmholtz \nor wave equation.\n", "97": "Signal Corps Research and Development on", "98": "The Arithmetic Translator-Compiler of", "99": "Possible Modifications to the International Algebraic Language", "100": "Recursive Subscripting Compilers and List-Types Memories", "101": "Nuclear Reactor Codes", "102": "A Comparison of 650 Programming Methods", "103": "COPE (Console Operator Proficiency Examination)* Each year electronic computers become more\nsophisticated, and the programs they must process \nbecome more complex.  Because of this,dependence of\nthose in computing on the skill and experience of \noperators is increasing.  At the same time, selection\nand training of qualified operators grows more \ndifficult.  To meet the need for a quick, accurate, uniform\noperator test and training aid, the authors \nhave developed COPE (Console Operator Proficiency Examination),\noutlined below.  While this examination \nis programmed specifically for the IBM 705 Model II with\ntwo Tape Record Coordinators, similar programs \ncould be developed for other computers.\n", "104": "Digital Simulation of Discrete Flow Systems* The discrete flow systems discussed are characterized\nby the movement of randomly arriving \nitems along interacting channels.  Programing a digital\ncomputer to simulate such systems utilizes some \ntechniques not common in other approaches to physical\nproblems.  The principal portion of the paper is \na discussion of two simulation studies that illustrate\nsome of the programming problems involved. One \nis of an extensive package-handling plant, with the\nobjective being optimization of parameters such as \nstorage capacities and processing rates.  In the other,\nair traffic flow and control procedures are simulated \nto compare the effects of alternative control decisions.\n", "105": "Two Methods for Word Inversion on the IBM 709", "106": "A Method for Overlapping and Erasure of Lists An important property of the Newell-Shaw-Simon\nscheme for computer storage of lists is that \ndata having multiple occurrences need not be stored\nat more than one place in the computer.  That is, \nlists may be \"overlapped.\"  Unfortunately, overlapping\nposes a problem for subsequent erasure.  Given \na list that is no longer needed, it is desired to erase\njust those parts that do not overlap other lists. \n In LISP, McCarthy employs an elegant but inefficient solution\nto the problem.  The present paper describes \na general method which enables efficient erasure.  The\nmethod employs interspersed reference counts to \ndescribe the extent of the overlapping.\n", "107": "Multiple Precision Arithmetic", "108": "Programmed Error Correction in Project Mercury", "109": "A Note on Approximating e^x", "110": "Fibonaccian Searching", "111": "On Programming the Numerical Solution of Polynomial Equations Numerical techniques are presented for computing\nthe roots of polynomial equations.  By applying \nthe recommended scaling and inversion rules, the basic\nBairstow and Newton-Raphson iterative techniques \ncan be applied with great reliability.  Both a high degree\nof accuracy and rapid convergence are realized. \n Numerical examples are shown to illustrate the pitfalls\nand to show how these are circumvented by application \nof the recommended procedures.\n", "112": "Numerical Solution of the Polynomial Equation (Algorithm 30)", "113": "Survey of Coded Character Representation", "114": "Survey of Punched Card Codes", "115": "Optimizers: Their Structure", "116": "The Sumador Chino On a recent motor trip through Mexico, the writer\ncame across on adding device which was referred \nto as a sumador chino (Chinese adder).  A survey of the more\navailable literature on the history of mathematics \nand on instruments of calculation has uncovered no reference\nto such a device.  The purpose of this communication \nis to enlist the help of other members in bringing to\nlight whatever may be known concerning the evolution \nand present status of the sumador chino.\n", "117": "An Estimation of the Relative Efficiency of Two Internal Sorting Methods", "118": "Character Scanning on the IBM 7070", "119": "Note on Eigenvalue Computation", "120": "A Simple Technique for Coding Differential Equations", "121": "Over-all Computation Control and Labelling", "122": "Least Squares Fitting of a Great Circle Through Points on a Sphere", "123": "Compilation for Two Computers with NELIAC NELIAC, a compiler based on ALGOL, was developed\nat the U.S. Navy Electronics Laboratory, San \nDiego,California, as a\"boot-strap\" compiler for the Remington\nRand Univac COUNTESS computer. This compiler \nwas used to generate a version of itself which, running\nas a COUNTESS program, generated machine code \nfor the Control Data Corporation CDC-1604.  All three\nversions of NELIAC accepted essentially identical \ninput language.\n", "124": "An Algorithm for the Assignment Problem The assignment problem is formulated and briefly\ndiscussed.  An efficient algorithm for its \nsolution is presented in ALGOL code.  An empirical relation\nbetween solution time and the size of the \nproblem is given, based on extensive experiments\ncarried out on a digital computer.\n", "125": "Polynomial Transformer (Algorithm 29)", "126": "Least Squares Fit By Orthogonal polynomials (Algorithm 28)", "127": "ASSIGNMENT (Algorithm 27)", "128": "ROOTFINDER III (Algorithm 26)", "129": "ROOTFINDER II (Algorithm 15)", "130": "Real Zeros of an Arbitrary Function (Algorithm 25)", "131": "Solution of Tri-Diagonal Linear Equations (Algorithm 24)", "132": "Math Sort (Algorithm 23)", "133": "Riccati-Bessel Functions of First And Second Kind (Algorithm 22)", "134": "Bessel Function for a Set of Integer Orders(Algorithm 21)", "135": "Digital Computers in Universities-IV", "136": "A Note on the Calculation of Interest", "137": "Evaluating Numbers Expressed as Strings of English Words", "138": "Some Thoughts on Reconciling Various", "139": "Binomial Coefficients (Algorithm 19)", "140": "Crout with Pivoting (Algorithm 16)", "141": "Some Thoughts on Parallel Processing", "142": "Comments on a Technique for Counting Ones ", "143": "A List of Computer Systems Programs for", "144": "Do It by the Numbers-Digital Shorthand Present communications systems transmit single\ncharacters in groups of coded pulses between \nsimple terminal equipments.  Since English words form only\na sparse set of all possible alphabetic combinations, \npresent methods are inefficient when computer systems\nare substituted for these terminals.  Using numeric \nrepresentations of entire words or common phrases (rather\nthan character-by-character representations) \nrequires approximately one-third of present transmission\ntime.  This saving is reflected in overall costs. \n Other benefits accrue in code and language translation\nschemes. Provision is made for transmission of \npurely numeric and/or binary streams, and for single\ncharacter-transmission of non-dictionary words such \nas the names of people or places.\n", "145": "Automatic Graders for Programming Classes", "146": "The Use of Computers in Engineering Classroom Instruction  On April 29-30, the Computer Committee of the\nCollege of Engineering, University of Michigan, \nwhich acts as a steering committee for The Ford Foundation\nProject on the Use of Computers in Engineering \nEducation, held a special conference to discuss certain\ntimely topics pertinent to the Ford Project. \n This report contains a condensed transcription of\nthe key ideas offered by the conference attendees \non selected topics. \n", "147": "Report on a Conference of University Computing Center Directors", "148": "Digital Computers in Universities-III", "149": "A Decision Rule for Improved Efficiency in Solving", "150": "Rational Interpolation by Continued Fractions (Algorithm 18)", "151": "TRDIAG (Algorithm 17)", "152": "CROUT With Pivoting (Algorithm 16)", "153": "Comments from a FORTRAN User", "154": "Rapidly Convergent Expressions for Evaluating e^x", "155": "Trie Memory", "156": "An Introductory Problem in Symbol Manipulation for the Student", "157": "Digital Computers in Universities -II", "158": "ROOTFINDER II (Algorithm 15)", "159": "ROOTFINDER (Algorithm 2)", "160": "ROOTFINDER II (Algorithm 15)", "161": "Abbreviating Words Systematically (Corrigendum)", "162": "A Variant Technique for Counting Ones", "163": "Counting Ones on the IBM 7090 ", "164": "A Short Study of Notation Efficiency", "165": "NELIAC-A Dialect of ALGOL", "166": "Programming Compatibility in a Family", "167": "Combining ALGOL Statement Analysis with Validity Checking", "168": "Multiprogram Scheduling Parts 3 and 4 Scheduling", "169": "The Multilingual Terminology Project", "170": "Some Thoughts on Reconciling Various Character Set Proposals", "171": "Digital Computers in Universities (Part I) ", "172": "Complex Exponential Integral (Algorithm 13)", "173": "ATLAS a new concept in large computer design", "174": "Interval Estimation of the Time in One State", "175": "The Solution of Simultaneous Ordinary Differential", "176": "Symbol Manipulation by Threaded Lists (Corrigendum)", "177": "Solution of Polynomial Equation by Bairstow", "178": "ROOTFINDER (Algorithm)", "179": "Evaluation of the Legendre Polynomial Pn(X) by Recursion (Algorithm)", "180": "Evaluation of the Laguerre Polynomial Ln(X) by Recursion (Algorithm)", "181": "Evaluation of the Hermite Polynomial Hn(X) by Recursion (Algorithm)", "182": "Evaluation of the Chebyshev Polynomial Tn(X) by Recursion (Algorithm) ", "183": "Conversion Between Floating Point Representations", "184": "A Short Method for Measuring Error in a Least-Squares Power Series", "185": "Multiprogram Scheduling Parts 1 and 2.  Introduction and Theory* In order to exploit fully a fast computer which\npossesses simultaneous processing abilities, \nit should to a large extent schedule its own workload.\n The scheduling routine must be capable of extremely \nrapid execution if it is not to prove self-defeating.\n The construction of a schedule entails determining \nwhich programs are to be run concurrently and which sequentially\nwith respect to each other.  A concise \nscheduling algorithm is described which tends to minimize\nthe time for executing the entire pending workload \n(or any subset of it), subject to external constraints\nsuch as precedence, urgency, etc.  The algorithm \nis applicable to a wide class of machines.\n", "186": "An Algorithm Defining ALGOL Assignment Statements (Addendum)", "187": "Compiling Connectives", "188": "The Department of Computer Mathematics at Moscow State University", "189": "The Future of Automatic Digital Computers", "190": "Bendix G-20 System", "191": "Abbreviating Words Systematically", "192": "A Technique for Counting Ones in a Binary Computer", "193": "A Start at Automatic Storage Assignment", "194": "Divisionless Computation of Square Roots Through Continued Squaring", "195": "What is a Code?", "196": "Report on the Algorithmic Language ALGOL 60", "197": "An Imaginary Number System", "198": "A High-Speed Multiplication Process for Digital Computers", "199": "Euclidian Algorithm (Algorithm 7)", "200": "Bessel Function I, Asymptotic Expansion (Algorithm 6)", "201": "Bessel Funtion I, Series Expansion (Algorithm 5)", "202": "A Control System For Logical Block Diagnosis With Data Loading This paper describes a section of an integrated\ndiagnostic monitor system which facilitates \nthe checking of sections of instructions or subroutines\nanywhere in the object program.  A new method \nof specifying all diagnostic operations in a format similar\nto a computer program makes the system convenient \nto use and relatively simple to understand.  The paper\nalso describes a number of other novel diagnostic \nfeatures which can be included in the system.\n", "203": "Decoding Combinations of the First n Integers Taken k at a Time", "204": "Proving Theorems by Pattern Recognition I", "205": "Macro Instruction Extensions of Compiler Languages Macroinstruction compilers constructed from\na small set of functions can be made extremely \npowerful.  In particular, conditional assembly, nested\ndefinitions, and parenthetical notation serve \nto make a compiler capable of accepting very\ngeneral extensions to its ground language.\n", "206": "Symbol Manipulation in XTRAN", "207": "Syntactic and Semantic Augments to ALGOL", "208": "An Introduction to Information Processing Language V", "209": "Symbol Manipulation by Threaded Lists", "210": "Recursive Functions of Symbolic Expressions", "211": "Share Standard Flow Chart Symbols", "212": "Bisection Routine (Algorithm 4)", "213": "Numerical Inversion of Laplace Transforms", "214": "An Algorithm Defining ALGOL Assignment Statements", "215": "The Execute Operations-A Fourth Mode of Instruction Sequencing", "216": "A Note on the Use of the Abacus in Number Conversion", "217": "Soviet Computer Technology-1959", "218": "Computer Preparation of a Poetry Concordance", "219": "Marriage-with Problems", "220": "A New Method of Computation of Square Roots Without Using Division", "221": "The Basic Side of Tape Labeling", "222": "Coding Isomorphisms The coding of external symbols into symbols\ninternal to a compute can sometimes be carried \nout in such a way that relevant informational properties\nare preserved, but in a form much more easily \ndealt with.  A case in point is presented.\n", "223": "Selfcipher: Programming", "224": "Sequential Formula Translation The syntax of an algorithmic language such\nas ALGOL is conveniently described as a sequence \nof states indicated by an element called cellar.  Transitions\nare controlled by admissible state-symbol \npairs which may be represented by a transition matrix.\nThis description of syntax furnishes at the same \ntime an extremely simple rule for translating into machine\nprograms statements in the algorithmic language. \n Sequential treatment, however, is not feasible in the case\nof certain optimizing processes such as recursive \naddress calculation.\n", "225": "A Techniquefor Handling Macro Instructions (Corrigendum)", "226": "Solution of Polynomial Equation by", "227": "ROOTFINDER (Algorithm 2)", "228": "QUADI (Algorithm 1)", "229": "A Terminology Proposal", "230": "A Proposal for Character Code Compatibility", "231": "A Proposal for a Set of Publication Standards for Use by the ACM", "232": "A High-Speed Sorting Procedure", "233": "Abstracts-Additional Nuclear Reactor Codes", "234": "A SAP-Like Assembly Program for the IBM 650", "235": "Two Think Pieces", "236": "Soviet Cybernetics and Computer This article records observations on Soviet\nresearch and technology in cybernetics and computer \nscience, made by the author during a visit to the Soviet\nUnion as a delegate to the IFAC Congress on \nAutomatic Control held in Moscow in the summer of 1960.\n", "237": "Computer Production of Peek-A-Boo Sheets", "238": "Simulation and Analysis of Biochemical Systems", "239": "Inefficiency of the Use of Boolean Functions", "240": "Processing Magnetic Tape Files with Variable Blocks", "241": "Machine Calculation of Moments of a Probability Distribution A method is presented for the calculation on a\nmachine of the moments of a probability distribution, \nnecessitating little more than n additions and n references\nto memory for each moment, instead of the \nminimum of n multiplication, 2n additions, and 2n references\nto memory required by the most straightforward \nmethod (where n is the number of entries in the probability\ndistribution).  The method is directly applicable \nwhen a tabulated distribution exists, as when it has\nbeen computed by repeated convolution; but in this \ncase it conserves both time and accuracy.\n", "242": "Notes on Geometric Weighted Check Digit Verification This note describes a method for utilizing\ngeometric weight modulus 11 checking digits on a \ncomputer which does not have either multiplication or\ndivision.  In addition some attempt has been made \nto show some limitations of this system.\n", "243": "N-Dimensional Codes for Detecting and Correcting Multiple Errors The paper introduces a new family of codes\nfor detecting and correcting multiple errors in \na binary-coded message.  The message itself is arranged\n(conceptually) into a multidimensional rectangular \narray.  The processes of encoding and error detection\nare based upon parity evaluations along prescribed \ndimensions of the array.  Effectiveness of the codes\nis increased by introducing a \"system check bit\", \nwhich is essentially a parity check on the other parity\nbits.  Only three-dimensional codes are discussed \nin this paper with parity evaluations along the horizontal,\nthe vertical, and one main diagonal.  However, \nthe family of codes is not restricted to three dimensions,\nas evidenced by the discussion by Minnick \nand Ashenhurst on a similar multidimensional single-bit\nselection plan used for another purpose [6]. \n A four-dimensional code, correcting three and detecting\nfour errors, has been developed; the extension \nto higher-dimensional codes with greater correction power is straightforward.\n", "244": "Incomplete Elliptic Integrals (Algorithm 73)", "245": "A Set of Associate Legendre Polynomials of the Second Kind (Algorithm 62)", "246": "Least-Squares Fit by Orthogonal Polynomials (Algorithm 28)", "247": "Incomplete Elliptic Integrals (Algorithm 73)", "248": "What is Proprietary In Mathematical Programming?-Impressions A panel discussion on \"What is Proprietary\nin Mathematical Programming?\" was sponsored by the \nSpecial Interest Committee on Mathematical Programming\nof the ACM during a Hall of Discussion/on September \n7th at the 16th National ACM meeting in Los Angeles.  This\nnote consists solely of the impressions garnered \nby the moderator of the panel and does not necessarily\nrepresent the position of any of the panelists \nor other participants in the discussion.\n", "249": "Specification Languages for Mechanical Languages", "250": "An Engineering Application of Logic-Structure Tables", "251": "Ballistic Cam Design  This paper presents a digital computer program\nfor the rapid calculation of manufacturing data \nessential to the design of preproduction cams which\nare utilized in ballistic computers of tank fire \ncontrol systems.  The cam profile generated introduces\nthe superelevation angle required by tank main \narmament for a particular type ammunition.\n", "252": "Programming a Duplex Computer System This paper describes a method of duplex-computer\nprogramming that has been used with two computers \nin a military defense system.  The method combines special\nprograms with a basic data processing program \npackage.  The duplex operation gives the system greater\nreliability.  After achieving the required level \nof integration, both computers do similar processing\non the same inputs and continually cross-check the \nintermediate and final results.\n", "253": "On a Program for Ray-Chaudhuri's Algorithm", "254": "SMALGOL-61 Prior to and during the 1961 Western Joint\nComputer Conference, several people in the Joint \nUsers Groups had expressed interest in defining a \"smalgol\"\nlanguage.  This is to be an ALGOL language \nfor use with compilers on relatively small size computers.\n A preliminary report resulted.  At the ACM \nNational Conference four months later, after considering\nseveral counter proposals, a final version was \nagreed upon by a subcommittee.  The recommendations\nof the Subcommittee for a standard subset of ALGOL \n60 for use on small computers is presented here.\n", "255": "Augmentation (Algorithm 68)", "256": "A Set of Test Matrices (Algorithm 52)", "257": "Invert (Algorithm 42)", "258": "Composition Generator (Algorithm 72)", "259": "Permutation (Algorithm 71)", "260": "Interpolation By Aitken (Algorithm 70)", "261": "Tape Splitting", "262": "MAP", "263": "Library Loading with Alternate Routine Selection", "264": "A Generalized Polyphase Merge Algorithm ", "265": "Low Level Language Subroutines for Use Within Fortran This paper describes some subroutines, coded\nin symbolic languages and for use within Fortran \ncoded programs, to deal with \"special arithmetic\" (e.g.\nmulti-precision arithmetic), symbol manipulation, \nbit manipulation and expanded character set input-output, and visual display.\n", "266": "Fitting Spheres by the Method of Least Squares", "267": "Some Proposals for Improving the Efficiency of ALGOL 60", "268": "Stochastic Evaluation of a Static Storage Allocation", "269": "Core Allocation Based on Probability", "270": "Techniques for Storage Allocation Algorithms ", "271": "A Semi-Automatic Storage Allocation System at Loading Time", "272": "A Storage Allocation Scheme for ALGOL 60 A storage allocation scheme for a machine\nwith a 2048 instruction core store and a magnetic \ndrum is described.  The use of the drum for storing\nprogram blocks and/or data must be directed by the \nprogrammer through auxiliary information in the ALGOL\nprogram.  The administrative routines controlling \nthe storage at run time are described in full.  A detailed example is given.\n", "273": "Experience in Automatic Storage Allocation ", "274": "Dynamic Storage Allocation in the Atlas Computer,", "275": "Dynamic Storage Allocation for an Information Retrieval System", "276": "Program Organization and Record Keeping for Dynamic Storage Allocation The material presented in this paper is part\nof the design plan of the core allocation portion \nof the ASCII-MATIC Programming System.  Project ASCII-MATIC\nis concerned with the application of computer \ntechniques to the activities of certain headquarters\nmilitary intelligence operations of the U.S. Army.\n", "277": "Problems of Storage Allocation in", "278": "A General Formulation of storage Allocation Formalization of a general computer storage\nallocation process is attempted.  With a given \ncomputer M is associated a fictitious computer M' essentially\nidentical to M except in respect to possession \nof unbounded primary storage.  Mappings of the total\nstorage set (internal and external) of M into the \ndirect address set of M' are introduced.  A program\nsequence P for M' is termed M-admissible (relative \nto a specific execution time period) if there is a mapping\nunderwhich P and its effective data referents \nare all located in the direct address set of M.  Storage\nallocation is considered as a process of establishing \nfor an arbitrary M' program  a sequence of mappings, a decoupling\nof the program into M-admissible subprograms \nand a linking set of interludes.  An existence proof\nin terms of a completely interpretive M program \nas indicated.  Some special cases are discussed.  Various\nrestrictions on generality of M' programs are \nconsidered under which more practical realization\nof allocation processes becomes tractable.\n", "279": "The Case for Dynamic storage Allocation ", "280": "A Preplanned Approach to a Storage Allocating Compiler", "281": "Putting a Hex on e^x Recent notes on approximate natural antilogy\nhave not considered indirect formulations for \ndescribing e^x.  In this note we produce a particular\nfamily of very fast, high precision and eminently \npractical exponential evaluation formulas derived from one such formulation.\n", "282": "Optimum Tape-Writing Procedures Consider a magnetic tape system with a read\ncheck after writing.  Where an error occurs in \nwriting a record, a programmed error routine may either\nbypass some or all of the area on tape or try \nto rewrite the record on the same area.  This paper evaluates\nthese two procedures on the basis of expected \nloss of computer time and develops a decision rule for\nselecting the optimum procedure.  The rule depends \ncritically on the number of times the tape being written\nwill be used in the future.  In the case where \nthe optimum procedure is to bypass an area, a second\ndecision-the size of the area to be bypassed-is \nnecessary.  A formula is developed to determine the\noptimum area to be bypassed for each procedure.\n", "283": "Inversion of a Complex Matrix", "284": "Manipulation of Algebraic Expressions An algorithm for algebraically manipulating\nexpressions of the form SUM{CiPi, i=1,...,n}; has \nbeen developed in conjunction with the development of programs\nfor systems analysis problems.  This algorithm \nenablesus to derive over-all system transfer functions\nfrom algebraically described block diagrams of \nany linear continuous multi-loop feedback system.  The\nmachine representation of the derived expression, \nis, by virtue of the algorithm, in a form which simplifies\nthe task of compiling.  The algorithm was \ndeveloped for a particular purpose in connection with\nsystem analysis studies.  However, its application \nas a mathematical device extends far beyond\nthe confines of the original problem.\n", "285": "Solution of Tridiagonal Matrices", "286": "An Iterative Method for Inversion of Power Series", "287": "The Generalized Important Event Technique", "288": "A Syntactical Chart of ALGOL 60", "289": "Critical Path Scheduling (Algorithm 40)", "290": "Chain Tracing (Algorithm 69)", "291": "Use of MOBOL in PreparingRetrieval Programs", "292": "An Information Retrieval Language for Legal Studies", "293": "The Applied Mathematics Laboratory of the David W. Taylor Model Basin", "294": "An Imaginary Number System", "295": "Rational Approximations for the Error Function and for Similar Functions", "296": "A Note on Multiple Precision Arithmetic", "297": "A Note on Fitting Great Circles by Least Squares", "298": "A 48-Bit Pseudo-Random Number Generator A new 48-bit pseudo-random number generator, suitable\nfor several computers, was tested statistically \nfor randomness to determine its adequacy for use in Monte\nCarlo programs.  Frequency tests, distributions \nof certain low-order moments, runs up and down, and runs\nabove and below the mean were applied to one-half \nmillion generated numbers lying within the interval\n(0,1) and to three sets of integers obtained from \nspecified bits within the generated numbers.  These\ntests substantiated the randomness of all numbers \nexcept for the set of integers coming from the least significant bits.\n", "299": "A Generalized Polyphase Merge Algorithm", "300": "COBOL: A Sample Problem A simplified Merchandise Control problem has\nbeen chosen for presenting COBOL to users and \npotential users of computing systems.  A mythical department\nstore, \"E. Language Bros., Inc.\", is programming \nin the COBOL language one of the many runs on its computer.\n", "301": "A Set of Test Matrices (Algorithm 52)", "302": "Augmentation (Algorithm 68)", "303": "Some Basic Terminology Connected With The suggestions in this paper are part of the\nterminology used in work for the University of \nPennsylvania's Office of computer Research and Education.\n The work is jointly supported by the National \nScience Foundation and the Air Force Office of Scientific Research.\n", "304": "Nth Roots of a Complex Number (Algorithm 53)", "305": "CRAM (Algorithm 67)", "306": "INVRS (Algorithm 66)", "307": "FIND (Algorithm 65)", "308": "QUICKSORT (Algorithm 64)", "309": "PARTITION (Algorithm 63)", "310": "A Set of Associate Legendre Polynomials", "311": "Procedures for Range Arithmetic (Algorithm 61)", "312": "A Further Note on Approximating e^x", "313": "An Iterative Method for Inversion of Power Series", "314": "A Divisionless Method of Integer Conversion", "315": "Solution of Tridiagonal Matrices", "316": "An Algorithm for Equivalence Declarations", "317": "On The Approximation of Curves by Line Segments Using Dynamic Programming", "318": "Combat Vehicle Firing Stability (Active Suspension)", "319": "On a Class of Iteration Formulas and Some Historical Notes The class of iteration formulas obtainable\nby rational approximations of \"Euler's formula\" \nis derived with the corresponding error estimates. \nSome historical notes on iterative procedures are \nfollowed by a derivation of Euler's formula with the\nassociated error estimate in a new notation which \nsimplifies the error estimate and suggests generalizations.\n The final section considers the Pade approximants \nto the \"Euler polynomial\" and shows how a number of known\nformulas may be derived from this unified approach. \n There is a short discussion of the \"best\" formula.\n", "320": "Logic-Structure Tables Logic tables are an excellent way of developing\nand expressing the logic required in procedures, \noperations, systems and circuits.  A set of rules for\nwriting and using logic tables is explained by \nmeans of some simple examples.  Then the logic structure\nof a vending machine is given in which two logic \ntables are used.  Logic tables are two-dimensional in\nnature, enabling us to fully express and consider \nboth the sequential and parallel aspects of logic.  They\ncan be compiled directly into a computer program \nand so eliminate the need for flow charting and hand coding.\n", "321": "ALGOL 60 Confidential The ALGOL 60 Report,* when first encountered,\nseems to describe a very complex language which \nwill be difficult to learn.  The \"metalinguistic formulae\"\nadmirably serve the purpose of precisely specifying \na language, but they are certainly not very readable\nfor a beginner.  However, experience has shown that \nonce the report is explained it is in fact easy to learn\nALGOL and to write algorithms in it.  The language \nis so general and powerful it can handle an enormous\nclass of problems.  It is not hard to learn those \nparts of ALGOL present in other compiler languages: how\nto write assignment and go to and for statements, \netc.  Indeed, a lot of the unnecessary restrictions\nimposed by other compiling languages have finally \nbeen lifted.  But ALGOL also allows many unobvious things\nto be written, as we will see later, and herein \nlies a problem: ALGOL seems to have become too general.\n So many restrictions have been lifted that a \nlot of technical details crop up which are hard to learn\nand to use correctly.  In this paper some of \nthe more obscure features of the language are considered\nand their usefulness is discussed.  Remarks \nare based on the authors' interpretations of the ALGOL 60 Report.\n", "322": "Operational Compatibility of Systems-CONVENTIONS The General Standards Committee of the SHARE\norganization has devoted considerable effort to \nthe problem of operating a computer efficiently in\nview of the growing number of programming systems \navailable.  Each of these programming systems has been\ncoded to utilize a fixed set of hardware components \nwithout recognizing the fact that others may be occupying\na storage medium required by the first.  These \nincompatibilities are currently resolved by manually setting\nup the computer for each system as required. \n The following set of conventions is being considered\nto minimize computer set-up time.  They are of \nsufficiently broad interest that we feel other computer\nusers should be aware of them. -George F. Ryckman, \nChairman\n", "323": "The State of Digital Computer Technology in Europe", "324": "Romberg Integration (Algorithm 60)", "325": "Numerical Solution of the Polynomial Equation (Algorithm 30)", "326": "MATHSORT (Algorithm 23)", "327": "Zeros of a Real Polynomial by Resultant Procedure (Algorithm 59)", "328": "Matrix Inversion (ALgorithm 58)", "329": "Automatic Abstracting and Indexing Survey and Recommendations In preparation for the widespread use of automatic\nscanners which will read documents and transmit \ntheir contents to other machines for analysis, this report\npresents a new concept in automatic analysis: \nthe relative-frequency approach to measuring  the significance\nof words, word groups, and sentences. \n The relative-frequency approach is discussed in detail,\nas is its application to problems of automatic \nindexing and automatic abstracting.  Included in the\nreport is a summary of automatic analysis studies \npublished as of the date of writing.  Conclusions are\nthat point toward more sophisticated mathematical \nand linguistic techniques for the solution of problems of automatic analysis.\n", "330": "A Method for Evaluating the Area of the Normal Function", "331": "Successive Approximations and Computer Storage", "332": "An Indirect Chaining Method for Addressing on Secondary Keys Methods for entering random access files on\nthe basis of one key are briefly surveyed.  The \nwidely used chaining method, based on a pseudo-random\nkey transformation, is reviewed in more detail. \n An efficient generalization of the chaining method\nwhich permits recovery on additional keys is then \npresented.\n", "333": "Design of an Improved* Transmission/Data Processing Code", "334": "Division and Square Root in the Quater-Imaginary Number System", "335": "Some Numerical Experiments Using Newton's Method Using a generalization of Newton's method, a nonlinear\nparabolic equation of the form U(t)-U(xx)=g(U) \nand a nonlinear elliptic equation U(xx)+U(yy)=exp(U)\nare solved numerically Comparison of these results \nwith results obtained using the Picard iteration procedure\nshow that in many cases the quisi linearization \nmethod offers substantial advantages in both time and accuracy.\n", "336": "A Practical Technique for the Determination of", "337": "Further Survey of Punched Card Codes", "338": "GROUT II (Algorithm 43)", "339": "Real Exponential Integral (Algorithm 20)", "340": "Legendre Polynomial (Algorithm 13)", "341": "Chebyschev Polynomial (Algorithm 10)", "342": "Solution of Polynomial Equation by Barstow-Hitchcock (Algorithm 3)", "343": "On Frequently Occurring Errors in ALGOL 60 Programs (Algorithm 25)", "344": "Ber or Bei Function (Algorithm 57)", "345": "Complete Elliptic Integral of the Second Kind (Algorithm 56)", "346": "Complete Elliptic Integral of the First Kind (Algorithm 55)", "347": "Gamma Function for Range 1 to 2 (Algorithm 54)", "348": "Nth Roots of a Complex Number (Algorithm 53)", "349": "A Set of Test Matrices", "350": "Adjust Inverse of a Matrix When an Element is Perturbed (Algorithm 51)", "351": "Inverse of a Finite Segment of the Hilbert Matrix (Algorithm 50)", "352": "Spherical Neumant Function (Algorithm 49)", "353": "Logarithm of A Complex Number (Algorithm 48)", "354": "Associated Legendre Functions of the First Kind", "355": "Exponential of a Complex Number (Algorithm 46)", "356": "INTEREST (Algorithm 45)", "357": "Bessel Functions Computed Recursively (Algorithm 44)", "358": "Crout with Pivoting II (Algorithm 43)", "359": "INVERT (Algorithm 42)", "360": "Evaluation of Determinant (Algorithm 41)", "361": "Programmed Error Correction on a Decimal Computer", "362": "Table Look-At Techniques", "363": "On Approximating Transcendental Numbers by Continued Fractions", "364": "On the Compilation of Subscripted Variables ", "365": "Bessel Functions of Integral Order and Complex Argument", "366": "Eigenvalues of a Symmetric 3 x 3 Matrix", "367": "Topological Ordering of a List of A network of directed line segments free of circular\nelements is assumed.  The lines are identified \nby their terminal nodes and the nodes are assumed to\nbe numbered by a non-topological system.  Given \na list of these lines in numeric order, a simple technique\ncan be used to create at high speed a list \nin topological order.\n", "368": "Real Zeros of an Arbitrary Function (Algorithm 25)", "369": "Crout with Pivoting (Algorithm 16)", "370": "Bisection Routine (Algorithm 4)", "371": "Remarks on Algorithms 2 and 3, Algorithm 15 and Algorithms 25 and 26", "372": "Critical Path Scheduling (Algorithm 40)", "373": "Correlation Coefficients with Matrix Multiplication (Algorithm 39)", "374": "Telescope2 (Algorithm 38)", "375": "Telescope1 (Algorithm 37)", "376": "Tchebycheff (Algorithm 36)", "377": "SIEVE (Algorithm 35)", "378": "A Generalized Technique for Symbol", "379": "Bitwise Operations", "380": "Comparison of Iterative Methods for the Calculation of nth Roots Three iterative methods for calculation of\nnth roots (including one proposed by the author) \nare compared in two ways: (1) Theoretical convergence\nestimates are given.  (2) A new macrocompiler which \nestimates machine running time is used to compare the\nrunning time of the three methods for a variety \nof input data.\n", "381": "An Alternate Form of the \"UNCOL Diagram\"", "382": "Statistical Programs at the University of North Carolina", "383": "On Finding Minimum Routes in a Network With Turn Penalties", "384": "Gamma Function (Algorithm 34)", "385": "FACTORIAL (Algorithm 33)", "386": "MULTINT (Algorithm 32)", "387": "Gamma Function (Algorithm 31)", "388": "Solution of Polynomial Equations by", "389": "Real Exponential Integral (Algorithm 20)", "390": "Complex Exponential Integral (Algorithm 13)", "391": "The BKS System for the Philco-2000 ", "392": "Comment on A Paper on Parallel Processing", "393": "Two Subroutines for Symbol Manipulation with an Algebraic Compiler", "394": "Multiple Programming Data Processing", "395": "Multiple-Precision Division ", "396": "   Automation of Program  Debugging    Automatic Debugging can substantially reduce lead-time between the coding\nand the effective use of a complex program. It also enforces analysis of\ndebugging criteria, resulting in verifiably accurate programs. The programmer\nspecifies the program to be debugged, memory areas, set of input data, maximum\nrepetition of loops, and checkpoint information for each set of data. The\nexecutive debugging program the runs the program to be debugged, performing\nchecking functions and creating a trace record of its own later analysis and\nlocation of errors. Applications are quite flexible, and the system can be used\nalone or in conjunction with other debugging techniques.\n", "397": "A Card Format for Reference Files in Information Processing This paper proposes a card format suitable for\na variety of reference files in information \nprocessing.  An 80-column IBM card is divided into two\nfields-reference material field (columns 1-67) \nand identification field (columns 68-80).  The format\nfor the reference material is flexible, while the \nformat for the identification is rigid.  The reference\nmaterial includes basically an index, title, source, \nclass, summary and cross reference for each entry. \nThe identification includes basically codes for a \nmatrix of descriptors, an entry number, and the kind,\nmajor interest, and source of the reference.  The \nidentification also provides a choice to identify material\nfor personal as well as general files.  Since \nthis card format is sufficient to identify the material\nnormally associated with reference files for \nbooks, articles, programming terms, hardware terms, equipment,\nmachine systems, abbreviations, etc., it \nis suitable as a standard for card reference files in information processing.\n", "398": "The SLANG System", "399": "Compiling Techniques for Boolean Expressions", "400": "Comments on the Implementation of Recursive", "401": "Allocation of Storage for Arrays in ALGOL 60", "402": "Dynamic Declarations", "403": "Thunks -- A Way of Compiling Procedure Statements", "404": "A Syntax Directed Compiler for ALGOL 60", "405": "An Algorithm for Coding Efficient Arithmetic Operations Most existing formula translation schemes\nyield inefficient coding.  A method is described \nwhich reduces the number of store and fetch operations,\nevaluates constant subexpressions during compilation, \nand recognizes many equivalent subexpressions.\n", "406": "The Use of Threaded Lists in Constructing a Combined", "407": "MADCAP: A Scientific Compiler for a Displayed Formula Textbook Language", "408": "The Internal Organization of the MAD Translator", "409": "CL-1, An Environment for a Compiler A flexible, large-scale programming system to\nfacilitate the solution of information processing \nproblems and to provide intercommunication between programs\nand/or programmers has been developed and \nrealized on the IBM 709/7090 computer.  The system is\nbased on a master file concept and has provisions \nfor accepting, storing, and retrieving both descriptions\nand instances of large and complex data sets, \nas well as algorithms defined on these data sets.  Both\ndata and algorithms may be expressed in a family \nof command and descriptive languages.  The concept\nof distinct data descriptions and the content and \nuse of such descriptions are discussed in some detail.\n", "410": "The CLIP Translator", "411": "Use of Magnetic Tape for Data Storage in the ORACLE-ALGOL Translator", "412": "Recursive Processes and ALGOL Translation", "413": "A Basic Compiler for Arithmetic Expressions", "414": "IBM 1440 Data Processing System Features Five New Units The IBM 1440 data processing system, announced\nrecently by the International Business Machines \nCorporation, not only features the 1311 disk storage\ndrive with interchangeable disk packs but four other \nnewly developed units.\n", "415": "The Use of Digital Computers in Western Germany", "416": "Multiple Shooting Method for Two-Point Boundary Value Problems", "417": "Legal Implications of Computer Use This paper points out a variety of ways computer\nsystems used in business and industry can \nbe involved in legal entanglements and suggests that\ncomputer specialists have a responsibility to call \nfor assistance in forestalling or minimizing those entanglements\nduring the planning stage.  Techniques \nare suggested for making legal clearance effective with\nthe least burden on the new technology and for \nachieving a favorable legal climate for it generally.\n Computer specialists also are alerted to potential \nopportunities to interpret to lawyers the technical aspects\nof computer systems involved in legal situations.\n", "418": "RANDOM (Algorithm 133)", "419": "Magic Square (Algorithm 118)", "420": "PERM (Algorithm 115)", "421": "Position of Point Relative to Polygon (Algorithm 112)", "422": "COMBINATION (Algorithm 94)", "423": "Matrix Inversion (Algorithm 58)", "424": "Gamma Function (Algorithm 31)", "425": "Complete Elliptic Integral (Algorithm 149)", "426": "Term of Magic Square (Algorithm 148)", "427": "PSIF (Algorithm 147)", "428": "Multiple Integration (Algorithm 146)", "429": "Adaptive Nimerical Integration by Simpson's Rule (Algorithm 145)", "430": "TREESORT2 (Algorithm 144)", "431": "TREESORT1 (Algorithm 143)", "432": "Triangular Regression (Algorithm 142)", "433": "Fixed-World-Length Arrays in Variable-Word-Length Computers", "434": "Character Manipulation in 1620 Fortran II", "435": "A Decision Matrix as the Basis for a Simple Data Input Routine Currently a great deal of time and effort is\nbeing spent on the development of bigger and better \ncompiler languages, multiprogram executive systems,\netc.  Since the implementation of  of new methods \nand procedures is not instantaneous, but rather occurs\nby an evolutionary process, we should be concerned \nalso with the problem of maintaining, improving and\nincorporating new ideas into existing systems.  It \nis with this somewhat neglected area that the author is\ninterested.  A method employing a decision matrix \nis presented for the handling of a standard systems\nprogramming problem,that of providing a data input \nroutine.\n", "436": "Evaluation of Polynomials by Computer", "437": "Compiling Matrix Operations", "438": "Mechanical Pragmatics: A Time-Motion Study", "439": "On-Line Digital Computer for Measurement of a Neurological Control System", "440": "Record Linkage Special difficulties are encountered in devising\nreliable systems for searching and updating \nany large files of documents that must be identified\nprimarily on the basis of names and other personal \nparticulars.  The underlying problem is that of making nearly\nmaximum use of items of identifying information \nthat are individually unreliable but that may collectively\nbe of considerable discriminating power.  \nRules that can be applied generally to name retrieval\nsystems have been developed in a methodological \nstudy of the linkage of vital and health records into\nfamily groupings for demographic research purposes. \n These rules are described, and the ways in which information\nutilization for matching may be optimized \nare discussed.\n", "441": "Topological Sorting of Large Networks Topological Sorting is a procedure required\nfor many problems involving analysis of networks. \n An example of one such problem is PERT.  The present\npaper presents a very general method for obtaining \ntopological order.  It permits treatment of larger networks\nthan can be handled on present procedures \nand achieves this with greater efficiency.  Although\nthe procedure can be adapted to any machine, it \nis discussed in terms of the 7090.  A PERT network of\n30,000 activities can be ordered in less than one \nhour of machine time.  The method was developed as\na byproduct of procedures needed by Westinghouse, \nBaltimore.  It has not been programmed and at present\nthere are no plans to implement it.  In regard \nto the techniques described, Westinghouse's present\nand anticipated needs are completely served by the \nLockheed program, which is in current use.\n", "442": "Crout with Equilibration and Iteration (Algorithm 135)", "443": "Complex Number to a Real Power (Algorithm 106)", "444": "Evaluation of Jacobi Symbol (Algorithm 99)", "445": "COMBINATION (Algorithm 94)", "446": "Simpson's Integration (Algorithm 84)", "447": "Certification of the Calculation of Easter", "448": "Path Matrix (Algorithm 141)", "449": "Matrix Inversion(Algorithm 140)", "450": "Solution of the Diophantine Equation (Algorithm 139)", "451": "Nesting of for Statement II (Algorithm 138)", "452": "Nesting of for Statement I (Algorithm 137)", "453": "Enlargement of a Group (Algorithm 136)", "454": "Crout with Equilibration and Iteration (Algorithm 135)", "455": "Exponentiation of Series (Algorithm 134)", "456": "RANDOM (Algorithm 133)", "457": "Quantum Mechanical Integrals Over all Slater-Type Integrals", "458": "Coefficient Determination (Algorithm 131)", "459": "PERMUTE (Algorithm 130)", "460": "MINIFUN (Algorithm 129)", "461": "Coding of Medical Case History Data for Computer Analysis", "462": "Computer Pattern Recognition Techniques: Electrocardiographic Diagnosis The use of programmed digital computers as general\npattern classification and recognition devices \nis one phase of the current lively interest in artificial\nintelligence.  It is important to choose a \nclass of signals which is, at present, undergoing a\ngood deal of visual inspection by trained people \nfor the purpose of pattern recognition.  In this way\ncomparisons between machine and human performance \nmay be obtained.  A practical result also serves as additional\nmotivation.  Clinical electrocardiograms \nmake up such a class of signals.  The approach to the\nproblem presented here centers upon the use of \nmultiple adaptive matched filters that classify normalized\nsignals.  The present report fives some of \nthe background for the application of this method.\n", "463": "On Ambiguity in Phrase Structure Languages", "464": "Syntactic Analysis by Digital Computer This paper provides an account of the Shadow\nlanguage that is used to describe syntax and of \na corresponding subroutine that enables a computer\nto perform syntactic analysis.  The input to this \nsubroutine consists of a string to be analyzed and a\ndescription of the syntax that is to be used.  The \nsyntax is expressed in the Shadow language.  The output\nconsists of a trace table that expresses the \nresults of the syntactic analysis in a tabular form.  Several\nversions of the subroutine and some associated \nprograms have been in use now for over three years.  The\npresent account of the language and the subroutine \ncontains a summary of material that has been described\npreviously in unpublished reports and also some \nadditional discussion of the work in relation to the more\ngeneral questions of problem-oriented languages \nand string transformations.\n", "465": "PERM (Algorithm 115)", "466": "General Order Arithmetic (Algorithm 93)", "467": "Permutation Generator (Algorithm 87)", "468": "Incomplete Elliptic Integrals (Algorithm 73)", "469": "Critical Path Scheduling (Algorithm 40)", "470": "Summation of Fourier Series (Algorithm 128)", "471": "ORTHO (Algorithm 127)", "472": "Gauss' Method (Algorithm 126)", "473": "WEIGHTCOEFF (Algorithm 125)", "474": "Input Data Organization in Fortran", "475": "A Test Matrix for Inversion Procedures", "476": "Further Remarks on Sampling a Tape File-II", "477": "Further Remarks on Sampling a Tape File-I", "478": "Implementing a Stack", "479": "A Dispersion Pass Algorithm for the Polyphase Merge This paper presents a new manner of dispersing\nstrings for a Polyphase merge.  If the number \nof strings dispersed is between two levels acceptable\nby Polyphase merge, a more economical technique \nof reaching the next level for Polyphase merge is shown and proved.\n", "480": "Quick Calculation of Jacobian Elliptic Functions (Corrigendum)", "481": "A One-Day Look At Computing", "482": "TALL-A List Processor for the Philco 200 Computer", "483": "On the Nonexistence of a Phrase Structure Grammar for ALGOL 60 ALGOL 60 is defined partly by formal mechanisms\nof phrase structure grammar, partly by informally \nstated restrictions.  It is shown that no formal mechanisms\nof the type used are sufficient to define \nALGOL 60.\n", "484": "Hankel Function (Algorithm 124)", "485": "Real Error Function, ERF(x) (Algorithm 123)", "486": "Tridiagonal Matrix (Algorithm 122)", "487": "NORMDEV (Algorithm 121)", "488": "A Heuristic for Page Turning In a Multiprogrammed Computer", "489": "Current Status of IPL-V for the Philco 2000 Computer (June 1962)", "490": "Programmed Methods for Printer Graphical Output", "491": "Use of Multiprogramming in the Design of a Low Cost Digital Computer", "492": "Analysis of a File Addressing Method This paper presents a new file addressing method\nbased on the calculation of an address from \nthe identification of a record.  For large recirculating\ntype files, it seems to be more advantageous \nthan customary ones.  The probability distribution of\nthe displacement of records from their calculated \naddress, which is one less than the number of probes\nrequired to address a record, is computed on the \nbasis of a Markov chain model.  For the reader not interested\nin the mathematics, the introduction and \nthe summary should be sufficient.\n", "493": "The Property Classification Method of File Design and Processing", "494": "A Finite Sequentially Compact Process for the Adjoints", "495": "A Procedure for Inverting Large Symmetric Matrices In the least squares method for simultaneous\nadjustment of several parameters, the coefficients \nof the normal equations are the elements of a symmetric\npositive-definite matrix.  In order to solve \nthe normal equations and evaluate the precision measures\nof the resulting parameters, inversion of this \nmatrix of coefficients is required.  Many available procedures\nfor matrix inversion do not take advantage \nof the symmetry.  Thus, when programmed for a high-speed\ncomputer, all n^2 elements must be stored and \nmanipulated, whereas only (n + 1)/2 of them are independent.\n In order to allow a computer of given memory \ncapacity to handle a larger matrix, the following procedure\nfor inverting a symmetric matrix has been \ndevised.\n", "496": "A Set of Matrices for Testing Computer Programs", "497": "Further Remarks on Line Segment Curve-Fitting Using Dynamic Programming In a recent paper, Bellman showed how dynamic\nprogramming could be used to determine the solution \nto a problem previously considered by Stone.  The problem\ncomprises the determination, given N, of the \nN points of subdivision of a given interval (a,B) and\nthe corresponding line segments, that give the \nbest least squares fit to a function g(x) in the interval.\n Bellman confined himself primarily to the \nanalytical derivation, suggesting briefly, however,\nhow the solution of the equation derived for each \nparticular point of subdivision u(i) could be reduced to\na discrete search.  In this paper, the computational \nprocedure is considered more fully, and the similarities\nto some of Stone's equations are indicated. \n It is further shown that an equation for u(i) involving\nno minimization may be found.  In addition, \nit is shown how Bellman's method may be applied to the\ncurve-fitting problem when the additional constraints \nare added that the ends of the line segments must be on the curve.\n", "498": "Magic Square (Algorithm 117 & 118)", "499": "Permutation Generator (Algorithm 87)", "500": "PERMUTE (Algorithm 86)", "501": "JACOBI (Algorithm 85)", "502": "Simpson's Integration (Algorithm 84)", "503": "Rational Roots of Polynomials with Integer Coefficients (Algorithm 78)", "504": "FACTORS (Algorithm 75)", "505": "Composition Generator (Algorithm 72)", "506": "PERMUTATION (Algorithm 71)", "507": "Partition, Quicksort, Find (Algorithm 63, 64, 65)", "508": "Matrix Inversion (Algorithm 58)", "509": "Matrix Inversion (Algorithm 58)", "510": "Ber or Bei Function (Algorithm 57)", "511": "A Set of Test Matrices (Algorithm 52)", "512": "Telescope 1 (Algorithm 37)", "513": "SIEVE (Algorithm 35)", "514": "Binomial Coefficients (Algorithm 19)", "515": "Rational Interpolation by Continued Fractions (Algorithm 18)", "516": "Matrix Inversion II (Algorithm 120)", "517": "Evaluation of Pert Network (Algorithm 119)", "518": "Magic Square (Odd Order) (Algorithm 118)", "519": "Magic Square (Even Order) (Algorithm 117)", "520": "Complex Division (Algorithm 116)", "521": "PERM (Algorithm 115)", "522": "Generation of Partitions with Constraints (Algorithm 114)", "523": "TREESORT (Algorithm 113)", "524": "Position of Point Relative to Polygon (Algorithm 112)", "525": "A Computer Technique for Handling Analysis of Variance", "526": "Character Manipulation in Fortran", "527": "The Description List of Concepts A concept is defined as a class of objects\nwhose members can be distinguished by processing \nits properties.  Property is defined to mean a partition\nof the set of all objects into disjoint classes. \n The formal definition of a concept is recursive in nature.\n A concept is described by a list structure. \n A one-to-one correspondence is established between the\nrecursive definition of a concept and its description \nlist structure.  Like the definition, the description\nlist structure of a concept is also built up from \nelementary list structures by a recursive process. \nThe list structures obtained this way are compared \nwith the description list structure discussed\nby the author in a previous publication.\n", "528": "FORTRAN for Business Data Processing", "529": "Regression and Coded Patterns in Data Editing", "530": "A Computer Method for Radiation Treatment Planning", "531": "Person-Matching by Electronic Methods Record linkage in the updating of files is\naccomplished in many establishments through the \nuse of a preassigned number, such as payroll number,\ncustomer number, or social security number.  In \nvital and health records, however, a unique number\nis generally not preassigned to an individual for \npurposes of reporting services received to the health\ndepartment.  In order to determine whether different \nphysician reports refer to the same individual, name\nand other identification must be compared.  This \nis a laborious operation which is subject to various\nerrors because of name misspellings, changes of \nname upon marriage, and other problems.  We are interested\nin the maintenance of a psychiatric case register \nin Maryland, where many of the reports from over a hundred\npsychiatric agencies refer to the same patient. \n These records must be linked in order to provide unduplicated\ncounts of individuals under care and longitudinal \nrecords of psychiatric history.  An earlier paper [1] describes\nour general procedures for register maintenance \nby use of a digital computer (Honeywell 800).  Here\nwe present in more detail our initial procedures \nfor the person-matching process in order to elicit comments\nand suggestions from persons who have had \nexperience in matching.\n", "532": "On the Computation of Rational Approximations to Continuous Functions", "533": "Digital Synthesis of Correlated Stationary Noise In this note we propose a method of generating\nstationary noise with a prescribed auto-covariance \nfunction by digital methods.  The need for such a technique\noften arises in testing the performance of \ndata processing and engineering systems, where inputs\ncorrupted with correlated noise (of a known form) \nare required.  The technique is quite simple and produces\nstrict-sense stationary noise which agrees \napproximately with R(t), the prescribed auto-covariance\nfunction (acf), over an interval [-T(0), T(0)]. \n The method consists of approximating the spectral density\nby a periodic process with spectral lines, \nand then synthesizing the periodic noise with random\nphases and appropriate amplitudes.  In order to \nsimplify discussion of the statistical properties of the\nnoise generated, the technique is first presented \nin terms of exact harmonic analysis.  In practice, discrete\nharmonic analysis as presented in the third \nsection is used.\n", "534": "Quick Calculation of Jacobian Elliptic Functions", "535": "Triangular Walk Pattern for the Down-hill", "536": "Nonlinear Regression and the Solution of Simultaneous Equations If one has a set of observables (Z1,...,Zm) which\nare bound in a relation with certain parameters \n(A1,...,An) by an equation S(Z1,...;A1,...)=0, one frequently\nhas the problem of determining a set of \nvalues of the Ai which minimizes the sum of squares of\ndifferences between observed and calculated values \nof a distinguished observable, say Zm.  If the solution\nof the above equation for Zm,  Zm=N(Z1,...;A1,...) \ngives rise to a function N which is nonlinear in the Ai,\nthen one may rely on a version of Gaussian regression \n[1,2] for an iteration scheme that converges to a minimizing\nset of values.  It is shown here that this \nsame minimization technique may be used for the solution\nof simultaneous (not necessarily linear) equations.\n", "537": "A Machine Program for Theorem-Proving The program of a proof procedure is discussed in\nconnection with trial runs and possible improvements.\n", "538": "Quantum Mechanical Integrals of Slater-Type Orbitals (Algorithm 110)", "539": "Definite Exponential Integrals B (Algorithm 109)", "540": "Definite Exponential Integrals A (Algorithm 108)", "541": "Simpson's Integration (Algorithm 84)", "542": "FACTORS (Algorithm 75)", "543": "Interpolation by Aitken (Algorithm 70)", "544": " Ber or Bei Function (Algorithm 57)", "545": "Adjust Inverse of a Matrix when an Element is Perturbed (Algorithm 51)", "546": "Logarithm of a Complex Number (Algorithm 48)", "547": "Gamma Function (Algorithm 34)", "548": "Molecular-Orbital Calculation of Molecular Interactions", "549": "Quantum Mechanical Integrals of Slater-Type Orbitals", "550": "Definite Exponential Integrals B (Algorithm 109)", "551": "Definite Exponential Integrals A (Algorithm 108)", "552": "Gauss's Method (Algorithm 107)", "553": "Complex Number to a Real Power (Algorithm 106)", "554": "Newton Maehly, (Algorithm 105)", "555": "Reduction to Jacobi (Algorithm 104)", "556": "On Translation of Boolean Expressions", "557": "Simulation of Computer Timing Device", "558": "A Modified Inversion Procedure for Product This paper describes a new algorithm for the\nselection of the pivot row in matrix inversion \nwhen using the product form of the inverse.  This algorithm\nhas been developed for linear programming \ncodes; however, it would be valuable for the inversion\nof any non-dense matrix.  The procedures described \nin this paper have been thoroughly tested and have been\nin operation on the Esso Research and Engineering \nIBM 7090 computer for nine months.  Substantial computer\ncost savings have been realized because of this \nprocedure.\n", "559": "Solution of Eigenvalue Problems With Approximately Known Eigenvectors", "560": "Communication Between Independently Translated Blocks", "561": "Analytic Differentiation By Computer", "562": "AVINT (Algorithm 77)", "563": "Sorting Procedures (Algorithm 76)", "564": "CRAM (Algorithm 67)", "565": "INVRS (Algorithm 66)", "566": "Matrix Inversion (Algorithm 58)", "567": "Logarithm of a Complex Number (Algorithm 48)", "568": "Exponential of a Complex Number (Algorithm 46)", "569": "Binomial Coefficients (Algorithm 19)", "570": "Simpson's Rule Integrator (Algorithm 103)", "571": "Permutation in Lexicographical Order (Algorithm 102)", "572": "Add Item to Chain-Linked List (Algorithm 100)", "573": "Remove Item From Chain-Linked List (Algorithm 101)", "574": "Evaluation of Jacobi Symbol (Algorithm 99)", "575": "Evaluation of Definite Complex Line Integrals (Algorithm 98)", "576": "Shortest Path (Algorithm 97)", "577": "ANCESTOR (Algorithm 96)", "578": "Generation of Partitions in Part-Count Form (Algorithm 95)", "579": "COMBINATION (Algorithm 94)", "580": "General Order Arithmetic (Algorithm 93)", "581": "A Note on Sampling a Tape-File", "582": "One Lost Bit", "583": "A Redundancy Check for ALGOL Programs", "584": "Report on the Algorithmic Language FORTRAN II", "585": "Initial Experience With an Operating Multiprogramming System The Lewis Research Center has been using various\nforms and degrees of program simultaneity \nin the operation of its modified Sperry-Rand Univac Scientific\nModel 1103 computer during the last five \nyears.  This simultaneity has evolved from an initial\nachievement of self-searching input and output \nto the automatic time sharing of independently coded\nproblems.  Several important machine and program \nsystem modifications were necessary to accomplish this\nevolution.  Several additional modifications, \nalthough not required, were added to facilitate ease\nof coding and operation.  All modifications had \nto proceed at a relatively temperate pace to insure that\nthe basic data-reduction work load of the computing \ncenter was completed on schedule.  Some educationally\nvaluable mistakes were made, and their suggested \ncures often pointed the way to useful future improvements\nor emphasized some of the basic principles \nof a multiprogramming system.  The material that follows\nis a description of the evolution of the programming \nand hardware system which has developed into the present\nmultiprogramming system at Lewis research Center.\n", "586": "Simultaneous System of Equations and", "587": "Romberg Integration (Algorithm 60)", "588": "Chebyshev Curve-Fit (Algorithm 91)", "589": "Evaluation of the Fresnel Cosine Integral (Algorithm 90)", "590": "Evaluation of the Fresnel Sine Integral (Algorithm 89)", "591": "Evaluation of Asymptotic Expression for the", "592": "COBOL Batching Problems", "593": "An Introduction to a Machine-Independent Data Division", "594": "An Advanced Input-Output System for a COBOL Compiler", "595": "Guides to Teaching COBOL The teaching of COBOL can be divided into\nthree main subject areas.  They are the syntax of \nCOBOL, the use of such syntax in solving any given problem,\nand programming concepts.  It is generally \naccepted that some knowledge of the hardware and computer\nlogic must be possessed by the programmer. \n The teaching problem arises in determining how thoroughly\na student must know the hardware and logic \nfor that computer for which he will write COBOL programs.\n Unfortunately, historical data concerning \nstudents' programming proficiency is almost non-existent\nand, at best, difficult to measure.  How then \nmight we approach solving this problem?\n", "596": "Floating-Point Arithmetic in COBOL In this paper the basic operations of floating-point\narithmetic are examined and COBOL procedures \nfor carrying these out are given, along with specification\nof working storage.  The paper concludes with \nan example in which these procedures are used.\n", "597": "Modular Data Processing Systems Written in COBOL", "598": "The COBOL Librarian - A Key to Object Program Efficiency Many answers to the question \"How may a COBOL\nCompiler be forced into the generation of an \nefficient object program?\"  The purpose of this article\nis to present one possible answer: the creation \nand full utilization of a well-constructed COBOL Library.\n", "599": "A Report Writer For COBOL", "600": "Syntactical Charts of COBOL 61", "601": "Interim Report on Bureau of Ships COBOL Evaluation Program", "602": "COBOL and Compatibility", "603": "Basic Elements of COBOL 61", "604": "Why COBOL?", "605": "Computer Simulation Of City Traffic In simulating traffic flow on city streets,\nthe National Bureau of Standards has used data \nprocessing techniques to tabulate and make motion pictures\nof vehicle movements in the model.  Each vehicle \nis assigned a digital identification giving points of\nentry and exit, type of vehicle, desired speed, \nand actual speed, in proportions simulating field data.\n Changes in the model can be made to observe \ntheir consequences and to determine the ability of a\nreal street to carry loads expected in the future.\n", "606": "A Method for Eliminating Ambiguity Due", "607": "The Calculation of Easter...", "608": "Permutation (Algorithm 71)", "609": "Permutation (Algorithm 71)", "610": "SIEVE (Algorithm 35)", "611": "Permutation Generator (Algorithm 87)", "612": "Permute (Algorithm 86)", "613": "JACOBI (Algorithm 85)", "614": "Simpson's Integration (Algorithm 84)", "615": "Addressing Multidimensional Arrays A useful method of representing a function of\nn variables is to consider the function to assume \nits values at selected points in n-dimensional space.\n Although this picture is of value to the analyst, \nthe elements of an n-dimensional array must exist in\nconventional storage as a linear array or vector. \n The means of performing the transformation of a set\nof indices locating on array element in n-space \nto the location (address) of the element in its storage\nvector is the subject of this paper.  It is noted \nthat the index address transformation is computationally\nidentical to the conversion of a number from \na fixed to a mixed radix number system.  Several ways\nof implementing the transformation are described.\n", "616": "An Information Algebra - Phase I Report-Language This report represents the results of the\nfirst phase of the work of the Language Structure \nGroup.  The goal of this work is to arrive at a proper\nstructure for a machine-independent problem-defining \nlanguage, at the systems level of data processing.  The\nreport is based, for the most part, on a mathematical \nmodel called \"An Information Algebra\" developed primarily\nby R. Bosak.  It is hoped that this report \nwill be read (a) with avid interest by programming language\ndesigners and implementors, and all those \ninterested in developing a theoretical approach to data\nprocessing; (b) with interest and understanding \nby professional programmers and systems analysts; and (c)\nwith appreciation by the businessman-analyst-manager. \n The authors have not attempted an exhaustive discourse\nin this report.  Rather, they have tried to present \na philosophy to the professional people who are vitally\nconcerned with providing a working language for \nthe systems analyst's use.  They trust that the ideas\nin this report will stimulate others to think along \nsimilar lines.  Questions and comments will be welcomed,\nand can be addressed to any of the members of \nthe Language Structure Group:  Robert Bosak, System\nDevelopment Corporation;  Richard F. Clippinger, \nHoneywell EDP Division;  Carey Dobbs, Remington Rand\nUnivac Division;  Roy Goldfinger (Chairman), IBM \nCorporation;  Renee B. Jasper, Navy Management Office;\n William Keating, National Cash Register;  George \nKendrick, General Electric Company;  Jean E. Sammet, IBM Corporation.\n", "617": "POSEIDON Any computer that forms part of a control system-whether\ncompletely automatic or partly human-must \nwork at the same speed as the control system.  It must\nperform its calculations or data processing fast \nenough for the results to be available at the required\ninstants in the action of the control system. \n This known as working in \"real time.\"\n", "618": "Computers- The Key to Total Systems Control: An Industrial Viewpoint Man-Man-machine processes are characterized in five\nmain types, and the markets for each type are \nshown for 1950 and 1960 and estimated for 1970.\n", "619": "Retrieval of Misspelled Names in an Airlines Passenger Record System This paper discusses the limited problem of\nrecognition and retrieval of a given misspelled \nname from among a roster of several hundred names, such\nas the reservation inventory for a given flight \nof a large jet airliner.  A program has been developed\nand operated on the Telefile (a stored-program \ncore and drum memory solid-state computer) which will\nretrieve passengers' records successfully, despite \nsignificant misspellings either at original entry time\nor at retrieval time.  The procedure involves \nan automatic scoring technique which matches the names\nin a condensed form. Only those few names most \nclosely resembling the requested name, with their phone\nnumbers annexed, are presented for the agents \nfinal manual selecton.  The program has successfully\nisolated and retrieved names which were subjected \nto a number of unusual (as well as usual) misspellings.\n", "620": "RATFACT (Algorithm 78)", "621": "Romberg Integration (Algorithm 60)", "622": "Optimal Classification of Objects (Algorithm 83)", "623": "Economising a Sequence 2 (Algorithm 82)", "624": "Economising a Sequence 1 (Algorithm 81)", "625": "Reciprocal Gamma Function of Real Argument (Algorithm 80)", "626": "A Method of Representation, Storage and Retrieval", "627": "Knotted List Structures", "628": "On a Floating-Point Number Representation", "629": "On a Wired-In Binary-to-Decimal Conversion Scheme", "630": "An Evaluation of Autocode Readability Of the many requirements of an autocode, the\npair of requirements \"easy to read\" and \"easy \nto write\" are not often compatible.  This paper argues\nthat readability can be added automatically in \nthe translation process so that the programmer can\nenjoy the utmost economy of expression, while for \nmanagement a full and valid COBOL version is printed to give\nall the advantages of readability and compatibility.\n", "631": "Automatic-Programming-Language Translation Through Syntactical Analysis*", "632": "Vectorcardiographic Diagnosis With The Aid of ALGOL", "633": "Simulation and Analysis of Biochemical Systems", "634": "Manipulation of Trees in Information Retrieval*", "635": "A Note on Multiplying Boolean Matrices", "636": "Tape Splitting in an Iterative Program", "637": "A NELIAC-Generated 7090-1401 Compiler NELIAC systems for several different machines\nhave been generated using the original NELIAC \nsystem developed at the Naval Electronics Laboratory,\nSan Diego, in 1958.  A basic \"bootstrap\" process \nwas used to generate all but the first, i.e. the systems\nwere described in the NELIAC language and generated \nby an existing NELIAC compiler.  This experience has\nshown there is no inherent difficulty in \"building \ncompilers with compilers\"; indeed, it pointed out many advantages\nin using a POL for constructing programming \nsystems.  This report presents the results of a project\ncompleted in May, 1961 in which the NELIAC system \nwas used to generate a compiler for the IBM 1401.  The\n1401 compiler, which runs on the 7090 and produces \n1401 programs, was described in the NELIAC language and\ngenerated with 7090 NELIAC system.  The reduction \nin programming time and the improvement in documentation\nof the system were very significant.\n", "638": "SURGE: A Recoding of the COBOL Merchandise Control Algorithm", "639": "Difference Expression Coefficients (Algorithm 79)", "640": "Rational Roots of Polynomials with Integer Coefficients (Algorithm 78)", "641": "Interpolation, Differentiation, and Integration (Algorithm 77)", "642": "An Introduction to ALGOL ", "643": "Simulation and Analysis of Biochemcial Systems", "644": "A String Language for Symbol Manipulation Based on ALGOL 60 An artificial computer programming language\nis proposed for describing the manipulation of \nstrings of characters and symbols.  The concept of strings,\nintroduced in the ALGOL 60 report, is extended \nby adding: (1) the declaration of strings, substrings,\nand string arrays with explicit lengths; (2) the \nability to concatenate and shift strings; and (3) the\nranking of symbols for comparing stings in Boolean \nrelations.  A primer or informal description of the\nlanguage is followed by examples, a description of \nexperiments with the language on an IBM 704 computer,\nand a formal description which, taken with the \nALGOL 60 Report, defines the proposed string language.\n", "645": "INVRS (Algorithm 66)", "646": "Inverse of a Finite Segment of the Hilbert Matrix (Algorithm 50)", "647": "Numerical Solution of the Polynomial Equation (Algorithm 30)", "648": "Sorting Procedures (Algorithm 76)", "649": "FACTORS (Algorithm 75)", "650": "Curve Fitting with Constraints (Algorithm 74)", "651": "A Survey of Languages and Systems for Information Retrieval", "652": "Use of Semantic Structure in Information Systems", "653": "Translation of Retrieval Requests Couched", "654": "Language Problems Posed by Heavily Structured Data", "655": "COMIT as an IR Language Many of the features that make COMIT a good\nall around symbol manipulation language also render \nit well suited to various types of information retrieval\nprograms.  Presented here is a general discussion \nof this unique and different programming language\nand an examination of some of its applications.\n", "656": "An Information System With The Ability To Extract Intelligence From Data", "657": "Information Structures for Processing and Retrieving", "658": "Discussion-The Pros and Cons of a Special IR Language", "659": "Reversion of Series (Algorithm 193)", "660": "More Test Matrices for Determinants and Inverses (Pracnique)", "661": "Indexing and the Lambda-Notation Some methods of indexing sequentially stored\nelements of sparse multi-dimensional arrays are \ndescribed in the scheme A notation.\n", "662": "Shuttle Sort (Algorithm 175)", "663": "Determinant (Algorithm 159)", "664": "Assignment (Algorithm 27)", "665": "Gauss-Seidel (Algorithm 220)", "666": "Topological Ordering for Pert Networks (Algorithm 219)", "667": "Kutta Merson (Algorithm 218)", "668": "Minimum Excess Cost Curve (Algorithm 217)", "669": "A Specification of JOVIAL", "670": "Some Legal Implications of the Use of Computers in the Banking Business The introduction of computers in to the banking\nbusiness has a wide variety of legal implications \nthat merit careful attention at this very early stage.\n The industry is highly regulated by government \nand, hence, is subject to many statutes and regulations.\n It also is affected by important common law \nrules established by courts.  The legal ramifications\ninvolve not only the mechanization itself, but \nalso the very significant, economically attractive phenomenon\nof off premises processing.  It is essential \nto identify and provide for many legal aspects right\nnow, before systems and practices crystallize, in \norder to avoid the later impact of unanticipated physical\ncomplications and expense.  The legal aspects \nof computerization in the banking business are especially\ndiverse.  In some states, there might be the \nbasic question whether banks are authorized by law to\ninvest in the new facilities, either directly or \nthrough cooperatives.  More challenging are questions\nrelating to off-premises processors, particularly \nwith respect to the obligation not to disclose information\nconcerning a bank's customers, the adequacy \nof fidelity bond coverage, the extent of liability for\nimproper refusal to pay a check, and susceptibility \nto regulation by government agencies.  Also pertinent\nis the propriety of data processing by banks for \nnonbank entities and particularly of the rendering of\nthat service without charge for bank depositors.\n", "671": "TELEFILE-A Case Study of an On-Line Savings Bank Application The development of an on-line computer system\nfor a savings bank institution is traced from \nthe early conceptual needs of the bank to the consummation\nof design by The Teleregister Corporation. \n Both bank and equipment criteria are specified which\nled to the development of the Telefile System of \nThe Teleregister Corporation.  Operation of the on-line\nand off-line programs are described and statistics \nare cited for reliability and performance of the system.\n Benefits to the bank are discussed from the \nbanker's point of view; an indication of future trends\nin the on-line savings bank field is also discussed.\n", "672": "Recent Developments Affecting ADP in Tax Administration", "673": "Account Classification at Automating Banks", "674": "Application of IBM 1620 EDP Methods to the Calculation", "675": "Coding Clinical Laboratory Data For Automatic Storage and Retrieval A series of clinical laboratory codes have been\ndeveloped to accept and store urin analysis, blood \nchemistry, and hematology test results for automatic\ndata processing.  The codes, although constructed \nas part of a computerized hospital simulation, have been\nable to handle the results of every laboratory \ntest that they have encountered.  The unique feature of\nthese codes is that they can accept conventionally \nrecorded qualitative as well as quantitative test results.\n Consequently, clinical test results need \nnot be arbitrarily stratified, standardized, or altered\nin any way to be coded.  This paper describes \nhow the codes were developed and presents a listing of the\nurin analysis codes.  Five criteria used in developing \nthe codes are outlined and the problem of multiple-synonymous\nterminology is discussed.  A solution to \nthe problem is described.  Flexible, computer-produced,\ncomposite laboratory reports are also discussed, \nalong with reproduction of such a report. The paper concludes\nthat even though many problems remain unsolved, \nthe next ten years could witness the emergence of a practical\nautomated information system in the laboratory.\n", "676": "On the Computation of a Certain Type of IncompleteBeta Functions", "677": "Length of Strings for a Merge Sort Detailed statistics are given on the length\nof maximal sorted strings which result form the \nfirst (internal sort) phase of a merge sort onto tapes.\n It is shown that the strings produced by an \nalternating method (i.e. one which produces ascending\nand descending strings alternately) tend to be \nonly three-fourths as long as those in a method which produces\nonly ascending strings, contrary to statements \nwhich have appeared previously in the literature.  A\nslight modification of the read-backward polyphase \nmerge algorithm is therefore suggested.\n", "678": "Optimizing Bit-time Computer Simulation A major component of a bit-time computer simulation\nprogram is the Boolean compiler.  The compiler \naccepts the Boolean functions representing the simulated computer's\ndigital circuits, and generates corresponding \nsets of machine instructions which are subsequently\nexecuted on the \"host\" computer.  Techniques are \ndiscussed for increasing the sophistication of the Boolean\ncompiler so as to optimize bit-time computer \nsimulation.  The techniques are applicable to any general-purpose computer.\n", "679": "Recent Improvements in MADCAP MADCAP is a programming language admitting subscripts,\nsuperscripts and certain forms of displayed \nformulas.  The basic implementation of this language was\ndescribed in a previous paper [MADCAP: A scientific \ncompiler for a displayed formula textbook language, Comm.\nACM 4 (Jan. 61), 31-36].  This paper discusses \nrecent improvements in the language in three areas: complex\ndisplay, logical control, and subprogramming. \n In the area of complex display, the most prominent improvements\nare a notation for integration and for \nthe binomial coefficients.  In the area of logical control\nthe chief new feature is a notation for variably \nnested looping.  The discussion of subprogramming is focused\non MADCAP's notation for and use of \"procedures.\"\n", "680": "An Error-Correcting Parse Algorithm", "681": "Flexible Abbreviation of Words in a Computer Language", "682": "Recursive programming in FORTRAN II", "683": "A Serial Technique to Determine Minimum Paths", "684": "Interpolation, Differentiation, and Integration (Algorithm 77)", "685": "Euler Summation (Algorithm 8)", "686": "Smooth (Algorithm 216)", "687": "Shanks (Algorithm 215)", "688": "q-Bessel Functions In(t)(Algorithm 214)", "689": "Report of a Visit to Discuss Common Programming", "690": "USA Participation in an International", "691": "A Description of the APT Language The APT (Automatically Programmed Tools) language\nfor numerical control programming is described \nusing the metalinguistic notation introduced in the ALGOL\n60 report.  Examples of APT usage are included. \n Presented also are an historical summary of the development\nof APT and a statement concerning its present \nstatus.  \n", "692": "On the Inverse of a Test Matrix", "693": "An Extension of Fibonaccian Search To Several Variables A technique which uses Fibonaccian search\nconcepts has been developed to solve optimization \nproblems involving unimodal functions of several variables.\n The technique has not been proven to be \noptimal in the sense that the one-dimensional Fibonaccian\nsearch is.  However, it is valuable for certain \nkinds of calculations.\n", "694": "A Comparison of Disks and Tapes The principal characteristics of current magnetic\ndisks and tape units are summarized and compared. \n Some of the characteristics of disk files are illustrated\nin a sorting example and compared to a tapesort. \n The conclusion is presented that disk files are competitive\nto tapes in some important applications.\n", "695": "Use of the Disk File on Stretch The paper begins by briefly describing the\nStretch (IBM 7030) computer with special emphasis \ngiven to the organization and operation of its input-output\nequipment.  Physical characteristics of the \ntwo-disk system (4,194,304 72-bit words, 8 usec-per-word\ntransmission rate, etc.) are noted.  Timing \nlimitations due to arm motion and disk rotation are discussed.\n Applications of disk usage are discussed \nseparately for problem programs and for systems programs\nsuch as compilers and the supervisory program. \nApproximately 260,000 words of disk storage are reserved\nfor the storage of systems programs and the \nsubroutine library.  Problem programs, however, are not\ncurrently filed on the disk.  Certain programming \ntechniques are discussed for transmitting words between\ndisk and core storage with minimum delaying and \ninterruption of the arithmetic unit.  Dumps on disk are\nconsidered for both recovery from computer malfunction \nand for mathematical or physical developments during\nthe calculation.  Some comments are made regarding \nthe reliability, economics, utility and weaknesses or\nlimitations of the disk system.  Several possible \nfuture applications are noted which appear to have disk connotations.\n", "696": "An Automatic Data Acquisition and Inquiry System Using Disk Files Lockheed Missiles and Space Company has installed\na large-scale Automatic Data Acquisition \n(ADA) system which ties together the Company's manufacturing\nfacilities located in Van Nuys and Sunnyvale, \nCalifornia.  The system includes over 200 remote Input\nStations which collect and transmit Company operating \ndata to a central Data Processing Center.  Two RCA 301\nEDP Systems are used to record and control the \nflow of data transmitted to the Data Processing Center.\n A large capacity RCA 366 Data Disc File is used \nto store information required to provide up-to-date\ninformation in response to inquiries received from \nremotely located Inquiry Stations.  In addition to storage\nof data on the disk files, the system automatically \nrecords all incoming and outgoing data on magnetic tape\nto be used as input to the Company's conventional \noff-line business data processing applications.\n", "697": "A Numerical Method for the Determination of Moving", "698": "DATA-DIAL: Two-Way Communication with An operating system is described which allows\nusers to call up a remotely located computer \nfrom ordinary dial telephones.  No special hardware or\nconnections are required at the users' telephones. \n Input to the computer is through the telephone dial;output\nfrom the computer is in spoken form.  Results \nof a test with telephones in the Boston area are reported.\n", "699": "A Contour-Map Program for X-Ray Crystallography A FORTRAN program is described for use with\nthe IBM 7090 system and an X, Y-plotter to produce \na contour map.  A matrix of points evenly spaced in\neach dimension is contoured.  Scale factors along \nthe axes may be different and the axes need not be perpendicular.\n", "700": "Hermite Interpolation (Algorithm 210)", "701": "Shuttle Sort (Algorithm 175)", "702": "Assign (Algorithm 173)", "703": "Assign (Algorithm 173)", "704": "Combinatorial of M Things Taken One At A Time", "705": "Combinatorial Of M Things Taken N At A Time (Algorithm 160)", "706": "Fourier Series Approximation (Algorithm 157)", "707": "Erf(x) (Algorithm 123)", "708": "Evaluation of the Fresnel Integrals (Algorithm 88, 89, 90)", "709": "Assignment (Algorithm 27)", "710": "Fresnel Integrals (Algorithm 213)", "711": "Frequency Distribution (Algorithm 212)", "712": "Hermite Interpolation (Algorithm 211)", "713": "Lagrangian Interpolation (Algorithm 210)", "714": "Gauss (Algorithm 209)", "715": "Discrete Convolution (Algorithm 208)", "716": "Stringsort (Algorithm 207)", "717": "Partitioning Algorithms for Finite Sets The partitions of a set with n elements are represented\nby certain n-tuples of positive integers. \n Algorithm are described which generate without repetitions\nthe n-tuples corresponding to: (1) all partitions \nof the given set, (2) all partitions of the given set\ninto m or fewer sets (1 <= m <= n), and (3) all \npartitions of the given set into exactly m sets (1 <= m <= n).\n", "718": "An Experiment in Automatic Verification of Programs  How effective is a compiler at replacing explicit\nverification, and what is the cost of this \ntechnique?\n", "719": "Variable Width Stacks Character addressable, variable field computers\npermit ready establishment and manipulation \nof variable width stacks.  Single machine commands may\npush variable field items down into such stacks \nor pop them up.  The availability of a variety of field\ndelimiters allows the machine to push down or \npop up more than one variable width item with one command.\n Since these stacking operations can be made \nthe basis of compiler decoding algorithms the proper\nuse of machines of this class for compilation has \nadvantages over machines with fixed-length words.\n", "720": "Format-Free Input in FORTRAN", "721": "Report on Proposed American Standard Flowchart This paper presents the essential contents of\nthe Proposed American Standard Flowchart Symbols \nfor Information Processing.  This is the first proposed\nstandard prepared by Subcommittee X3.6 on Problem \nDescription and Analysis of the American Standards Association (ASA).\n", "722": "ALCOR Group Representation of ALGOL Symbols", "723": "ECMA Subset of ALGOL 60", "724": "A Profile of the Programmer Synopsis: 549 members of the ACM participated\nin a study concerned primarily with the attitudes \nof programmers toward their careers and jobs.  A very\nhigh percentage of programmers have apparently \nentered their careers by accident; it has proven a happy\nchoice for most and they expect to remain in \nthe field during the next five years.  Their principal\njob satisfactions relate to the nature of their \nwork, and mostfind their jobs offer high level of professional\ninterest and good working conditions. \n Salary and advancement prospects, however,are not as\nsatisfactory.  More than half report a positive \nattitude toward programmers and programming on the part\nof their organizations.  Turnover among themselves \nis attributed primarily to poor management-salary is\nseen as the principal motivating factor in turnover \namong other programmers.  Nature of the work offered\nand salary are principal determinants in accepting \na new job.  Programmers are less mobile than expected.\n Programmers tend to see their colleagues in a \nfavorable light, on the whole.  Personalities seem to\nvary with function, systems programmers differing \nfrom applications programmers.  Four principal problems\nfor programming in the immediate future are listed \nby participants: languages, personnel, various specific\napplications and techniques, and building programming \nas a profession.\n", "725": "Group Participation Computer Demonstration", "726": "A General Program for the Analysis of This paper describes a general-purpose program\nthat will handle those incomplete block designs \nknown as square and rectangular lattices.  Flow diagrams\nare given so that the method of calculation \nmay be programmed for any digital computer.\n", "727": "On the Approximate Solution of Delta(u)=F(u) Three-dimensional Dirichlet problems for Delta(u)=F(u),\nFu >= 0, are treated numerically by \nan exceptionally fast, exceptionally accurate numerical\nmethod.  Programming details, numerous examples \nand mathematical theory are supplied.Extension of the\nmethod in a natural way to n-dimensional problems \nis indicated by means of a 4-dimensional example.\n", "728": "Computer-Drawn Flowcharts* To meet the need for improved documentation\nof written computer programs, a simple system for \neffective communication is presented, which has shown\ngreat promise.  The programmer describes his program \nin a simple format, and the computer prepares flow charts\nand other cross-referenced listings from this \ninput.  The description can be kept up-to-date easily,\nand the final output clearly explains the original \nprogram.  The system has also proved to be a valuable debugging and coding aid.\n", "729": "A Generalization of ALGOL", "730": "MIRFAG: A Compiler Based on Standard A pilot version of the compiler MIRFAG, now\nin operation, is described.  The chief features \nof the system, which is intended for the solution of scientific\nproblems, are the presentation of mathematical \nformulas entirely in standard textbook notation.  The use\nof plain English for organizational instructions, \nautomatic error diagnosis indicating the actual location\nof the error in the uncompiled program, and \nan attempt to minimize that fragmentation of the original\nproblem statement which is a normal feature \nof programming systems.\n", "731": "Symmetric List Processor  A list processing system in which each list\ncell contains both a forward and a backward link \nas well as a datum is described.  This system is intended\nfor imbeding in higher level languages capable \nof calling functions and subroutines coded in machine language.\n The presentation is in the form of FORTRAN \nprograms depending on only a limited set of FORTRAN programs\ndepending on only a limited set of \"primitive\" \nmachine language subroutines which are also defined.\n Finally, a set of field, particularly character, \nmanipulation primitives are given to round out the system.\n", "732": "Monte Carlo Inverse (Algorithm 166)", "733": "Newton Interpolation with Forward Divided Differences (Algorithm 169)", "734": "Newton Interpolation with Backward Divided Differences (Algorithm 168)", "735": "Calculation of Confluent Divided Differences (Algorithm 167)", "736": "Modified Hankel Functions (Algorithm 163)", "737": "Exponentiation of Series (Algorithm 158)", "738": "Fourier Series Approximation (Algorithm 157)", "739": "MINIFUN (Algorithm 129)", "740": "INTEREST (Algorithm 45)", "741": "Evaluation of Determinant (Algorithm 41)", "742": "Evaluation of Determinant (Algorithm 41)", "743": "ARCCOSIN (Algorithm 206)", "744": "ATIVE (Algorithm 205)", "745": "STEEP2 (Algorithm 204)", "746": "STEEP1 (Algorithm 203)", "747": "Generation of Permutations in Lexicographical Order (Algorithm 202)", "748": "A Semi-Iterative Process for Evaluating Arctangents", "749": "Note onStochastic Matrices", "750": "PEI Matrix Eigenvectors", "751": "A Note on a Set of Test Matrices for Inversion", "752": "Closing Out a Print Tape", "753": "A Procedure for Converting Logic Table Conditions", "754": "Ye Indiscreet Monitor", "755": "An Exponential Method of Numerical Integration A formula for numerical integration is prepared,\nwhich involves an exponential term.  This \nformula is compared to two standard integration methods,\nand it is shown that for a large class of differential \nequations, the exponential formula has superior stability\nproperties for large step sizes.  Thus this \nformula may be used with a large step size to decrease the\ntotal computing time for a solution significantly, \nparticularly in those engineering problems where high accuracy is not needed.\n", "756": "A Computer Program for Editing the News", "757": "Simulation of a Traffic Network", "758": "Skeletal Structure of PERT and CPA Computer Programs An introduction to the inner mechanics of\nPERT and CPA computer programs is provided.  The \nmajor components of these programs as well as their\npurposes and interrelationships are outlined.\n", "759": "Continued Operation Notation for Symbol A brief account is given of a notational device\nthat is very useful in the formal representation \nof syntaxes, string relationships and string transformation\nprocedures and also of computing procedures \nthat deal with arrays of functions of many variables. \nThe device consists of the use of certain \"continued \noperation\" or \"collective\" symbols that are analogous to the summation\nsymbol (Sigma) and continued multiplication \nsymbol (Pi) of conventional mathematics.\n", "760": "Dialects of FORTRAN", "761": "A Note on the Dangling Else in ALGOL 60 Some revisions of ALGOL 60 are proposed, which\nnot only eliminate certain ambiguous statements \nbut also add some convenience to the language.  A discussion\nof the background of the problem and a sketch \nof a proof that the ambiguities have been removed is included.\n", "762": "Some Remarks on the Syntax of Symbolic Programming Languages", "763": "A Syntax Controlled Generator of Formal Language Processors", "764": "Reduction of a Matrix Containing Polynomial Elements (Algorithm 170)", "765": "Orthogonal Polynomial Least Squares Surface Fit (Algorithm 164)", "766": "XY-move Plotting (Algorithm 162)", "767": "Certification of Algorithm 161", "768": "Certification of Algorithm 160", "769": "Algebra of Sets (Algorithm 156)", "770": "Combination in Any Order (Algorithm 155)", "771": "Combination in Lexicographical Order (Algorithm 154)", "772": "GOMORY (Algorithm 153)", "773": "Matrix Inversion (Algorithm 140)", "774": "Jacobi (Algorithm 85)", "775": "Interpolation, Differentiation, and Integration (Algorithm 77)", "776": "Partition, Quicksort, and Find (Algorithm 62, 64, & 65)", "777": "A Set of Test Matrices (Algorithm 52)", "778": "Associated Legendre Functions of the First Kind", "779": "CROUT II (Algorithm 43)", "780": "Algorithm 42 INVERT, Alg.107 Gauss's", "781": "Telescope 2 (Algorithm 38)", "782": "Telescope 1 (Algorithm 37)", "783": "Shellsort (Algorithm 201)", "784": "Normal Random (Algorithm 200)", "785": "Conversions Between Calendar Date And Julian day Number (Algorithm 199)", "786": "Adaptive Integration and Multiple Integration (Algorithm 198)", "787": "Matrix Division (Algorithm 197)", "788": "Muller's Method for Finding Roots of", "789": "Bandsolve (Algorithm 195)", "790": "Zersol (Algorithm 194)", "791": "Character Manipulation in 7090 Fortran", "792": "Multiple-Precision Binary-To-Decimal Integer", "793": "Mapped List Structures", "794": "A List-Type Storage Technique for Alphameric Information A method which is economic in terms of space and\ntime is proposed for the storage and manipulation \nof character strings of arbitrary length in a fixed\nword-length computer.  The method is illustrated \nin an application to Algol-type identifiers in an Algol-like block structure.\n", "795": "Debugging Systems at the Source Language Level", "796": "SABRAG, A Time-Sharing Low-Cost Computer The serial SABRAC computer designed and built\nin the Scientific Department of the Israel defense \nMinistry has a 5000-location magnetic drum, main store.\n To avoid a need to resort to optimum programming \ntechniques and to increase its overall efficiency the\ncomputer has also been given a 224-word ferrite \ncore store from which the program is obeyed.  Transfers\nbetween the core and drum stores and to and from \nthe twin paper-tape input and output channels are all\navailable autonomously (concurrently, time-shared). \n Multiplication and division orders are also autonomous,\nso that the machine may be executing up to three \norders simultaneously.  All functions naturally are interlocked.\n A number of other advanced orders and \nfacilities are also incorporated.In particular, an\n\"Execute\" order permits a temporary jump for up \nto four orders and a second modifier register permits double\nmodification in general and relative addressing \nof subroutines in particular.  Thus the overall effective\nspeed of the machine is muchhigher than its \nbasic specification would lead one to expect and its\ndesign indicates one way in which the concepts of \ntime sharing may be incorporated in \"low-cost\" computers.\n", "797": "American Standard Code for Information Interchange", "798": "A Catalogue Entry Retrieval System", "799": "Design of a Separable Transition-Diagram Compiler* A COBOL compiler design is presented which is\ncompact enough to permit rapid, one-pass compilation \nof a large subset of COBOL on a moderately large computer.\n Versions of the same compiler for smaller \nmachines require only two working tapes plus a compiler\ntape.  The methods given are largely applicable \nto the construction of ALGOL compilers.\n", "800": "The Linking Segment Subprogram Language and Linking Loader", "801": "Least Squares Solution with Constraints (Algorithm 177)", "802": "SYMINV2 (Algorithm 150)", "803": "Syminv2 (Algorithm 150)", "804": "Exponentiation of Series (Algorithms 134)", "805": "Newton Maehly (Algorithm 105)", "806": "Remark on Certification of Matrix Inversion Procedures", "807": "Reversion of Series (Algorithm 193)", "808": "Confluent Hypergeometric (Algorithm 192)", "809": "Hypergeometric (Algorithm 191)", "810": "Complex Power (Algorithm 190)", "811": "Smoothing 2 (Algorithm 189)", "812": "Smoothing 1 (Algorithm 188) ", "813": "Differences and Derivatives (Algorithm 187)", "814": "Complex Arithmetic (Algorithm 186)", "815": "Normal Probability for Curve Fitting (Algorithm 185)", "816": "Erlang Probability for Curve Fitting (Algorithm 184)", "817": "Nexcom (Algorithm 152)", "818": "Realizing Boolean Connectives on The IBM 1620", "819": "Polynomial Evaluation Revised", "820": "Checking for Loops in Networks", "821": "Further Remarks on Sampling a Tape File-III", "822": "Real-Time Programming Specifications Problems in the implementation of large real-time\napplications are treated, and suggested guidelines \nfor both program and file specifications are developed.\n The problems delineated also occur in systems \nprogramming.\n", "823": "A Syntactic Description of BC NELLIAC", "824": "DESCRIPTRAN-Automated Descriptive Geometry* Descriptive geometry consists of procedures originally\ndesigned to solve 3-space geometry problems \nby graphical constructions and measurement instead of\nby computation.  However, in addition to this it \nunifies and simplifies the approach to many such problems.\n When one can call subroutines that compute \nnew coordinates that correspond to those obtainable from\nthe graphical constructions, there is the three-way \nadvantage of the approach of descriptive geometry, the\naccuracy of computation and the speed of the digital \ncomputer.  DESCRIPTRAN makes it possible to program\nmany problems in 3-space with a few statements; it \nconsists of 15 subroutines analogous to the procedures of descriptive geometry.\n", "825": "PIP: A Photo-Interpretive Program An operating computer program that processes\nphotographically recorded data is described.  \nThe input to the program consists of spark-chamber photographs\non which tracks of high-energy particles \nare recorded.  The program automatically scans, measures\nand performs the preliminary interpretation \nof these photographs.  In continuous operation a processing\nrate of 5,000 photographic frames per hour \nis achieved.\n", "826": "Remarks on Fortran Subroutines for Time Series Analysis", "827": "Disk File Sorting Sorting techniques using an IBM 1401 with\na random access storage device are evaluated.\n", "828": "Incompressible flow Network Calculations A general method for the calculation of flows\nand pressures in fluid flow networks is presented. \n The method is applicable to computer use.\n", "829": "The External Language KLIPA For the URAL-2 Digital computer", "830": "CORC-The Cornell Computing Language", "831": "Real Error Function, ERF (Algorithm 123)", "832": "Curve Fitting with Constraints (Algorithm 74)", "833": "Reduction of a Symmetric Bandmatrix to Triple Diagonal Form", "834": "Nonrecursive Adaptive Integration (Algorithm 182)", "835": "Complementary Error Function-Large X (Algorithm 181)", "836": "Error Function-Large X (Algorithm 180)", "837": "Incomplete Beta Ratio (Algorithm 179)", "838": "Direct Search (Algorithm 178)", "839": "Least Squares Solution with Constraints (Algorithm 177)", "840": "Least Squares Surface Fit (Algorithm 176)", "841": "Shuttle Sort (Algorithm 175)", "842": "A Posteriori Bounds on a Zero of a Polynomial (Algorithm 174)", "843": "Assign (Algorithm 173)", "844": "1410 Fortran Edit Feature", "845": "Another Test Matrix for Determinants and Inverses", "846": "Self-Inverse Conversion Table", "847": "A Penny-Matching Program The logic of a penny-matching program\nwritten for the CSX-1 is described.\n", "848": "A Note on Range Transformations for Square Root and Logarithm There was the germ of an idea in two previous\npapers [1,2] which no one seems to have picked \nup in almost five years.  For certain functions it seems\ndesirable to transform the argument to a short \nrange symmetric about 10.1 will give examples of this\nusage for the square root and logarithm function \nfor both binary and decimal machines.\n", "849": "Use of Tree Structures for Processing Files In data processing problems, files are frequently\nused which must both be searched and altered. \n Binary search techniques are efficient for searching\nlarge files, but the associated file organization \nis not readily adapted to the file alterations.  Conversely,\na chained file allocation permits efficient \nalteration but cannot be searched efficiently. A file\norganized into a tree-like structure is discussed, \nand it is shown that such a file may both be searched\nand altered with times proportional to slog(s)N, \nwhere N is the number of file items and s is a parameter\nof the tree.  It is also shown that optimizing \nthe value of s leads to a search time which is only 25\nper cent slower than the binary search.  The tree \norganization employs two data chains and may be considered\nto be a compromise between the organizations \nfor the binary search and the chained file.  The relation\nof the tree organization to multidimensional \nindexing and to the trie structure is also discussed.\n", "850": "Conversion, Reconversion and Comparison The logic is described for converting highly\nvariable input records into a format that can \nbe easily and efficiently processed by a sorting program.\n The internal record formats are discussed \nin relation to (1) their conversion from input formats,\n(2) their reconversion to output formats, and \n(3) comparison techniques between internal formats.\n", "851": "Design and Characteristics of a Variable-Length This paper describes the application of several\nnew techniques for sorting fixed-length records \nto the problems of variable-length record sorting. \nThe techniques have been implemented on a Sylvania \n9400 computer system with 32,000 fixed-length words\nof memory.  Specifically, the techniques sequence \nvariable-length records of unrestricted size, produce\nlong initial strings of data, merge strings of \ndata at the power of T-1, where T is the number of work\ntapes in a system, and do not restrict the volume \nof input data.\n", "852": "A Method of Comparing the Time Requirements of Sorting Methods", "853": "The COBOL Sort Verb", "854": "Some Characteristics of Sorting in Computing The substantial differences in characteristics\nof random access storage and tape devices dictate \nthat concepts and objectives of computer program design\nbe considered from the viewpoint of the external \nfile medium used.  This is particularly true in the\ncase of sorting.  In a tape-oriented system, the \nmajor sorting problem is that of minimizing merge time\ndespite the limited orders of merge possible. \n In contrast, sorting in a random access-oriented system\nencourages the selection of the optimum order \nof merge from many possible orders.  The latter problem\nis discussed in this paper, along with criteria \ndeveloped for determining the optimum order of merge according\nto the various properties of random access \nstorage devices.  Attention is also given to the problem\nof key sorting versus record sorting and the \npossibly serious disadvantage of key sorting on a random access system.\n", "855": "Organization and Structure of Dataon Disk File An approach to the organization and structure\nof data on Bryant Disc File Memory Systems for \nsorting and performing other data processing functions\nis presented.  The following areas are covered: \ncharacteristics of Bryant Disc File Systems on the Bendix\nG-20 and RCA 301; two proposed \"chaining\" structures \nfor data; and functions of a Disk File Executive Routine.\n The concepts for sorting and performing file \nmaintenance processing using the proposed structure and\nexecutive routine are discussed.  Additionally, \nit is shown that sorting can be accomplished\nwithout the use of disk storage work areas.\n", "856": "Sorting with Large Volume, Random Access, Drum Storage An approach to sorting records is described\nusing random access drum memory.  The Sort program \ndescribed is designed to be a generalized, self-generating\nsort, applicable to a variety of record statements. \n This description is divided into three parts.  The\nfirst part presents the operating environment; the \nsecond defines the general solution; the third part\ndescribes the internal sort-merge technique.\n", "857": "Sorting Nonredundant Files-Techniques Used in the FACT Compiler Some typical file structures, including some\ncalled \"non-redundant,\" are examined,and the \nmethods used in FACT to sort such files are discussed.\n", "858": "A Tape File Merge Pattern Generator A routine is presented which specifies the\nsequence of merge cycles to effect the merging of \nsorted tape files.  The routine is designed to minimize\nelapsed computer time by varying the power of \nthe merge cycles, so as to use all the available tape\ndrives, with its characteristic of assigning one \ndrive to a single-reel file and two drives to each multiple-reel file.\n", "859": "Computer Planned Collates", "860": "A Comparison Between the Polyphase and Oscillating Sort Techniques A comparison between the Oscillating and Polyphase\nSort techniques is developed for computer \nsystems having from four to ten tape drives.  The basis\nfor the comparison is the total reading and writing \nrequired for various number of input strings\nand tape drives for the two techniques.\n", "861": "Read-Backward Polyphase Sorting Read-backward Polyphase sorting provides more\nefficient use of the tapes available to a sort \nthan most other sorting techniques.  Backward Polyphase\nproduces a continuous merging process from n-1 \ntapes where n is the total number of tapes being used in\nthe sorting process.  Any of the available presorting \ntechniques may be used in conjunction with the Polyphase\nmerge sort provided that the presort has the \ncapability of producing both ascending and descending\nstrings and distributing the strings on the various \ntapes as required by the Polyphase Merge.\n", "862": "String Distribution for the Polyphase Sort", "863": "Multiphase Sorting", "864": "An Empirical Study of Minimal Storage Sorting", "865": "Internal and Tape Sorting Using the Replacement-Selection Technique A general technique for sequencing unsorted\nrecords is presented.  The technique is shown to \nbe applicable for the first stage of a generalized sort\nprogram (the formation of initial strings) as \nwell as for sorting records within a memory storage (an\ninternal sort).  It is shown that given N records \nin memory storage, records are sequenced using 1+log2\nN tests per record, that initial string lengths \nwill average 2N for random input records, and that reading,\nwriting and processing can be accomplished \nsimultaneously if the computer permits such overlap.\n", "866": "Sorting on Computers", "867": "Least Squares Fitting of Planes to Surfaces Using Dynamic Programming Dynamic programming has recently been used\nby Stone, by Bellman and by Gluss to determine the \ncloset fit of broken line segments to a curve in an\ninterval under the constraint that the number of \nsegments is fixed.  In the present paper successive\nmodels are developed to extend the method to the \nfitting of broken plane segments to surfaces z=g(x,y) defined\nover certain types of subareas of the (x,y)-space. \n The first model considers a rectangular area, with\nthe constraint that the plane segments are defined \nover a grid in the (x,y)-space.  It is then shown how\nthis model may be incorporated into an algorithm \nthat provides successive approximations to optimal fits\nfor any type of closed area.  Finally, applications \nare briefly described.\n", "868": "A Suggested Method of Making Fuller Use of Strings in ALGOL 60", "869": "Term of Magic Square (Algorithm 148)", "870": "Term of Magic Square (Algorithm 148)", "871": "PSIF (Algorithm 147)", "872": "Adaptive Numerical Integration by Simpson's Rule (Algorithm 145)", "873": "Random (Algorithm 133)", "874": "Chebyshev Curvefit (Algorithm 91)", "875": "Incomplete Elliptic Integrals (Algorithm 73)", "876": "Complete Elliptic Integral (Algorithm 149)", "877": "Complete Elliptic Integral of the First Kind (Algorithm 55)", "878": "Reduction of a Matrix Containing Polynomial Elements (Algorithm 170)", "879": "Newton Interpolation with Forward Divided Differences (Algorithm 169)", "880": "Newton Interpolation with Backward Divided Differences", "881": "Calculation of Confluent Divided Differences (Algorithm 167)", "882": "Monte Carlo (Algorithm 166)", "883": "Complete Elliptic Integrals (Algorithm 165)", "884": "Orthogonal Polynomial Least Squares Surface Fit (Algorithm 164)", "885": "Modified Hankel Function (Algorithm 163)", "886": "XY-move Plotting (Algorithm 162)", "887": "Combinatorial of M Things Taken One at a Time,", "888": "Algorithm 160 Combinatorial of M Things Taken N at A Time", "889": "Official Actions and Responses to ALGOL As a Programming Language", "890": "Selected Definitions  A selection of the definitions prepared by the\nACM Standards Committee's Subcommittee on Programming \nTerminology is presented for review by the ACM membership.\n", "891": "Everyman's Information Retrieval System The information retrieval problem whose solution\nis presented here was posed by a technical \nlibrary with limited bubget and personnel.  The solution,\nhowever, is quite general and is applicable \nto many different types of retrieval problems.  Further,the\nmethod of solution makes it possible for \nmany groups who have previously dismissed an information\nretrieval program as expensive and difficult \n(from a programming stand-point) to reconsider their position,\nfor the present solution makes it possible \nto install an information retrieval program in less than\nthree months, and with relatively little equipment.\n", "892": "RECOL-A Retrieval Command Language An interrogation scheme is described for the\nretrieval and manipulation of data file records. \n The language of the interrogation scheme allows for selecting\nfile records with the are of logical condition \nstatements, defining record classes, associating file\nrecords, editing printed output, and summarizing \nthe results of the above operations.  Some examples of\na typical file application and the more significant \nfeatures of a particular machine implementation are given.\n", "893": "Significance Arithmetic on a Digital Computer The 7090 at NYU has been modified to include\na \"Significance Mode\" of operation which is intended \nto facilitate the identification of significant bits in\nthe results of floating-point arithmetic operations. \n The manner in which floating-point arithmetic is handled\nin this mode is discussed.  Several numerical \nexperiments using this mode are described and comparisons\nare made with the ordinary \"normalized mode.\" \n Examples include power series evaluation, linear equations\nsolution, determinant evaluation and matrix \ninversion.\n", "894": "An Iterative Factorization Technique for Polynomials An iterative technique is displayed whereby factors\nof arbitrary degree can be found for polynomials \nin one variable.  Convergence is shown to occur always\nif a certain Jacobian does not vanish and if the \ninitial approximation to a factor is near enough to an\nactual factor.  The process is simply programmed, \nand preliminary results indicate it to be well adapted\nto use with digital computers.  For factors of \ndegree two, the technique is similar to that of Bairstow,\nthe present method being somewhat simpler.\n", "895": "A Computational Extension of the Variate Difference Method Presented here is a computational extension\nof the variate difference method as developed by \nG. Tintner [1].\n", "896": "Characteristic Values and Vectors of Defective Matrices", "897": "Note on the Proof of the Non-existence", "898": "Random (Algorithm 133)", "899": "Magic Square (Algorithm 117 & 118)", "900": "Ancestor (Algorithm 79)", "901": "Difference Expression Coefficients (Algorithm 79)", "902": "Determinant (Algorithm 159)", "903": "Exponentiation of Series (Algorithm 134 )", "904": "Fourier Series Approximation (Algorithm 157)", "905": "Algebra of Sets (Algorithm 156)", "906": "Combination in any Order (Algorithm 155)", "907": "Combination in Lexicographical Order (Algorithm 154)", "908": "Test Matrix for Inversion ", "909": "Arithmetizing Declarations (Corrigendum)", "910": "Selective Instruction Trap for the 7090", "911": "A Variant Method of File Searching", "912": "Addressing an Array Yi in k-Dimensions", "913": "Neliac", "914": "Jovial and Its Documentation", "915": "Documentation of IPL-V", "916": "FORTRAN", "917": "COMIT", "918": "COBOL", "919": "Documentation Problems: ALGOL 60", "920": "Toward Better Documentation of Programming Languages", "921": "Incomplete Elliptic Integrals (Algorithm 73)", "922": "Multint (Algorithm 32)", "923": "Gomory (Algorithm 153)", "924": "Nexcom (Algorithm 152)", "925": "Location of a Vector in a Lexicographically Ordered ListAlgorithm 151)", "926": "Syminv2 (Algorithm 150)", "927": "Linear Programming Applied to Ultraviolet Absorption Spectroscopy", "928": "Character Manipulation in FORTRAN", "929": "Glossary Construction", "930": "Decimal-to-Binary Conversion of Short Fields", "931": "Systematic Mistake Analysis of Digital Computer Programs", "932": "Matrix Inversion by Gauss-Jordan Inversion II (Algorithm 120)", "933": "Magic Squares (Algorithm 117 & 118)", "934": "Gauss's Method (Algorithm 107)", "935": "Calculating Primes by Means of GPS (Algorithm)", "936": "A Set of Test Matrices (Algorithm 52)", "937": "Inverse of a Finite Segment of the Hilbert Matrix (Algorithm 50)", "938": "Invert (Algorithm 42)", "939": "Gamma Function (Algorithm 31)", "940": "Generating Discrete Random Variables in a Computer This note is concerned with details of how to\ninstruct a computer to choose one from many things \nwith assigned probabilities.  The method uses a uniform\nvariable to direct the computer to a memory location; \nif this is done by a sequence of appropriately chosen\nconditional probabilities, efficient use of memory \nspace and quite fast programs will result.\n", "941": "A Recursive Program for the General n-Dimensional Integral A general program is outlined for n-dimensional\nintegration with variable limits.  The program \nis of a recursive nature and uses Simpson's rule combined\nwith repeated bisection to attain the required \naccuracy.  It was developed in the Ferranti Mercury Autocode Scheme.\n", "942": "FORTRAN Subroutines for Time Series Analysis The authors have recently been concerned in a\ntime-series study that constituted a fairly typical \npiece of applied statistical research, involving extensive\ncomputations on a moderately large quantity \nof data.  Wehave found that the many different numerical\nprocesses that were required could be built \nup almost completely from a small number of basic operations,\nand a set of FORTRAN subroutines has been \nwritten to perform these.  The main purpose of this\nnote is to describe these subroutines, but since \nthe question of general statistical programs is\ntopical [1], we include some general remarks.\n", "943": "Terms Frequently Combined in Problem Description", "944": "Storage and Search Properties of a Tree-Organized Memory System A memory with list properties [1] may be used\nto construct numeric, alphabetic or alphanumeric \ntrees.  Such trees have information storage and retrieval\nproperties applicable to problems involving \nlarge quantities of data or to problems where the quantity,\nword length and distribution of stored information \nis not known a priori, or changes rapidly during the processing.\n The purpose of this paper is to examine \nthe storage and search properties of a tree-organized\nstorage system assuming that a memory possessing \ncertain list properties is available.  Of prime interest\nis the application where a symbol table, dictionary \nor similar file is to be stored and searched.\n", "945": "Arithmetizing Declarations: An Application to COBOL", "946": "Suggestions on ALGOL 60 (ROME) Issues - A Report by the American", "947": "Supplement to the ALGOL 60 Report", "948": "Note on the Use of Procedures ", "949": "Integer and Signed Constants in ALGOL A few remarks are given on the relations between\nsyntax and semantics in the programming languages. \n The aim is to point out that, if it is true that the grammar\nof a context-free language should be conceived \nnot only as a strings-generating device but also as a\nmethod for expressing a meaning, then the grammar \nof ALGOL is open to some criticism.\n", "950": "Parallel Methods for Integrating Ordinary Differential Equations This paper is dedicated to the proposition that,\nin order to take full advantage for real-time \ncomputations of highly parallel computers as can be\nexpected to be available in the near future, much \nof numerical analysis will have to be recast in a more\n\"parallel\" form.  By this is meant that serial \nalgorithms ought to be replaced by algorithm which\nconsist of several subtasks which can be computed \nwithout knowledge of the results of the other subtasks. \nAs an example, a method is proposed for \"parallelizing\" \nthe numerical integration of an ordinary differential\nequation, which process, by all standard methods, \nis entirely serial.\n", "951": "Rational Chebyshev Approximations The second Remes algorithm is used to approximate\nthe integrals Kis by rational functions.\n The related coefficients for the approximations of\nKi1, Ki2, Ki3 are given for different precisions.\n", "952": "Another use of FORTRAN II Chaining", "953": "Scanning Text with a 1401", "954": "A Note on the Calculation of Probabilities in an F-Distribution", "955": "A Class of Matrices to Test Inversion Procedures", "956": "A Family of Test Matrices", "957": "Method for Partial Rewriting of Magnetic Tape", "958": "A Case of too Much Precision", "959": "Mark Sense and Port-A-Punch Programming Inputs", "960": "Curve Fitting with Format Fortran", "961": "Limited Bit Manipulation Using FORTRAN II Techniques are developed for manipulating bits\nusing only FORTRAN II.  These techniques allow \nindividual bits to be tested, certain fields to be\nshifted, and numbers coded in BCD to be converted \nto Binary.\n", "962": "Double-Precision Squares Root for The CDC-3600 In January of 1960, the late Hans J. Maehly completed\na summary of approximations to the elementary \nfunctions for the CDC-1604 computer.  The approximations\nand techniques suggested by Maehly are equally \napplicable to the second large computer in the CDC line,\nthe 3600.  Unlike the 1604, however, the 3600 \nhas built-in double-precision floating-point arithmetic.\n The present work, largely inspired by the successes \nof Maehly and his associates, concerns the extension of one\nof Maehly's ideas to a double-precision subroutine \nfor the 3600.\n", "963": "Relative Effects of Central Processor and Input-Output Presented in this paper is a technique for\ndetermining the relative effects of the internal \nspeed of the computer and the speed of the input-output\nunits upon the overall speed of the system. Equations \nare derived which permit the determination of these\neffects from hardware usage measurements.\n", "964": "Mechanization of Tedious Algebra-the A table of formulas for certain integrals\ninvolving Legendre functions has been constructed \nmechanically by a program which performed algebraic operations.\n The formulas are all rational algebraic \nexpressions in a single variable and were constructed\nby a recurrence procedure.  They are of interest \nin molecular quantum chemistry.  Trivial coding techniques\nwere used to write the relevant programs in \nFORTRAN.  The results were photo composed on a Photon\nS-560 system, that was controlled by tapes which \nwere punched directly from the computer output, so\navoiding manual keyboarding, transcription errors \nand keyboarded correction.\n", "965": "Greatest Common Divisor (Algorithm 237 [A1])", "966": "Evaluation of Determinant (Algorithm 224 [F3])", "967": "Complementary Error Function (Algorithm 181 [S15])", "968": "Radical-Inverse Quasi-Random Point Sequence (Algorithm 247 [G5])", "969": "Graycode (Algorithm 246 [Z])", "970": "Treesort 3 (Algorithm [M1])", "971": "Time Sharing in a Traffic Control Program The Toronto traffic signal control system consists\nof a variety of logically distinct computer \nprograms, all competing for machine time.  To satisfy\nthese demands, a time-sharing program has been \nwritten whose purpose is to execute, in the order of a\npredefined priority, the various subprograms within \nthe real-time system.  In this paper the more interesting\naspects of the time-sharing program are outlined.\n", "972": "An Executive System Implemented as a Finite-State Automaton The 473L command and control system used by\nthe Air Force permits many operators to access \nlarge data files through the use of a computer.  The man-machine\ninterface is satisfied by several communication \nconsoles from which operators may enter queries and\nview replies.  A data link permits remote stations \nto send messages, status reports and inventories directly\nto the computer.  The information received \nover the on-line data link is used to update the data files\nwhich are stored on disk.  The 473L programming \nsystem is divided into an Executive Control Program and\nfive components with different processing priorities. \n These priorities permit the system to be most sensitive\nto the console inputs and permit the operators \nat all the consoles to time share the central processor.\n The Executive Control Program provides for \nthe orderly transitions of control among the programming\nsystem components. The major emphasis of the \npaper is on the technique of using the definition of a\nfinite-state automaton for organizing the Executive \nControl Program.\n", "973": "Estimation of Heart Parameters Using Skin Potential Measurements A fundamental problem of vector cardiography\nis the estimation of the state of the heart on \nthe basis of skin potential measurements.  A mathematical\nmodel relating ventricular dipoles to surface \npotentials is sketched.  Then it is shown that the inverse\nproblem-that of determining electrical heart \nparameters on the basis of skin potential measurements-may\nbe viewed as a nonlinear multipoint boundary \nvalue problem.  A feasible solution, employing quasilinearization\nand high-speed digital computers, is \ngiven.\n", "974": "A Technique for Reading Gapless Tapes Makes Electrocardiograph To study arrhythmias and higher frequency\ncomponents of the electrocardiogram, long series \nof patient heart cycles must be examined before valid\ncomparison of different heart beats can be made. \nA technique is presented for the automatic analysis\nof long series heart cycles via a digital computer.\n", "975": "The New Program of Work for the International", "976": "Fresnel Integrals (Algorithm 213 [S20])", "977": "Conversions Between Calendar Date and", "978": "Fresnel Integrals (Algorithm 244 [S20])", "979": "Logarithm of a Complex Number (Algorithm 243 [B3])", "980": "Multiple-Precision Arithmetic and the Exact Described in this paper is a system of general-purpose\nmultiple-precision fixed-point routines \nand their use in subroutines which calculate exactly\nthe quantum-mechanical 3-j, 6-j and 9-j symbols \nof large arguments.\n", "981": "Rounding Problems in Commercial Data Processing A common requirement in commercial data processing\nis that the sum of a set of numbers, rounded \nin a generally understood manner, be equal to the sum\nof the numbers rounded individually.  Four rounding \nprocedures are described to accomplish this.  The particular\nprocedure that is appropriate depends upon \nwhether the numbers being accumulated can vary in sign,\nwhether their sum can vary in sign, and whether \nthe last number being summed can be recognized as such prior to its rounding.\n", "982": "An Inductive Approach to Language Translation The possibility of natural language translation\nby means of fixed operations on example translations \nis considered.  The conception of sentence translation\nwhich motivates the work is informally presented, \nand the measurement of physical similarity in pairs of\nstrings is discussed, a notion which plays a central \nrole in the proposed type of translator.  Experimental\nevidence is presented in support of the premise \nupon which this conception is based.\n", "983": "Take-up reels for One-Inch Perforated Tape for", "984": "Report on Input-Output Procedures for ALGOL 60 (IFIP)", "985": "Report on SUBSET ALGOL 60 (IFIP)", "986": "Proposed Amendment to Proposed American Standard", "987": "FORTRAN vs. Basic FORTRAN (A Programming Language", "988": "History and Summary of FORTRAN Standardization Development for the ASA", "989": "A Method of Syntax Specification", "990": "Constraint-Type Statements in Programming Languages A proposal is made for including in a programming\nlanguage statements which imply relations \nbetween variables but which are not explicit assignment\nstatements.  The compiler sets up a Newtonian \niteration making use for the purpose of a routine for formal differentiation.\n", "991": "Gamma Function with Controller Accuracy (Algorithm 225 [S14])", "992": "Gamma Function (Algorithm 221 [S14])", "993": "Kutta Merson (Algorithm 218 [D2])", "994": "Stringsort (Algorithm 207 [M1])", "995": "Steep1 (Algorithm 203 [E4])", "996": "Permutations of a Set with Repetitions (Algorithm 242 [G6])", "997": "Patent Protection of Computer Programs", "998": "Computer Programs are Patentable", "999": "Joint Inventorship of Computers", "1000": "Computer Patent Disclosures", "1001": "Copyright Aspects of Computer Usage This paper is concerned with the question of\nwhat constitutes infringement of a copyright on \na book or other nondramatic literary work when the work\nis fed into a computer and is indexed, analyzed, \npartially reprinted, or otherwise utilized by the computer\nto produce eye-readable output.  The question \nof copyrightability of programs and infringement of copyrights\non programs is also discussed.  The paper \nis directed primarily to a discussion of the present\nlaw.  Some aspects of the proposed new copyright \nlaw are also included.  General recommendations are\nmade with respect to the proposed revision of the \ncopyright law.\n", "1002": "A Rapid Method for Digital Filtering Since much of the computer time spent in time-series\nanalysis is used for multiplications, \na minimum multiplication method was devised for digital\nfiltering, with the expectation that it would \nbe useful in the on line, real-time analysis of biological\ndata.  The filters are constructed from a succession \nof readily analyzable components in a manner that facilitates\ncascading.  The repertoire of frequency \nresponse curves includes relatively good low-pass and\nband-pass designs.  Programs are available for \nimplementing both the synthesis of these filters, and\ntheir application on computers whose assemblers \nallow the definition of recursive macros.\n", "1003": "A Computer Analysis Method For Thermal Diffusion in Biochemical Systems In the thermal detection of rapid biochemical\nreactions it is necessary to correct the temperature \ndata for transient heat conduction losses in a cylindrical\ncalorimeter.  To handle the complexities arising \nfrom varying thermal-relaxation times of concentric insulating\nlayers, a computer program was developed \nwhich gives the temperature distribution of the system\nas a function of radius and time.  This distribution \nis corrected at each step by a subroutine which calculates\nthe instantaneous chemical state of there \naction, as well as the heat produced by this reaction.\n The program is based on a direct statement of \nFourier's law of heat conduction and the chemical rate\nequation to provide a \"bookkeeping law\" to follow \nthe reactants and the flow of heat packets, in such a\nway that the computer continually stores the heat \ndistribution.  A computer analysis method is here regarded\nas one in which the physical laws of a process \nare used explicitly in the program. Usually this results\nin by passing much of the mathematical procedures \nconventionally used.  The program was tested against\nsome known exact solutions of the heat equation \nand gave identical results, and compared well with experimental\ndata of a known biochemical reaction. \n The construction of computer programs based on the direct\nstatement of the physical laws is a principle \nof general applicability which has been applied\nto several other physical phenomena.\n", "1004": "Arctangent (Algorithm [B1])", "1005": "Coordinates on an Ellipsoid (Algorithm 240 [Z])", "1006": "A Storage Allocation and Reference Structure A method is proposed and discussed which allows\na subscripted-variable capability (in the FORTRAN \nsense) to be added to AUTOCODER-Type assembly systems.\n", "1007": "Extension of Existing Compilers By Sophisticated Use of Macros A description is presented of an application\nin which macros and string concatenation were \nemployed to add a new facility to BELFAP.\n", "1008": "Scheduling Meetings with a Computer Computer scheduling of papers as it was developed\nfor the 1960 meeting of the Federation of \nAmerican Societies for Experimental Biology (FASEB) is described.\n The FASEB meeting is the largest scientific \nmeeting held in the United States each year.  The technique\ndeveloped for FASEB can be applied to schedule \nany meeting with parallel sessions.\n", "1009": "Solution of Combinatorial Problems Using Generating The utility of generating functions in solving\ncombinatorial problems is discussed.  Particular \nimplementation results are presented and evaluated.\n", "1010": "A Multiuser Computation Facility for Education and Research Present-day computing facilities are limited\nin their value for scientific research by inability \nto interact strongly with users.  The full power of a\nresearch computing instrument should be available \nat many terminals that give each user the ability to generate,\ncorrect and operate any procedure he wishes, \neither simple or complex.  Implementation is described\nfor a small-scale multiuser computer system that \npermits several users to work independently with the\nmachine, and to obtain satisfactory response using \ntypewriter communication.\n", "1011": "Logarithm of a Complex Number (Algorithm 48 [B3])", "1012": "Formal Parsing Systems Automatic syntactic analysis has recently become\nimportant for both natural language data processing \nand syntax-directed compilers.  A formal parsing system\nG = (V,u,T,R) consists of two finite disjoint \nvocabularies, V and T, a many-many map, u, from V onto\nT, and a recursive set R of strings in T called \nsyntactic sentence classes.  Every program for automatic\nsyntactic analysis determines a formal parsing \nsystem.  A directed production analyzer (I,T,X,p) is a\nnondeterministic pushdown-store machine with internal \nvocabulary I, input vocabulary T, and all productions\nof p in the form:  (Z,a) -> aY1 ... Ym where  Z, \nYi are elements of the set I and a is an element of the\nset T.  Every context-free language can be analyzed \nby a directed production analyzer.  The Kuno-Oettinger\nmultiple-path syntactic analyzer for English is \na concrete example of a directed production analyzer\nand of a working parsing algorithm.  The connection \nbetween structures assigned by the analyzer and those of\na conventional phrase structure grammar is examined \nin this paper.\n", "1013": "Final Examination Scheduling A method for scheduling final examinations\nto yield a minimal number of student conflicts is \ndescribed.  The \"minimization\" is achieved by repetitively\nevaluating a nonlinear set of equations.  \nImbeded in the process is a random or Monte Carlo selection\nof assignments.  As in such heuristic techniques, \nthe solution may not be optimum and many solutions\nmay be found which yield locally minimal results. \n Computer programs are described and empirical results given.\n", "1014": "Machine Controls for Analysis of Variance A major problem in using the analysis of variance,\nas the number of factors increases, is the \nexponential rise in the number of interactions.  Even\nthough the experimenter may not be interested in \nthese interactions it is impossible to ignore them in\nmost experimental designs because of the problem \nof getting error terms.  It is natural therefore to look\nto the computer to handle the bulk of work involved \nin computing the interactions.  A program device\nto get the computer to do this is described.\n", "1015": "Near-Minimax Polynomial Approximations and Partitioning of Intervals A method of near-minimax polynomial approximation\nis described.  As a by-product, this method \nprovides a formula for an estimate of the maximum error\nassociated with a given degree of approximation. \n Using this formula, a partitioning algorithm is obtained\nfor dividing a basic interval into subintervals \nfor which approximations of equal degree give equal maximum error.\n", "1016": "Interchangcable Perforated Tape Variable Block", "1017": "Comments on Bit-Sequencing of the ASCII", "1018": "Gauss (Algorithm 209 [S15])", "1019": "XY move Plotting (Algorithm 162 [J6])", "1020": "Free Field Read (Algorithm 239 [I5])", "1021": "Conjugate Gradient Method (Algorithm 238 [F4])", "1022": "Greatest Common Divisor (Algorithm 237 [A1])", "1023": "Bessel Functions of the First Kind (Algorithm 236 [S17])", "1024": "A Note on the Formation of Free List", "1025": "A Method of Syntax-Checking ALGOL 60 A syntax checker was designed based on the syntax\nof ALGOL as described in the ALGOL 60 Report \n[Communications of the ACM, May, 1960].  Since the definition\nof the elements of the language is recursive \nit seemed most desirable to design the syntax checker\nas a set of mutually recursive processors tied \ntogether by subroutines which perform certain bookkeeping\nfunctions.  Because of the recursive nature \nof the language and of the syntax checker the problem\nof recovery after an error required much attention. \n A method was devised which permits most programs\nto be checked completely despite errors.\n", "1026": "Divide-and-Correct Methods for Multiple Precision Division A division problem is defined and notation\nto relate it to the problem of multiple precision \noperation in a digital computer is introduced.  A basic\ndivide-and-correct method for multiple precision \ndivision is formulated and its known properties briefly\nreviewed.  Of particular interest is the fact \nthat the method produces at each step a set of precisely\nthree estimates for the desired result, one \nof which is exact.\n", "1027": "An Alternate Checksum Method", "1028": "Investigation of a New Analytical Method A recently proposed analytical approach to\nnumerical derivative evaluation is discussed.  The \ntechnique is shown to be both accurate and easy to\napply, though certain indicated modifications are \nrequired.  Its use should greatly facilitate the writing\nand debugging of programs requiring derivatives \nof highly complex functions.\n", "1029": "A Simple Automatic Derivative Evaluation Program A procedure for automatic evaluation of total/partial\nderivatives of arbitrary algebraic functions \nis presented.  The technique permits computation of\nnumerical values of derivatives without developing \nanalytical expressions for the derivatives.  The key\nto the method is the decomposition of the given \nfunction, by introduction of intermediate variables,\ninto a series of elementary functional steps.  A \nlibrary of elementary function subroutines is provided\nfor the automatic evaluation and differentiation \nof these new variables.  The final step in this process\nproduces the desired function's derivative.  \nThe main feature of this approach is its simplicity.\n It can be used as a quick-reaction tool where the \nderivation of analytical derivatives is laborious and\nalso as a debugging tool for programs which contain \nderivatives.\n", "1030": "Techniques for the Simulation of Computer Logic The simulation of a digital computer is an\nintegral part of most computer design automation \nsystems.  The evaluation of the Boolean functions which\ncharacterize the computer being simulated constitutes \none major portion of a simulation system.  Four general\nprocedural classes for evaluating these functions \nare defined.  Toward greatly increased efficiency of a simulation\nsystem, methods are presented for simultaneously \nevaluating many functions for one set of values of the\nvariables,and for evaluating simultaneously one \nfunction for many sets of values for the variables.\n", "1031": "A Note on Starting the Newton-Raphson Method Determination of a suitable initial estimate\nfor a root of an equation f(x) = 0 by means of \ncomputing the roots of a sequence of related equations is described.\n", "1032": "Theoretical Considerations in Information Retrieval Systems Information storage and retrieval systems are composed\nof three major components: (a) identification \nof information and tagging it for effective retrieval,\n(b) searching strategy, how to enter the file \nto circumvent the scanning of nonrelevant material, and\n(c) file organization to make access to information \nefficient.  For identification of information the paper\nsuggests that a metalanguage (recently discussed \nin a paper by Goffman, Verhoeff and Belzer) associated\nwith an object language be used.  For searching \nstrategy, a linear model for an evaluation function\nof relevancy is developed which rewards the system \nfor retrieving relevant documents and not retrieving\nthe nonrelevant, and penalizes the system for the \nescaped relevant documents and false drops.  The inadequacies\nof a linear model are indicated.  Two approaches \nto file organization are discussed.  One is self-organization\nof the file based on its history and past \nperformance, and the second is a self-generating subset\nof the file with a high probability of being \nrelevant.\n", "1033": "Experimental Personalized Array Translator System A system designed for intimate man-machine\ninteraction in a general-purpose problem-solving \nenvironment is experimentally operational.  The system\nutilizers an array-oriented symbolic source language \ncontaining powerful statement types.  These include numeric,\nBoolean, relational and selection operators \non operands which can be entire arrays.  The system also\npermits simple specification of test and argument \narrays in single statements.  The completely symbolic\noperating system includes display and entry of \nprogram and data.  Sequence control is aided by an interrupt\nswitch which allows the user to interact \nwith the program during execution. In addition to normal\nstored program sequencing, the system provides \ntrace options and the ability to enter any statement\nfor immediate execution.  Present implementation \nof the system is with an interpretive translator on an IBM 1620 computer.\n", "1034": "Autosate An automated data system analysis technique is\ndescribed. The technique is designed to alleviate \nsome of the principal problems that beset current analysis-large\ndata workloads, long span of time between \nproject inception and system operational date, the lack\nof explicit directions for conducting data system \nanalysis and using the results, and the lack of a technique\nto control data system changes throughout \nits lifetime. The analysis is geared to determining workload,\nrelationships and storage characteristics \nof documents in the information network automatically.\n", "1035": "Characteristics of the FORTRAN CEP Language The FORTRAN CEP languages differs from FORTRAN\nII mainly because: (1) it extends the variety \nof the modes for real quantities; (2) it allows suitable\nmixtures, in an input/output list or in an expression, \nof quantities that occur under different modes; (3)\nit makes it possible to address a greater number \nof input/output equipment; and (4) it removes the restrictions\non the complexity of the list of quantities \nto be transmitted between the magnetic core memory\nand the drum or the magnetic tape units.\n", "1036": "Remark on Further Generalization of ALGOL", "1037": "Reduction of a Matrix Containing Polynomial", "1038": "Crout with Equilibration and Iteration (Algorithm 135 [F4])", "1039": "Summation of Fourier Series (Algorithm 128 [C6])", "1040": "Romberg Integration(Algorithm 60 [D1])", "1041": "Random Permutation (Algorithm 235 [G6])", "1042": "Poisson-Charlier Polynomials (Algorithm 234 [S23])", "1043": "Talk-A High-Level Source Language Debugging TALK, meaning Take A Look, is a debugging technique\nwhich aids substantially in debugging complex \nreal-time programming systems by interrupting the users\nprogram at desired points to extract previously \nspecified data.  The extracted data is later edited,\nlisting the associated data with its high-level \nsource language identification.\n", "1044": "An Automatic Loader for Subroutine Nests A method for automatic loading of library subroutines,\nwhich can be adapted to operate in conjunction \nwith any conventional two-pass assembler is described.\n The method is specifically designed to cope with \na nested library structure.\n", "1045": "Programming Analysis of Variance by Sequences A special operator calculus developed by Hartley\nin 1956 together with a new mapping scheme \nhas been found to be efficient in programming analysis\nof variance for multifactor experiments. The operator \ncalculus and the mapping scheme are described in detail.\n", "1046": "A Compiler-Building System Developed by Brooker and Morris In a number of articles published during the\npast two years, R. A. Brooker and D. Morris (joined \nby J.S. Rohl in their most recent paper have presented\na very interesting programming system that they \nhave developed for the Ferranti Atlas computer.  The\npresent paper describes some of the major features \nof their system. it expands on some points that the original\nauthors cover briefly, and treats only very \nlightly some topics to which they devote considerable space.\n The purpose of this paper is purely expository. \n Except in some very small details, and in some comments,\nit does not intentionally depart from or add \nto the material published in the listed references.\n", "1047": "Generation of Test Matrices by Similarity Transformations A method for obtaining test matrices with\na prescribed distribution of characteristic roots \nis given.  The process consists of using particularly\nsimple similarity transformations to generate full \nmatrices from canonical forms.  The matrices generated\nalso have known characteristic vectors, inverses \nand determinants.\n", "1048": "Approximate Solution of Axially Symmetric Problems A variety of physical problems in such diverse\nfields as electrostatic  field theory, heat \nand ideal fluid flow, and stress concentration theory\nreduce, under the assumption of axial symmetry, \nto the study of an elliptic partial differential equation.\n Dirichlet-type problems associated with this \nequation are studied on regions whose boundaries include\na nondegenerate portion of the x-axis and exceedingly \naccurate numerical methods are given for approximating solutions.\n", "1049": "Numerical Solution of Nonlinear Two-Point Solution of nonlinear two-point boundary-value\nproblems is often an extremely difficult task. \n Quite apart from questions of reality and uniqueness,\nthere is no established numerical technique for \nthis problem.  At present, shooting techniques are the\neasiest method of attacking these problems.  When \nthese fail, the more difficult method of finite differences\ncan often be used to obtain a solution.  \nThis paper gives examples and discusses the finite difference\nmethod for non-linear two-point boundary-value \nproblems.\n", "1050": "A Parts Breakdown Technique Using List Structures List structured parts breakdown is proposed\nand discussed.  Implementation facts are presented \non operating program using these techniques.\n", "1051": "Multiword List Items The list concept as originally proposed by\nNewell, Simon and Shaw specified single computer \nwords as elements of a list.  This report describes the\nuse of two or more consecutive words as one element. \n Such use results in a considerable saving in both the\nspace required to hold a given amount of data, \nand in the execution time required to perform a given\nprocess on the data.  Following a brief description \nof standard list structures with single-word items, the\nmultiword items are introduced.  Then variable-length \nitems are described, along with the corresponding space-utilization\nproblems.  Finally, several examples \nare given to illustrate the use of multiword lists. This\npaper attempts to draw together various recent \npapers which have applied some of these concepts in different\nways, and indicate how they relate to the \nmore general problems.\n", "1052": "Reducing Truncation Errors by Programming In accumulating a sum such as in a numerical\nintegration with a large number of intervals, \nthe sum itself becomes much larger than the individual\naddends.  This may produce a less accurate sum \nas the number of intervals is increased.  Separate variables\ncan be established as accumulators to hold \npartial sums within various distinct intervals.  Thus,\nthe extensive successive truncations are eliminated.\n", "1053": "Design and Implementation of a General-Purpose Input Routine A general-purpose input routine is discussed\nand advocated for FORTRAN.  The philosophy of \nsuch programs is examined and exemplified.\n", "1054": "Gauss-Seidel (Algorithm 220 )", "1055": "q-Bessel Functions In(t) (Algorithm 214)", "1056": "Shellsort (Algorithm 201)", "1057": "Critical Path Scheduling (Algorithm 40)", "1058": "Simpson's Rule for Multiple Integration (Algorithm 233)", "1059": "Heapsort (Algorithm 232)", "1060": "Matrix Inversion (Algorithm 231)", "1061": "Matrix Permutation (Algorithm 230)", "1062": "Symbol Manipulation in FORTRAN-SASP I Subroutines A set of subroutines for use in FORTRAN are\ndescribed whose purpose is to synthesize output \nstrings from (i) input strings which have been analyzed\nby the SHADOW general syntactic analysis subroutine \nreported earlier, and/or (ii) packed BCD strings formed\nin any way.  Function-type subroutines are included \nfor intermediate manipulations, which are performed\non the strings which are stored in an abbreviated \ninternal representation.  The automatic way in which\nan internal representation for each newly created \nsubstring is stored sequentially in a block of common\nstorage, and the manner in which a storage block \nis dynamically allocated for that purpose, are discussed.\n", "1063": "One-Inch Perforated Paper Tape for Information", "1064": "Perforated Tape Code for Information", "1065": "Bit Sequencing of the American Standard Code for", "1066": "Growing Applications of Linear Programming Use of linear programming models has grown so\nextensively in recent years that the whole concept \nfor organizing a computer code has undergone a radical\nchange.  It no longer is adequate merely to reduce \na mathematical algorithm (i.e. the simplex method) to\na computer code.  An advanced code must cope with \nsuch a variety of situations that the respective computer\nsubprograms must be organized into an integrated \nsystem.  Emphasis in this paper is devoted to the underlying\nprinciples upon which future linear programming \nsystems must be based.  These viewpoints are influenced\nby the new demands that applications within the \npetroleum industry are placing on such systems.  Some\nof the components of such a system are: translation \nof problem statement in terms of basic data to linear\nprogramming matrix coefficients, data transmission \nfor direct computer entry, data file at the computer center,\ndata processing and editing prior to solving \nthe simplex algorithm, an efficient and reliable code\nfor solving the above-mentioned algorithm, and \nflexible means for summarizing the results.\n", "1067": "Picture Generation With a Standard Line Printer A method is described for producing gray-toned\npictures on a line printer by utilizing the \ndifferent degrees of blackness of standard print characters.\n Gray scales with 17, 32 and 64 levels have \nbeen devised.  Scanned images of blood cells are used to display the technique.\n", "1068": "A FORTRAN II Load-Time-Saver", "1069": "A Method for Comparing the Internal Operating Speeds of Computers", "1070": "Expand, A System for Input Card Replication", "1071": "Computer-Usage Accounting for Generalized Time-Sharing Systems The current development of general time-sharing\nsystems requires a revision of accounting procedures \nfor computer usage. Since time-sharing system users\noperate concurrently, it is necessary to be more \nprecise as to the amount of computer time and storage\nspace that a user actually utilizes.  The various \ncost factors which should be considered for computer usage\naccounting in generalized time-sharing systems \nare discussed.\n", "1072": "An Improved Equivalence Algorithm An algorithm for assigning storage on the basis\nof EQUIVALENCE, DIMENSION and COMMON declarations \nis presented.  The algorithm is based on a tree structure,\nand has reduced computation time by 40 percent \nover a previously published algorithm by identifying all\nequivalence classes with one scan of the EQUIVALENCE \ndeclarations.  The method is applicable in any problem\nin which it is necessary to identify equivalence \nclasses, given the element pairs defining the equivalence relation.\n", "1073": "A Fast Procedure for Generating Exponential Random Variables A very fast method for generating exponential\nrandom variables in a digital computer is outlined.\n", "1074": "Shanks (Algorithm 215)", "1075": "Shuttlesort (Algorithm 175)", "1076": "Multiple Integration (Algorithm 146)", "1077": "Chebyshev Curve Fit (Algorithm 91)", "1078": "Elementary Functions by Continued Fractions (Algorithm 229)", "1079": "Q-Bessel Functions (Algorithm 228)", "1080": "Chebyshev Polynomial Coefficients (Algorithm 227)", "1081": "Normal Distribution Function (Algorithm 226)", "1082": "Gamma Function with Controlled Accuracy (Algorithm 225)", "1083": "An Experiment in a User-Oriented Computer System A version of a software-hardware system for\nthe purpose of facilitating the programming and \nanalysis of well-formulated problems is described.  A modified\nFlexowriter is used to generate computer-acceptable \ninput when equations or computable requests are typed\nin much the same manner as they would appear in \nconventional mathematical texts.  The typing and language\nrules are quite flexible and unrestrictive. \n While the compiler part is efficient, the system as\na whole has much broader aspects as a tool for the \nstudy of problem solving and self-teaching systems.\n", "1084": "On Declaring Arbitrarily Coded Alphabets The inability of existing programming languages\nto handle character strings from more than \none or two alphabets is mentioned and a scheme for declaring\nadditional alphabets is proposed.  The scheme \nprovides for: many-to-one encodings, right or left\njustification, collating sequences different from \nnumeric sequence, variations in character size (number\nof bits.) from alphabet to alphabet, and arbitrary \nsource-language character representation.\n", "1085": "Specification for General-Purpose Paper Cards for", "1086": "A Proposal for Input-Output Conventions in ALGOL", "1087": "Problems in Automatic Abstracting A variety of problems concerning the design\nand operation of an automatic abstracting system \nare discussed.  The purpose is to a general view of\nseveral major problem areas.  No attempt is made \nto discuss details or to indicate preferences among alternative solutions.\n", "1088": "Menu Planning by Computer A computer code has been developed which plans\nmenus by finding minimum cost combinations of \nmenu items such that the daily dietary, gastronomic\nand production requirements can be satisfied for \na sequence of days.  A fast, special integer programming\nalgorithm is described which approximates the \ntheoretical solution to the problem.  If necessary, any\nmenu can be changed on-line and then post-optimized. \n Up to 30 percent saving on food cost is possible. \nA FORTRAN program for the IBM 1410 is available on \nrequest.  A considerable amount of data processing\nmust precede the implementation of the system.\n", "1089": "Designing a Computer Center", "1090": "Incomplete Beta Function Ratios (Algorithm 222)", "1091": "Hypergeometric and Confluent Hypergeometric (Algorithm 191 & 192)", "1092": "Nonrecursive Adaptive Integration (Algorithm 182)", "1093": "Evaluation of Determinant (Algorithm 224)", "1094": "Prime Twins (Algorithm 223)", "1095": "Decimal Tables of Binary Coded Tables", "1096": "On Avoiding Matrix Reversals Between 7090 FORTRAN II and 7090 FORTRAN IV", "1097": "An Algorithm for Converting Integers from Base A to Base B A little known, simple algorithm for integer\nconversion between number systems is presented \nand proved.\n", "1098": "A Comparison of List-Processing Computer Languages A detailed comparison is presented of COMIT,\nIPL-V, LISP 1.5 and SLIP - four well-known computer \nprogramming languages which, among them, exhibit all the\nprincipal characteristics of existing list-processing \nlanguages.  Important common features of list-processing\nlanguages are reviewed: forms of data structures \nwhich are manipulated, necessity for dynamic allocation\nof storage, use of pushdown stores, and use of \nrecursive operations.  Principal differences between the\nfour languages under consideration are detailed: \nrepresentations of data, both by the programmer and within\nthe machine; methods for storage allocation; \nprogramming formalisms and special processes available,\nincluding arithmetic facilities; and usability \nin terms of availability, documentation, learning aids\nand debugging facilities.  A rough comparison \nshows that all the languages discussed have approximately\nthe same speed.  Finally, the authors give \nsome heuristics to aid in the selection of one of these\nlanguages for use in particular problem applications, \nconcluding that no one of the languages considered is\ndistinctly superior in all possible list-processing \napplications.\n", "1099": "Professional Computer Work for the Blind Developments in computer technology have opened\nnew professional opportunities for the intelligent \nblind.  Since there are few if any occupations in which the\nblind can participate without serious disadvantage, \nthe opportunities offered them to gain entrance into\nvarious occupations through computer use including \nthat of programmer, is important for future rehabilitation\nplanning. Also of immediate interest is the \nfact that the blind may be especially suited for programming\nwork.  Because of intense training in and \nconstant experience with locating objects in the unseen\nenvironment and also because of superbly trained \nmemory, the blind brings to the work of programming skills\nwhich the sighted has had little need to acquire. \n These qualifications should result in fewer debugging\nproblems and make the blind a valuable addition \nto any systems group.  Before the blind could become a\nserious professional, a number of aids and techniques \nhad to be developed that can mediate between machines\nand programmer.  This paper describes the techniques \nand aids which were designed by the staff of the Medical\nComputing Center of the University of Cincinnati \nCollege of Medicine.\n", "1100": "Status of Computer Sciences Curricula in Colleges and Universities", "1101": "The Place of Logical Design and Switching", "1102": "Mechanical Languages: A Course Specification", "1103": "Logic for the Computer Sciences ", "1104": "An Undergraduate Curriculum in Numerical Analysis", "1105": "On Introducing Digital Computing", "1106": "Programming of Digital Computers", "1107": "Computers and Education", "1108": "Digital Data Processor for Tracking the Partially Illuminated Moon* A study of lunar tracking techniques and fabrication\nof a breadboard to assess the feasibility \nof the best technique selected was conducted to define\na tracking system for observation of the sight line \nto the center of a partially illuminated moon.  The\ndata processing portion of the system is presented \nin detail and then described in general are the operation\nof the tracker head assembly for data readout, \nthe operation of the entire system and the effect data\nprocessing considerations have on the design of \nthe tracker system.  The system basically consists of\nan optical sensor, digital computer and tracker \ndrive mechanism.  The three system units, connected\nin cascade, comprise the control loop.  For this \napplication, an optical telescope with a radial mechanical\nscanning mechanism was used that read out \nlunar sight line measurement information.  This information\nis sequentially read into a special purpose \ndigital computer that extracts the measurements and\ncomputes the error signals that drive the tracker \nto the appropriate attitude.\n", "1109": "Conversion of a Power to a Series of Chebyshev Polynomials* Even slowly convergent power series can be\nrearranged as series in Chebyshev polynomials if \nappropriate sequence transformations are used in evaluating\nthe coefficients.  The method is illustrated \nby computing the coefficients for the expansion\nof the logarithm and dilogarithm.\n", "1110": "A Fourier Series Method for the Numerical Solution A Fourier series method is described which, when\napplied to a certain class of parabolic partial \ndifferential equations, reduces the problem to a system\nof ordinary differential equations.  An application \nis given for which the method shows a considerable advantage\nover conventional finite difference methods.\n", "1111": "A Class of Iterative Techniques For the Factorization of Polynomials* A method of iteration is developed in terms\nof a function of somewhat arbitrary character. \n Sufficient conditions are given for convergence of\nthe process, yielding factors of arbitrary degree \nfor polynomials in one variable.  Both Lin's method\nand Newton's method occur as special cases.\n", "1112": "A Technique for Computer Detection and Correction of Spelling Errors* The method described assumes that a word\nwhich cannot be found in a dictionary has at most \none error, which might be a wrong, missing or extra letter\nor a single transposition.  The unidentified \ninput word is compared to the dictionary again, testing\neach time to see if the words match-assuming \none of these errors occurred.  During a test run on garbled\ntext, correct identifications were made for \nover 95 percent of these error types.\n", "1113": "Computer-Made Perspective Movies as a Scientific and Communication Tool* It is easy to program the basic transformation\nrequired for a perspective drawing.  This fact \nplus the advent of high speed microfilm printers such\nas the General Dynamics Electronics S-C 4020 makes \npossible perspective movies as the direct output from\na computer.  The programming of such a movie is \nbriefly described for studying the angular motions of\na satellite containing an attitude control system. \n In the movie, a domino-shaped box represents the satellite\nand a sphere with circles of latitude and \nlongitude represents the earth.  The cost was approximately\nthree to eight minutes of IBM 7090 time per \none minute of movie.\n", "1114": "Generating a Canonical Prefix Encoding* Computer programs for generating a minimum-redundancy\nexhaustive prefix encoding are described. \n One program generates a Huffman frequency tree, another\ndetermines the structure functions of an encoding, \nand a third program assigns codes.\n", "1115": "Randomized Binary Searching With Tree Structure A more efficient method of using tree structures\nis proposed, which utilizers both plus and \nminus branches in the search path.  Very significant\ngains result when the search key includes alphabetic \ncharacters.\n", "1116": "Tests on a Computer Method for Constructing School Timetables* A previously proposed computer method for constructing\ntimetables, based on an iteration involving \nBoolean matrices, is described.  In limited tests the\nmethod has successfully produced timetables on \nevery trial.  References are given which relate the\ntimetable problem to theorems on matrices of zeros \nand ones, and to theorems on bipartite graphs.  Some\nproblems of applying the method to constructing \ntimetables in real situations are noted.\n", "1117": "Polyphase Sorting With Overlapped Rewind* A variation of the polyphase merge technique\nof sorting is described which permits one tape \nat a time to be rewound while the merge is continued on\nthe remaining tapes.  The result is the overlapping \nof a major portion of the rewind time.  The technique\nshould be considered whenever a sort is written \nto operate on five or more tapes that cannot be read backwards.\n The savings of the overlap method appear \nto increase as the number of available tapes is increased.\n", "1118": "FORTRAN Subroutines for Time Series Data Reduction*", "1119": "An Open Letter to X3.4.3 (FORTRAN Standards -- American Association)", "1120": "\"ALCOR Group Representations of ALGOL Symbols,\"", "1121": "Comments on \"A Continued Operation Notation\"* This note is intended to clarify and correct\nseveral points in a recent paper describing some \nnotations for symbol manipulation by M.P. Barnett [Comm. ACM 6(August, 1963)].\n", "1122": "A Note on Some Compiling Algorithms Two compiling generators for arithmetic expressions\nare discussed: one presently in use in \nan experimental compiler, and an improvement\nsuggested by K. Speierman of Burroughs.\n", "1123": "Gauss (Algorithm 209)", "1124": "Matrix Division (Algorithm 197)", "1125": "Syminv2 (Algorithm 150)", "1126": "ERF (Algorithm 123)", "1127": "Tridiagonal Matrix (Algorithm 122)", "1128": "Evaluation of Determinant (Algorithm 41)", "1129": "Incomplete Beta Function Ratios (Algorithm 222)", "1130": "Gamma Function (Althm 221)", "1131": "On Context and Ambiguity in Parsing*", "1132": "An Extension to ALGOL for Manipulating Formulae*", "1133": "A Programming Package for Some General Modes of Arithmetic*", "1134": "Some Effects of the 6600 Computer on Language Structures* The problem of compiling efficient 6600 codes\nprompted the development of an intermediate language \nreflecting the structure of the machine, that is more\neasily manipulated in improving object program \nefficiency.  The subject of this paper is the intermediate\nlanguage and methods of manipulating it.  \nCompilations of a series of arithmetic statements are\ndiscussed.  It is assumed that all functions and \nexponentials have been removed from these statements,\nand replaced by simple variables.  For purposes \nof simplicity the treatment of subscripts is ignored. \nA simplified 6600 structure is presented to illustrate\nthe compiling method.  Several assumptions are made\nfor purposes of simplification, although there are \ncases in which the assumptions are violated in the actual machine.\n", "1135": "A General Business-Oriented Language Based on Decision Expressions* The structure of a digital compute programming\nlanguage which covers a wide class of business \nand file processing applications is presented.  Such\na structure, based on identifying and incorporating \ninto a compiler the aspects common to all processes\nof such class, permits writing extremely compact \nprograms, even for comparatively complex applications,\nin terms of tables of control expressions which \nexpress only information characteristic of the particular\napplication.  Furthermore,local changes of \na process (e.g. changes affecting only one of the output\nfiles involved) can be effected by local modifications \nin the program (e.g. modification of only one entry of the\ntables).  This structure also allows for inexpensive \npreparation of loading-speed compilers which translate the\nsource programs into efficient machine codes. \n The approach adopted here departs from conventional mechanical\nlanguage design philosophies.  It stresses \nthe structural analysis of the class of processes to be represented\nin the languages, as opposed to emphasizing \nformal (i.e., contents-independent) syntactical definitions.\n It relies exclusively on nonprocedural \nrepresentation of process as sets (tables) of relations\nbetween data and results (there are no control \nstatements such as GO TO, etc.), instead of using procedure\ndescriptions (which are one-to-one translations \nof flowcharts).  Here an invariant pattern of procedure\nis identified as characteristic of the class \nof all batch file processes.  This new philosophy has\nthe potential to overcome well-known deficiencies \nof other business-oriented languages and fully meets\nthe requirements set by CODASYL for such languages, \nincluding machine-independence.\n", "1136": "Beginnings of a Theory of Information Handling*", "1137": "A Format Language*", "1138": "Formalism in Programming Languages*", "1139": "FORTRAN IV as a Syntax Language*", "1140": "\"Structural Connections\" in Formal Language*", "1141": "Bounded Context Syntactic Analysis", "1142": "An Extension of ALGOL-Like Languages", "1143": "Analysis of Decay-Type Data* A comparative study has been made of a variety\nof numerical techniques for fitting experimental \ndata of the decay type by forms involving the sums of\nexponentials.  Statistical errors of the fitted \nparameters are also calculated.  These methods have been\napplied to artificially-generated sets of data \nas well as to the results of experiments with radioactive\ntracers on both human and animal subjects. \n Results show that the values of the fitted parameters\nare very sensitive to variations in the fitting \nprocedure.  Therefore great care very sensitive to variations\nin the fitting procedure.  Therefore great \ncare must be exercised in identifying such values with\nphysical constants.  Although the values of functions \nderived from these fitted parameters which can definitely\nbe associated with physical entities are generally \nmore stable under variations in the fitting techniques,\nerror bounds can be so large that no great confidence \ncan be placed even in them.  It would therefore appear\nbest to select a uniform technique both for running \nthe experiments and for analyzing the data, and then\nto consider as significant only relative results \nbetween one subject and the next.\n", "1144": "Digital Computer Determination of Alpha Source Activity A technique is described for determining the\nactivity and homogeneity of an alpha source.  \nIt is believed that the technique, using a digital computer,\nhas many uses and applications in the field \nof nuclear physics. The technique involves computer\nmanipulation of the digital image of the nuclear \nsource.  Experimental details are given.\n", "1145": "GIT-A Heuristic Program for Testing Pairs Given a pair of directed line graphs, the problem\nof ascertaining whether or not they are isomorphic \nis one for which no efficient algorithmic solution is known.\n Since a straightforward enumerative algorithm \nmight require 40 years of running time on a very high\nspeed computer in order to compare two 15-node \ngraphs, a more sophisticated approach seems called\nfor.  The situation is similar to that prevailing \nin areas such as game-playing and theorem-proving, where\npractical algorithms are unknown (for the interesting \ncases), but where various practical though only partially\nsuccessful techniques are available.  Git-Graph \nIsomorphism Tester-incorporates a variety of processes\nthat attempt to narrow down the search for an \nisomorphism, or to demonstrate that none exists.  No one\nscheme is relied upon exclusively for a solution, \nand the program is designed to avoid excessive computation\nalong fruitless lines.  GIT has been written \nin the COMIT language and successfully tested on the IBM 7090.\n", "1146": "An Efficient Composite Formula for Multidimensional Quadrature A (2s+1)-point second-degree quadrature formula\nfor integration over an s-dimensional hyper-rectangle \nis presented.  All but one of the points lie on the\nsurface with weights of opposite sign attached to \npoints on opposite faces.  When a large volume is subdivided\ninto congruent rectangular subdivisions, \nonly one point is required in each interior subdivision\nto achieve second-degree accuracy.\n", "1147": "On the Numerical Solution of Boundary Value Problems A numerical method is presented for the solution\nof boundary value problems involving linear \nordinary differential equations.  The method described\nis noniterative and makes use of any one-step \nnumerical integration scheme to reduce the problem from\none of boundary values to one of initial values. \n Comments are made concerning some numerical results\nof applying the method to a specific problem.  In \naddition an extension of the algorithm described\nto more general problems is discussed.\n", "1148": "An Example in \"Significant-Digit\" Arithmetic* Different methods of handling the summing process\nfor the geometric series are shown to give \nresults indicating widely differing significances when carried\nout in a machine incorporating \"significant-digit\" \narithmetic.\n", "1149": "GARGOYLE , A Language for Compiler Writing*", "1150": "A Fortran Post-Mortem Procedure", "1151": "A Note on Multiplying Boolean Matrices II", "1152": "Floating-Point Arithmetic with 84-Bit Numbers A classic and straightforward technique is\npresented which is not limited to the size or type \nof number representation used or multiple precision arithmetic.\n", "1153": "A Fast Procedure for Generating Normal Random Variables* A technique for generating normally distributed\nrandom numbers is described.  It is faster \nthan those currently in general use and is readily\napplicable to both binary and decimal computers.\n", "1154": "Multi-Tape and Infinite-State Automata -- A Survey A survey of machines which are more powerful\nthan finite automata and less powerful than general \nTuring machines is presented.  It is felt that the machines\nin this category are as closely related to \ndigital computers as either the finite automata or the\nunrestricted Turing machines.  Intermediate machines \ncan be created by adjoining on infinite-state memory\nto a finite-state machine and then performing any \nor all of the following: (1) restrict the manner in\nwhich the unbounded portion of the memory can be \naccessed, (2) bound the number of steps allowed for a\ncomputation by some increasing recursive function \nof the length of the input, (3) restrict the total amount\nof memory available in the same manner.  Examples \nfrom all three classes and their properties are discussed.\n", "1155": "Experiments with a Deductive Question-Answering Program As an investigation in artificial intelligence,\ncomputer experiments on deductive question-answering \nwere run with a LISP program called DEDUCOM, an acronym\nfor DEDUctive COMmunicator. When given 68 facts, \nDEDUCOM answered 10 questions answerable from the facts.\n A fact tells DEDUCOM either some specific information \nor a method of answering a general kind of question.\n Some conclusions drawn in the article are: (1) \nDEDUCOM can answer a wide variety of questions.  (2)\nA human can increase the deductive power of DEDUCOM \nby telling it more facts.  (3) DEDUCOM can write very\nsimple programs (it is hoped that this ability \nis the forerunner of an ability to self-program, which\nis a way to learn).  (4)DEDUCOM's search procedure \nat present has two bad defects: some questions answerable\nfrom the given facts cannot be answered and \nsome other answerable questions can be answered only if\nthe relevant facts are given in the \"right\" order. \n (6) At present, DEDUCOM's method of making logical deductions\nin predicate calculus has two bad defects: \nsome facts have to be changed to logically equivalent ones\nbefore being given to DEDUCOM, and some redundant \nfacts have to be given to DEDUCOM.\n", "1156": "Hankel Function (Algorithm 124 [S17])", "1157": "Procedure for the Normal Distribution Functions (Algorithm 272 [S15])", "1158": "Program Structures for Parallel Processing Constructs for organizing and explicating parallel\nprogram segments are discussed as extensions \nto ALGOL 60.  The constructs serve as meta-commands and\nare motivated by equipment having multiprocessing \ncapability.\n", "1159": "Machine Independence: Its Technology and Economics A survey is offered of techniques for transferring\nprograms, and especially compilers, from \none computer to another.  Of the methods examined, the\n\"bootstrap\" technique is singled out for detailed \ndiscussion, with emphasis on its economics. The considerations\nthat determine the applicability of bootstrapping \nin any specific case are discussed, and an attempt\nis made to assign appropriate qualitative weights \nto them.  Finally, reasons are given for believing that the\nmachine-independence problem is being substantially \ndiminished by current trends in computer design, and\nthat it is this process of convergence in hardware \ndesign rather than any foreseeable software developments\nthat will lead to its satisfactory resolution.\n", "1160": "CAT: A 7090-3600 Computer-Aided Translation A semi-automatic translation system has been implemented\nwhich converts 7090 FAP language programs \ninto 3600 assembly language.  The input to the system\nis a FAP program deck which has been specially \nprepared for translation by the user.  The output consists\nof the translated COMPASS language program \ntogether with a comprehensive diagnostic listing which the\nuser must analyze in order to verify any questionable \nareas of the translation.  The translation processor\nconsists of three distinct phases: an assembly of \nthe FAP program, a comprehensive analysis of the assembled\ncode with particular regard to the actions \nof instructions upon other instructions and upon data,\nand finally the output pass which generates the \nCOMPASS program in the form of macro instructions.\n", "1161": "1401 Compatibility Feature on the IBM System/360 Model 30 The \"second generation\" of stored-program computers,\nof which IBM 1400 series was a part, brought \nEDP into the mass market for the first time on a large\nscale.  As this era unfolded, rapid changes in \ntechnology led to rapid obsolescence of data processing\nequipment.  Program written for a particular \nsystem required tedious conversion as incompatible new\nmachines came into use.  The IBM System/360 has \nbeen designed with the conversion problem specifically\nin mind.  One of the conversion aids available \non the Model 30 is the 1401 compatibility feature.  This\nfeature, in conjunction with other aids, permits \na smooth and inexpensive transition to optimum use of the new system.\n", "1162": "An Assembly Language for Reprogramming Complete reprogramming of compiler language programs\nis seldom necessary.  It is assembly language \nprograms which present the greatest difficulty.  Assembly\nlanguages generally provide a one-for-one translation \nfrom a symbolic to a numeric version of a program, that\nis, from assembly language to machine language. \n The meta-language presented here can be used to specify\nthe mapping of any language which conforms to \na canonical list form into an arbitrary stream of bits.\n This bit stream may be treated as a machine \nlanguage program, a character stream, or whatever else\nthe user might desire.  Thus, this meta-language \ncan be used to map from one assembly language into another\nor from the assembly language for one machine \ninto the machine language of another.\n", "1163": "Philco/IBM Translation at Problem-Oriented, Symbolic and Binary Levels A translation system has been developed to\neliminate most of the effort formerly required to \nreprogram Philco 2000 series codes for IBM 7094 operation.\n Experience with this system is limited but \nhighly successful encouraging application of the\ntechniques to other source and object languages.\n", "1164": "Emulation of Large Systems The conversion problem and a new technique\ncalled emulation are discussed.  The technique of \nemulation is developed and includes sections on both the\nCentral Processing Unit (CPU) and the Input/Output \nunit (I/O).  This general treatment is followed by three\nsections that describe in greater detail the \nimplementation of compatibility features using the emulation\ntechniques for the IBM 7074, 7080 and 7090 \nsystems on IBM System/360.\n", "1165": "The Spectra 70/45 Emulator for the RCA 301 The RCA 301 Emulator System is supplied with\nthe Spectra 70/45 as a reprogramming aid.  It \nallows an RCA 301 object program to be run on the Spectra\n70/45 without necessitating changes in the \nRCA 301 object code.  Execution rates are considerably\nbetter than traditional simulation.  The Emulator \nprovides an increase in throughput capacity for the\n301 user on the Spectra 70/45.  The Emulator makes \nuse of both hardware micro-program routines and\nsoftware routines to accomplish its function.\n", "1166": "A Use of Macros in Translation of Symbolic A set of macro-operations has been prepared\nto assist in translating IBM 7090 symbolic assembly \nlanguage programs to IBM 7040 machine language programs.\n This set, inserted at the beginning of the \n7090 symbolic deck, treats incompatible instruction mnemonics\nas macro-instructions to produce equivalent \n7040 instruction sets.  Incompatible instructions are\ncategorized into basic operational classes which \ncan be expressed by a single basic skeleton.  Several levels\nof macro calls are required to supply arguments \nto the basic skeleton for each particular instruction.\n Modification at execution time of the address \nor tag of an incompatible instruction requires incorporation\nof an address-tag equivalent.  I/O is handled \nby generating calls to I/O simulation subroutines.\n", "1167": "On the Translation of Machine Language Programs Automatic translation of machine language\nprograms is becoming a highly desirable goal with \nthe advent of new large-scale computers.  The pitfalls that\nmake it difficult to achieve completely automatic \ntranslations are analyzed, and it is shown that these are\nprimarily of a semantic nature.  A semi-automatic \nprocedure for resolving semantic problems is suggested.\n", "1168": "Across Machine Lines in COBOL The production of a large, file-maintenance-and-retrieval\nprogram system written in COBOL is \ndescribed.  The COBOL language was used specifically to\nenable the system to operate on three IBM computers.\n", "1169": "An Algorithm for Minimizing Backboard Wiring Functions A partially exhaustive algorithm is presented\nfor solving the following problem arising from \nautomatic layout of a computer.  Given an ordered set\nE1, E2,..., EN of N computer components, for each \npermutation of the elements E1, E2.., EN, there is attached\na value of an integer function F.  The algorithm \nfinds a local minimum of F by evaluating the set {Delta\nF} of the increments corresponding to a certain \nset of exchanges of two elements.Then the exchange\ncorresponding to the least negative increment of \n{Delta F} is performed.  The process is iterated and stopped\nwhen the set of the increments is a positive \nor empty set, which, it is proved, corresponds to a\nminimum.  The procedure is similar to the Downhill \nMethod for finding the minimum of a real function F(P),\nand can be applied to other placement problems. \n Experimental results are presented with backboards formed\nby many elements and different initial placements.\n", "1170": "Analyzing English Syntax with a Pattern-Learning Parser A dependency analysis system based on pattern\nrecognition and learning logic was developed \nto infer word classes and rules of syntactic combination\nfrom experience with text which had been analyzed. \n The characteristics used to form word classes are the\ndepth in the dependency tree of each word, the \ndirection of its governor and the same features for\neach of its immediate neighbors. Syntactic rules \nof combination show the relation of a word to its governor\nin the depth pattern of the sentence.  The \nsystem was tested on 400 elementary basic English sentences\nincluding 300 used earlier by Knowlton in \na different learning parser of all 400 sentences.  After\nexperience with 300 sentences it was able to \ngeneralize with 77 percent accuracy to the next 100.\n In accumulative learning trials after the first \n200 sentences it averaged a probability of .9 for accurately\nparsing each new sentence it encountered. \n It was concluded that the system is adequate for learning\nto parse the bulk of basic English but that \nfurther development is required before conclusions about\nits application to ordinary English can be stored. \n The system is operational and available on\nthe ARPA/SDC time-shared computing system.\n", "1171": "A Comparison of the Primal-Simplex and Primal-Dual A statistical comparison of the primal-dual\nand the more commonly used primal-simplex algorithm \nfor solving linear programming problems has been made under\nthe assumption of starting with a full artificial \nbasis.  Under these conditions the primal-dual method\nshows a statistically significant superiority on \nrandomly generated problems.  It has also been found, via\na regression analysis, that the relevant parameters \nin determining the difference in the number of iterations\nbetween the algorithms is not only the number \nof constraints and the number of variables but\nalso the ratio of the latter to the former.\n", "1172": "Conversion of Limited-Entry Decision Tables to Computer Programs Decision tables are useful for describing a\nset of complex decision rules based on given sets \nof conditions.  Algorithms that can efficiently convert\nthe tables into computer programs will extend \nthe usefulness of decision tables to computer users.\n Two such algorithms, based on work done by M. S. \nMontalbano, are described and extended here to handle\ndashes and ELSE-decision rules.  The first algorithm \nminimizes the computer storage space required for the\nresultant program, the second minimizes computer \nrunning time. During the conversion process, both pinpoint\nany contradictions or redundancies among the \nrules in a table.\n", "1173": "The Performance of a System for Automatic Segmentation The GIER ALGOL compiler makes use of an automatic\nsystem for handling the transfers of program \nsegments from the drum store to the core store at program\nexecution time.  The logic of this system is \ndescribed. The performance of the system is discussed,\nprimarily on the basis of execution times related \nto two specific programs.  This discussion concludes with\nan assessment of the potential gains of various \nways of improving the system.\n", "1174": "Inverse Permutation (Algorithm 250 [G6])", "1175": "Quickersort (Algorithm 271 [M1])", "1176": "Finding Eigenvectors by Gaussian Elimination (Algorithm 270 [F2])", "1177": "Determinant Evaluation (Algorithm 269 [F3])", "1178": "ALGOL 60 Reference Language Editor (Algorithm 268 [R2])", "1179": "PUFFT-The Purdue University Fast FORTRAN Translator A core resident, compile-and-go system designed\nfor the IBM 7090/7094 computer is described. \n In little more than half of the 32k word core memory\nPUFFT provides a monitor for job sequencing, a \ntranslator for the full FORTRAN IV language, the FORTRAN\nsubroutine library, an input--output system \nfor use at compile time and at execute time, and a rather\nelaborate diagnostic message writing routine. \n Batches of small- and medium-sized FORTRAN IV source\nlanguage programs are processed at very high speeds. \n Language compatibility has been maintained so that\nprograms may be debugged in the PUFFT system and \nthen recompiled and run in the IBJOB-IBFTC system supplied by the manufacturer.\n", "1180": "AXLE: An Axiomatic Language for String Transformations AXLE is a language designed for data manipulation.\n Data arranged in a linear form in a workspace \nis transformed according to a table of axioms, called imperatives.\n A transformation consists of a matching \nprocedure, which decides where an imperative is applicable,\nand a replacement procedure that modifies \nthat part of the workspace.  Imperatives are applied\nin accordance with definitions of symbolic terms, \npresented systematically in an assertion table.  The\nprocess of definition includes the special case \nof recursive assertions.  Several complete programs\nof imperatives are given to show a few applications\nof the language.\n", "1181": "A Simple Data Transmission System Using the Office Telephone A method has evolved for transmitting data of\na type originating in many laboratory situation \ndirect to a central computer.  The method requires almost\nno specialized equipment and uses any ordinary \ntelephone on a \"callup\" basis.  Present applications\ninclude cardiac-output calculations, radio-activity \ntracer studies and neurophysiology time-sequence studies of nerve impulses.\n", "1182": "Contextual Correlates of Synonymy Experimental corroboration was obtained for\nthe hypothesis that the proportion of words common \nto the contexts of word A and to the contexts of word\nB is a function of the degree to which A and B \nare similar in meaning.  The shapes of the functions,\nhowever, indicate that similarity of context is \nreliable as criterion only for detecting pairs\nof words that are very similar in meaning.\n", "1183": "A Note on the Use of a Digital Computer A special purpose compiler was written with\nFORTRAN II language and made possible the writing \nof very long programs by the computer.  The procedure is\nbased on a straight-forward use of FORMAT statements \nfor generating machine-written programs.\n", "1184": "A Fast Storage Allocator A fast storage bookkeeping method is described\nwhich is particularly appropriate for list-structure \noperations and other situations involving many sizes\nof blocks that are fixed in size and location.  \n This scheme, used in the LLLLLL or L6 (Bell Telephone Laboratories\nLow-Level List Language), makes available \nblocks of computer registers in several different sizes:\nthe smaller blocks are obtained by successively \nsplitting larger ones in half, and the larger blocks are reconstituted\nif and when their parts are simultaneously \nfree.\n", "1185": "A program to Solve the Pentomino Problem by the Recursive Use of Macros A coding technique is described in which certain\nmacro-instructions are given lists as arguments \nand are thereby used recursively.  The discussion covers\nprimarily an example in which the technique \nis used to solve the pentomino problem-the problem of\nfitting 12 pentominos without overlapping into \na plane area formed of 60 elemental squares.\n", "1186": "Recursive Solution of a Class Of Combinatorial Problems: An Example Combinatorial problems requiring the selection\nof n elements from a set of m elements may be \nsolved by a recursion process analogous to that for\ncomputing binomial coefficients.  Several specific \nproblems are analyzed, the general technique is exposed,\nand an ALGOL program is developed for one of \nthe problems.\n", "1187": "Note on an ASCII-Octal Code Table (Standards)", "1188": "An ALGOL-like Computer Design Language The idea of constructing a computer design\nlanguage by making use of an ALGOL-like programming \nlanguage is presented.  A computer designer can benefit\nfrom using a design language at a higher level \njust as a computer user can benefit from a higher level\nprogramming language.  The purposes and requirements \nof the design language are enumerated.  To achieve most\nof the purposes a translator is required to translate \na design of computer logic into a set of Boolean equations.\n The design language is presented in terms \nof vocabulary, statements, sequences and microprogram.\n Included are examples of identifiers, expressions \nwith both unary and binary operators, declaration statements,\ntransfer statements, terminal statements, \nexchange statements, if statements, do statements, go\nto statements, several sequences and a microprogram.\n", "1189": "Random Normal Deviate (Algorithm 267 [G5])", "1190": "Pseudo-Random Numbers (Algorithm 266 [G5])", "1191": "Find Precedence Functions (Algorithm 265 [L2])", "1192": "Interpolation in a Table (Algorithm 264 [E1])", "1193": "Gomory 1 (Algorithm 263 [H])", "1194": "Establishment of the ACM Repository and Principles The history of the establishment of the ACM Repository\nat the Moore School, University of Pennsylvania, \nis reviewed briefly.  Two principles are presented as\nparamount in the provision of information services: \n(1) easy accessibility to the information files by users\nunfamiliar with file organization, and (2) value \nof service exceeding user costs.  These principles serve\nas guides in mechanizing the ACM Repository. \n The main features of the information system are direct\nuser access via on-line teletypewriter console, \ndirect user access to all details of the system organization,\nunrestricted and expandable search vocabulary, \nuser access through many facets of document indexing,\nand stochastic search through linked index terms \nand other file relationships.  The first contribution\nto the ACM Repository consisted of 315 documents, \nrelating primarily to early research on compilers.  These\ndocuments have been cataloged and indexed and \nthe catalog is scheduled to appear in Computing Reviews.\n The indexing system is described in detail. \n The Main Catalog is used to describe the documents,\nand inverted lists are provided by the Repository \nsystem for retrieval by concept coordination.\n", "1195": "UPLIFTS-University of Pittsburgh Linear File Tandem System A series of computer programs has been developed\nand is now operational for processing the \nNational Aeronautics and Space Administration linear file\nsystem on an IBM 1401-7090 combined data processing \nsystem.  The program are note-worthy in that they create\nfixed length logical records and fixed length \nblocks from variable length source data, and format\nthe output for optimization of processing on the \nIBM 7090 system.  The programs are completely self-checking\nand test for both validity and accuracy of \nthe input materials as provided by the National\nAeronautics and Space Administration.\n", "1196": "Applications of Differential Equations in General Problem Solving A large class of problems leading to digital\ncomputer processing can be formulated in terms \nof the numerical solution of systems of ordinary differential\nequations.  Powerful methods are in existence \nfor the solution of such systems.  A good general purpose\nroutine for the solution of such systems furnishes \na powerful tool for processing many problems.  This is\ntrue from the point of view of ease of programming, \nease of debugging, and minimization of computer time.\n A number of examples are discussed in detail.\n", "1197": "Finding Zeros of a Polynomial by the Q-D Algorithm A method which finds simultaneously all the zeros\nof a polynomial, developed by H. Rutishauser, \nhas been tested on a number of polynomials with real\ncoefficients.  This slowly converging method (the \nQuotient-Difference (Q-D) algorithm) provides starting\nvalues for a Newton or a Bairstow algorithm for \nmore rapid convergence.  Necessary and sufficient conditions\nfor the existence of the Q-D scheme are \nnot completely known; however, failure may occur when\nzeros have equal, or nearly equal magnitudes.  \nSuccess was achieved, in most of the cases tried, with\nthe failures usually traceable to the equal magnitude \ndifficulty.  In some cases, computer roundoff may result\nin errors which spoil the scheme.  Even if the \nQ-D algorithm does not give all the zeros,\nit will usually find a majority of them.\n", "1198": "Solution of a Problem in Concurrent Programming Control A number of mainly independent sequential-cyclic\nprocesses with restricted means of communication \nwith each other can be made in such a way that at any\nmoment one and only one of them is engaged in the \n\"critical section\" of its cycle.\n", "1199": "A Computer Center Simulation Project Today's computation centers are based on rapidly\nchanging technologies of hardware and software \nsystems.  It is difficult, therefore, to base decisions\non experience; in most instances, the benefits \nof comparable experience for a given problem situation\nare not available.  In this paper, a mathematical \nmodel of the Lockheed Central Computer Center is formulated\nthat describes the operation of a computation \ncenter in terms of information nets, decision processes,\nand control functions.  Experiments performed \nwith this model, the results of the experiments,\nand the application of the results are discussed.\n", "1200": "On Reversible Subroutines and Computers that Run Backwards A computer design is describe which permits\nsubroutines to be executed backward as well as \nforward, either with their instructions unchanged or\nreplaced with conjugate instructions.  It is shown \nthat using this concept a number of new subroutine types\ncan be developed with rather unusual properties. \n Since these properties are analogous to certain matrix\noperations, a parallel nomenclature is suggested \nfor their classification.\n", "1201": "Generation of Permutations in Lexico-Graphical", "1202": "Normal Random (Algorithm 200 [G5])", "1203": "Normdey (Algorithm 121 [G5])", "1204": "Character Structure and Character Parity Sense for", "1205": "An Undergraduate Program in Computer Science-Preliminary Recommendations", "1206": "The Self-Judgment Method of Curve Fitting A computer-oriented method for processing and\ncommunicating numerical data is described.  The \nInstrument Reliability Factors (IRF), which exactly\ndefine the limits of reliability of each measured \nitem of information, are used to compute the Maximum\nPermitted Error (MPE) associated with each values \nof each ordinate.  The Self-Judgment Principle (SJP)\nis used to discard wrong information and to compute \nmean values of the parameters and their MPE's in terms\nof the IRF.  Data compatibility tests with any \nnumber of different equations can be made quickly. \nOtherwise intractable problems are easily solved, \nand the design of many experiments is greatly simplified.\n The computational and mathematical techniques \nused to reduce bias in the SJP are discussed.  Inadequacies\nin the statistical and graphical methods \nof curve fitting are noted.\n", "1207": "Remarks on Simulation of Boolean Functions", "1208": "Simulation of Computer Logic by Fortran Arithmetic", "1209": "Negative and Zero Subscripts in Fortran II Programming for the IBM 1620", "1210": "File-Handling Within FORTRAN This note describes some FORTRAN subroutines\nto facilitate handling of tape files.  They allow \nsymbolic naming of information files, without violating\nthe casual scientific programmer's idea of simplicity. \n Some comments on two years use of these subroutines are given.\n", "1211": "A Note on Storage of Strings A method for storing strings is described which\nuses blocks of indefinite size, and is therefore \ncompletely dynamic.  Its relation to similar schemes is discussed.\n", "1212": "Non-linear Extrapolation and Two-Point Boundary Value Problems It is suggested that the convergence properties\nof the usual Picard successive approximation \nscheme may be improved through use of non-linrar extrapolation\ntechniques.  A numerical example is provided.\n", "1213": "Dynamic Format Specifications The use and implementation of two new FORTRAN\nformat conversions are discussed.  These format \ntypes give the FORTRAN programmer control of input/output\nspecifications at execution time.\n", "1214": "Some Experiments in Algebraic Manipulation by Computer  A set of subroutines to allow algebraic manipulations\non the IBM 7094 computer has been written \na List Processor, SLIP.  A series of four problems of increasing\ndifficulty were solved using these routines.\n", "1215": "Some Techniques Used in the ALCOR ILLINOIS 7090 An ALGOL compiler has been written by the\nALCOR group for the IBM 7090.  Some little known \nbut significant techniques in compiler writing, together\nwith organizational details of this compiler, \nare described.  Timing estimates and an indication\nof compiler requirements are also given.\n", "1216": "Symbolic Derivatives Without List Processing, Subroutines, or Recursion A routine has been developed which computes and\nprints out the symbolic derivative of an absolutely \ncontinuous elementary function of one or several variables.\n No use is made of list-processing languages. \n The chain rule is applied and the result is edited to\nproduce results as elegant and efficient as those \nobtained by hand computation.  A subset may be imbeded\nin a formula translator to introduce a differentiation \noperator into an \"algebraic\" programming language.\n", "1217": "Map of Partitions into Integers (Algorithm 264 [A1])", "1218": "Partition Generator (Algorithm 263 [A1])", "1219": "Number of Restricted Partitions of N (Algorithm 262 [A1])", "1220": "9-J Symbols (Algorithm 261 [Z])", "1221": "6-J Symbols (Algorithm 260 [Z])", "1222": "Legendre Functions for Arguments Larger Than One (Algorithm 259 [S16])", "1223": "High Speed Compilation of Efficient Object Code A three-pass compiler with the following properties\nis briefly described:  The last two passes \nscan an intermediate language produced by the preceding\npass in essentially the reverse of the order \nin which it was generated, so that the first pass is the\nonly one which hasto read the bulky problem-oriented \ninput.  The double scan, one in either direction, performed\nby the first two passes, allows the compiler \nto remove locally constant expressions and recursively\ncalculable expressions from loops and to do the \nimportant part of common subexpression recognition.\n Optimization such as the effective use of index \nregisters, although as important, is not discussed since\nthe object code which would be most efficient \nis highly machine dependent.  The discussion is in terms\nof a FORTRAN-like language, although the technique \nis applicable to most algebraic languages.\n", "1224": "Determining a Computing Center Environment An investigation is described in which several\ngenerally unavailable parameters descriptive \nof a computing center environment are obtained.  The\nactual data collection and reduction is described, \nand the results of one month of this collection are tabulated and summarized.\n", "1225": "The Predictive Analyzer and a Path Elimination Technique Some of the characteristic features of a predictive\nanalyzer, a system of syntactic analysis \nnow operational at Harvard on and IBM 7094, are delineated.\n The advantages and disadvantages of the \nsystem are discussed in comparison to those of an immediate\nconstituent analyzer, developed at the RAND \nCorporation with Robinson's English grammar.  In addition,\na new technique is described for repetitive \npath elimination for a predictive analyzer, which can\nnow claim efficiency both in processing time and \ncore storage requirement.\n", "1226": "The Organization of Structured Files A data file is an integral part of a data processing\nsystem.  In many systems, the selection \nof an organization for the data within the file can\nbe critical to the system's operating efficiency. \n This paper provides the systems designer with an information\nsource which describes ten techniques that \nmay be employed for organizing structured data.  The\ncharacteristics of the organizations described are \napplication independent, thus providing the designer with\na reference which allows him to limit the number \nof file organizations he must consider for his system.\n", "1227": "Transport (Algorithm 258 [H])", "1228": "Treesort 3 (Algorithm 245 [M1])", "1229": "Random Permutation (Algorithm 235 [G6])", "1230": "Method for Hyphenating at the End of a Printed Line A description of a method of hyphenation is\npresented as a result of application of several \ngeneral rules.  The character sets considered by the\nroutine and the method are briefly outlined.\n", "1231": "Peephole Optimization Redundant instructions may be discarded during\nthe final stage of compilation by using a simple \noptimizing technique called peephole optimization.\nThe method is described and examplesare given.\n", "1232": "Representation of the Standard ECMA 7-Bit", "1233": "Conventions for the Use of Symbols in the Preparation This paper is intended as an outline of the\nvarious conventions which are being considered \nfor the use of flowcharts for information processing\nsystems.  The conventions are applied to the use \nof the symbols appearing in the proposed American Standard\nFlowchart Symbols and not with the symbols \nper se.\n", "1234": "The Structure of Yet Another ALGOL Compiler A high-speed \"top down\" method of syntax analysis\nwhich completely eliminates \"back-up\" of \nthe source string has been implemented in a convenient\nmacro-language.  A technique of  simulation at \ncompile time of the use of a conventional run-time stack\nenables the generation of code for expressions \nwhich minimizes stores, fetches and stack-pointer motion\nat run time, while properly trating recursion \nand side effects of procedures.  Block structure and\nrecursion are handled without need for interpretive \nmethods at run times.  The \"context problem\" in the transmission\nto recursive procedures of parameters \n\"called by name\" is solved in a manner which permits the\nhandling of the common cases of simple expressions \nand array identifiers with particular efficiency.\n", "1235": "A Stochastic Approach to the Grammatical Coding of English A computer program is described which will\nassign each word in an English text to its form \nclass or part of speech.  The program operates at relatively\nhigh speed in only a limited storage space. \n About half of the word-events in a corpus are identified\nthrough the use of a small dictionary of function \nwords and frequently occurring lexical words.  Some suffix\ntests and logical-decision rules are employed \nto code additional words.  Finally, the remaining words\nare assigned to one class or another on the basis \nof the most probable form classes to occur within the already\nidentified contexts.  The conditional probabilities \nused as a basis for this coding were empirically derived\nfrom a separate hand-coded corpus.On preliminary \ntrials, the accuracy of the coder was 91% to 93%, with\nobvious ways of improving the algorithm being \nsuggested by an analysis of the results.\n", "1236": "The SMART Automatic Document Retrieval System-An Illustration A fully automatic document retrieval system\noperating on the IBM 7094 is described.  The system \nis characterized by the fact that several hundred different\nmethods are available to analyze documents \nand search requests.  This feature is used in the retrieval\nprocess by leaving the exact sequence of \noperations initially unspecified, and adapting the\nsearch strategy to the needs of individual users. \n The system is used not only to simulate an actual operating\nenvironment, but also to test the effectiveness \nof the various available processing methods.  Results obtained\nso far seem to indicate that some combination \nof analysis procedures can in general be relied upon to\nretrieve the wanted information.  A typical search \nrequest is used as an example in the present report to illustrate\nsystems operations and evaluation procedures.\n", "1237": "Conversion of Decision Tables To Computer Programs Several translation procedures for the conversion\nof decision tables to programs are presented \nand then evaluated in terms of storage requirements,\nexecution time and compile time.  The procedures \nare valuable as hand-coding guides or as algorithms for\na compiler.  Both limited-entry and extended-entry \ntables are analyzed.  In addition to table analysis,\nthe nature of table-oriented programming languages \nand features is discussed.  It is presumed that the reader\nis familiar with the nature of decision tables \nand conventional definitions.\n", "1238": "A Technique for Integrated Reports from a Multi-run System The requirements of a requisition accounting\nsystem for the San Francisco Overseas Supply Agency \n(OSA) included exception reporting to OSA itself.  The simultaneous\nsatisfaction of the reporting requirement \nand the accounting requirements posed definite problems\nin system design, particularly the handling of \nthe reporting function.  A practical and satisfactory\nsolution was developed by expanding the basic system \nwith two tailored service runs for report production.\n These two runs permitted a final system that was \neasier to debug, easy to maintain, efficient in production\nand responsive to the changing requirements\nof OSA.\n", "1239": "Graycode (Algorithm 246 [Z])", "1240": "Transport (Algorithm 258 [H])", "1241": "Havie Integrator (Algorithm 257 [D1])", "1242": "Modified Graeffe Method (Algorithm 256 [C2])", "1243": "Testing the Understanding of the Difference Between", "1244": "Bit Manipulation in Fortran Language", "1245": "A Fortran n-Ary Counter", "1246": "Deeply Nested Iterations ", "1247": "An Operating Environment for Dynamic-Recursive Presented in this paper is a brief nontechnical\nintroduction to OEDIPUS, a computer programming \nsystem which can serve as an operating environment for\ndynamic and/or recursive programs and programming \nsystems.  The available services include dynamic allocation\nof storage for contiguous blocks of arbitrary \nsize, input and output for a hierarchy of data types,\na public pushdown list for automatic recursive \nprogramming, a rudimentary compiler for subroutine\ncommunication and bookkeeping, and debugging aids.\n", "1248": "On the Automatic Simplification of Computer Programs Presented in this paper is the problem of writing\na program which would examine any other program \nand perform such simplifications on it as can be detected\nfrom the argument-program's form alone, without \nhaving any knowledge of what it is supposed to do.\n", "1249": " Recorded Magnetic Tape for Information Interchange", "1250": "Graphic Symbols for Problem Definition", "1251": "American Standard and IFIP/ICC Vocabularies compared The \"Proposed American Standard Vocabulary of\nInformation Processing\" and the \"IFIP/ICC Vocabulary \nof Terms Used in Information Processing\" are analyzed and compared.\n", "1252": "Symbolic Notations for Statistical Tables The preparation of statistical tables is an\nimportant function of the data processing systems \nof some organizations, and a symbolic notation for the\ndescription of tables has been shown to be a useful \naid to documentation.  Such a notation also provides\nthe first step towards making automatic a tedious \nand time-consuming part of system design and programming\nin many computer applications.  One notation \nis described and suggestions are made for the implementation of the larger goal.\n", "1253": "QUIKSCRIPT-A SIMSCRIPT- Like Language for the G-20 QUIKSCRIPT is a simulation language based on\nSIMSCRIPT and programmed entirely in an algebraic \nlanguage, 20-GATE.  The QUIKSCRIPT language, its internal\nimplementation, and major differences between \nQUIKSCRIPT and SIMSCRIPT are presented.  This paper is\nnot a programming guide to the language, but rather \nan attempt to present its flavor.  A brief description of\nSIMSCRIPT is included, as is a sufficient description \nof 20-GATE to render this material understandable\nto the reader familiar with algebraic languages.\n", "1254": "The Iteration Element A recent addition to the MAD language has made\nthe iteration structure of the MAD THROUGH statement \n(corresponding to the ALGOL for statement and the FORTRAN\nDO statement) available within expressions.\n", "1255": "A Method of Data List Processing With Application to EEG Analysis A set of subroutines is discussed, which is\ndesigned to aid in the programming of computations \non indexed lists of numbers using machine language\nor a symbolic assembly system.  The most commonly \nperformed list operations are outlined, and logically\narranged into five groups.  As an example, the \ncomputation of power spectral density from the autocovariance\nfunction is discussed for a class of EEG \nsignals.\n", "1256": "Dynamic Variable Formatting", "1257": "DEBUG-An Extension to Current On-Line Debugging Techniques A method of on-linr assembly-language debugging\nwhich greatly simplifies several of the bookkeeping \ntasks characteristically associated with that process\nhas been developed and implemented in a program \nfor the UNIVAC M-460 computer at Air Force Cambridge Research\nLaboratories.  With this program, an online \nuser may insert or delete (in symbolic assembly language)\nany number of lines at any point of his previously \nassembled program in core, with the remainder\nof the program being relocated appropriately.\n", "1258": "An Extended Arithmetic Package In many fields, for example algebraic number\ntheory, arithmetic must be carried out to a degree \nof precision which exceeds the normal hardware capacity\nof most machines.  In such cases, an extended \narithmetic package provides a comprehensive and easy-to-use\nway of performing such arithmetic.  Such \na package was coded for the IBM 7090.  In discussing\nthe general problems associated with the design \nof an extended arithmetic package, specific reference is made to this program.\n", "1259": "Applications of Binary Numbers In Computer Routines A binary number can be thought of as an alternate\nform of expression for either a set of letters \nor a decimal number.  There are then three equivalent\nexpressions, easily translatable to one another, \neach having different characteristics.  Four examples\nare given in which the form of an expression is \nchanged to an equivalent expression to save space or gain power.\n", "1260": "Least-Squares Analysis of Resonance Spectra on Small Computers The problem of analyzing data from a Mossbauer\neffect experiment is discussed.  By using the \ncut step procedure for convergence and by imposing physical\nconstraints on the functional form of the \ncalculation it is possible to make the analysis on a\nsmall computer.  The analysis has been carried out \non an IBM 1410 computer with a 40,000 BCD core memory.\n", "1261": "Modeling and Simulation of Digital Networks The simulation of digital networks on a digital\ncomputer provides the engineer with an effective \nmeans of analyzing time-quantized logical behavior.  The\ndigital network is modeled as a set of time-dependent \nor time-independent Boolean transformations; each transformation\ndescribing the input-output relationship \nof a model element comprising the network mode.  The\nsimplicity of utilizing the FORTRAN IV Programming \nSystem as a digital Network Simulator is discussed an\nillustrated.  This simplicity is derived from a \ncommon modeling technique applicable to combinational\nand sequential digital networks and a systematic \nprogramming approach.\n", "1262": "Procedure-Oriented Language Statements to Facilitate Parallel Processing Two statements are suggested which allow a programmer\nwriting in a procedure-oriented language \nto indicate sections of program which are to be executed\nin parallel.  The statements are DO TOGETHER \nand HOLD.  These serve partly as brackets in establishing\na range of parallel operation and partly to \ndefine each parallel path within this range.  DO TOGETHERs\nmay be nested.  The statements should be particularly \neffective for use with computing devices capable of\nattaining some degree of compute-compute overlap.\n", "1263": "Metalanguage and Syntax Specification Two metalanguages are described, one sufficient\nfor the table specification of the ALGOL syntax, \nthe other with additional metaoperators adequate and used\nfor the formal table description of Basic FORTRAN.\n", "1264": "BLNSYS-A 1401 Operating System with Braille Capabilities BLNSYS is an operating system designed for\na 4K 1401 with common optional features and two \nattached tape drives.  Printed output of this system\nor of executing programs may be in either English \nor braille.  Even though this system was written for\na small machine with minimal peripheral equipment, \njobs may be batched, so that card handling and lost\nprocessing time is at a minimum.  This system will \nperform any or all of the following users specified\nfunctions: assemble SPS source decks, post list, \nproduce condensed or uncondensed object decks, execute\nuser's program, list card input to a program, \nlist punched output, provide a storage dump, execute\na program submitted for execution as an uncondensed \nobject deck under debugging trace control, card-to-braille\nconversion, brailled listings of 7040 IBSYS \nbatch output, and update or duplicate the system tape\nitself.  Input-ouput subroutines are also included \nin the system.\n", "1265": "On the Relative Efficiencies of Context-Free Grammar Recognizers A number of diverse recognition procedures\nthat have been proposed for parsing sentences with \nrespect to a context-free grammar are described in this\npaper by means of a common device.  Each procedure \nis defined by giving an algorithm for obtaining a nondeterministic\nTuring Machine recognizer that is \nequivalent to a given context-free grammar.  The formalization\nof the Turing Machine has been chosen \nto make possible particularly simple description of\nthe parsing procedures considered.  An attempt has \nbeen made to compare recognition efficiencies for the\nprocedures defined.  For a few simple grammars \nand sentences a formal comparison has been made.  Empirical\ncomparison of the recognition of more realistic \nprogramming languages such as LISP and ALGOL has been\nmade by means of a program which simulates the \nTuring Machine on the Univac M-460 computer.  Several\nalgorithms for producing grammars equivalent to \na given context-free grammar have been considered, and\nthe increase in recognition efficiency they afford \nhas been empirically investigated.\n", "1266": "Considerations Relating to Purpose of FORTRAN Standardization", "1267": "Performance of Systems Used for Data Transmission Information thruput as a characteristic of\nsystems performance is discussed.  This discussion \nincludes the pertinent aspects of information transfer,\nof determination of transfer rate of information \nbits (TRIB), of residual errors, and of standard measurement\nconditions.  The paper also presents an \norderly arrangement of characteristics and parameters\nthat affect information thruput, and some examples \non procedures for determining a thruput rate in terms of\nTRIB.  It concludes that a performance characteristic \ninvolving information rate can best be expressed as the\nTRIB in conjunction with the Residual Error Rate.\n", "1268": "Logarithm of a Complex Number (Algorithm 243 [B3])", "1269": "Computation of Fourier Coefficients (Algorithm [C6])", "1270": "On ALGOL Education: Automatic Grading Programs Two ALGOL grader programs are presented for\nthe computer evaluation of student ALGOL programs. \nOne is for a beginner's program; it furnishes random data\nand checks answers. The other provides a searching \ntest of the reliability and efficiency of an integration\nprocedure.  There is a statement of the essential \nproperties of a computer system, in order that\ngrader programs can be effectively used.\n", "1271": "Secondary Key Retrieval Using an IBM 7090-1301 System The secondary key retrieval method involves\nthe preparation of secondary storage lists from \nprimary data records. Search requests are satisfied by\nlogical operations on appropriate lists, producing \na complete set of addresses of primary records relevant\nto the request.  Experimental results are presented \nand a comparative analysis is given.\n", "1272": "Expanding the Editing Function In Language Data Processing In automatic abstracting, citation indexing,\nmechanical translation and other such procedures, \nediting is required whenever the automatic method leaves\nsomething to be desired.  This paper discusses \nthe economy of editing as a function of the amount of condensation\nof text in language processing operations, \nand then contends that editing can be regarded as an\nopportunity rather than as an unwelcome necessity. \n \"Heavy editing,\" which goes beyond mere correction\nand improvement of computer output, is exemplified \nby the use of a concordance in preparing a survey article\nor lecture.  Other opportunities for heavy \nediting are described, chief among them being interpretation and\nexpansion of computer output in such \nprocesses as factor analysis.  Applications are described,\nsuch processes as factor analysis.  Applications \nare described, such as the quick, unbiased evaluation\nof a large volume of incoming mail or telegrams, \nyielding summary reports not possible for either\nhumans or computers to produce alone.\n", "1273": "Remark on Romberg Quadrature A modified form of Romberg quadrature is described,\nwhich is less sensitive to the accumulation \nof rounding errors than the customary one.\n", "1274": "On the Numerical Solution of an N-Point Boundary A method for the numerical solution of then-point\nboundary value problem for homogeneous linear \nordinary differential equations is developed.  The\nmethod requires two Runge-Kutta integrations over \nthe interval under consideration and the solution of\na linear system of equations with n-1 unknowns.\n", "1275": "Code Structures for Protection and Manipulation", "1276": "Still Another Use for FORTRAN II Chaining", "1277": "The Use of Cobol Subroutines in Fortran Main Programs", "1278": "Wengert's Numerical Method for Partial Derivatives, In a recent article in the Communications\nof the ACM, R. Wengert suggested a technique for \nmachine evaluation of the partial derivatives of a function\ngiven in analytical form.  In solving non-linear \nboundary-value problems using quasilinearization many\npartial derivatives must be formed analytically \nand then evaluated numerically.  Wengert's method appears\nvery attractive from the programming viewpoint \nequations which might not otherwise be undertaken.\n", "1279": "Use of a Conditional Base Number System for A procedure is described for the relatively\nefficient encoding of sequences of characters which \nhave predecessor-successor selection rules.  The procedure\nis shown to assign a unique integer to each \nsequence and to generate a reasonably compact set of values.\n", "1280": "Numerical Integration of a Differential-Difference Systems in which variable time-lags are present\nare of common occurrence in biology.  Variable \nflow rates are a common cause of these variable lags.\n At present no extensive body of knowledge exists \nconcerning the effects which these variable lags can\ncause.  Shown here is a method of reducing some \ndifferential-difference equations to ordinary differential\nequations which can then be studied numerically \nwith ease.  Subsequent study will deal with situations\nin which multiple-lags and lags dependent on the \nsolution itself are present.\n", "1281": "Data Input by Question and Answer A data input scheme for a time-sharing computer\nis described in this paper.  Instead of using\nformat statements to determine the input, the computer\nasks the user for the required values one at a \ntime.  The computer converses with the user during the\ninput process, checks for errors, provides standard \ndata, and allows editing of values input.\n", "1282": "The Use of FORTRAN in Subroutines with COBOL Main Programs By using the proper COBOL coding techniques and\naccounting for differences in storage allocation \nand library routines between the two languages, it is\npossible to write FORTRAN IV subroutines that may \nbe called from COBOL main programs.  Such a technique\nenables the programmer to take advantage of the \nmost useful properties of each language while\nminimizing their respective disadvantages.\n", "1283": "Matrix Inversion (Algorithm 231 [F1])", "1284": "Bessel Function for a Set of Integer Orders", "1285": "Eigenvalues and Eigenvectors of a Real Symmetric", "1286": "Eigenvalues of a Real Symmetric Matrix", "1287": "Vector Coupling or Clebsch-Gordan Coefficients (Algorithm 252 [Z])", "1288": "CLP-The Cornell List Processor Presented in this paper are the highlights of\nCLP, a teaching language which has been employed \nat Cornell University and was constructed to serve as a means\nof introducing simulation and other list-processing \nconcepts.  The various advantages of CLP are discussed and examples are given.\n", "1289": "Proposed Revised American Standard Code for Information Interchange", "1290": "Transparent-Mode Control Procedures for Data This paper gives the considerations of Task\nGroup X3.3.4 in the area of transparent-mode data \ncommunication control philosophy.  The appearance of this\npaper was forecast (underthe name of \"second-level \ncontrol\") in the earlier tutorial paper, \"Control Procedures\nfor Data Communications,\" Task Group document \nX3.3.4.44, dated May 1964.  The present paper elaborates\nupon solutions to the problems of transparency \nto the basic ASCII communication control characters\nas outlined in the previous paper mentioned above. \n Moreover, it goes on to cover the additional control problems\nof handling material such as off line encrypted \ndata or non-ASCII codes by means of systems providing\ncomplete character transparency.  It does not cover \nconcepts of transparency in which the normal character\nstructure or modulation rate of a system may be \nabandoned.  In conjunction with the earlier tutorial\npaper, this paper is expected to lead to a proposal \nfor stand ardizationof data communication control procedures\nusing the American Stand ard Code for Information \nInterchange.\n", "1291": "Tabular Input of Data ", "1292": "On a Divide-and-Correct Method For Variable Precision Division Described in this paper is a divide-and-correct\nmethod for variable precision division in digital \ncomputers.  Unlike the earlier methods of Stein and\nPope, the present method uses a suitably rounded \nform of the normalized divisor for getting an estimate\nof the quotient characters.  This results in a \ncorrection of at most plus or minus one to the estimate,\nto obtain the exact quotient character.  It \nis believed that this method will be widely applicable\nfor division operations in variable word-length \ncharacter-oriented machines.\n", "1293": "Method is Randomness  Certain nonrandom properties of a commonly used\nrandom number generator are described and analyzed.\n", "1294": "Note on Triple-Precision Floating-Point Arithmetic with 132-Bit Numbers In a recent paper, Gregory and Raney described\na technique for double-precision floating-point \narithmetic.  A similar technique can be developed for\ntriple-precision floating-point arithmetic and \nit is  the purpose of this note to describe this technique.\n Only the multiplication and the division \nalgorithms are described, since the addition-subtraction\nalgorithm can be obtained by a trivial modification \nof the algorithm in Gregory's and Raney's paper.\n", "1295": "PERT Time Calculations Without Topological Ordering A simplified technique is presented for PERT\nTime calculations without topological ordering. \n Each event is assigned a unique memory location.  An activity\nis represented by a link.  A link is defined \nas a memory location containing the address of another\nmemory location.  The time information for an \nactivity is carried with its link.  For a typical net,\nthe majority of activities can be described by \none 36-bit cell each.  The remainder use two 36-bit\ncells each.  The links are unidirectional; forward \nduring the T(E) calculation (expected completion time for\nan activity);backward during the T(L) calculation \n(time latest allowable for completion of an activity). \nThe calculations progress through the net topologically \neven though the net is not represented topologically in core.\n", "1296": "Ative (Algorithm 205 [E4])", "1297": "Steep1 (Algorithm 203 [E4])", "1298": "Adaptive Numerical Integration by Simpson's Rule (Algorithm 145 [D1])", "1299": "Solutions of the Diophantine Equation (Algorithm 139 [A1])", "1300": "Function Minimization (Algorithm 251[E4])", "1301": "On ALGOL I/O Conventions", "1302": "Parallel Signaling Speeds for Data Transmission", "1303": "A Correspondence Between ALGOL 60 and Church's Lambda-Notation: Part II*", "1304": "A Rapid Turnaround Multi-Programming System In this paper, basic features, system characteristics\nand the control algorithm for a multi-programming \nsystem with rapid turnaround time are described.\n", "1305": "The Internal Structure of the FORTRAN CEP Translator The FORTRAN CEP translator converts a source\nprogram written in the FORTRAN CEP language into \nan object program written in the language of the CEP\ncomputer.  In this paper, after an outline of the \nCEP computer, the internal structure of the translator\nis described.  Emphasis is on the compilation \nof expressions, of input/output lists, and of subscripted variables.\n", "1306": "A Class of Unambiguous Computer Languages Discussed in this paper is the concept of\na fully nested computer language which may be one \nmeans of designing computer languages which would be completely\nfree of ambiguities.  Several suggestions \nare also given here for the redefinition of ALGOL as a fully nested language.\n", "1307": "A Lightpen-Controlled Program For On-Line Data Analysis This paper describes a technique designed\nto ease the use of a data processing system by a \nperson, in particular, a scientist, who is intimately and\nprimarily concerned with interpreting the significance \nof data handled by the system.  Since such a person is\noften unable to spend the time necessary to master \na programming language, it is essential that he be aided\nin composing commands to the computer.  In the \nsystem described, the user is not required to learn\nor remember the vocabulary of the language because \nthe vocabulary is displayed before him on\"menus\" by\nmeans of a computer-drive scope.  He selects the \nvarious vocabulary elements required by pointing with\nthe light pen.  By use of a small unordered set \nof rewriting rules applied as a result of light pen\nselections, the user generates only syntactically\ncorrect commands to the system.  He does not have to learn\nor remember the grammar.  The program restricts \nthe user severely in the particular language he can use,\nbut the method for communicating with the program \nmakes these restrictions seem quite natural and unconstraining.\n The program has been used successfully \nfor over ten months.\n", "1308": "A Mathematical Model for Mechanical part Description The flexibility of a mathematical model takes\nadvantage of the common information requirements \nof computer-aided engineering drawing, numerical control\ntape generation, and physical characteristic \ncomputation.  By judicious control of man-machine communication\nrequirements, improved results over conventional \nengineering design processes are possible.  An English-like\ninput language, tailored for use by draftsmen \nand designers, will describe the part and specify the\noutput desired.  One approach to the mathematical \nmodel consists of a group of surface-defining quadric\nequations, which are created by a system of modular \nsubprogram.  Other subprograms will convert the mathematical\nmodel into instructions for driving automatic \ndrafting machines and numerical controlled machine tools.\n Physical part characteristics, such as center \nof gravity, can be computed by subprograms and used in\ndynamic analysis work.  The proposed overall system \nis presented and experiments and demonstrations are discussed.\n", "1309": "A Computer User-Oriented System A computer language system has been developed\nwhich makes possible fast preparation of management \nreports, regardless of computational complexity or format\nvariety.  Costs are sufficiently low so that \nindividually tailored reports can be prepared for every\nmanager.  The system requires initial preparation \nof large data banks containing data in elementary form.\n Use of two special languages, EXTRACT and MATRAN, \npermits selective extraction of any data subset, efficient\nprocessing through any computational sequence, \nand flexible presentation of results in either tabular\nor graphical form.  Matrix algebra is used as \na fundamental vehicle for accomplishing both manipulation and computation.\n", "1310": "A Rapid Braille Transliteration Technique for Certain IBM Machines", "1311": "Efficient Autocorrelation ", "1312": "Recursion and Iteration", "1313": "Construction of Nonlinear Programming Test Problems", "1314": "The Organization of Symbol Tables An efficient symbol table organization is an\nimportant feature in the design of any compiler. \n During the construction of the Virginia ALGOL 60 compiler\nfor the Burroughs B205, the primary consideration \nin the symbol table design was that the recognition of\nidentifiers and reserved words should be as rapid \nas possible.  The general features of the technique are described.\n", "1315": "Automation of the Radioisotope Accountability System The Radioisotope Service of the Veterans Administration\nHospital, Omaha, Nebraska, used a manual \nsystem of radioisotope accountability for three years.  The\nprocedure which was satisfactory but time-consuming \nwas converted from manual to a fully automated computer\nsystem in January, 1963.  The program for purchased \nradioisotopes is written in FORMAT FORTRAN for the IBM\n1620 Computer.  A second program for maintaining \naccountability for reactor-created radioisotopes is written\n in the FORCOM programming language.  A minimum \namount of bookkeeping is required by the reactor operating\nstaff.  The United States Atomic Energy Commission \nregulations specify that records be kept.  This system\nprovides detailed records for each container of \nradioactive material purchased and/or created in the Triga\nreactor indicating the amounts received, used, \nand/or transferred to the health physicist for disposal.\n Consolidated records contain total amounts \nreceived, used, and/or disposed of for any specified period\nof time.  Purchased radioisotopes are reported \nin millicuries; reactor-created radioisotopes in microcuries.\n", "1316": "Bessel Functions of the First Kind (Algorithm 236 [S17])", "1317": "Poisson-Charlier Polynomials (Algorithm 234 [S23])", "1318": "Arccossin (Algorithm 206 [B1])", "1319": "Crout with Equilibration and Iteration (Algorithm 135 [F4])", "1320": "Inverse Permutation (Algorithm 250 [G6])", "1321": "Outreal N (Algorithm [I5])", "1322": "Netflow (Algorithm 248 [H])", "1323": "A Correspondence Between ALGOL 60 and Church's Lambda-Notation: Part I* This paper describes how some of the semantics\nof ALGOL 60 can be formalized by establishing \na correspondence between expressions of ALGOL 60 and expressions\nin a modified form of Church's L-notation. \n First a model for computer languages and compute behavior\nis described, based on the notions of functional \napplication and functional abstraction, but also having\nanalogues for imperative language features.  \nThen this model is used as an \"abstract object language\"\ninto which ALGOL 60 is mapped.  Many of ALGOL \n60's features emerge as particular arrangements of\na small number of structural rules, suggesting new \nclassifications and generalizations.  The correspondence\nis first described informally, mainly by illustrations. \n The second part of the paper gives a formal description,\ni.e. an \"abstract compiler\" into the \"abstract \nobjct language.\"  This is itself presented in a \"purely\nfunctional\" notation, that is one using only \napplication and abstraction.\n", "1324": "Answering English questions by Computer: A Survey Fifteen experimental English language question-answering\nsystems which are programmed and operating \nare described and reviewed.  The systems range from a conversation\nmachine to programs which make sentences \nabout pictures and systems which translate from English\ninto logical calculi.  Systems are classified \nas list-structured data-based, graphic data-based, text-based\nand inferential.  Principles and methods \nof operations are detailed and discussed.  It is concluded\nthat the data-base question-answer has passed \nfrom initial research into the early developmental\nphase.  The most difficult and important research \nquestions for the advancement of general-purpose language\nprocessors are seen to be concerned with measuring, \ndealing with ambiguities, translating into formal\nlanguages and searching large tree structures.\n", "1325": "Remote, On-Line, Real-time Computer Diagnosis Presented in this paper is a brief report on\nthe hardware, software, system configuration and \nfunction of a system for the remote, online, real-time digital\ncomputer diagnosis of clinical electrocardiograms. \n It seems likely that efforts of this sort will lead\nto a satisfactory solution to the problem of the \nautomatic diagnosis of electrocardiograms.  Current\nattempts by the authors to extend the diagnostic \ncapabilities of the present system are particularly concerned\nwith increasing the fidelity of the adaptive \nmatched filters, the development of three dimensional pattern analysis,\nthe analysis of parallel electrocardiographer-computer \ndiagnostic interaction, and a study of the possibility\nof introducing major, tree-like branching decisions \nearly in the diagnostic process.\n", "1326": "Boundary Networks A feasible computer procedure is described\nfor determining the total or partial inclusion of \narbitrarily given points and lines with respect to a\nset of general polygonal domains which partition \na plane bounded region.  A scheme for the computer representation\nof the boundaries of the domains and \nan algorithm, based on this  scheme, for evaluating\nthe inclusion relations are specified in detail. \n The method employs several levels of selection criteria\nfor the purpose of reducing the number of accesses \nto auxiliary storage devices and the amount of boundary\ndata for which processing is required.\n", "1327": "Use of Decision Tables in Computer Programming A decision table is a tabular form for displaying\ndecision logic.  Decision tables have many \ninherent advantages.  The technique to be illustrated\nputs these advantages to use in that it enables \none to program directly from a decision table.  The technique\nis based on the creation of a binary image \nof a limited entry decision table in computer memory.\n A binary image of a given set of input conditions \ncan also be created.  This data image is used to scan\nthe decision table image to arrive at the proper \ncourse of action.  There are several advantages gained\nfrom the programming point view: (1) amount of \ncomputer memory used is drastically reduced, (2) programming\nis simplified, and (3) documentation is \nbrief and clear.\n", "1328": "Further Remarks on Reducing Truncation Errors", "1329": "Simulation of Boolean Functions in a Decimal computer", "1330": "Automated Plotting Flow-Charts on a Small Computer", "1331": "Code Structures for Protection and Manipulation of Variable-Length Items When items are made up of a variable number\nof characters, each containing the same number \nof bits, certain control information (partition symbols)\nis inserted to mark their separations.  Since \nerrors in identification of these control characters\ncan lead to serious trouble, methods of protecting \nthese symbols are indicated.  A 6-bit code assignment\nof alphanumeric characters for fixed word-length \ncomputers is given and its suitability for error detection\nand variable-length item manipulation is shown. \n Also indicated is its flexibility during certain arithmetic operations.\n", "1332": "Subroutine Assembly A description is given of an assembly system,\nwhich requires only one pass and does not maintain \na table of information about the subroutine library.\n", "1333": "Reducing Truncation Errors Using Cascading Accumulators When accumulating a large number of quantities\nas in numerical integration, the sum itself \nmay become much larger than the individual addends.\n This results in truncation error.  Much of this \nerror can be eliminated using cascading accumulators\nas noted in a recent article by Wolfe.  A simpler \nand slightly more flexible algorithm is presented which\ndeals also with the case of negative addends.\n", "1334": "Mechanization of Tedious Algebra: The A computer program has been written to generate\ntables of formulas for the Newcomb operators \nof planetary theory.  The Newcomb operators are expressed\nas polynomials in two variables, one of which \nstands for a simple differential operator, and the other\nfor an arbitrary integer.  The polynomials are \ngenerated by a recurrence scheme.  The program is coded in\nFORTRAN, using simple array manipulation techniques \nto perform the algebraic operations.  Formulas for over\n100 Newcomb operators have been produced by the \nprogram and typeset photographically on an S-560 Photon system.\n", "1335": "Character Set for Optical Character", "1336": "NPL: Highlights of A New Programming Language", "1337": "EULER: A Generalization of ALGOL, and its Formal Definition", "1338": "Additional Comments on a Problem in Concurrent Progamming Control", "1339": "A Contribution to the Development of ALGOL", "1340": "Multiplexing of Slow Peripherals The philosophy of a monitor which allows slow\noutput devices to be multiplexed is presented.\n", "1341": "Levels of Computer Systems In building current computer systems, we tend\nto break them down into \"levels\" of control, \ncommand and communication; in using the system, we break\nour problems down correspondingly.  The continued \nuse of such a structure raises questions about its effects\non the usefulness of future systems, particularly \nwith regard to such trends as time sharing, parallel\nprogramming, and, eventually, systems which learn. \n In this essay some of these questions are posed, and\nthe general attitude we must take in pursuing the \nproblem further is discussed.\n", "1342": "Transportation Problem (Algorithms 293 [H])", "1343": "Havie Integrator (Algorithm 257 [D1])", "1344": "Statistical Computations Based Upon Algebraically Specified Models Based upon a machine-readable statistical model\nand related symbolic specifications, an efficient \nmethod of performing calculations for statistical models\nof a balanced complete nature is presented. \n Fixes, mixed, and random analysis of variance models\nare considered.  A procedure for obtaining variance \ncomponents and calculated F statistics for the model terms is included.\n", "1345": "Tensor Calculations on the Computer A FORMAC program has been written which is capable\nof calculating various quantities of interest \nin tensor calculus.  Using this code, Christoffel symbols\nhave been calculated for 12 basic orthogonal \ncoordinate systems.\n", "1346": "On the Application of the Process of Equalization The second Remes algorithm as originally established\nfor polynomials, may converge or not when \nthe approximating functions are rational.  However, the\nfew results known in this domain show how efficient \nthe algorithm can be to obtain approximations with a\nsmall error, much more than in the polynomial case, \nin which the best approximation can be very nearly\napproached directly by a series development.  The \naim of this paper is to investigate the limitations\nof the applicability of certain extensions of the \nalgorithm to the case where the approximations are rational\nas well as to present some numerical results.\n", "1347": "General Time-Varying Systems Error Sensitivities Program The evaluation, by the propagation of variance\ntechnique, of the sensitivity of time-varying \nsystems to initial condition and parameter errors, involves\nthe determination of several system-dependent \npartial derivative matrices.  This requirement has led to\nseparate programs for each system under investigation. \n A new program, through utilization of the Wengert differentiation\ntechnique, automatically determines \nthe required matrices from specific system equations supplied\nin subroutine form at execution time, eliminating \nthe need for individualized programs, and presaging the\nfurther development of extremely general computer \nprograms.\n", "1348": "FLOWTRACE, A Computer Program for Flowcharting Programs The FLOWTRACE system produces flowcharts of programs\nwritten in \"almost any\" programming language. \n One most describe the syntax of the control statements\nin his language; for this purpose a metalanguage \nis available.  The resultant object deck is used to\nflowchart any programs in the language described. \n Several examples of FAP and SNOBOL flowcharts are given.\n However, it is not necessary to confine one's \nscope to existing languages.  One may define his own\nlanguage in any \"well-structured\" manner.  This \nfeature is particularly useful when it is desirable\nto chart only comments within a program.  Such an \napproach permits the documentation of descriptive remarks\nand avoids the inclusion of coding details.\n", "1349": "Computing Capabilities at Western European Universities This report on the author's trip to universities\nin Western Europe in the summer of 1966 gives \nbrief descriptions of computing activities at each institution\nvisited.  Present equipment capabilities \nvary from moderate to large scale; however, many institutions\nplan to acquire complex time-shared systems \nin the near future.  In the author's opinion, the state\nof the art lags behind that on this continent. \n This lag is attributed to four principal factors: (a)\nthe handicapping organization of academic procedures; \n(b) the university-government financial relationship;\n(c) the subordinated organization of the computing \nfacility; (d) the paucity of professional interchange\nof knowledge.  The effects of these constraints \nare explicated.\n", "1350": "The Augmented Predictive Analyzer for Context-Free It has been proven by Greibach that for a given\ncontext-free grammar G, a standard-form grammar \nGs can be constructed, which generates the same languages\nas is generated by G and whose rules are all \nof the form Z --> cY(1) ... Y(m), (m >= O) where Z and\nY(i) are intermediate symbols and c a terminal \nsymbol.  Since the predictive analyzer at Harvard uses\na standard-form grammar, it can accept the language \nof any context-free Grammar G, given an equivalent standard-form\ngrammar Gs.  The structural descriptions \nSD(Gs,X) assigned to a given sentence X by the predictive\nanalyzer, however, are usually different from \nthe structural descriptions SD(G,X) assigned to the\nsame sentence by the original context-free grammar \nG from which Gs is derived.  In Section 1, an algorithm,\noriginally due to Abbott is described standard-form \ngrammar each of whose rules is in standard form, supplemented\nby additional information describing its \nderivation from the original context-free grammar. \nA technique for performing the SD(Gs,X) to SD(G,X) \ntransformation effectively is also described.  In section\n2, the augmented predictive analyzer as a parsing \nalgorithm for arbitrary context-free languages is compared\nwith two other parsing algorithms: a selective \ntop-to-bottom algorithm similar to Irons' \"error correcting\nparse algorithm\" and an immediate constituent \nanalyzer which is an extension of Sakai-Cocke's algorithm\nfor normal grammars.  The comparison is based \nupon several criteria of efficiency, covering core-storage\nrequirements, complexities of the programs \nand processing time.\n", "1351": "Automatic Error Bounds on Real Zeros of Rational Functions A procedure for implementing an interval arithmetic\nversion of the Newton-Raphson method is \nproposed.  The procedure require only a starting interval\nover which the zeros of a given rational function \nare to be located.  The method automatically provides bounds \nfor roundoff error.\n", "1352": "Automatic Integration of a Function with a Parameter Two efficient methods for automatic numerical\nintegration are Romberg integration and adaptive \nSimpson integration.  For integrands of the form f(x)g(x,a)\nwhere a is a parameter, it is shown that \nRomberg's method is more efficient.  A FORTRAN program\nshows how to achieve this greater efficiency.\n", "1353": "Techniques for Automatic Tolerance Control in Linear Programming In this technical note, the numerical steps\nfor the simplex method of linear programming are \nreviewed and the tolerances needed in the numerical procedure\nare defined.  Objective criteria are given \nfor accomplishing the numerical steps of the method\nand the calculation of necessary tolerances.\n", "1354": "Conversion of Decision Tables to Computer The rule mask technique is one method of converting\nlimited entry decision tables to computer \nprograms.  Recent discussion suggest that in many circumstances\nit is to be preferred to the technique \nof constructing networks or trees.  A drawback of the\ntechnique as hitherto presented is its liability \nto produce object programs of longer run time than necessary.\n In this paper a modification of the technique \nis discussed which takes into account both rule frequencies\nand the relative times for evaluating conditions. \n This can materially improve object program run time.\n", "1355": "Regular Coulomb Wave Functions (Algorithm 292 )", "1356": "Havie Integrator (Algorithm 257 [D1])", "1357": "Examination Scheduling (Algorithm 286 [H])", "1358": "Syntax Macros and Extended Translation A translation approach is described which allows\none to extended the syntax and semantics of \na given high-level base language by the use of a new\nformalism called a syntax-macro.  Syntax-macros \ndefine string transformations based on syntactic elements\nof the base language.  Two types of macros \nare discussed, and examples are given of their use.  The\nconditional generation of macros based on options \nand alternatives recognized by the scan are also described.\n", "1359": "Data Filtering Applied to Information Storage and Retrieval Applications Manipulation of data strings is the most complex\nprocessing function in information storage \nand retrieval applications.  Data string manipulation\nis discussed within the context of an interpretive \nprocessing environment controlled by the use of procedural\ndirectives.  The sequence of procedural directives \nis derived from a job assumed to be expressed in a user-oriented\nsource language.  Each data string with \nthe structured data environment (data bank) is explicitly\nor implicitly related to a format declaration\nresiding in a format library.  The processing mechanics\nassociated with data string manipulation is developed \nin accordance with a generalized data filtering concept.\n This results in the implementation of a two-part \ndata filter module that satisfies internal processing\nfunctions by filtering data strings through format \ndeclarations associated with its input and output ports.\n", "1360": "Description of Systems Used for Data Transmission* (An ASA Tutorial)", "1361": "Rectangular Holes in Twelve-Row Punched", "1362": "Code Extension in ASCII* (An ASA Tutorial) The American Standard Code for Information\nInterchange (ASCII) contains a number of control \ncharacters associated with the principle of code extension,\nthat is, with the representation of information \nwhich cannot be directly represented by means of the characters\nin the Code.  The manner of use of these \ncharacters has not previously been completely described.\n This paper presents a set of mutually consistent \nphilosophies regarding code extension applications,\nand suggests a corollary set of doctrines for the \napplication of the code extension characters.  Distinctions\nare drawn between code extension and such \nother concepts as \"graphic substitution\" or \"syntactic\nrepresentation\" which are often used to meet similar \nrequirements.  Also covered are certain topics which\nare not truly concerned with code extension but \nwhich are often linked with it in discussion on code applications.\n The material in this paper is equally \napplicable in principle to the (proposed) ISO international\n7-bit code for information interchange.\n", "1363": "A General Method of Systematic Interval Computation A procedure is given for continuously computing\nand monitoring the step size to be used by \na self-starting, p-th order numerical integration method\nto solve an initial value problem.  The procedure \nuses an estimate of the truncation error to calculate the step size.\n", "1364": "Mathematical Experimentation in Time-Lag Modulation Equations of the form du/dt = g(u(t),u(h(t)))\narise in a number of scientific contexts.  The \nauthors point out some interesting properties of the\nsolution u'(t) = -u(t-1-k*sin(wt))+sin(at).  These \nproperties were obtained by means of numerical solution.\n", "1365": "Eliminating Monotonous Mathematics with FORMAC The FORMAC (FORmula MAnipulation Compiler)\nprogramming system provides a powerful tool for \nperforming mathematical analysis.  It is an extension\nof FORTRAN IV which permits the use of the computer \nto perform the tedious algebraic computations that arise\nin many different fields.  Among the areas in \nwhich it has been successfully used are: differentiation\nof complicated expressions, expansion of truncated \npower series, solution of simultaneous equations with\nliteral coefficients, nonlinear maximum likelihood \nestimation, tensor analysis, and generation of the coefficients\nof equations in Keplerian motion.  These \ntypes of analysis-which arose in the solution of specific\npractical problems in physics, engineering, \nastronomy, statistics and astronautics-are discussed in\nthe paper.  In addition to its usage for specific \nproblem solutions, FORMAC can also be used to automate\nthe analysis phase in certain production programming. \n Several such applications are presented.\n", "1366": "Computer Simulation-Discussion of the The purpose of this paper is to present a comparison\nof some computer simulation languages \nand of some of the involved in comparing software packages\nfor digital computers are discussed in Part \nI.  The issue is obvious: users of digital computers\nmust choose from available languages or write their \nown.  Substantial costs can occur, particularly in training,\nimplementation and computer time if an inappropriate \nlanguage is chosen.More and more computer simulation\nlanguages are being developed: comparisons and \nevaluations of existing languages are useful for designers\nand implementers as well as users.  The second \npart is devoted to computer simulation and simulation\nlanguages.  The computational characteristics of \nsimulation are discussed with  special attention being\npaid to a distinction between continuous and discrete \nchange models.  Part III presents a detailed comparison\nof six simulation languages and packages: SIMSCRIPT, \nCLP, CSL, GASP, CPSS and SOL.  The characteristics of\neach are summarized in a series of tables.  The \nimplications of this analysis for designers of languages,\nfor users, and for implementers are developed. \n The conclusion of the paper is that the packages now\navailable for computer simulation offer features \nwhich none of the more general-purpose packages do and\nthat analysis of strengths and weaknesses of each \nsuggests ways in which both current and future simulation\nlanguages and packages can be improved.\n", "1367": "Character Structure and Character Parity Sense", "1368": "Systematic Generation of Hamiltonian Circuits For a combinatorial matrix which may specify\nboth directed and nondirected arcs, the paper \ndescribes a computer program which generates systematically\nand exhaustively all the Hamiltonian circuits. \nSpecific application is made to the \"traveling salesman\" problem.\n", "1369": "Half Rotations in N-Dimensional Euclidean Space An iterative procedure is described for determining\nhalf rotations in n-dimensional Euclidean \nspace. The method is a variant of the cyclic Jacobi\nprocedure and utilizers elementary plane rotations \nto obtain the half rotation matrix.  Numerical examples are given.\n", "1370": "Linear Equations, Exact Solutions (Algorithm 290 [F4])", "1371": "Logarithm of Gamma Function (Algorithm 291 [S14])", "1372": "Direct Search (Algorithm 178 [E4])", "1373": "Gamma Function; Gamma Function for Range 1 to", "1374": "Evaluation of Determinant; Determinant", "1375": "Function Minimization (Algorithm 251 [E4])", "1376": "Modified Graeffee Method (Algorithm 256 [C2])", "1377": "Pseudo-Random Numbers (Algorithm 266 [G5])", "1378": "Pseudo-Random Numbers (Algorithm 266 [G5])", "1379": "A Final Solution to the Dangling Else of ALGOL 60 and Related Languages The dangling else problem consists of a class\nof potential ambiguities in ALGOL-like conditional \nstatements whose basic form is \"if B1 then if B2 then\nS1 else S2\" where B1 and B2 are Boolean expressions \nand S1 and S2 are basic statements.  The difficulty\nlies in whether to attach the else to the first if \nor to the second one.  Existing solutions to the problem\nare either ambiguous or unnecessarily restrictive. \n Let Sand S1 be statements.  We define S to be closed\nif \"S else S1\" is not a statement, and to be open \nif \"S else S1\" is a statement.  Thus an unconditional\nstatement is  a closed statement.  Open and closed \nconditional statements are defined by syntax equations\nin such a way as to preserve openness and closure. \n In each case, an else must always be preceded by a closed\nstatement.  It is shown that the syntax equations \nare unambiguous, and that may change in the statement\ntypes required within the syntax equations would \nlead to either ambiguity or unnecessary restriction.\n", "1380": "SIMULA-an ALGOL-Based Simulation Language This paper is an introduction to SIMULA, a\nprogramming language designed to provide a systems \nanalyst with unified concepts which facilitate the\nconcise description of discrete event systems.  A \nsystem description also serves as a source language simulation\nprogram.  SIMULA is an extension of ALGOL \n60 in which the most important new concepts\nis that of quasi-parallel processing.\n", "1381": "Impact of Computers on the Undergraduate Mathematics Curriculum  The use of computers to permit the widespread application\nof mathematical ideas requiring computation \nin science and technology is extremely significant for\nthe understanding of our current society.  Student \ninterest in this development is intense and if properly\nutilized should yield a much better understanding \nof mathematical concepts as well as the ideas of programming\nand logical structure which have been introduced \ninto many fields by the use of computers.  The present\npaper suggests that that portion of the undergraduate \nmathematical curriculum which is preparation for the use\nof mathematics by persons who are not professional \nmathematicians be modified to include the extensions\nand clarifications which are possible because of \ncomputers.  An early introduction to programming is\ndesirable to permit a continuing use of automatic \ncomputation to illustrate and clarify mathematical concepts.\n Following the calculus equation stage an \nintensive introduction to numerical analysis should\nbe added to the current curriculum.  In addition \nto providing competence in the mostly used computing\ntechniques, it would permit a more sophisticated \nutilization of the advanced mathematical ideas associated\nwith complex variables and transform theories.\n", "1382": "Desired Computer Impact on Undergraduate Mathematics  Three matters relating to the theme of the\nSymposium are discussed here.  The author examines \nsome projections concerning the supply and demand for\nmathematicians in the United States through the \nmid-1970s, comments briefly on some of the factors which\nmay influence the professional activities of \napplied mathematicians over the next several years,\nand discusses in broad terms how this information \nmay relate to the undergraduate training of mathematicians.\n", "1383": "Implications of the Digital Computer The digital computer has profoundly altered the\ndefinition of what is interesting in mathematics. \n The importance of applied logic in human affairs is\nchanged by the existence of the \"logical engine.\" \n The result is that one should no longer think in terms\nof a single discipline of mathematics but in \nterms of a complex of mathematical sciences.\n", "1384": "Mathematics for Undergraduate Computer Scientists The mathematical requirements for an undergraduate\nprogram in Computer Science are a subject \nof debate.  The Association for Computing Machinery's\nCurriculum Committee, however, believes that these \nrequirements are essentially the same as the mathematical\ncontent of physical sciences undergraduate \nprograms.  The Committee believes that these requirements\nshould assure the student of a broad mathematical \nbackground and should enable him to take a wide variety\nof courses in other scientific disciplines.  \nThe Committee's concern is to develop a solid\nscientific  approach to Computer Science.\n", "1385": "Computer Technology in Communist China, 1956-1965 Based on information from translations of Communist\nChinese news items and periodical literature \nfor the 1965 period, computer technology in China is\nreviewed under the following headings: (1) initial \nplanning, organization and educational aspects of computer\ntechnology and automation; (2) machine development \nprogress: two major specific machines in 1958-59, with\nSoviet aid; a vacuum in 1960-64 due to the withdrawal \nof Soviet aid; then presumably all-Chinese-made machines\nfrom 1965 to the present; (3) computer applications; \n(4) the trend of automation: control of production processes\nrather than data processing; and (5) the \n\"Yun Ch'ou Hsueh\" (Science of Operation and Programming)\ncampaign of 1958-60, during which an attempt \nwas made to bring concepts such as linear programming\nto ordinary Chinese workers and peasants.  Communist \nChina is adjudged to have a marginal computer capability,\nwith most of its machines probably being of \na binary nature; however, a turning point may have been reached in mid-1965.\n", "1386": "Symbolic Factoring of Polynomials in Several Variables An algorithm for finding the symbolic factors of\na multi-variate polynomial with integer coefficients \nis presented.  The algorithm is an extension of a technique\nused by Kronecker in a proof that the prime \nfactoring of any polynomial may be found in a finite number\nof steps.  The algorithm consists of factoring \nsingle-variable instances of the given polynomial by\nKronecker's method and introducing the remaining \nvariables by interpolation.  Techniques for implementing the\nalgorithm and several examples are discussed. \n The algorithm promises sufficient power to be used efficiently\nin an online system for symbolic mathematics.\n", "1387": "Solution of Systems of Polynomial Equations By Elimination The elimination procedure as described by Williams\nhas been coded in LISP and FORMAC and used \nin solving systems of polynomial equations.  It is found\nthat the method is very effective in the case \nof small systems, where it yields all solutions without\nthe need for initial estimates. The method, by \nitself, appears in appropriate, however, in the solution\nof large systems of equation due to the explosive \ngrowth in the intermediate equations and the hazards\nwhich arise when the coefficients are truncated. \n A comparison is made with difficulties found in other\nproblems in non-numerical mathematics such as \nsymbolic integration and simplification.\n", "1388": "AUTOMAST: Automatic Mathematical Analysis and Symbolic Translation A procedure for numerically solving systems\nof ordinary differential equation is shown to also \ngenerate symbolic solutions.  The procedure is based\non a finite Taylor series expansion that includes \nan estimate of the error in the final result.  A computer\nprogram is described that reads in a system \nof such equations and then generates the expansions\nfor all of the dependent variables. The expansions \nare determined symbolically, hence any non-numeric parameters\nin the original equations are carried automatically \ninto the final expansions.  Thus the exact influence\nof any parameters on the problem solution can be \neasily displayed.\n", "1389": "A Programmer's Description of L^6 Bell Telephone Laboratories' Low-Linked List Language\nL^6 (pronounced \"L-six\") is a new programming \nlanguage for list structure manipulations.  It contains\nmany of the facilities which underlie such list \nprocessors as IPL, LISP, COMIT ad SNOBOL, but permits\nthe user to get much closer to machine code in \norder to write faster-running programs, to use storage\nmore efficiently and to build a wider variety \nof linked data structures.\n", "1390": "CONVERT A programming language is described which\nis applicable to problems conveniently described \nby transformation rules.  By this is meant that patterns\nmay be prescribed, each being associated with \na skeleton, so that a series of such pairs may be searched\nuntil a pattern is found which matches an \nexpression to be transformed.  The conditions for a match\nare governed by a code which also allows subexpressions \nto be identified and eventually substituted into the\ncorresponding skeleton.  The primitive patterns \nand primitive skeletons are described, as well as the\nprinciple which allow their elaboration in to more \ncomplicated patterns and skeletons.  The advantages of the\nlanguage are that it allows one to apply transformation \nrules to lists and arrays as easily as strings, that both\npatterns and skeletons may be defined recursively, \nand that as a consequence programs may be stated quite concisely.\n", "1391": "Computer Experiments in Finite Algebra A medium-scale programming system is written\nin MAD and FAP on the IBM 7094 to manipulate some \nof the objects of modern algebra: finite groups, maps\nand sets of maps, subsets and sets of subsets, \nconstant integers and truth-values.  Designed to operate\nin a time-sharing environment, the system can \nserve as a teacher's aid to the undergraduate student of\nmodern algebra, as well as for the working scientist \nor engineer wishing to familiarize himself with the subset.\n", "1392": "Experience with FORMAC Algorithm Design Various facets of the design and implementation\nof mathematical expression manipulation algorithms \nare discussed.  Concrete examples are provided by the\nFORMAC EXPAND and differentiation algorithms, a \nbasic FORMAC utility routine, and an experiment in the\nextraction of the skeletal structure of an expression. \n One recurrent theme is the need to avoid excessive\nintermediate expression swell in order to minimize \ncore storage requirements. Although many details from\nthe FORMAC implementation are presented, an attempt \nis made to stress principles and ideas of general relevance\nin the design of algorithms for manipulating \nmathematical expressions.\n", "1393": "PM, A System for Polynomial Manipulation PM is an IBM 7094 program system for formal manipulation\nof polynomials in any number of variables, \nwith integral coefficients unrestricted in size.  Some\nof the formal operations which can be performed \nby the system are sums, differences, products, quotients,\nderivatives, substitutions and greater common \ndivisors.  PM is based on the REFCO III list processing\nsystem, which is described and compared with \nthe LISP and SLIP systems.  The PM subroutines for arithmetic\nof large integers are described as constituting \nan independently useful subsystem.  PM is compared with\nthe ALPAK system in several respects, including \nthe choice of canonical forms for polynomials.  A new\nalgorithm for polynomial greatest common divisor \ncalculation is mentioned, and exaples are\nincluded to illustrate its superiority.\n", "1394": "Computation of Algebraic Properties of Elementary A large number of calculations in high-energy\nelementary particle physics involve the manipulation \nof complicated algebraic expressions containing both\ntensor and noncommutative matrix quantities.  Many \nof these calculations take several months to complete, although\nthe operations involved follow straightforward \nrules.  In this paper a program is described, which has\nbeen developed in LISP for solving such problems. \n The manner in which these problems are encountered is\noutlined, and their representation in the computer \ndiscussed.  At present, about six months of human work\ntakes less than fifteen minutes on an IBM 7090. \n Limitations of the present system and future plans are also outlined.\n", "1395": "On the Implementation of AMBIT, A Language for Symbol Manipulation A brief description is given of the implementation\ntechnique for the replacement rule of the \nAMBIT programming language.  The algorithm for the \"AMBIT\nscan\" and an example of its application are \ngiven.  The algorithm is applicable to other members\nof the family of string transformation languages \nof which AMBIT is a member, and it provides a rationale\nfor the design of the AMBIT language.\n", "1396": "Survey of Formula Manipulation The field of formula manipulation is surveyed,\nwith particular attention to the specific capabilities \nof differentiation, integration and the supporting capabilities\nof simplification, displays and input/output \nediting, and precision arithmetic.  General systems-both\nbatch and online-are described.  Finally, some \nprograms to solve specific applications are discussed.\n", "1397": "Proceedings of the ACM Symposium on Symbolic and Algebraic Manipulation The ACM Symposium on Symbolic and Algebraic\nManipulation brought together over four hundred \npeople interested in programming languages designed\nfor manipulation of algebraic formulas and symbol \nstrings, in their applications, and in algorithms for\ntheir implementation.  Twenty-eight papers were \npresented, followed by a lively panel discussion of\nfuture directions.  Evening meetings were arranged \nfor several interest groups.  The conference was sponsored\nby the ACM Special Interest Committee on Symbolic \nand Algebraic Manipulation.  The program committee consisted\nof Chairman Jean E. Sammet, Paul Abrahams, \nThomas E. Cheatham, Max Goldstein, and Douglas Mcllroy.\n Conference arrangements were made by Lewis C. \nClapp, Daniel Bobrow and James H. Griesmer.-Robert W. Floyd, Editor\n", "1398": "Robot Data Screening: A Solution to Multivariate A new approach is outlined toward the solution\nof the type of multivariate problem that is \nfound usually in the biological and social sciences as\nwell as in medicine.  This approach uses a \"logical\" \nrather than a \"statistical\" criterion by which variables\nare grouped into a deterministic model.  Algorithm \nare developed by which some variables are kept on for\nfurther analysis while others are eliminated.  \nCriteria for the acceptance of a variable as well as the\ntermination of the searching process are derived \nfrom information theory.\n", "1399": "On Top-to-Bottom Recognition and Left Recursion A procedure is given for obtaining structural\ndescriptions in a context-free grammar by performing \nthe recognition according to a strongly equivalent, \nleft-recursion-freegrammar. The effect of allowing \nnull strings in the rewriting rules is discussed.\n", "1400": "Free-Text Inputs to Utility Routines Through the use of some rather simple techniques,\nit is frequently possible to produce a program \nwhich will accept free-text inputs.  The techniques are\ndiscussed and related to a general tape manipulation \nroutine.\n", "1401": "Quasilinearization and the Calculation of Eigenvalues Several eigenvalue problems for systems of\nordinary differential equations are considered. \n They are resolved computationally using the quasilinerization\ntechnique, a quadratically convergent \nsuccessive approximation scheme related to\nthe Newton-Raphson-Kantorovich method.\n", "1402": "Partial Step Integration A partial step integration equation is derived\nfor use with the Adams or Adams-Bashforth method \nof integration of differential equations.  This method\nof obtaining functional values at points intermediate \nto the integration points yields accuracy comparable\nto the integration and does not require storing \nof additional information as in interpolation methods.\n", "1403": "A Method for Finding the m Smallest Values of The minimum value of a monotonic increasing\nfunction defined on a partially ordered set S is \nassumed on the set of minimal points of S.  This observation\nis used to devise an efficient method for \nfinding the m smallest functional values of monotonic\nfunctions defined on ordered pairs of positive \nintegers.  The method is easily extended to include\nmonotonic functions defined on ordered n-tuples. \n Included is a FORTRAN program which was written to implement\nthe procedure for a certain important case.\n", "1404": "Computational Aspects of Multiple Covariance The computational procedure for the analysis\nof multiple covariance in statistics is discussed \nwith reference to the analysis of variance.  A special\noperator calculus developed by Hartly for programming \nanalysis of variance for multifactor experiments is extended\nto cover the analysis of covariance.  This \nextension is accomplished by utilizing the connection\nbetween the analysis of covariance and the analysis \nof variance and by introducing a new operator.  The\nresults are illustrated by a numerical example for \nanalysis of covariance, in which the basic computations\nare shown to be carried out by an analysis-of-variance \nprogram.\n", "1405": "Matrix Triangulation with Integer Arithmetic (Algorithm 287 [F1])", "1406": "Solution of simultaneous Linear Diophantine", "1407": "Confidence Interval for a Ratio (Algorithm 289 [G1])", "1408": "The Eschenbach Drum Scheme The prime function of a drum, operating in\nreal time, is to perform accesses quickly.  The \nusual means for increasing this capacity is to incorporate\nengineering or hardware improvements.  In \nthis paper the problem is attacked not by changing the\ndrum, but rather by modifying the manner in which \nit operates.  At the outset, a drum is given a functional\ndefinition.  Then a simple design scheme (Eschenbach) \nis introduced which enormously increases the rate of\naccessing for drums so defined.  This is shown to \nenable a system to perform a job by employing fewer or\nless expensive drums.  It is suggested that although \nthe design scheme has a specific use, the method underlying it\nhas more general applicability.  The question \nof the efficacy of the drum scheme is then raised.  To\ndeal with this, a standard of efficiency is developed \nin light of realistic real-time circumstances.  The drum\nscheme is then modelled in a manner which permits \nit to be analyzed as a problem in queueing theory. \nThus one is enabled to ascertain whether the drum \nscheme is efficient enough for its application.  Again,\nwhereas the analysis of the drum scheme has a \nspecific use, the methods underlying it have more general applicability.\n", "1409": "NEBULA: A Digital Computer Using a 20 Mc Glass Delay Line Memory Oregon State University has designed and constructed\na medium-speed serial digital computer \nusing glass delay lines circulating at 22 Mc as memory.\n The design objectives as originally conceived \nin a special seminar were: (1) to be a research project\nin computer design; (2) to be usable as an educational \nmachine;and (3) to have easily modifiable hardware for\nbasic research in computer systems design.  An \nunusual arrangement of information within the 22 Mc\nmemory allows a simple interface with the 340 Kc \narithmetic unit, which results in an effective zero latency\ntime and provides possibilities for an associative \nmemory.  The arithmetic unit has a command structure similar\nto large parallel machines, and uses flip-flop \narithmetic and control registers throughout.  All hardware\ndevelopment has been aimed toward the concept \nof easy modification, elaborate console controls for\neffective man-machine interaction and low cost.\n", "1410": "Interarrival Statistics for Time Sharing Systems The optimization of time-shared system performance\nrequires the description of the stochastic \nprocesses governing the user inputs and the program activity.\n This paper provides a statistical description \nof the user input process in the SDC-ARPA general-purpose\nTime-Sharing System (TSS).  The input process \nis assumed to be stationary, and to be defined by the\ninterarrival time distribution.  The data obtained \nappear to justify satisfactorily the common assumption\nthat the interarrival times are serially independent. \n The data do not appear to justify, except as a very\nrough approximation, the usual assumption off an \nexponential distribution for interarrival time.  A much\nmore satisfactory approximation to the data can \nbe obtained with a biphase or triphase hyperexponential distribution.\n", "1411": "Comparison of Several Algorithms for Computation Several algorithms for computation of basic\nstatistics are compared by their performance on \nsystematically generated test data.  The statistics\ncalculated were the mean, standard deviation and \ncorrelation coefficient.  For each statistic, the algorithm\nincluded the usual computing formulas, correction \ndue to an accumulated error term, and a recursive computation\nof the current value of the statistic. \n The usual computing formulas were also evaluated in\ndouble precision.  Large errors were noted for some \ncalculation using the usual computing formulas.  The most\nreliable technique was correction of the initial \nestimate by use of an accumulated error term.  To eliminate\nthe need for making two passes on the data, \nit was suggested that the initial estimate of the\nmean be obtained from a subset of the data.\n", "1412": "The Banking Information System Concept Most large commercial banks have progressed to\nthe  point where their major accounting applications \nhave been automated and more sophisticated usage of\ndata processing equipment is being sought.  This, \ncoupled with the availability of equipment well suited\nto real-time, direct access processing,has led \nto development within some banks of the central file\nof data base approach toward a banking information \nsystem.  The banking information system now serves the\ntwo-fold purpose of providing real-time responses \nto inquires about individual account stasus and providing\nmore complex combinations of information for \nmanagement use.  Both kinds of processing draw upon a\ncommon store of data contained in the direct access \ncentral file.  This data base includes indexes which\nfacilitate cross referencing of account information \nso that all relationships between bank and customer may\nbe discerned.  In introducing the banking information \nsystem concept, a gradual approach to account cross-referencing\nand file conversion is most prudent. \n Generally, this system must interface with other computer\napplications already existing within the bank.\n", "1413": "A Vision of Technology and Education Educational technology is currently quite\nfashionable.  Here, as in many other branches or \naspects of technology, changes possible in the next generation\nor two are now known as ideas, discoveries \nor inventions.  The unknown is whether the potential\nwill become the actual and, if so, on what time \nscale.  This ignorance stems largely from ignorance about\nthe social response to potential technological \nchange.  The object of this paper is to present a vision\nof potential educational technology and to raise \nquestions about the modes of social response and\nadaptation likely to be evoked by such a vision.\n", "1414": "Twelve-Row Punched-Card Code for Information", "1415": "Automatic Derivation of Microsentences The decomposition of long complex English sentences\ninto shorter kernel-like constituent sentences \n(microsentences)has often been suggested as an avenue\ntoward conducting automatic retrieval of natural \nlanguage messages.  To explore the prospects of such\na step, the authors attempted in 1963 to prepare \na general program for deriving microsentences from longer\nsentences that had been syntactically analyzed \nby the Harvard Multipath Analysis Program.  The basic\nidea was to extract the subject, verb and object \n(if any) of each clause and to reassemble these materials\ninto a grammatical microsentence.  A program \nis described in this paper, which was designed to operate\non the tree structure output of the analyzer, \nand the microsentences that were produced are exhibited.\n The authors conclude that while microsentences \nof the quality achieved do not open up immediate prospects\nfor improving the performance of automatic \nmessage retrieval systems, they may have practical\nvalue in man-machine systems using human monitors \nto select the preferred syntactic interpretation of a sentence.\n", "1416": "A Fortran Technique for Simplifying Input to Report Generators Typical report generators allow the production\nof standard forms when tabulating a magnetic \ntape file; the extraction of nonstandard sets of information,\nwith suitable annotation, involves troublesome \nforms design.  A method of information extraction involving\nthe calculation of suitable FORTRAN FORMAT \nstatements, which combats this problem, is described.\n", "1417": "Economies of Scale and the IBM System/360 Cost functions among five System/360 models\nare analyzed through examinations of instruction \ntimes, program kernels and a \"typical\" instruction mix.\n Comparisons are made between the data developed \nhere and Grosch's Law which seems to be applicable to\nmuch of the data.  Sizable economies of scale are \nunquestionably present in computing equipment. \n", "1418": "Examination Scheduling (Algorithm 286 [ZH])", "1419": "Chebyshev Quadrature (Algorithm 279 [D1])", "1420": "A New Uniform Pseudorandom Number Generator A new multiplicative congruential pseudorandom\nnumber generator is discussed, in which the \nmodulus is the largest prime within accumulator capacity\nand the multiplier is a primitive root of that \nprime.  This generator passes the usual statistical\ntests and in addition the least significant bits \nappear to be as random as the most significant bits-a\nproperty which generators having modulus 2^k do \nnot possess.\n", "1421": "A Contribution to the Development of ALGOL A programming language similar in many respects\nto ALGOL 60, but incorporating a large number \nof improvements based on six years experience with that\nlanguage, is described in detail.  Part I consists \nof an introduction to the new language and a summary\nof the changes made to ALGOL 60, together with a \ndiscussion of the motives behind there visions.  Part II\nis a rigorous definition of the proposed language. \n Part III describes a set of proposed standard procedures\nto be used with the language, including facilities \nfor input/output.\n", "1422": "Eleven-Sixteenths Inch Perforated", "1423": "A Simple Algorithm for Computing the Generalized Inverse of a Matrix The generalized inverse of a matrix is important\nin analysis because it provides an extension \nof the concept of an inverse which applies to all matrices.\n It also has many applications in numerical \nanalysis, but it is not widely used because the existing\nalgorithms are fairly complicated and require \nconsiderable storage space.  A simple extension has\nbeen found to the conventional orthogonalization \nmethod for inverting non-singular matrices, which gives\nthe generalized inverse with little extra effort \nand with no additional storage requirements.  The algorithm\ngives the generalized inverse for any m by \nn matrix A, including the special case when m+n and A\nis non-singular and the case when m>n and rank(A) \n= n.  In the first case the algorithm gives the ordinary\ninverse of A.  In the second case the algorithm \nyields the ordinary least squares transformation matrix\nINV(A'A)A' and has the advantage of avoiding \nthe loss of significance which results in forming the product A'A explicitly.\n", "1424": "Automatic Analysis of Electronic Digital Circuits Using List Processing A mapping from black diagrams of digital circuits\nto list structures is described, together \nwith a list processing program written for the Control\nData 3600 which uses this mapping to automatically \ncarry out circuit analysis.\n", "1425": "Flow Diagrams, Turing Machines And In the first part of the paper, flow diagrams\nare introduced to represent inter al. mappings \nof a set into itself.  Although not every diagram is\ndecomposable into a finite number of given base \ndiagrams, this becomes true at a semantical level due\nto a suitable extension of the given set and of \nthe basic mappings defined in it.  Two normalization\nmethods of flow diagrams are given.  The first has \nthree base diagrams; the second, only two.  In the second\npart of the paper, the second method is applied \nto the theory of Turing machines.  With every Turing\nmachine provided with a two-way half-tape, there \nis associated a similar machine, doing essentially\nthe same job, but working on a tape obtained from \nthe first one by interspersing alternate blank squares.\n The new machine belongs to the family, elsewhere \nintroduced, generated by composition and iteration from\nthe two machines L and R.  That family is a proper \nsubfamily of the whole family of Turing machines.\n", "1426": "A Simulation of Hospital Admission Policy A study is described which simulates different\nadmission policies of a large specialized hospital. \n The objective is to determine better policies for\nstabilization of admission and census rates while \nmaintaining a reasonably full hospital.  There types of\npolicies were examined: admission based on percentages \nof discharge rates, discharge rates plus or minus a\nconstant, and fixed authorizations independent of \ndischarge rates.  The last type policy produced more stable\nsimulated results, and when put into practice, \nimprovements were realized.\n", "1427": "Simulation of Radioisotope Scans by Computer In radioisotope scanning, a field which is assuming\nincreasing importance in medical diagnosis, \nthe scan is a two-dimensional pattern made up of dots.\n Areas of increased source activity are represented \non the scan by areas of increased dot density.  To study\nthe output of scanners with various characteristics, \na program which simulates radioisotope scans has been\nwritten  for a PDP-1 computer with auxiliary disk \nstorage and cathode ray tube display.  Past and present\nresearch using the output of the simulator has \nshown the flexibility of the system to be important.\n The structure of this program can be useful in \nthe simulation of the output of any quantum-limited system.\n", "1428": "SHOCK III, A Computer System As an Aid SHOCK III, an online digital computer system\nto assist the physician, nurse and paramedical \npersonnel in monitoring and reporting on critically ill patients, is described.\n", "1429": "Matrix Reduction Using the Hungarian Method The application of Kuhn's Hungarian Method\nto the problem of matrix reduction as needed in \nGotlieb's method for timetable generation is described.\n The method is suited to both hand and computer \ncalculation.  Devices to improve the efficiency\nof the basic algorithm are discussed.\n", "1430": "Multiple Precision Floating-Point Conversion Decimal-to-binary and binary-to-decimal floating-point\nconversion is often performed by using \na table of the powers 10^i, (ia positive integer) for\nconverting from base 10 to base 2, and by using \na table of the coefficient of a polynomial approximation\nof 10^x, (0<=x<1) for converting from base 2 \nto base 10.  These tables occupy a large storage region\nin the case of a nonsingle precision conversion. \n This paper shows that a single small table suffices\nfor a floating-point conversion from decimal to \nbinary, and vice versa, in any useful precision.\n", "1431": "On a Storage Mapping Function For Data Structures Some basic facts about certain data structures\nare reviewed and an efficient algorithm is presented \nfor constructing a storage mapping function for\na structure from the structure's definition.\n", "1432": "Incorporation of Nonstandard Input/Output Devices into FORTRAN Systems A FORTRAN system may readily be modified to\nhandle input/output with nonstandard media on the \nsame basis on which it handles the standard media.  This\nis done by providing a character-handling subroutine \nsuited to the nonstandard medium and arranged to be called\nby an otherwise unused output statement type \nor unit number. This method was used to control output\nof alphanumeric information on a digital graph \nplotter.\n", "1433": "A Note on Linear Programming Algorithm Design: A Combinatorial Problem As linear programming models grow bigger and\nbigger in size, much actual data that must be \nmemorized is often put on magnetic tape or disk, and\nconsequently there is an improportionality fast \nrise in the consumption of computer time.To cut down\nthis expense, an ever increasing effort is made \nto design more efficient algorithms.  This paper is\nmeant to support the effort.  It is attempted to \nfind some characteristics of the way a pivot column\nis found.  The number of repetitions of a certain \ntransfer of data from tape to core memory is considered.\n After some simplification, the problem is restated \nin a general way.  The generating function of the probability\ndistribution and the moment generating \nfunction of the number of repetitions is found.  Asymptotic\nformulas are given for the moments using \na result from a paper of S. Narumi [1].  The results\nmay be applied to write very efficient routines \nthat search for an extreme value in a table.  Formulas\nprovide a means of calculating the computer timings \nin this case.\n", "1434": "A Monte Carlo Algorithm for Assigning Students to Classes A technique of random choice is illustrated\nby application to the problem of assigning students \nto a fixed schedule of courses.  Using the technique\nit is possible to reduce or eliminate difficulties \nthat result when a popular section is filled and closed\nbefore all students requesting and requiring \nit have been scheduled.  The effectiveness of automatic\nscheduling is retained without loss of the students \nprivilege of picking favorite instructors.\n", "1435": "Design of Computer Simulation Experiments for Industrial Systems The aim of this paper is to provide background\ninformation on the existing literature on experimental \ndesign techniques which may be applicable to the design\nof computer simulation experiments for industrial \nsystems.  Although major emphasis is placed on analysis\nof variance techniques, three other techniques \nof data analysis are considered-multiple ranking procedures,\nsequential sampling and spectral analysis. \n The paper treats four specific experimental design\nproblems and several techniques for solving them. \n The four experimental design problems are: (1) the\nproblem of stochastic convergence, (2) the problem \nof factor selection, (3) the problem of motive\nand (4) the many response problem.\n", "1436": "Interchange of Two Blocks of Data (Algorithm 284 [K2])", "1437": "The Mutual Primal-Dual Method (Algorithm 285 [H])", "1438": "A Method for Locating Zeros of Complex Functions A method for computing the index, or winding\nnumber, is developed and applied to the problem \nof finding zeros of functions from the plane into the plane.\n", "1439": "Mechanization of the Curve Fitting Process: DATAN A process for fitting a curve to approximate data\nand the problem it creates for the engineer-programmer \nis defined.  An approach has also been defined and a system\nhas been written for the SRU 1107 to mechanize \na major portion of this process.  The techniques developed\nto accomplish the mechanization are largely \nempirical, and are dependent for their information\nonly on the actual data points.\n", "1440": "Starting Approximations for Square Root Calculation on IBM System/360 Several starting approximations for square\nroot calculation by Newton's method are presented \nin a form to facilitate their use in IBM System/360 square\nroot routines.  These approximations include \nseveral for the range [1/16, 1], which is the interval\nof primary interest on IBM System/360.\n", "1441": "Methods of Numerical Integration Applied to A study has been made to determine which methods\nof numerical integration require the least \ncomputation time for a given amount of truncation error\nwhen applied to a particular system of ordinary \ndifferential equations where function evaluations are\nrelatively trivial.  Recent methods due to Butcher \nand Gear are compared with classic Runge-Kutta, Kutta-Nystrom\nand Adams methods.  Some of the newer one-step \nmethods due to Butcher are found to be slightly superior,\nbut no one method is found to have any great \nadvantage over the others in the application to this particular problem.\n", "1442": "Recorded Magnetic Tape For Information Interchange", "1443": "A Method for Finding the Least Squares Estimate When the helical trajectories of two charged\nparticles moving away from a common point in a \nmagnetic field are reconstructed from measurements on\nthe tracks, the reconstructed tracks are perturbed \nby measurement and other errors and do not, in general,\nintersect.  A method is given for adjusting the \nreconstructed tracks in a least squares manner so that they do intersect.\n", "1444": "An Algorithm for Generating Projective Reduction An ALGOL procedure is given for automatically\ngenerating formulas for matrix elements arising \nin the variational solution of the Schrodinger\nequation for many-electron systems.\n", "1445": "Use of the Computer to Teach Introductory Statistics It has always been obvious that the aid to calculation\noffered by the computer forces a change \nin the curricula of mathematics, statistics, physics,\nengineering and other courses.  Not so obvious \nare the many pedagogic aids the computer can offer in\nteaching the subject matter.  The possibilities \nof giving the student a better technical as well as conceptual\nunderstanding of statistics were explored \nfor a number of years at the College of Medicine of\nthe University of Cincinnati and are reported here.\n", "1446": "Chebyshev Quadrature (Algorithm 279 [D1])", "1447": "Abscissas and Weights for Gregory Quadrature [D1])", "1448": "Abscissas and Weights for Romberg Quadrature (Algorithm 281 [D1])", "1449": "Derivatives (Algorithm 282 [S22])", "1450": "Simultaneous Displacement of Polynomial", "1451": "Runge-Kutta Integration (Algorithm 9 [D2])", "1452": "Kutta-Merson (Algorithm 218 [D2]", "1453": "A Nonrecursive Method of Syntax Specification The use of the Kleene regular expression notation\nfor describing algebraic language syntax, \nin particular of ALGOL, is described in this paper. \nA FORTRAN II computer program for carrying out the \nelimination algorithm of Gorn,similar to Gaussian elimination\nfor linear systems of algebraic equations, \nis described.  This was applied to numerous smaller\nlanguages, including some sublanguage of ALGOL.  \nA hand calculation result of the application of the algorithm\nto all of ALGOL is given, thus expressing \nthe Revised ALGOL 1960 syntax in completely nonrecursive\nterms, as far as its context-free portion is \nconcerned.  This description in many ways is far more\nintuitively understood than the previous recursive \ndescription, it is suggested.  The paper also includes\nresults of the machine program, which does not \ninclude a simplification algorithm.\n", "1454": "A Simple User-Oriented Compiler Source Language For the nonprogrammer, difficulty in using\na language increases rapidly with the number of \nnonproblem-oriented conventions.  A simple language, even\nif inelegant, which considers the user's background \nas part of the problem may be more effective than a source\nlanguage containing subtle and more powerful \ncapabilities.  The language described in this paper is\nused to write computer programs which test electronic \nequipment.  Because this testing process contains few\ncomplex ideas, there is little need for the elegance \nand redundancy of a highly syntax-oriented language.\n A simple and direct language will suffice for the \nproblem.  The eventual users of this language are military\ndepot personnel who cannot he expected to \nhave computer programming skill or significant programming\ntraining.  For this nonprogramming-oriented \nuser, it was essential to create a language using familiar\nengineering statements; programming-oriented \nconventions would have unnecessarily complicated his task.\n", "1455": "TRAC, A Procedure-Describing Language for the Reactive Typewriter A description of the TRAC (Text Reckoning\nAnd Compiling) language and processing algorithm \nis given.  The TRAC language was developed as the basis\nof a software package for the reactive typewriter. \n In the TRAC language, one can write procedures for\naccepting, naming and storing any character string \nfrom the typewriter; for modifying any string in any way;\nfor treating any string at any time as an executable \nprocedure, or as a name, or as text; and for printing\nout any string.  The TRAC language is based upon \nan extension and generalization to character strings\nof the programming concept of the \"macro.\"  Through \nthe ability of TRAC to accept and store definitions of\nprocedures, the capabilities of the language can \nbe indefinitely extended, and can deal with character\nstrings, integers and Boolean vector variables.\n", "1456": "Storage and Retrieval of Aspects of Meaning in Directed Graph Structures An experimental system that uses LISP to make\na conceptual dictionary is described.  The dictionary \nassociates with each English word the syntactic information,\ndefinitional material, and references to \nthe contexts in which it has been used to define other words.\n Such relations as class inclusion, possession, \nand active or passive actions are used as definitional\nmaterial.  The resulting structure serves as a \npowerful vehicle for research on the logic of question answering.\n Examples of methods of inputting information \nand answering simple English questions are given.  An\nimportant conclusion is that, although LISP and \nother list processing languages are ideally suited for\nproducing complex associative structures, they \nare inadequate vehicles for language processing on any\nlarge scale-at east until they can use auxiliary \nmemory as a continuous extension of core memory.\n", "1457": "Data Manipulation and Programming Problems Automatic information retrieval programs require\nthe manipulation of a variety of different \ndata structures, including linear text, sparse matrices,\nand tree or list structures.  The main data \nmanipulations to be performed in automatic information\nsystems are first briefly reviewed.  A variety \nof data representations which have been used to describe\nstructured information are then examined, and \nthe characteristics of various processing languages are\noutlined in the light of the procedures requiring \nimplementation.  Advantages of these programming languages\nfor the retrieval application are examined, \nand suggestions are made for the design of programming\nfacilities to aid in information retrieval.\n", "1458": "Online Programming When the transition has been made from off line\nto online programming, there are a number of \nchanges in the working conditions noted.  These changes\nin the environment make necessary corresponding \nchanges in the processes related to producing and checking\nout programs.  In the main, it it not the \nprogramming language itself which must be changed to\nprovide a facility for the online user; it is the \nsystem surrounding the programming language.  In this\npaper the online environment and its effect on \nprogramming are discussed.\n", "1459": "Requirements for Real-Time Languages Real-time languages have different requirements\nfrom other programming languages because of \nthe special nature of their applications, the environment\nin which their object programs are executed \nand the environment in which they may be compiled.  It\nmay not be the language extensions that ultimately \nadvance developments in the field.  Progress may be made\nby attacking the special compiling and executing \nsystem problems that must be solved.\n", "1460": "Evolution of the Meta-Assembly Program A generalized assembler called a \"meta-assembler\"\nis described.  The meta-assembler is defined \nand factors which contributed to its evolution are presented.\n How a meta-assembler is made to function \nas an assembly program is described. Finally, the implication\nof meta-assemblers on compiler design is \ndiscussed.\n", "1461": "Discussion Summary on Operating Systems", "1462": "Multilevel Operating Systems The Basic software for all newer computers\nis built on the well-established need for standard \noperating systems. This implies that all applications-no\nmatter how large, complex or time consuming-must \noperate under (or, more precisely, on top of) the standard\nsystem.  Large applications require supervisory \nmonitors which handle problems similar to those of\nthe operating systems, but at a different level.  \nSometimes, still a third or even a fourth such level\nis required or desirable.  This leads naturally \nto the concept of multilevel systems-similar vertically,\nbut different horizontally.  Proper division \nof responsibility between levels leads to greater efficiency and\nless logical complexity, while actually \nenhancing capability.\n", "1463": "More on Extensible Machines One of the most salient characteristics of extensible\nmachines (EM) is the facility for providing \nsystem control over program-to-program and program-to-data\nlinkage (e.g., address connection).  It is \nthe intent of this paper to expand and clarify the remarks\nconcerning program-to-program and program-to-data \nlinkage that were embodied in the authors' previous\npaper on the EM concepts, and to, finally, trace \nthe employment of linkage mechanisms through\nvarious levels of programming languages.\n", "1464": "An ALGOL Compiler: Construction and Use An ALGOL translator has been prepared and integrated\ninto the IBSYS Operating System.  Assembly \nand \"go\" features of IBSYS permit immediate execution with\noptional listings, decks and debugging information. \n Using the chain feature of IBSYS, links written in\nMAP or FORTRAN as well as ALGOL may be called by \nthe ALGOL main program.  In addition, procedures coded\nin MAP may be included in any ALGOL program.  \nAlthough assembly plus loading time exceeds compilation\ntime, the total time is satisfactory and the \nuser gets ease and facility which are fully compensating.\n", "1465": "Program Translation Viewed as a General Data Processing Problem Efficiency dictates that the overall effectiveness\nof a compiler be increased by all means \navailable.  For a compiler to have a substantial useful\nlife it needs a clear logical structure, reliability \nand sound data processing techniques.  A compiler must\nbe based on fixed conventions to preserve efficiency \nand reliability; empty options and default conventions\nviolate this dictum.  Use of structure to associate \nvarious parts of a program and economy of\nfeatures promote clarity and reliability.\n", "1466": "Discussion Summary on Graphical Languages", "1467": "A Graphical ServiceSystem With Variable Syntax Man-machine interaction in many fields of endeavor\nshould be greatly facilitated in the near \nfuture through the use of interactive graphical languages.\n To provide a variety of display scope communication \nprocedures, a Graphic Service system which functions\nas a generalized graphical language translator, \nis being developed to aid the definition as\nwell as the use of new graphical languages.\n", "1468": "Syntax-Directed Interpretation of Classes of Pictures A descriptive scheme for classes of pictures based\non labeling techniques using parallel processing \nalgorithms was proposed by the author some years ago.\n Since then much work has been done in applying \nthis to bubble chamber pictures.  The parallel processing\nsimulator, originally written for an IBM 7094\nsystem, has now been rewritten for a CDC 3600 system.\n This paper descriptive models by considering their \nspecific application to bubble chamber pictures.  How\nthe description generated in this phase can be \nembedded in a larger \"conversation\" program is explained\nby means of a certain specific example that \nhas been worked out.  A partial generative grammar for\n\"handwritten\" English letters is given, as are \nalso a few computer-generated outputs using this grammar\nand the parallel processing simulator mentioned \nearlier.\n", "1469": "The Next 700 Programming Languages  A family of unimplemented computing languages\nis described that is intended to span differences \nof application area by a unified framework.  This framework\ndictates the rules about the uses of user-coined \nnames, and the conventions about characterizing functional\nrelationships.  Within this framework the \ndesign of a specific language splits into two independent\nparts.  One is the choice of written appearances \nof programs (or more generally, their physical representation).\n The other is the choice of the abstract \nentities (such as numbers, character-strings, lists\nof them, functional relations among them) that can \nbe referred to in the language.  The system is biased\ntowards \"expressions\" rather than \"statements.\" \n It includes a nonprocedural(purely functional) subsystem\nthat aims to expand the class of users' needs \nthat can be met by a single print-instruction, without sacrificing\nthe important properties that make \nconventional right-hand-side expressions easy to construct and understand.\n", "1470": "The Structure of Programming Languages The following are identified as major components\nof every programming language: (1) the elementary \nprogram statement, (2) mechanisms for linking elementary\nstatements together, (3) the means by which \na program can obtain data inputs.  Several alternative\nforms of each of these components are described, \ncompared and evaluated.  Many examples, frequently from\nlist processing languages, illustrate the forms \ndescribed.  Elementary program statements usually take\nthe form of commands, requirements, or implicit \nspecifications.  A command is an imperative statement\nthat commands the action to be taken.  A requirement \ndescribes the effect to be achieved without saying anything\nabout the actions to be taken.  An implicit \nspecification is similar to a requirement, but the programmer\nmust understand what actions will be taken \nto achieve the desired effect.  Subroutines may be entered\nexplicitly, by execute call, or by function \ncomposition.  Explicitly called subroutines generally\nrequire special linkage conventions.  An execute \nsubroutine call is syntactically indistinguishable from\na basic instruction of the programming language. \n Function composition is a convenient alternative to\nthe explicit call.  The three principal ways of \ngetting inputs for routines are (1) by referring to\nthe data itself, (2) by referring to the data by \na \"name\", and (3) by referring to it implicitly by means\nof variables or functions.  Names are useful \nentry points into permanent data structures, but can\nbe error-causing distractions in other contexts. \nThe author discusses advantages, disadvantages, and factors\ninfluencing the choice of a form of component \nfor a language.   He concludes by suggesting the evolution\nof programming languages toward one which \nwill permit all the most convenient ways of structuring\nprograms, organizing systems, and referencing \ndata.\n", "1471": "Programming Semantics for Multiprogrammed computations The semantics are defined for a number of meta-instructions\nwhich perform operation essential \nto the writing of programs in multiprogrammed computer\nsystems.  These meta-instructions relate to parallel \nprocessing, protection of separate computations, program\ndebugging, and the sharing among users of memory \nsegments and other computing objects, the names of which\nare hierarchically structured.  The language \nsophistication contemplated is midway between an assembly\nlanguage and an advanced algebraic language.\n", "1472": "Description of a High Capacity, Fast The operating system for the UNIVAC 1107 at Case\nInstitute is reviewed.  The system is of interest \nbecause of the low turnaround times achieved, the high\nthroughput achieved and the lack of an operating \nstaff.  Turnaround times below 5 minutes and job volume\nabove 75,000 per quarter year one reported.\n", "1473": "The Stability of the Fourth Order Runge-Kutta The problem of the region of stability of the\nfourth order-Runge-Kutta method for the solution \nof systems of differential equations is studied.  This\nregion can be characterized by means of linear \ntransformation but can not be given in a closed form.\n In the paper, this region is determined by the \nelectronic digital computer Z22.\n", "1474": "Tests of Probabilistic Models for Propagation of Roundoff Errors In any prolonged computation it is generally\nassumed that the accumulated effect of roundoff \nerrors is in some sense statistical.  The purpose of this\npaper is to give precise descriptions of certain \nprobabilistic models for roundoff error, and then to\ndescribe a series of experiments for testing the \nvalidity of these models.  It is concluded that the models\nare in general very good.  Discrepancies are \nboth rare and mild.  The test techniques can also be\nused to experiment with various types of special \narithmetic.\n", "1475": "Dribble Posting a Master File Many business applications employ sequential\nmagnetic tape rather than random-access storage \ntechniques to process a very small number of transactions\nagainst a voluminous master file.  In such \nsituations, it may prove economical to avoid creating a\nnew master file during each updating run by producing \ninstead a dribble ledger containing only those master\nfile accounts which have experienced activity.\n", "1476": "Control Procedures for Data Communication-An ASA Progress Report Sectional Committee X.3 of the American Standards\nAssociation, has charged one of its task \ngroups, X3.3.4, with the responsibility to \"Define and specify\nfunctional control requirements and characteristics \ngoverning the operation of digital data generating and\nreceiving systems interconnected by communication \nsystem.\"  This effort is primarily directed toward systems\nemploying the American Standard Code for Information \nInterchange (ASCII).  This paper represents a progress\nreport on the work of this group toward a proposal \nfor national and international standardization in the\nfield of control procedures.  It describes both \nthe old and new work of the task group.  The new work\nis presented in detail, while the work that has \nbeen presented in earlier papers [\"Control Procedures for\nData Communication,\" Task Group document X3.3.4/44, \nMay 1964: \"Transparent-Mode Control Procedures for Data\nCommunication,\" Task Group document X3.3.4/58, \nDecember, 1964: Comm. ACM 8 (Apr. 1965), 203-206; \"Control\nProcedures for Data Communications,\" Task \nGroup document X3.3.4/60, March, 1965] is retained here\nin summary form.  Many of the concepts and principles \ndescribed herein have been submitted to the International\nOrganization for Standardization via earlier \npapers and are now embodied in working papers of that organization. \n", "1477": "EULER: A Generalization of ALGOL, and its Formal Definition: Part II*", "1478": "Exponential Curve Fit (Algorithm 275 [E2])", "1479": "Constrained Exponential Curve Fit (Algorithm 276 [E2])", "1480": "Computation of Chebyshev Series Coefficients (Algorithm 277[C6])", "1481": "Graph Plotter (Algorithm 278 [J6])", "1482": "BUGSYS: A Programming System for Picture Processing-Not for Debugging BUGSYS is a picture processing and measuring\nsystem that depends upon a pictorial input to \nthe computer's memory.  BUGSYS can be used for many\ntypes of applications.  In particular, the authors \nhave used the system for the analysis of linear graphs.\n The main concept of the system is the use of \na collection of programmable pointers, which\nare visualized as a family of \"bugs.\"\n", "1483": "A Comparison of the FORTRAN Language A feature-by-feature comparison is made of five\ndifferent implementations of FORTRAN IV representing \nthree different manufacturers.  A table is constructed\nshowing, where possible, the use of each feature \nin each implementation.  Only those items which are\ndifferent from, or have been added to FORTRAN II \nare shown.\n", "1484": "A Language for Describing the Functions of Synchronous Systems*  Before the design of a system is started, the\nexact function desired of it should be specified. \n It is suggested that a computer-oriented language be\nused for this purpose.  The inadequacies of the \nstandard programming languages for the description of\nsystems are discussed, and a dialect of ALGOL which \nis suitable for describing synchronous systems is introduced.\n These descriptions can be used for simulation \nand automatic design of the system described, in\naddition to communicating system specifications.\n", "1485": "The Structure of Programming Languages In this paper the major components of every\nprogramming language are identified as: (1) the \nelementary program statement, (2) mechanisms for linking\nelementary statements together, (3) the means \nby which a program can obtain data inputs.  Several\nalternative forms of each of these components are \nalso described, compared and evaluated.  Many examples,\nfrequently from list processing languages, illustrate \nthe forms described.  The advantages, disadvantages and\nfactors influencing the choice of a form of component \nfor a language are discussed, and the paper concludes\nwith the suggestion that programming languages \nevolve toward one which will permit all the most convenient\nways of structuring programs, organizing \nsystems and referencing data.\n", "1486": "A Reprogramming Machine In this paper a description is given of a model\nprogramming system which is directed by a programming \nlanguage and has a library for storing the user's items.\n Rules are given for transforming programs written \nin the language and for rearranging the items in the\nlibrary so that they share their common parts.  \nSome speculations are made about how the mechanical\ndetection of common parts or patterns of library \nitems could help a user to solve his problems, and about\nthe relationships between the behavior of the \nreprogramming machine and human intelligent behavior.\n", "1487": "ELIZA-A Computer Program For the Study ofNatural ELIZA is a program operating within the MAC\ntime-sharing system at MIT which makes certain \nkinds of natural language conversation between man and\ncomputer possible.  Input sentences are analyzed \non the basis of decomposition rules which are triggered\nby key words appearing in the input text.  Responses \nare generated by reassembly rules associated with selected\ndecomposition rules.  the fundamental technical \nproblems with which ELIZA is concerned are: (1)the\nidentification of key words, (2) the discovery of \nminimal context, (3) the choice of appropriate transformations,\n(4) generation of responses in the absence \nof key words, and (5) the provision of an editing capability\nfor ELIZA \"scripts\".  A discussion of some \npsychological issues relevant to the ELIZA approach as\nwell as of future developments concludes the paper.\n", "1488": "Programming Decision Tables in FORTRAN, COBOL or ALGOL A simple broad-based approach for programming\ndecision tables in FORTRAN or COBOL is developed \nand presented.  With inputs in standard form, as defined\nin the paper, the programming of any decision \ntable can be done with one or two FORTRAN statements,\nor with two COBOL statements, if the COMPUTE verb \nis available in the COBOL processor.  It is  shown\nthat the method is applicable even when there are \nmore than two mutually exclusive states of one, two or\nmore table conditions.  It is further shown that \nmulti-state conditions in decision tables can often\nsimplify the programming.  The method outlined has \nthe further advantage that all possible combinations\nof conditions are considered.  It is shown that \nthe suggested procedure is easily implemented in ALGOL.\n", "1489": "Data, Documentation and Decision Tables In business data processing systems, it is\nnecessary to be able to define and document data, \nfiles, programs and decision rules in a way that adequately\nrepresents both (1) their changing information \ncontent, and (2) their continuous interaction.  Tabular\ndescription makes this possible, being notably \nobjective, through and economical in cost and time when\nsystems must be analyzed and programs prepared \nor modified.  To show how quickly tabular techniques\nmake an unfamiliar system manageable, a detailed \nexample and a self-test are provided.\n", "1490": "One Inch Perforated Paper Tape for Information", "1491": "EULER: A Generalization ALGOL, and its Formal Definition: Part I* A method for defining programming languages is\ndeveloped which introduces a rigorous relationship \nbetween structure and meaning.  The structure of a\nlanguage is defined by a phrase structure syntax, \nthe meaning in terms of the effects which the execution\nof a sequence of interpretation rules exerts \nupon a fixed set of variables, called the Environment.\n There exists a one-to-one correspondence between \nsyntactic rules and interpretation rules is determined by\nthe sequence of corresponding syntactic reductions \nwhich constitute a parse.  The individual interpretation\nrules are explained in terms of an elementary \nan d obvious algorithmic notation.  A constructive\nmethod for evaluating a text is provided, and for \ncertain decidable classes of languages their unambiguity\nis proved.  As an example, a generalization \nof ALGOL is described in full detail to demonstrate that\nconcepts like block-structure, procedures, parameters, \netc. can be defined adequately and precisely by this method.\n", "1492": "Serrev (Algorithm 273 [C1])", "1493": "Generation of Hilbert Derived Test Matrix (Algorithm 274 [F1])", "1494": "Complete Elliptic Integral of the Second Kind (Algorithm 56 [S21])", "1495": "Solution of Transcendental Equations by Series Reversion An algorithm is developed for expressing the\nsolution Y, of the equation F(Y) = G(X) as a power \nseries in (X - X0) when f and g are given as power series,and\nthe root Y0, is known at Y=X0.  The algorithm \nis illustrated for the equation Y^Y = X, i.e., (1+y)*ln(1+y) = ln(1+x).\n", "1496": "A Formal Semantics for Computer Languages A semantic meta-language has been developed\nfor representing the meanings of statements in \na large class of computer languages.  This meta-language\nhas been the basis for construction of an efficient, \nfunctioning compiler-compiler.  An informal discussion\nof the meta-language based on the example of a \ncomplete translator for a small language is presented.\n", "1497": "On the Normalization Requirement of This paper presents an analysis on the normalization\nrequirement of the divisor in a divide-and-correct \nmethod.  This analysis is made subject to the condition\nthat not more than one correction is required \nto obtain the true quotient character, from the trial\nestimate got from the division of a two-precision \nsegment of every partial remainder by a suitably rounded\nsingle-precision divisor.  (This segmented division \nis denoted here as a (2, 1) precision basic division.)\n It is found that the normalization requirement \ncould be narrowed down to a smaller range of divisors,\nprovided the magnitude of the character next to \nthe leading character of the divisor is known.  If,\nhowever, the normalization is to be eliminated one \nhas to choose proper higher precision segments of operands\nfor the basic division.  Also considered is \nthe possibility of eliminating the normalization by an\nincrease on the number of corrections on the quotient \nestimate got from a (2, 1) precision basic division.\n It is shown that such a scheme is economical only \nfor small radices.\n", "1498": "The ALCOR Illinois 7090/7094 Post Mortem Dump A dump technique for programs written in ALGOL\n60 is described.  This technique provides an \nintelligible analysis of an unsuccessful computation\nprocess in terms of the original source program.\n", "1499": "Chebyschev Curve-Fit (revised) (Algorithm 318 [E2])", "1500": "Chebyschev Curve-Fit (Algorithm 91 [E2])", "1501": "Eigenvectors of a 2n x 2n Matrix It has been known that the eigenvalues of a\ncertain 2n x 2n matrix can be obtained by use of \ntwo smaller matrices of order n which can be easily\nconstructed.  An algorithm is given to obtain the \neigenvectors of the 2n x 2n matrix by use of\nthe eigenvectors of the smaller matrices.\n", "1502": "An Online Editor An online, interactive system for test editing\nis described in detail, with remarks on the \ntheoretical and experimental justification for its form.\n Emphasis throughout the system is on providing \nmaximum convenience and power for the user.  Notable\nfeatures are its ability to handle any piece of \ntext, the content-searching facility, and the character-by-character\nediting operations.  The editor \ncan be programmed to a limited extent.\n", "1503": "A SIMSCRIPT-FORTRAN Case Study Two programs for a vehicle dispatching model,\none written in 7040 SIMSCRIPT and the other in \n7040 FORTRAN IV are compared. The comparison is made\nin terms of basic program design decisions, storage \nrequirements, computer time used, and the ease of making\nchanges.  In the SIMSCRIPT program, the primary \ndesign considerations center around the choice of model\nvariables, model changing events, and model testing. \n In the FORTRAN program, basic design problems relate\nto the representation of the passage of time, the \nallocation of storage, and the organization of input\ndata.  The comparison of these differently designed \nprograms shows that the SIMSCRIPT program uses more computer\nstorage and more computer time, but requires \nfewer program changes to introduce model revisions.\n", "1504": "Algorithms for Finding a Fundamental Set Given the adjacency matrix of the graph, the algorithm\npresented in this paper finds a spanning \ntree and then constructs the set of fundamental cycles.\n Our algorithm is slower than an algorithm presented \nby Welch by a ratio of N/3 (N is the number of nodes)\nbut requires less storage.  For graphs with a large \nnumber of nodes and edges, when storage is limited our\nalgorithm is superior to Welch's; however, when \nthe graphs are small, or machine storage is very large,\nWelch's algorithm is superior.  Timing estimates \nand storage requirements for both methods are presented.\n", "1505": "A System Organization for Resource Allocation  This paper introduces a system for resource management\nusing the concepts of \"process,\" facility,\" \nand \"event.\"  Except for the processor no attempt has\nbeen made to give serious suggestions for the policy \nto be followed for resource allocation.  However, a basic\nframework is provided in which a system analyst \ncan express solutions to resource management problems.\n The paper is divided into a tutorial presentation, \na description of the system primitives, and a small collection\nof examples of the use of the primitives.\n", "1506": "The LACONIQ Monitor: Time Sharing for Online Dialogues The LACONIQ (Laboratory Computer Online Inquiry)\nMonitor was developed primarily to support \nnon-numerical applications such as retrieval from very\nlarge files by means of a \"dialogue\" between a \nsystem user and a retrieval application.  The monitor\nwas designed so that it could work with a small \ncomputer (an IBM System 360/30).  Therefore techniques\nfor resource allocation were important.  For this \nreason the use of core storage, computational facilities,\nand input-output were all scheduled.  An unusual \nfeature of the system is that it is event-driven rather\nthan clock-driven.  The program segments called \ninto execution by the remote CRT consoles are invariably\nrun to completion rather than \"rolled-out\" to \nbe brought back at a later time.\n", "1507": "A Multiprogramming Environment for Online Data Acquis ition and Analysis An experimental system for acquis ition and analysis\nof large bodies of data derived from scientific \nexperiments is described.  Its architecture and implementation\nis largely based on certain objectives \nand characteristics of a general data analysis scheme.\n Early applications have been oriented towards \nthe investigation of data obtained in biological research.\n Some of the problems encountered by the chosen \napproach are discussed.\n", "1508": "Magnetic Tape Labels for Information Interchange (Proposed USA Standard)", "1509": "Recorded Magnetic Tape for Information Interchange", "1510": "Finding a Solution of N Functional Equations", "1511": "The Damped Taylor's Series Method for Minimizing", "1512": "Solution of Simultaneous Non-Linear Equations (Algorithm 316[C5])", "1513": "PERMUTATION (Algorithm 317 [G6])", "1514": "On the Expected Gain From Adjust ing Matched Term Retrieval Systems A file adjustment procedure based on maximizing\nthe Bayes expected gain proposed for matched \nterm retrieval systems.  The expected gain and its probability\ndistribution are derived as a function \nof: (1) the prior proportion of omitted terms, and (2) the\ncoefficient of separation between two distributions \ncorresponding to values of an adjustment statistic.  An\nexample evaluates the gain parameters for a typical \ninformation retrieval system.\n", "1515": "A Computer System for Inference Execution and Data Retrieval This paper presents a RAND project concerned\nwith the use of computers as assistants in the \nlogical analysis of large collections of factual data.\n A system called Relational Data File was developed \nfor this purpose.  The Relational Data File is briefly\ndetailed and problems arising from its implementation \nare discussed.\n", "1516": "Automatic Data Compression The \"information explosion\" noted in recent\nyears makes it essential that storage requirements \nfor all information be kept to a minimum.  A fully automatic\nand rapid three-part compressor which can \nbe used with \"any\" body of information to greatly reduce\nslow external storage requirements and to increase \nthe rate of information transmission through a computer\nis described in this paper.  The system will \nalso automatically decode the compressed information\non an item-by-item basis when it is required.  The \nthree component compressors, which can be used separately\nto accomplish their specific tasks, are discussed: \nNUPAK for the automatic compression of numerical data, ANPAK\nfor the automatic compression of \"any\" information, \nand IOPAK for further compression of information to be stored on tape or cards.\n", "1517": "Methods for Analyzing Data from Computer Simulation Experiments This paper addresses itself to the problem of\nanalyzing data generated by computer simulations \nof economic systems.  We first turn to a hypothetical firm,\nwhose operation is represented by  single-channel, \nmultistation queueing model.  The firm seeks to maximize\ntotal expected profit for the coming period \nby selecting one of five operating plans, where each\nplan incorporates a certain marketing strategy, \nan allocation of productive inputs, and a total cost.\n The results of the simulated activity under each \nplan are subjected to an F-test, two multiple comparison\nmethods, and a multiple ranking method.  We \nillustrate, compare, and evaluate these techniques.\n The paper adopts the position that the particular \ntechnique of analysis (possibly not any one of the above)\nchosen by the experimenter should be an expression \nof his experimental objective: The F-test tests the homogeneity\nof the plans; multiple comparison methods \nquantify their differences; and multiple ranking methods\ndirectly identify the one best plan or best \nplans.\n", "1518": "An Experimental Model of System/360 The problem of predicting the performance of\nmodern computer systems is formidable.  One general \ntechnique which can ease this problem is macroscopic simulation.\n This paper reports on the applicability \nof that technique to System/360.  The paper describes\nan experimental model of System/360-its hardware, \nsoftware, and its environment.  The measures of system performance\nproduced by the model consist of statistics \nrelating to turnaround time, throughput, hardware utilization,\nsoftware utilization, and queueing processes. \n The model is mechanized in SIMSCRIPT and consists of\nsome 1750 statements.  An auxiliary programs, the \nJob Generator, creates automatically the properties\nof System/360 jobs that get simulated.\n", "1519": "GEORGE 3-A General Purpose Time Sharing and Operating System An Operating System is described which will\nrun on a wide variety of configurations of the \nI.C.T. 1900, and can handle a large number of online console\nusers while at the same time running several \noff line (background) jobs.  The system is not oriented\ntowards either mode and can be either a batch \nprocessing system (such as the ATLAS Supervisor, IBSYS,\nor GECOS), or a multiaccess system (resembling, \nto the user, CTSS or MULTICS), or both simultaneously,\ndepending on the installation, which can adjust \nthe Schedulers.  Both online users and off line jobs use\na common Command Language.  The system includes \na Multilevel device-independent File Store.\n", "1520": "Absolute Value and Square Root of a Complex Number (Algorithm 312 [A2])", "1521": "Multi-Dimensional Partition Generator (Algorithm 313 [A1])", "1522": "Chebyschev Quadrature (Algorithm 279 [D1])", "1523": "SHARER, a Time Sharing System for the CDC 6600 A time sharing system embedded within the\nstandard batch processing system for the CDC 6600 \nis described.  The system is general purpose and file-based,\nproviding facilities for file input, manipulation, \nediting, compilation, and conversational execution.\n It uses a simple scheme for system extension for \na machine with only one relocation and memory bound register.\n No attempt was made to use reentrant code, \nor to simulate segmentation or paging.  Implementation\ntime was approximately six man-years, with the \nmajority of the code being written in FORTRAN.\n", "1524": "A Stopping Criterion for Polynomial Root Finding When searching for the root of a polynomial,\nit is generally difficult to know just when to \naccept a number as an adequate approximation to the root.\n In this paper an algorithm is presented which \nallows one to terminate the iteration process on the\nbasis of calculated bounds for the roundoff error \nwhich occurs in evaluating the polynomial.  This stopping\ncriterion has been tested on numerous examples \nand has been found to serve as a satisfactory means\nfor accepting a complex number as a zero of a real \npolynomial.\n", "1525": "On Computing The Fast Fourier Transform Cooley and Tukey have proposed a fast algorithm\nfor computing complex Fourier transform and \nhave shown major time savings in using it to compute\nlarge transforms on a digital computer.  With n \na power of two, computing time for this algorithm is\nproportional to n log2 n, a major improvement over \nother methods with computing time proportional to n^2.\n In this paper, the fast Fourier transform algorithm \nis briefly reviewed and fast difference equation methods\nfor accurately computing the needed trigonometric \nfunction values are given.  The problem of computing\na large Fourier transform on a system with virtual \nmemory is considered, and a solution is proposed.  This\nmethod has been used to compute complex Fourier \ntransforms of size n = 2^16 on a computer with 2^15\nwords of core storage; this exceeds by a factor of \neight the maximum radix two transform size with fixed\nallocation of this amount of core storage.  The \nmethod has also been used to compute large mixed radix\ntransforms.  A scaling plan for computing the \nfast Fourier transform with fixed-point arithmetic is also given.\n", "1526": "Multiprogramming under a Page on Demand Strategy A model of multiprogramming for a particular\ncomputer system using a page on demand strategy \nis developed.  Analysis of this model is used to predict\nperformance (measured by the average usage of \nthe CPU) when user programs are typical of those arising\nfrom an interactive time sharing environment. \n The effect of several hardware modifications is also\nanalyzed.  A parameter, readily calculated from \nthe hardware characteristics and the program statistics,\nis proposed for gauging the effect of multiprogramming.\n", "1527": "A Grammar Base Question Answering Procedure The subject of this paper is a procedure for\nthe automatic retrieval of certain segments of \nstored information, either explicitly or implicitly represented,\nthrough questions posed in natural language \nsentences.  This procedure makes use of a sentence recognition\ndevice for the class of grammars which \nwill correctly decide between the grammatical and ungrammatical\nsentences of a natural language.  It \nis possible to make use of a recognition device of this\nsort for the following reason: Much data is fully \nexpressible as a set of sentences in a natural language,\na set which can be exhaustively and exclusively \ngenerated by a grammar.  Based upon the rules of this grammar,\na sentence recognizer will evaluate sentences, \nquestions in the normal situation.  Since the recognition\nfunction succeeds just in case the posed question \nis drawn from the set of sentences expressing the data,\nor, more correctly, is grammatical in terms of \nthe grammar for this set of sentences, sentence recognition\nitself is a procedure for retrieving information. \n When the recognition function succeeds, its\nvalue represents the requested information.\n", "1528": "Three Fonts of Computer Drawn Letters Detailed descriptions are given for three fonts\nof letters.  Letter shapes are entirely described \nby numbers.  The basic vectors are in a general form\nso the fonts may be easily drawn on a variety of \ncomputers and cathode-ray tubes.  The fonts include both\nupper and lower case Roman letters, mathematical \nsigns, and upper and lower case Greek letters.  Design\nof the fonts is described.  However, the principal \ncontribution of this paper concerns the fonts themselves.\n", "1529": "Decomposition Programming An Analysis of Matrix Substructure  A petroleum blending problem was analyzed in order\nto compare the primal and primal-dual decomposition \nalgorithms.  In the course of the analysis, a substructure\nwas discovered which has relevance to the \nrelative performance of the two algorithms and to their\nabsolute performance as compared with a standard \nprimal-Simplex solution without decomposition.\n", "1530": "The ML/I Macro Processor A general purpose macro processor called ML/I\nis described.  ML/I has been implemented on the \nPDP-7 and I.C.T. Atlas 2 computers and is intended as a\ntool to allow users to extend any existing programming \nlanguage by incorporating new statements and other\nsyntactic forms of their own choosing and in their \nown notation.  This allows a complete user-oriented\nlanguage to be built up with relative ease.\n", "1531": "The Remaining Trouble Spots in ALGOL 60 This paper lists the ambiguities remaining\nin the language ALGOL 60, which have been noticed \nsince the publication of the Revised ALGOL 60 Report in 1963.\n", "1532": "The Hardware-Software Complementarity", "1533": "A Marovian Model of the University of Michigan Executive System A mathematical model of a computer's executive\nsystem is postulated and its parameters estimated \nwith the aid of extensive data on the system's operation.\n Although simplifying assumptions are made, \nthe results predicted by the model agree reasonable well\nwith actual results.  The model is used to study \nthe effects of changes in the executive system and\nin one of its compilers.  Further applications of \nthe model are discussed.\n", "1534": "DAD, The C.S.I.R.O. Operating System The design and implementation of the C.S.I.R.O.\noperating system, DAD, is described in detail. \n This system is designed for the Control Data 3600 using\na large drum backing store and is intended to \nallow the integration of a remote console (display) subsystem\ninto a conventional job stack environment. \n The use of the drums, the buffering of input and output\non slow peripherals, and the execution of normal \njob stack work are described.  The display subsystem\nis described only as it integrates into the rest \nof the system.  The techniques found useful in the development\nof DAD are given, and an assessment is \nmade of the validity of various design decisions.  Performance\nfigures based on several months of operation \nare tabulated.\n", "1535": "A Comment on Index Register Allocation A technique is presented to reduce the enumeration\nrequired by a known procedure for optimal \nindex register allocation in straight-line programs.\n This technique is based on the construction of \na link diagram, which shows at any step the future occurrences\nof indexes which must be loaded into index \nregisters.  This diagram determines in advance the required\nregister configuration at certain steps of \nthe program, so that the program is subdivided into separate\nportions to which the allocation procedure \nmay be applied independently.\n", "1536": "Dynamic Computation of Derivatives It is shown how Wengert's procedure for computation\nof derivatives can be implemented conveniently \nby use of compiler-generated complex addition, subtraction,\nand linkage to complex arithmetic subroutines.\n Evaluation of a function and derivative proceed in\nparallel, as in Wengert's procedure, but with the \n\"imaginary\" parts of variables declared complex bearing\nthe values of the derivatives of the real parts. \n This technique provides a simple way to compute the\nderivatives of a function, without the need for \nderiving and programming the evaluation of\nexplicit formulas for the derivatives.\n", "1537": "Prime Number Generator 1 (Algorithm 310 [A1])", "1538": "Prime Number Generator 2 (Algorithm 311 [A1])", "1539": "Prime Number Generator 1; Prime Number Generator", "1540": "An Algorithm for Class Scheduling With Section Preference An algorithm for assignment of students to classes\nin a fixed time schedule that allows students \nto give a preference for sections within courses is given.\n If consistent with the objective of balanced \nsections, these preferences will be honored.  The algorithm\nis more stochastic than Monte Carlo in nature. \n Results are given that compare it to a nonpreference assignment algorithm.\n", "1541": "A Language for Modeling and Simulating Dynamic Systems The general objective of this language is\nto facilitate both the modeling and experimental \naspects of simulation studies.  The ability to represent\nsystems containing highly interactive processes \nis an essential feature.  The nature of the language,\nand the role of the process concept, is presented \nby means of an extended example.\n", "1542": "A Microprogrammed Implementation of EULER on IBM System/360 Model 30 An experimental processing system for the algorithmic\nlanguage EULER has been implemented in \nmicroprogramming on an IBM System/360 Model 30 using a\nsecond Read-Only Storage unit.  The system consists \nof a microprogrammed compiler and a microprogrammed\nString Language Interpreter, and of an I/O control \nprogram written in 360 machine language.  The system is described\nand results are given in terms of microprogram \nand main storage space required and compiler and interpreter\nperformance obtained.  The role of microprogramming \nis stressed, which opens a new dimension in the processing\nof interpretive code.  The structure and content \nof a higher level language can be matched by an appropriate\ninterpretive language which can be executed \nefficiently by microprograms on existing computer hardware.\n", "1543": "Computer Formulation of the Equations of Motion Using Tensor Notation A means is described for extending the area\nof application of digital computers beyond the \nnumerical data processing stage and reducing the need for\nhuman participation in the formulation of certain \ntypes of computer problems.  By the use of tensor calculus\nand a computer language designed to facilitate \nsymbolic mathematical computation, a method has been\ndevised whereby a digital computer can be used to \ndo non-numeric work, that is, symbolic algebraic manipulation\nand differentiation. To illustrate the \ntechniques involved, a digital computer has been used\nto derive the equations of motion of a point mass \nin a general orthogonal curvilinear coordinate system.\n Since this operation involves a formulation in \nterms of first- and second-order differential coefficients,\nit provides a good demonstration of a computer's \ncapability to do non-numeric work and to assist in the\nformulation process which normally precedes the \nnumerical data processing stage.  Moreover, this particular\nproblem serves to illustrate the advantages \nof the mathematical techniques employed.  With the program\nprepared for this purpose the computer will \nderive the equations of motion in any coordinate system\nrequested by the user.   Results are presented \nfor the following coordinate systems: cylindrical\npolar, spherical polar, and prolate spheroidal.\n", "1544": "Tele-CUPL: A Telephone Time Sharing System A general purpose, remote access, computing system\nis described, that employs twelve-key keyboard \ntelephones as terminals.  Audio output is provided directly\nto the telephone terminals, but the system \nwill normally be used in conjunction with remotely located\nhigh speed printing devices.  The system is \na compatible extension of an existing batch processing\nsystem.  A significant element of the system is \na scheme for transmitting alphanumeric information by single\nstrokes on a numeric keyboard.  The programmed \nscanner uses context to eliminate the ambiguity in transmission.\n", "1545": "Legal Safeguards to Insure Privacy in a Computer Society", "1546": "Toward Standards for Handwritten Zero and Oh", "1547": "Gamma Function with Arbitrary Precision (Algorithm 309 [S14])", "1548": "Parsing of Decision Tables Reduction in the size of decision tables can be\naccomplished by several techniques.  The techniques \nconsidered in this paper are on the parsing of decision\ntables with regard to horizontal and vertical \ndata structures, job identity, hardware and job priorities,\nand context relationships.  Such parsing \nrests upon some conventions for the linkage of decision tables.\n", "1549": "An Efficient Machine-Independent Procedure for A method for returning registers to the free\nlist is an essential part of any list processing \nsystem.  In this paper, past solutions of the recovery\nproblem are reviewed and compared.  A new algorithm \nis presented which offers significant advantages of speed\nand storage utilization.  The routine for implementing \nthis algorithm can be written in the list language with\nwhich it is to be used, thus insuring a degree \nof machine independence.  Finally, the application of the\nalgorithm to a number of different list structures \nappearing in the literature is indicated.\n", "1550": "A Comparison of Batch Processing and Instant Turnaround A study of the programming efforts of students\nin an introductory programming course is presented \nand the effects of having instant turnaround (a few minutes)\nas opposed to conventional batch processing \nwith turnaround times of a few hours are examined.  Among\nthe items compared are the number of computer \nruns per trip to the computation center, program preparation\ntime, keypunching time, debugging time, \nnumber of runs, and elapsed time from the first run\nto the last run on each problem.  Even though the \nresults are influenced by the fact that \"bonus points\"\nwere given for completion of a programming problem\nin less than a specified number of runs, there\nis evidence to support \"Instant\" over \"Batch\".\n", "1551": "On Compiling Algorithms for Arithmetic Expressions This paper deals with algorithms concerning arithmetic\nexpressions used in a FORTRAN IV compiler \nfor a HITAC-5020 computer having n accumulators.  The\nalgorithms generate an object code which minimizes \nthe frequency of storing and recovering the partial results\nof the arithmetic expressions in cases where \nthere are several accumulators.\n", "1552": "The AED Free Storage Package The most fundamental underlying problem in sophisticated\nsoftware systems involving elaborate, \nchanging data structure is dynamic storage allocation\nfor flexible problem modeling.  The Free Storage \nPackage of the AED-1 Compiler Systems allows blocks\nof available storage to be obtained and returned \nfor reuse.  The total available space is partitioned\ninto a hierarchy of free storage zones, each of \nwhich has its own characteristics.  Blocks may be of\nany size, and special provisions allow efficient \nhandling of selected sizes, control of shattering and\ngarbage collection, and sharing of physical space \nbetween zones.  The routines of the package perform\nhigh level functions automatically, but also allow \naccess and control of fine internal details as well.\n", "1553": "Contextual Understanding by Computers A further development of a computer program\n(ELIZA) capable of conversing in natural language \nis discussed.  The importance of context to both human\nand machine understanding is stressed.  It is \nargued that the adequacy of the level of understanding\nachieved in a particular conversation depends \non the purpose of that conversation, and that absolute\nunderstanding on the part of either humans or \nmachines is impossible.\n", "1554": "A Computer Technique for Displaying n-Dimensional Hyperobjects A digital computer and automatic plotter have\nbeen used to generate three-dimensional stereoscopic \nmovies of the three-dimensional parallel and perspective\nprojections of four-dimensional hyperobjects \nrotating in four-dimensional space.  The observed projections\nand their motions were a direct extension\nof three-dimensional experience, but no profound \"feeling\"\nor insight into the fourth spatial dimension \nwas obtained.  The technique can be generalized to n-dimensions\nand applied to any n-dimensional hyperobject \nor hypersurface.\n", "1555": "Symmetric Polynomials (Algorithm 305 [C1])", "1556": "Permutations with Repetitions (Algorithm 306 [G6])", "1557": "Symmetric Group Characters (Algorithm 307 [A1])", "1558": "Generation of Permutations in Pseudo-Lexicographic", "1559": "Permutation Generator; Permutation in Lexicographical", "1560": "Transport; Transportation Problem (Algorithm 258[H]; Algorithm 293[H])", "1561": "The Mutual Primal-Dual Method (Algorithm 285 [H])", "1562": "Airy Function (Algorithm 301 [S20])", "1563": "A Method for Finding Hamilton Paths and Knight's Tours The use of Warnsdorff's rule for finding a\nknight's tour is generalized and applied to the \nproblem of finding a Hamilton path in a graph.  A graph-theoretic\njustification for the method is given.\n", "1564": "Description of Basic Algorithm in DETAB/65 Preprocessor The basic algorithm for the conversion of decision\ntables into COBOL code is contained in the\ngenerator portion of the DETAB/65 preprocessor.  The\ngenerator analyzes a decision table and produces \nsimple COBOL conditional statements.  Core storage is\nsaved by using queueing techniques and extensive \nindexing and also by outputting the code as it is generated,\na line at a time.  The only optimization \nattempted is the elimination of obviously unnecessary\ntests on certain conditions in the decision table. \n Since the preprocessor and this language associated with\nit were developed for COBOL users, the preprocessor \nwas written in a modular form in required COBOL-61.\n", "1565": "A Language-Independent Macro Processor A macro processor is described which can be\nused with almost any source language.  It provides \nall features normally associated with a macro facility,\nplus the ability to make arbitrary transformations \nof the argument strings.  The program is used at the\nBasser Computing Department, University of Sydney, \nSydney, Australia, to process text for eight different compilers.\n", "1566": "Optimal Starting Values for Newton-Raphson Calculation of SQRT(x) The problem of obtaining starting values for\nthe Newton-Raphson calculation of SQRT(x) on a \ndigital computer is considered.  It is shown that the\nconventionally used best uniform approximations \nto SQRT(x) do not provide optimal starting values. \nThe problem of obtaining optimal starting values. \n The problem of obtaining optimal starting values is\nstated, and several basic results are proved.  A \ntable of optimal polynomial starting values is given.\n", "1567": "On the Representation of Symmetric Polynomials Relations are given between certain symmetric\npolynomials in the light of the theory of the \nsymmetric group.  Such an approach unifies earlier work\nand lends insight to previously published work \nby Aaron Booker.  A generalization of Graeffe's root-squaring\ntechnique for the determination of the \nroots of a polynomial is suggested.\n", "1568": "Plotting a Function of Three Independent Variables A method is developed for constructing an approximate\nplot of a function of three independent \nvariables.  The plot is similar to a conventional contour\nmap except that there are three scales to represent \nthe independent variables.  Scale values of the three\nindependent variables are added vectorially, and \nthe value of the function is then read from\nthe values associated with nearby contours.\n", "1569": "Implementing Phrase-Structure Productions in PL/I A method is described for implementing the productions\nof a context-free phrase structure grammar \nin a PL/I procedure whose structure and statements parallel\nthe structure and notation of the grammar.\n", "1570": "String Processing Techniques The internal organization of string processing\nsystems is discussed.  Six techniques for data \nstructures are presented and evaluated on the basis of:\n(1) creation of strings; (2) examination of strings; \nand (3) alteration of strings.  Speed of operation, storage\nrequirements, effect on paging, and programmer \nconvenience are also considered.  One of the techniques,\nsingle-word linked blocks, is used in an example \ndemonstrating an implementation of a SNOBOL string\nprocessing language on an IBM System/360.\n", "1571": "A User-Oriented Time-Shared Online System An existing system and planned additions within\nthe Data Processing Laboratory of the Brain \nResearch Institute at UCLA is described.  The system\nrepresents an attempt to provide research workers \nof the Institute with the ability to interact directly\nwith a highly sophisticated digital computing \ncomplex in the most direct and simple fashion possible.\n It is anticipated that, with the accumulation \nof experience using the present system, significant advances\nwill be possible in the system design through \ndetermination of interface parameters between the\nbiological scientist and the digital computer.\n", "1572": "The Simulation of Time sharing Systems The development of new large scale time-sharing\nsystems has raised a number of problems for \ncomputation center management.  Not only is it necessary\nto develop an appropriate hardware configuration \nfor these systems, but appropriate software adjustments\nmust be made.  Unfortunately, these systems often \ndo not respond to changes in the manner that intuition\nwould suggest, and there are few guides to assist \nin the analysis of performance characteristics.  The\ndevelopment of a comprehensive simulation model \nto assist in the investigation of these questions is\ndescribed in this paper.  The resulting model has \na general purpose design and can be used to study a\nvariety of time-sharing systems.  It can also be \nused to assist in the design and development of new time-sharing\nalgorithms or techniques.  For the sake \nof efficiency and greater applicability, the model was\nimplemented in a limited FORTRAN subset that is \ncompatible with most FORTRAN IV compilers. The use of\nthe simulation is demonstrated by a study of the \nIBM 360/67 time-sharing system.\n", "1573": "An Adaptive Quadrature Procedure with", "1574": "Normal Curve Integral (Algorithm 304 [S15])", "1575": "Incomplete Beta Ratio (Algorithm 179 [S14])", "1576": "Eigenvalues of a Real Symmetric Matrix", "1577": "Eigenvalues and Eigenvectors of a Real Symmetric", "1578": "Generalized Least Squares Fit By Orthogonal", "1579": "Real Error Function, ERF(x) (Algorithm 123 [S15])", "1580": "Error Function-Large X (Algorithm 180 [S15])", "1581": "Complementary Error Function-Large X (Algorithm 181 [S15])", "1582": "GAUSS (Algorithm 209 [S15])", "1583": "Normal Distribution Function (Algorithm 226 [S15])", "1584": "Procedure for the Normal Distribution Functions (Algorithm 272 [S15])", "1585": "Normal Curve Integral (Algorithm 304 [S15])", "1586": "A Generalized Bairstow Algorithm The Bairstow algorithm is generalized to the\ncase of a polynomial which is itself a linear \ncombination of polynomials satisfying a three-term recursion.\n Convergence properties of the method are \nderived.\n", "1587": "Storage Allocation in a Certain Iterative Process A method of core storage allocation in a certain\niterative process is described and estimates \nof the machine time required are given.  The method is\napplicable to iterative processes in which input \ndata items once chosen are never again needed.  In this\nmethod the input data is continuously relocated \nand the space made available apportioned to the output\ntables when an overflow occurs.  Some important \nspecial cases are considered in which considerable simplification occurs.\n", "1588": "PL/I List Processing The concepts of list processing have been introduced\ninto the PL/I language.  With these new \nfacilities, it is possible to write PL/I procedures that\noperate on simple and complex data list organizations. \n Most list-processing languages have suffered from their\ninability to deal directly with complex data \nstructures and/or from their inability to perform the\ncomplete range of programming language operations \nupon the data list structures.  These two problems have\nbeen eliminated in the list-processing facilities \nof PL/I.  The basic concepts of list processing and\nthe philosophy of the PL/I language extensions are \ndiscussed.  In addition, several detailed list-processing examples are provided.\n", "1589": "DIALOG: A Conversational Programming System with a Graphical Orientation DIALOG is an algebraic language for online\nuse with a graphical input-output console device. \n It is a computational aid for the casual user, which\nprovides basic facilities for graphical and numeric \ninput and display, online and off line program preparation\nand storage, and hard copy presentation of \nresults.  Use of the system requires a minimum of experience\nor instruction, since the growth of an overlaying \nsystem control language has been prevented, and there\nare no processor-oriented statements, like variable \ntype or dimension declarations.  Moreover, in the online\nsituation the processor interacts with the graphical \nkeyboard on a character-by-character basis so as to\nrestrict the programmer's choice of input symbols \nto those which are syntactically correct. DIALOG has been\nin daily operation at the IIT Research Institute \nsince February, 1966.\n", "1590": "Pitch Period Determination of Speech Sounds A computer procedure which determines pitch\nperiods by the recognition of the peak structure \nof the speech waveform is described.  Speech sounds were\nsampled by a microphone and an analog-to-digital \nconverter attached to an interconnected IBM 7090-PDP-1\nsystem.  These utterances were recorded at the \nnormal noise level of the computer room but were not\nband-compressed or phase-distorted in any manner. \n A sequence of operations defined on the speech wave selects\na list of points along the waveform as candidates \nfor pitch markers.  These markers are validated by\nan error detection and correction procedure.About \n95 percent of the pitch periods were recognized correctly\nwithin 1 to 2 times real-time on the IBM 7090.\n", "1591": "A Model for a Multifunctional Teaching System A teaching system model that was incorporated\ninto an operating system of a large computer \nis described.  The model transferred control to the\noperating system to execute functions other than \nteaching, and then recovered control in order to resume\nteaching.  The teaching system (ABAC-II) was \nwritten to run under the operating system (IBSYS) for\nthe IBM 7044 Graphic System.  Because the teaching \nsystem automatically terminated and rescheduled itself,\na student studying a course presented at a cathode-ray \ndisplay terminal could switch readily between student\nmode and programmer mode.  During the latter, the \nfull resources of the operating system (language processors,\ncompilers, library and user's programs) \nwere at his disposal.  He could for example, write, assemble,\ndebug, and execute at the terminal a program \nwritten in any language processed by the operating system.\n A course could therefore include text material \ninterleaved with programming problems which the student\ncould solve without leaving the terminal.  Exercises \nin simulation and gaming could also be provided.  The\nimplications of a teaching system with this degree \nof flexibility for industrial and executive training\nas well as academic education are discussed.  In \naddition, the advantages of this type of system for computer\nprogramming and operation are also considered.\n", "1592": "String Similarity and Misspellings The problem of programming a computer to determine\nwhether or not a string of characters is \na misspelling of a given word was considered.  A numberof\nalgorithms were evaluated-some proposed by \nother writers, some by the author.  These techniques\nwere tested on a collection of misspellings made \nby students at various grade levels.  While many of\nthe methods were clearly unsatisfactory, some gave \nas few as 2.1 percent incorrect determinations.\n", "1593": "A Simple Technique for Digital Division A simple and economical method for digital\ndivision is described.  The method is suitable for \ndivisors whose leading character is either radix less\none or is unity with the next character equal to \nzero; also the method is direct and needs only half the\nnumber of arithmetic operations needed by a variant \nof the Harvard iterative method, described by Gilman,\nwhich is suitable for similar divisors.\n", "1594": "An Algorithm for Generating Permutations An algorithm is described which under repeated\napplication generates all permutations of K \nelements.  Only the previously generated permutation,\nthe constant K, and a temporary index are needed. \n Starting with a particular ordering of K elements (abcd),\nrepeated application of the algorithm will \ngenerate K-1 additional permutations by K-1 successive\nrotations.  From the initial circular ordering \nof K objects, another circular ordering can be obtained\nby rotating the K-1 lowest elements.  For each \nnew K-1 circular ordering, another K-2 can be obtained\nby rotating the K-2 lowest elements.  By continuing \nin this manner, applications of the algorithm will generate\nall (K-1)! circular orderings, or since each \ncircular ordering yields K permutations the\nalgorithm generates all K! permutations.\n", "1595": "On the Computer Enumeration of Finite Topologies The problem of enumerating the number of topologies\nwhich can be formed from a finite point \nset is considered both theoretically and computationally.\n Certain fundamental results are established, \nleading to an algorithm for enumerating finite topologies,\nand computed results are given for n <= 7. \n An interesting side result of the computational work\nwas the unearthing of a theoretical error which \nhad been induced into the literature; the use of the computer\nin combinatorics represents, chronologically, \nan early application, and this side result underscores\nits continuing usefulness in this area.\n", "1596": "Airy Function (Algorithm 301 [S20])", "1597": "Transpose Vector Stored Array (Algorithm 302 [K2])", "1598": "Least Squares Fit By Orthogonal Polynomials (Algorithm 28 [E2])", "1599": "Numerical Solution of the Polynomial Equation (Algorithm 300 [C2])", "1600": "Chebyshev Quadrature (Algorithm 279 [D1])", "1601": "Parallel Numerical Methods for the Solution of Equations Classical iterative procedures for the numerical\nsolution of equations provide at each stage \na single new approximation to the root in question.  A\ntechnique is given for the development of numerical \nprocedures which provide, at each stage, several approximations\nto a solution of an equation.  The s8everal \napproximations obtained in any iteration are computationally\nindependent, making the methods of interest \nin a parallel processing environment.  Convergence is\ninsured by extracting the \"best information\" at \neach iteration.  Several families of numerical procedures\nwhich use the technique of the procedures in \na parallel processing environment are developed and measurements\nof these statistics are reported.  These \nmeasurements are interpreted in a parallel processing\nenvironment.  In such an environment the procedures \nobtained are superior to standard algorithms.\n", "1602": "POSE: A Language for Posing Problems to a Computer A language, POSE, is described which is a drastic\ndeparture from the FORTRAN/ALGOL type, though \nit does utilize FORTRAN formula and logic representations\n(and actually contains FORTRAN VI as a subset). \n With the new language, the user need only describe\nhis problem in \"equation-like\" form. The method \nof solution is automatically provided in conjunction\nwith the translation from equation form to computer \ninstruction. In this way the POSE language user can\nsolve difficult computational problems (like the \nsolution of differential equation) without requiring\na knowledge of numerical methods or the intricacies \nof computer subroutine logic. Essentially all clerical\noperations now required for FORTRAN programming \nhave been automated so that the POSE programmer\nneed not be concerned with these details.\n", "1603": "A Multiprogramming Monitor for Small Machines INT, a combination hardware/software monitor\ndesigned to control a wide variety of real-time \ninput/output devices, is described.  The simple hardware\nadditions provide a uniform device to machine \ninterface for such elements as keyboards graphic input\ndevices, and interval timers.  The software relieves \nthe user program from the details of input/output timing,\nbuffering, and task scheduling and provides \nparallel processing capability.  User programs communicate\nwith the monitor through a small set of meta-instruction \nwhich consists mostly of machine-language subroutine calls.\n", "1604": "Further Analysis of a Computing Center Environment Empirical distributions of program lengths,\nexecution times, processing times, and loading \ntimes of over 10,000 jobs serviced in a university computing\ncenter environment are presented.  The data \nare subdivided according to certain characteristics of users\nand jobs to obtain selected empirical conditional \ndistributions of those time properties as well as statistical\nmeasures of other interesting properties. \n The results are interpreted in terms of the properties of the system studied.\n", "1605": "An Experimental Comparison of Time Sharing and Batch Processing The effectiveness for program development\nof the MIT Compatible Time-Sharing System (CTSS) \nwas compared with that of the IBM IBSYS batch-processing\nsystem by means of a statistically designed \nexperiment.  An identical set of four programming problems\nwas assigned to each of a group of four programming \nsubjects.  Influences external to the systems, such as\nthe sequence of problem solution, and programmer \nand problem characteristics, were specified as design\nfactors in the experiment.  Data was obtained for \nsix variables (e.g., programmer time, computer time,\nelapsed time, etc.) which were considered to be \ndefinitive of \"system effectiveness,\" and analysis of\nvariance techniques were employed to estimate system \ndifferences in these variables after differences due to\nthe design factors had been eliminated.  Statistical \nanalysis of the experimental results provided strong\nevidence of important system differences, as well \nas a critique of the experimental design itself\nwith implications for further experimentation.\n", "1606": "Chi-Squared Integral (Algorithm 299 [S15])", "1607": "Coulomb Wave Functions (Algorithm 300 [S22])", "1608": "Numerical Integration of Function That Has a Pole It is common to need to integrate numerically\nfunctions that diverge somewhere outside the \nrange of integration.  Even if the divergence occurs quite\nfar away, integration formulas like Simpson's, \nthat depend on fitting a polynomial, usually will be\ninaccurate: near a pole they will be very bad.  \nA method is described that gives formulas that will integrate\nfunctions of this kind accurately if the \norders and positions of the poles are known.  Explicit\nformulas are given that are easy to use on an \nautomatic computer.  It is shown that they can be used\nfor some other singularities as well as poles. \n If the integral converges, integration can be carried\nto the singularity.  The accuracy of the integration \nwith a pole of second order is discussed, and, as an example,\nthe new formula is compared with Simpson's. \n The new formulas are useful even far from the pole,\nwhile near the pole their advantage is overwhelming.\n", "1609": "Scheduling University Course Examinations by Computer A new approach to the problem of scheduling\ncourse examinations is presented.  In principle, \nan examination schedule which requires a minimum number\nof examination periods and satisfies the constraint \nthat no student be required to take two examinations\nsimultaneously can be found in two steps.  First, \ncourse which may have their examinations scheduled at\nthe same period are grouped together in all possible \nways.  Then a minimum number of these groups, such that\neach course is included at least once, are selected. \n By removing multiple occurrences of courses and then scheduling\neach group at a different period a minimal \nschedule can be obtained.  Known algorithms for carrying\nout these procedures are prohibitively expensive. \n Approximations to the ideal procedure outlined above are\ngiven which yield nonminimal but feasible schedules \nwith a very small expenditure of time.  Results of experiments\nusing these techniques are given.  These \nare encouraging and indicate that further experimentation would be worthwhile.\n", "1610": "A Method for the Solution of Transportation Problems with Tall Matrices A method is presented for the solution of the\ntransportation problem having a cost matrix with \nfew columns.  The computer implementation of this method\nshows it to be very fast and efficient.  Application \nare indicted for the personnel classification problem\nas well as the classical transportation problem. \n An example is worked out in detail.\n", "1611": "Scheduling Project Networks Some of the basic concepts and terminology\nof project networking are developed.  The Critical \nPath Algorithm incorporated in the C-E-I-R proprietary\nscheduling system RAMPS (Resource Allocation and \nMulti-Project Scheduling) is described.  The error detection\nand network analysis features of the algorithm \nare also described.\n", "1612": "Top-to-bottom Parsing Rehabilitated? This note is concerned with the efficiency\nof the Top-to-Bottom parsing algorithm as used in \nconnection with programming language grammars.  It is\nshown, for instance, that retracing of unprofitable \npaths can often be eliminated by a suitable rearrangement\nof the productions defining the grammar.  The \nessential weakness of the method is in dealing with complicated\nsyntactic structures which are in practice \nonly sparsely occupied, e.g., arithmetic expressions.\n", "1613": "One-Pass Compilation of Arithmetic Expressions for a Parallel Processor Under the assumption that a processor may have\na multiplicity of arithmetic units, a compiler \nfor such a processor should produce object code to take\nadvantage of possible parallelism of operation. \n Most of the presently known compilation techniques\nare inadequate for such a processor because they \nproduce expression structures that must be evaluated serially.\n A technique is presented here for compiling \narithmetic expressions into structures that can be\nevaluated with a high degree of parallelism.  The \nalgorithm is a variant of the so-called \"top-down\"\nanalysis technique, and requires only one pass of \nthe input text.\n", "1614": "A Proposal for Definitions in ALGOL An extension to ALGOL is proposed for adding\nnew data types and operators to the language. \n Definitions may occur in any block heading and terminate\nwith the block.  They are an integral part \nof the program and are not fixed in the language.  Even\nthe behavior of existing operators may be redefined. \n The processing of text containing defined contexts features\na \"replacement rule\" that eliminates unnecessary \niterations and temporary storage.  Examples of definition sets\nare given for real and complex matrices, \ncomplex numbers, file processing, and list manipulation.\n", "1615": "An Algorithm for Generating Root Locus Diagrams A technique for using a digital computer to\ndraw both ordinary and time-lag root locus diagrams \nis described.  Ordinary diagrams are drawn much faster\nand more accurately than ever before.  Time-lag \ndiagrams, which had been impossible to obtain, are drawn\nwith the same speed and accuracy as ordinary \ndiagrams.\n", "1616": "Tensor Calculations on Computer: Appendix In the main text of the paper [Comm. ACM 9,\n12 (Dec. 196), 864], a FORMAC program was discussed \nwhich is capable of calculating various quantities\nof interest in tensor calculus.  This Appendix is \nintended as an example of the program output.  Chrisoffel\nsymbols calculated for 12 basic orthogonal \ncoordinate systems are listed.\n", "1617": "Eigenvalues and Eigenvectors of the", "1618": "Determination of the Square-Root of a Positive", "1619": "Error-Free Methods for Statistical Computations Neely has discussed computational error generated\nby some algorithms used to compute various \nstatistics.  In the present paper methods are described\nwhich are error-free, simple in concept, and \nusually less costly in machine time than those mentioned by Neely.\n", "1620": "Methods of Evaluating Polynomial Approximations The method of nested multiplication is commonly\nused in function evaluation routines to evaluate \napproximation polynomials.  New polynomial evaluation\nmethods have been developed in recent years which \nrequire fewer multiplications than nested multiplication\nand may therefore be preferable for use in function \nevaluation routines.  Although some of these methods\ndo not appear to be practically useful because of \nrounding-error difficulties, several methods of evaluating\nlow-degree polynomials have been found to \nbe satisfactory.  Three such methods are described and illustrated.\n", "1621": "Computer Typesetting of ALGOL An application of computer-aided typesetting\nis introduced.  A working method is described \nfor publishing ALGOL by computerized translation from\nHardware into Reference representation, computerized \nplanning of typographical lay-out and computerized control\nof a typesetting machine.  The point is made \nthat experts in science, technology, and programming are\nguaranteed a correct ALGOL documentation without \nspending valuable time and power on typographic considerations and proofreading.\n", "1622": "An Efficient Procedure for the Generation of Closed Subsets An efficient algorithm is described for generating\nsubsets of a set S which satisfy constraints \nof the form: \"If s(i) is a member of the subset, then\ns(j) must also be a member of the subset.\"  The \nalgorithm has been programmed in the WISP language and\nsuccessfully run on the IBM 7094 in connection \nwith a routine to detect feedback in multidimensional iterative networks.\n", "1623": "An Application of FORMAC A nonlinear circuit analysis problem is stated\nand the way in which it was solved using FORMAC \nis indicated.  The solution of the problem using FORMAC\nwas notable since several other methods that \nwere tried failed.  The problem is straightforward (although\nuntenable by hand) but nevertheless involved \nan elaborate use of the FORMAC language.  The program\nwas fairly large and utilized practically every \ncommand.  In particular, it made extensive use of the\nPART command.  Several tricks were necessary in \norder to circumvent some of the shortcomings of the\nFORMAC system.  This paper is more concerned with \nthe use of programming techniques in FORMAC than with\nthe actual engineering problem, although readers \nmay be interested in the problem because it is stated\nin a general (mathematical) sense and could be \nof interest in areas other than circuit analysis.\n", "1624": "Automatic Dimensioning Examples of algorithm that will accomplish\nautomatic storage reservation without the need for \nexplicit array declarations are described.\n", "1625": "On the Automatic Simplification of Source-Language Programs Methods of simplification that can be applied\nautomatically to programs written in an ALGOL-like \nlanguage are discussed.  The simplifications are based\non the form of the program and the knowledge obtained \nby a processor, without any understanding of what the\nprogram is supposed to do.  These methods have \nbeen implemented in a processor called SURE that accepts\na program written in JOVIAL and outputs an equivalent \nJOVIAL program that may be shorter and may be executed\nfaster than the original.  SURE is described, \nsome of the problems encountered in automatic improvement\nat the source-language level are discussed, \nand further types of automatic program improvement are suggested.\n", "1626": "Structure of a LISP System Using Two-Level Storage In an ideal list-processing system there would\nbe enough core memory to contain all the data \nand programs.  Described in this paper are a number\nof techniques that have been used to build a LISP \nsystem utilizing a drum for its principal storage medium,\n with a surprisingly low time penalty for use \nof this slow storage device.  The techniques include\ncareful segmentation of system programs, allocation \nof virtual memory to allow address arithmetic for type\ndetermination, and a special algorithm for building \nreasonably linearized lists.  A scheme for binding variables\nis described which is good in this environment \nand allows for complete compatibility between compiled\nand interpreted programs with no special declarations.\n", "1627": "Application of Level Changing to a Multilevel Storage Organization A technique for organizing the devices of a computer\nstorage system is described.  This technique, \ncalled the multilevel store, provides a means for economically\nsatisfying the requirements for very large \nstorage capacities of certain data management and information\nretrieval systems.  The concept of level \nchanging is introduced and its application to the multilevel\nstore is discussed.  A possible means for \nphysically organizing the information for efficient\nuse of the multilevel store is presented.\n", "1628": "The Emergence of a Profession Computer programming deals with an enormous\nvariety of activities and is carried on by people \nwith a great variety of backgrounds.  It seems clear\nthat part but not all of this activity is evolving \ntoward a distinct professional field, but that the\nscope of this emerging profession, and some of its \neconomic, social, and educational characteristics are\nas yet by no means well defined.  In this paper, \nthese issues are examined and some opinions about them are expressed.\n", "1629": "Stat-Pack: A Biostatistical Programming Package A package of FORTRAN statistical programs for use\non almost any small to medium size (40k characters \nor 8k words) for which a FORTRAN II compiler exists\nis described and its availability is announced.  \nThe major design criteria of ease of use, ease of modification,\nflexibility of input and detail of output \nare described.\n", "1630": "Computer Representation of Planar Regions by Their Skeletons Any region can be regarded as a union of maximal\nneighborhoods of its points, and can be specified \nby the centers and radii of these neighborhoods; this\nset is a sort of\"skeleton\" of the region.  The \nstorage required to represent a region in this way is\ncomparable to that required when it is represented \nby encoding its boundary.  Moreover, the skeleton representation\nseems to have advantages when it is \nnecessary to determine repeatedly whether points are inside\nor outside the region, or to perform set-theoretic \noperations on regions.\n", "1631": "Testing a Random Number Generator The first 1,000,000 numbers produced by the\nrandom number generator used in the General Purpose \nSystems Simulator (GPSS) were subjected to statistical\ntests.  The tests are described and the results \nof the tests are presented.  These particular tests indicate\nthat the numbers are satisfactory.  It is \nrecommended that suitable tests be applied to all\nrandom numbers used in computer simulations.\n", "1632": "Programming the Tabular Method of Analysis The ease of programming the tabular method of analysis\nof variance for complete factorial experiments \nin a FORTRAN language is demonstrated.  In this method,\nthe total sum of squares is partitioned into \northogonal single degree of freedom sums of squares;\nmain effect and interaction sums of squares are \nthen obtained by appropriate pooling of the single degree\nof freedom sums of squares.  Program segments \nto accomplish the procedure are presented.  Modifications\nto handle hierarchical designs and replicated \nexperiments are mentioned. A FORTRAN II program\nfor an IBM 7094 is described briefly.\n", "1633": "A Modified Newton Method for Polynomials A modified Newton method for polynomials is\ndiscussed.  It is assumed one has approximations \nfor all the roots of the polynomial.  Three variations\nare described.  If the roots are simple, it is \nshown that under appropriate conditions, two\nof the variations are cubically convergent.\n", "1634": "27 bits Are Not Enough for 8-digit Accuracy From the inequality 10^8 < 2^27, we are likely\nto conclude that we can represent 8-digit decimal \nfloating-point numbers accurately by 27-bit floating-point\nnumbers.  However, we need 28 significant \nbits to represent some 8-digit numbers accurately. \nIn general, we can show that if 10^p < 2^q-1, then \nq significant bits are always enough for p-digit decimal\naccuracy.  Finally, we can define a compact \n27-bit floating-point representation that will give 28\nsignificant bits, for numbers of practical importance.\n", "1635": "Parameters for Pseudo Runge-Kutta Methods The object of this note is to present a choice\nof the free parameters in the third- and fourth-order \npseudo Runge-Kutta methods involving two points. This\nchoice of parameters causes a bound on the principal \npart of the truncation error term to be near the minimum\nfor the fourth-order method and at the minimum \nfor the third-order method.\n", "1636": "Invariant Imbeding and the Numerical Integration In such diverse areas as radiative transfer\nin planetary atmospheres and optimal guidance and \ncontrol, two-point boundary-value problems for unstable\nsystems arise, greatly complicating the numerical \nsolution.  An invariant imbeding technique is presented\nwhich is useful in overcoming these frequently \nencountered instabilities, and the results\nof some numerical experiments are given.\n", "1637": "Problems in the Statistical Analysis of Simulation Research is continued into statistical analysis\nof simulation experiments containing autocorrelated \ntime series.  It is shown how to estimate the lengths\nof sample records needed to use certain large sample \nresults in measuring stability.  Analogies between autocorrelated\ndata and independent observations are \ndescribed.  A way to test the difference of the mean\nof two experiments is suggested.  It is shown how \nthe variance of the sample mean relates to the spectrum\nof the generating process, and estimation of \nthe quantities of interest is described. The results\nexpand the possibilities of statistical spectral \nanalysis as applied to simulation experiments.\n", "1638": "Sorting by Replacement Selecting In sorting by replacement selecting, the expected\nlength of a sequence beginning with the i-th \nelement (i>1) is proved to be 2F, in accordance with\na conjecture of E. H. Friend, where F is the number \nof memory cells used.  The expected length of the j-th\nsequence is determined to be F times a j-th degree \npolynomial in e, such that the value of this polynomial\napproaches 2 as j approaches infinity.  Recursive \nformulas are obtained for both the mean and the standard\ndeviation of the length of the j-th sequence. \n The mathematical proofs of these results are based\nupon the assumption that n, the number of items to \nbe sorted, is infinite, but it is shown that the error\ndue to the finiteness of n approaches zero rapidly \nas n increases.\n", "1639": "Exponential Curve Fit (Algorithm 295 [E2])", "1640": "Generalized Least Squared Fit By Orthogonal", "1641": "A Use of Fast and Slow Memories in List-Processing Languages A scheme is described which permitting a substantial\nincrease in memory space utilized to store \nlist-structured data.  It consists in reducing to one\nlevel a nonhomogeneous store composed of fast (core) \nand slow (disk or drum) memories.  The space available\nin slow memory is divided into pages each containing \na given number of machine words.  The reduction to a\none-level memory is performed by a program which \nleaves the most often called pages in the fast memory.\n When a new page from slow store is requested, \nthe page in core having the longest period of inactivity\nis transferred back to the slow store.  The \ncomplete scheme has been implemented in connection with\na LISP embedding into ALGOL, using an IBM 7044 \nwith 32k of core memory and disks.  Gains in memory space\nwere about 100-fold.  As often happens in programming \napplications the price of the additional space is computer\ntime.  Although the disks have an access time \n10^4 times slower than core, tests indicate that the\nactual slow down varied from 3 to 10, depending \non the number of pages available in the fast store.\n", "1642": "Time Sharing on a Computer with a Small Memory Techniques to make time sharing attractive on\na computer with a small central memory are presented. \n \"Small\" is taken to mean that only one user program plus\na monitor will fit into the memory at any time. \n The techniques depend on having two levels of secondary\nstorage: level 1, several times larger than \nthe main memory and quite fast; and level 2,\nmany times larger and slower than level 1.\n", "1643": "An Improvement to Iterative Methods of Polynomial Factorization Methods of polynomial factorization which\nfind the zeros one at a time require the division \nof the polynomial by the accepted factor.  It is shown\nhow the accuracy of this division may be increased \nby dividing in order of both ascending and descending\npowers of the variable and choosing a crossover \npoint which minimizes a very simply calculated error criterion.\n", "1644": "On the Computation of Least Squares Polynomials Rounding error accumulated during digital computation\nof a least squares polynomial makes the \ncomputed polynomial only an approximation to the true least\nsquare polynomial.  A simple method for adjust ing \nthe constant term of the computed polynomial to get\na better approximation to the true least squares \npolynomial is described.\n", "1645": "A Note on Computing Approximations to the Exponential Function Two methods are discussed which result in near\nminimax rational approximations to the exponential \nfunction and at the same time retain the desirable property\nthat the approximation for negative values \nof the argument is the reciprocal of the approximation\nfor corresponding positive values.  These methods \nlead to approximations which are much superior to the\ncommonly used convergents of the Gaussian continued \nfraction for the exponential.  Coefficients and errors\nare given for the intervals [-.5*ln 2, .5*ln 2] \nand [-ln 2, ln 2].\n", "1646": "DITRAN-A Compiler Emphasizing Diagnostics DITRAN (Diagnostic FORTRAN) is an implementation\nof ASA Basic FORTRAN with rather extensive \nerror checking capabilities both at compilation time\nand during execution of a program.  The need for \nimproved diagnostic capabilities and some objectives\nto be met by any compiler are discussed.  Attention \nis given to the design and implementation of DITRAN\nand the particular techniques employed to provide \nthe diagnostic features.  The handling of error messages\nby a general macro approach is described.  Special \nfeatures which provide teaching aids for use by instructors are noted.\n", "1647": "WATFOR-The University of Waterloo FORTRAN IV Compiler WATFOR is an in-core, load-and-go compiler\nwhich has been implemented within the IBM 7040/44 \noperating system.  FORTRAN IV was selected as the source\nlanguage in order to achieve maximum language \ncompatibility with other available compiling systems,\nin particular the IBM 7040/44 FORTRAN IV system. \n The principal advantage of the WATFOR compiler is that\nit translates FORTRAN IV programs at speeds of \nup to 100 statements per second.  Since the compiler\nresides core there is virtually no system overhead, \nand hence large batches of \"student\" programs may be processed very\nefficiently.  The compiler also provides \nextensive error diagnostics, during both the compilation\nand the execution phases of a program run.  \nThis feature makes the system attractive to\nboth learners and learned users alike.\n", "1648": "Uniform Random (Algorithm 294 [G5])", "1649": "Data Directed Input-Output in FORTRAN A statement which is similar to the NAMELIST\nstatement of FORTRAN IV has been incorporated \nin the FORTRAN 63 compiler.  The FORTRAN 63 implementation\nallows a greater flexibility and simplicity \nthan the FORTRAN IV feature.  The Hollerith names, the\nlocation, the mode and the dimensions of a variable \ncan be discovered by means of standard FORTRAN statements.\n Methods of using this information are illustrated \nin relation to general purpose data directed input and\noutput routines; some other uses such as matrix \nmanipulation are discussed.\n", "1650": "A Unifying Computational Method for the A computational method which may be used for\nthe calculation of sums of squares in the analysis \nof variance of complete factorial experiments and in\nthe computation of main effect or interaction means \nis described.  The method is elucidated as unifying since\none method can be used for a variety of purposes \neach previously requiring different methods.  The programming\nadvantages of such a method are obvious. \n The following variants are discussed: (1) the standard\nanalysis of variance; (2) analyses omitting certain \nlevels of one or more factors; (3) separate analyses\nfor some levels of a factor or for combinations \nof levels of more than one factor.  These are performed\nsimultaneously; (4) the calculation of main effect \nor interaction means.  The mean expects the data in standard\norder and it leaves the data in that order \nso that many analyses of the same data can be performed\nwithout rearrangement.  The total sum of squares, \nexcluding a replication sum of squares, is partitioned\ninto all polynomial partitions and their interactions \neach with one degree of freedom.  This is so even\nif factors have unequally spaced factor levels.\n", "1651": "An Interpretive Input Routine for Linear Programming In this descriptive article an input code\nis presented which greatly simplifies data input \nto any linear programming solution routine, for subsequent\nuse either as a pedagogical device or for \nsolving rather small LP problems.  This latter (limited)\nuse derives not at all from inherent limitations \nin the code itself, but from an efficiency evaluation:\nlarge LP problems would doubtless benefit from \nan input system more suited for bulk data handling than\nthe input code described.  From a user's standpoint, \ninput appears almost exactly as a textbook presentation\nof the LP problem (limited only by a keypunch's \ninability to write subscripts, etc.).  The input interpreter\nscans column wise, thus no fixed format \ndata preparation is required.  The user may also, under\nvery general requirements only, liberally use \neditorial comments throughout the input deck as an\naid in identification, e.g., of row constraints.  \nThe article includes examples of input, output from a\nsolution routine presently in use, and a skeleton \nflowchart of the input interpreter.\n", "1652": "A Code for Non-numeric Information Processing A code has been specifically designed to simplify\nthe internal information processing operations \nwithin an online computer system with respect to non-numeric\napplications, and to maximize the transfer \nrate of the information channel linking the system and\nthe system user.  The code has direct application \nto problems in area such as information retrieval, document\nclassification, computer-aided teaching and \ntext editing.  This code, called IPC (Information Processing\nCode), is an 8-bit code set constructed \nso that 7, 6, 5 and 4-bit subsets can be easily derived\nfrom the basic set.  The code set is organized \nso that simple binary operations can distinguish between\nthe numeric alphabetic, special symbol and control \ncharacter codes.  The number of usable characters within\nthe basic set size may be expanded either by \nuse of escape codes included in the set, or by suitable\ninterpretation of otherwise unassigned codes \non the basis of the requirements of local environments.\n", "1653": "System Performance Evaluation: Survey and Appraisal The state of the art of system performance\nevaluation is reviewed and evaluation goals and \nproblems are examined.  Throughput, turnaround, and\navailability are defined as fundamental measures \nof performance; overhead and CPU speed are placed in\nperspective.  The appropriateness of instruction \nmixes, kernels, simulators, and other tools is discussed,\nas well as pitfalls which may be encountered \nwhen using them.  Analysis, simulation, and synthesis are\npresented as three levels of approach to evaluation, \nrequiring successively greater amounts of information.\n The central role of measurement in performance \nevaluation and in the development of evaluation methods is explored.\n", "1654": "A University's Educational Program in Computer Science After a review of the power of contemporary computers,\ncomputer science is defined in several \nways.  The objectives of computer science education are\nstated, and it is asserted that in a North American \nuniversity these will be achieved only through a computer\nscience department.  The program at Stanford \nUniversity is reviewed as an example.  The appendices\ninclude syllabic of Ph.D. qualifying examinations \nfor Stanford's Computer Science Department.\n", "1655": "Code Extension Procedures for Information standard code, code, information interchange, characters,\nshift out, shift in, escape, data link \nescape, control functions, standard procedures,\ncode extension, code table, bit pattern\n", "1656": "Procedures for the Standardization Process* (Proposed USA Standard) standardization, procedures, criteria\n", "1657": "Implementation of the SHARER2 Time-Sharing System A simple mechanism is described for the execution\nof part of a program with its own memory \nprotection.  This allows such a program to act as a\nsuboperating system.  An improved version of the \nSHARER time-sharing system using this feature is described.\n operating system, memory protection, time-sharing,\nmultiprogramming, monitor, submonitor, suboperating \nsystem\n", "1658": "Analysis of Algorithms for the Zero-One Programming Problem This paper is concerned with a review and examination\nof several existing algorithms for the \nzero-one programming problem.  Computational experience\nis summarized.  The machine time and storage \nrequirements of several of the algorithms are compared\nover several test problems of small and intermediate \nsize.  Computer experiments still provide little hope\nof solving problems with over 100 variables with \na reasonable amount of machine time.\n operations research, optimization theory, integer\nprogramming, zero-one variables, algorithms\n", "1659": "Computational Linguistics in a Ph.D. Computer Science Program This report contains recommendations for a\ncourse curriculum on computational linguistics in \na Ph.D. computer science program.  A classification of the\nsubject areas contained in computational linguistics \nis presented, and ten courses in these areas are described.\n A basic bibliography in computational linguistics \nis appended.\n computational linguistics, mathematical linguistics,\nlanguage and computer, language data processing, \ncomputational linguistics course curriculum, computational\nlinguistics graduate program, computational \nlinguistics bibliography, computer science curriculum\n", "1660": "Index By Subject To algorithms, 1960-1968", "1661": "Multint (Algorithm 32 [D1]) numerical integration, multidimensional integration, Gaussian integration\n", "1662": "Eigenvalues and Eigenvectors of a Real General Matrix [F2]) eigenvalues, eigenvectors, latent roots, latent\nvectors, Householder's method, QR algorithm, inverse \niteration\n", "1663": "Generator of Random Numbers Satisfying the Poisson distribution [G5]) Poisson distribution, random number generator, Monte Carlo\n", "1664": "An Algorithm for Deriving the Equations of A method is described whereby a digital computer\ncan be used to derive the equations of mathematical \nphysics in any curvilinear coordinate system requested\nby the user.  The effectiveness of the technique \nis demonstrated by using it to derive the Navier-Stokes\nequations of fluid motion and the continuity \nequation.  To derive these equations by this method, the\nuser need know only the coordinate transformation \nequations relating the curvilinear coordinates of interest\nto an orthogonal Cartesian triad. When this \nprogram is used and the coordinate transformation equations\nare supplied as input, the computer will \nderive the Navier-Stokes equations and the continuity\nequation.  The equations obtained will be relative \nto the curvilinear coordinate system specified by the\ntransformation equations used as input.  In this \npaper the emphasis is on theoretical considerations and\nmethodology rather than on programming details. \n Results are presented for cylindrical polar\nand spherical polar coordinate systems.\n FORMAC, Navier-Strokes equations, continuity equation,\ntensor, tensor equation, curvilinear coordinate \nsystems, FORTRAN, symbolic manipulation\n", "1665": "Automatic Generation of Efficient Lexical The practical application of the theory of\nfinite-state automata to automatically generate \nlexical processors is dealt with in this tutorial article\nby the use of the AED RWORD system, developed \nat M.I.T. as part of the AED-1 system.  This system\naccepts as input description of the multicharacter \nitems or of words allowable in a language given in terms\nof a subset of regular expressions. The output \nof the system is a lexical processor which reads a string\nof characters and combines them into the items \nas defined by the regular expressions.  Each output\nitem is identified by a code number together with \na pointer to a block of storage containing the characters\nand character count in the item.  The processors \nproduced by the system are based on finite-state machines.\n Each state of a \"machine\" corresponds to \na unique condition in the lexical processing of a character\nstring.  At each state a character is read, \nand the machine changes to a new state.  At each transition\nappropriate actions are taken based on the \nparticular character read.  The system has been in operation\nsince 1966, and processors generated have \ncompared favorably in speed to carefully hand-coded programs\nto accomplish the same task.  Lexical processors \nfor AED-O and MAD are among the many which have been\nproduced.  The techniques employed are independent \nof the nature of the items being evaluated.  If the\nword \"events\" is substituted for character string, \nthese processors may be described as generalized decision-making\nmechanisms based upon an ordered sequence \nof events.  This allows the system to be used in a\nrange of applications outside the area of lexical \nprocessing.  However convenient these advantages may\nbe, speed is the most important consideration.  \nIn designing a system for automatic generation of a\nlexical processor, the goal was a processor which \ncompletely eliminated backup or rereading, which was nearly\nas fast as hand-coded processors, which would \nanalyze the language and detect errors, and\nwhich would be convenient and easy to use.\n character string, compiler, finite-state automata, finite-state\nmachine, lexical processor, nondeterministic \nmachine, parsing, plex structure, regular expressions,sequential\nmachine, syntactic analysis\n", "1666": "Solution of Linear Programs in 0-1 Variables linear programming, zero-one variables, partial enumeration\n", "1667": "Roots of Polynomials by a Root-Squaring root finders, roots of polynomial equations, polynomial\nzeros, root-squaring operations, Graeffe \nmethod, resultant procedure, subresultant procedure,\ntesting of roots, acceptance criteria\n", "1668": "An Algol Procedure for the Fast Fourier Transform fast Fourier transform, multivariate Fourier transform,\nFourier series, harmonic analysis, spectral \nanalysis, orthogonal polynomials, orthogonal transformation,\nvirtual core memory, permutation\n", "1669": "Algol Procedures for the Fast Fourier Transform (Algorithm 338 [C6]) fast Fourier transform, complex Fourier transform,\nmultivariate Fourier transform, Fourier series, \nharmonic analysis, spectral analysis, orthogonal polynomials,\northogonal transformation, virtual core \nmemory, permutation\n", "1670": "Correspondences of 8-Bit and Hollerith Codes for USA standard, card code, punched card, punched card\ncode, hole-patterns, hole-patterns assignment, \npunched card systems\n", "1671": "A Phonological Rule Tester The design and implementation of a system to\nalleviate the problem of rule evaluation for the \nlinguist in the area of phonology are presented.  It\npermits the user to define, on-line, sets of rules \nstatable within the framework presented in The Sound\nPatterns of English by Chomsky and Halle, 1968, \nto define phonemes as bundles of specified distinctive\nfeatures, to define data as strings of phonemes \nwith associated grammatical structure, to test the effect\nof applying rules to the data, and to store \nboth the definitions and results.  The rule application\nfacility described in detail was implemented \nby translating linguistic rules to rules in FLIP, a\nformat-directed list processor embedded in LISP. \n This made the system construction easy while providing\nsophisticated capabilities for the linguist. \n The system is written in BBN LISP on the Scientific\nData System 940 computer and is designed to be used \non-line in interactive fashion, with control returned\nto the user after each command is executed.\n phonology, rule tester, linguistics, transformational\ngrammar, LISP, format-directed list processing, \non-line systems\n", "1672": "Practical Error Coefficients in the Integration Theoretical and practical values of error coefficients\nuseful in bounding the error in integrating \nperiodic analytic functions with the trapezoidal rule\nare tabulated for various ranges of the parameters.\n theoretical error coefficients, practical error coefficients,\nnumerical integration, periodic analytic \nfunctions, trapezoidal rule, roundoff error,\ntruncation error, integration algorithm\n", "1673": "Approximate Solution of Initial Boundary Wave A new boundary-value technique is proposed for\nthe treatment of initial-boundary-value problems \nfor linear and mildly nonlinear wave equations.   Several\nillustrative examples are offered to demonstrate \nthe ease with which the method can be applied.\n initial-boundary-value problem, wave equation, boundary-value technique\n", "1674": "One-Line Random Number Generators and Their Use in Combinations Some one-line random number generators, i.e.\ngenerators requiring a single FORTRAN instruction \nare discussed, and some short FORTRAN programs which\nmix several such generators are described.  The \naim is to provide methods for incorporating random number\ngenerators directly in FORTRAN programs, by \nmeans of a few in-line instructions.  The advantages are\nspeed (avoiding linkage to and from a subroutine), \nconvenience, and versatility.  Anyone wishing to experiment\nwith generators, either using congruential \ngenerators by themselves or mixing several generators\nto provide a composite with potentially better \nstatistical properties than the library generators\ncurrently available, may wish to consider some of \nthe simple FORTRAN program discussed here. \n random number generation, Monte Carlo, simulation\n", "1675": "A Note on a Relevance Estimate and Its Improvement In this paper the effect of iterating the improvement\nprocedure is examined.  It is shown that \napplications of the improvement factor beyond the first\ntime are ineffectual, and that the factor is \nbut a scale factor.\n information retrieval, relevance, indexing, classification\n", "1676": "The LRLTRAN Compiler Extensive software problems confront an organization\nwhich possesses a number of different \ncomputers and which frequently acquires new ones. \nTo maintain cohesion, a system must be developed, \nwritten in a high level language, which minimizes machine\ndependencies and isolates those which are necessary. \n A language and a compiler for the language are discussed\nhere.  The language, called LRLTRAN, is a heavily \naugmented FORTRAN.  The tree-pass compiler makes use\ninternally of a postfix Polish notation (pass I \nto pass II) and a tree representation referred to as\na \"composite blocking table\" (pass I to pass III). \n Machine-independent optimization occurs in pass II\nand DO-loop and machine-dependent optimization in \npass III.\n compiler, compiler-compiler, machine independence,\nscatter storage technique, Polish processor, \ncommon subsegments, tree representation, optimization\n", "1677": "Storage Organization in Programming Systems The system of program and data representation\nthat has been in use on the Rice University computer \nfor five years is described.  Each logical entity in storage\noccupies a block of consecutive memory locations. \n Each block is labeled by a codeword and may contain\na program, a data vector, or codewords which in \nturn label blocks to form arrays.  This storage arrangement\nis discussed with its realized advantages \nor programming systems: simplicity of programmed addressing,\nflexibility of data structures, efficiency \nof memory utilization, variability of system composition\nduring execution, means of linkage between programs \nand from programs to data, and basis for storage protection.\n The application of labeled blocks may be \nextended to areas of time-sharing and multimedia storage\ncontrol.  On the basis of experience at rice, \nsome ideas on such extensions are presented.\n storage allocation, storage organization, storage\ncontrol, codewords, data representation, program \nrepresentation, data structures, storage protection,\naddressing mechanisms, paging, segmentation, file \nhandling\n", "1678": "Automata, Formal Languages, Abstract Switching, A number of courses are listed in the area\ndescribe as automata, formal languages, abstract \nswitching, and computability, that might be available\nto a Ph.D. student in computer science.  A brief \ncatalog description of each course is applied and the\nrole of each of the courses in the graduate program \nis discussed.\n Ph.D. computer-science curriculum, Ph.D. computer\nscience program, automata, formal languages, \nswitching theory, theory of computability\n", "1679": "A Fast Fourier Transform Algorithm for Real-Valued Series A new procedure is presented for calculating the\ncomplex, discrete Fourier transform of real-valued \ntime series.  This procedure is described for an example\nwhere the number of points in the series is \nan integral power of two.  This algorithm preserves\nthe order and symmetry of the Cooley-Turkey fast \nFourier transform algorithm while effecting the two-to-one\nreduction in computation and storage which \ncan be achieved when the series is real.  Also discussed\nare hardware and software implementations of \nthe algorithm which perform only (N/4) log2 (N/2) complex\nmultiply and add operations, and which require \nonly N real storage locations in analyzing each N-point record.\n fast Fourier transform, time series analysis, digital\nfiltering, spectral analysis, real-time spectrum \nanalyzers, Fourier analysis, discrete Fourier transform,\ndigital spectrum analysis, Fourier analysis \nalgorithm, Fourier synthesis algorithm\n", "1680": "A General-Purpose Display Processing and Tutorial System ADEPT (A display-Expedited Processing and Tutorial)\nsystem is described.  This system was designed \nto improve man-computer communications by employing\na display unit to interleave tutoring with other \ncomputer operations such as simulation, programming, and\ninformation retrieval.  It is written in FORTRAN \nIV (G) for the IBM System/360, Model 40, and the IBM 2250\ndisplay Unit under Operating System/360.  Adept \nis a cataloged program that controls the standard operating\nsystem by terminating and rescheduling itself \nautomatically, relinquishing computer resources allocated\nto it, and surrendering control to the operating \nsystem to perform other jobs.  It expands the power\nand flexibility of computer-assisted instruction \nby making immediately available to students, teachers,\nand other users, the full resources (system-cataloged \nprograms) of the operating system.  Language processors\nand compilers, simulation models, mathematical \nsolution techniques, stored data, and all other library and\nuser programs can be incorporated into instructional \nmaterial without reprogramming.  Illustrations of the various\napplications are presented and their implications \nare discussed.\n computer-assisted instruction, tutorial systems,\nprogramming, simulation, modeling, information \nretrieval operating systems, graphics, displays, man-machine\ninterface, on-line computing, graphic programming\n", "1681": "Easy English,a Language for Information Easy English is a natural command language\ndesigned to simplify communication between man and \nmachine through remote typewriter console.  It has been developed\nfor retrieval of documents from a computerized \ndata base, the Moore School Information Systems Laboratory\nfiles.  Requests are formulated in a standardized \nsyntactical form (examples of which are presented), and\nthis form is then transformed into an equivalent \nquery expressed in the retrieval system's original Symbolic\nCommand Language, which is briefly described. \n Operation of easy English is detailed by illustration\nof the transformations performed upon a sample \nrequest up to the point at which the request string\nis sent to the system.  A macro flowchart of Easy \nEnglish is included, and an Appendix provides\nthe printout of a retrieval demonstration.\n natural language communication, on-line searching,\nremote console communication, information retrieval, \nman-machine communication, remote terminal communication,\ntranslator, document retrieval, conversational \nmode, information retrieval language, symbolic command language\n", "1682": "The Implementation of a BASIC System in a Multiprogramming Environment The implementation of a remote terminal BASIC system\nwithin the context of an existing multiprogramming \ncomputer system, the Burroughs B5500, is described.\n This implementation combines a unique mixture of \nmachine language and interpretive techniques with an incremental compiler.\n multiprogramming, incremental compilation, compilers, interpreters\n", "1683": "Boolean matrix Methods for the Detection of Simple Precedence Grammars A mechanical procedure is derived for determining\nwhether a given context-free phrase structure \ngrammar is a simple precedence grammar.  This procedure\nconsists of elementary operations on suitably \ndefined Boolean matrices.  Application of the\nprocedure to operator grammars is also given.\n syntax analysis, precedence analysis, simple precedence\ngrammar, simple precedence language, operator \ngrammar, operator precedence, compilers, bounded-context\nsyntactic analysis, Boolean matrices, relations\n", "1684": "Ambiguity in Limited Entry Decision Tables The use of decision tables as a tool in systems\nanalysis and for program specification is now \nbecoming accepted.  Rules on redundancy, contradiction,\nand completeness for limited entry tables were \npublished in 1963.  These are usually used for checking,\npreceded if necessary by a conversion from extended \nto limited entry form.  Processors which automatically\ntranslate tables to more conventional program \nusually base their diagnostic facilities on these rules.\n In this paper it is suggested that these rules \nare unsatisfactory and that the important aspect of\nchecking is to eliminate ambiguity from tables.  \nAmbiguity is defined and discussed, and a procedure for\nproducing checked-out decision tables is proposed. \n The theoretical basis of the algorithm used is established.\nThe importance of well-designed diagnostic \nfacilities in decision table processors is emphasized.\n decision tables, DETAB-65, systems analysis \n", "1685": "GAN, a System for Generating and Analyzing Activity Networks GAN, a system for generating activity networks,\nis designed to save time in the preparation \nof activity networks and to deal conveniently with network\nprograms.  A defining description of a programming \nlanguage designed for generating activity network from\na set of standard networks is presented.  Also, \na general idea of a language for performing calculations\non activity networks (scheduling activity networks) \nis given.\n activity network, management project, standard network,\nnetwork generator, network assembler, activity \nnetwork analysis, network calculation, network program\n", "1686": "Computer Synthesis of Holograms for 3-D Display Optical and digital holography are reviewed.\n The mathematical model and computational techniques \nof the authors' digital holographic process are discussed,\nand applications of computer holography are \nsuggested.  Computer holograms have been made of three-dimensional\nobjects which give faithful reconstructions, \neven in white light.  A new approach based on point\napertures for the image is discussed.  Photographs \nof the images reconstructed from digital holograms are presented.\n holography, optics, Fourier transforms, computer\napplications, display device, photography, physics, \nmathematics, image processing\n", "1687": "Netflow (Algorithm 248 [H]) capacitated network, linear programming, minimum-cost\nflow, network flow, out-of-kilter\n", "1688": "Netflow (Algorithm 248 [H]) capacitated network, linear programming, minimum-cost\nflow, network flow, out-of-kilter\n", "1689": "Calculation of a Polynomial and its Derivative function evaluation, polynomial evaluation,\nAlgol procedure, Horner's scheme\n", "1690": "Netflow (Algorithm 336 [H]) capacitated network, linear programming, minimum-cost\nflow, network flow, out-of-kilter\n", "1691": "A Comparison of the Correlational Behavior Hutchinson states that the \"new\" (prime modulo)\nmultiplicative congruential pseudorandom generator, \nattributed to D. H. Lehmer, has passed the usual statistical\ntests for random number generators.  It \nis here empirically shown that generators of this type\ncan produce sequences whose autocorrelation functions \nup to lag 50 exhibit evidence of nonrandomness for many\nmultiplicative constants.  An alternative generator \nproposed by Tausworthe, which uses irreducible polynomials\nover the field of characteristic two, is shown \nto be free from this defect.  The applicability of these\ntwo generators to the IBM 360 is then discussed. \n Since computer word size can affect a generator's statistical\nbehavior the older mixed and simple congruential \ngenerators, although extensively tested on computers\nhaving 36 or more bits per word, may not be optimum \ngenerators for the IBM 360.\n random numbers, pseudorandom number generators, autocorrelation\nfunction, serial correlation, digital \nshift-register generators, linear recurrence modulo\ntwo, irreducible polynomials, primitive trinomials \nmodulo two, congruential generators, prime numbers,\nstatistical tests for randomness, IBM 360, 32-bit \nversus 36-bit word size\n", "1692": "Numerical Solution of a Thin Plate Heat Transfer Problem The numerical solution of a system of linear\nequations resulting from a discrete approximation \nto a thin plate heat transfer problem is considered.\n The slow convergence of point iterative methods \nis analyzed and shown to be caused by one of the boundary\nconditions. The difficulty may be removed by \na standard line iterative technique.\n heat transfer problem, Poisson equation, boundary\nvalue problem, thin domain, successive overrelaxation \n(SOR), block SOR\n", "1693": "GPL, a Truly General Purpose Language A truly general purpose programming language,\nGPL, is described which contains facilities for \nconstructing (within the language) new data types as\nwell as facilities for operations performed upon \nthem.  The basic language is minimal in the sense that\nno basic element can be derived from the others \nwith high efficiency in the object programs.  Constructs\nlike the ALGOL 60 for-statements,and if-statements \nare not basic; they are special types of procedures.\n New \"symbols\" (underlined words in ALGOL 60) are \nimplicitly defined by usage in other declarations.  As\npart words are definable, packed words are handled \nas easily as full words.  \"Address\" variables\n(pointers) are included in full generality.\n programming language, general purpose, self-extending, macro, ALGOL\n", "1694": "An Algorithm for the Probability of An algorithm is presented which efficiently evaluates\nthe probability for the union of n independent \nand not mutually exclusive events. The problem is that\nof evaluating the sums of the products of all \npossible combinations of n variables in minimum time and storage space.\n algorithm, probability, optimum, storage vs. time\ncompromise, set union, mutually exclusive events\n", "1695": "PLEXUS-An On-Line System for Modeling Neural Networks A description is presented of PLEXUS, a system\nwhich enables a user to construct and specify \na neural network, to analyze the output data produced\nby the network, and to store and retrieve networks \nand data from a library.  The system, operated entirely\nfrom a digital display unit, interacts directly \nwith the user and permits easy and rapid transitions\nbetween the various phases of the modeling process. \n PLEXUS is designed to complement neurophysiological research\nso that the systematic development of neural \nmodels can be coordinated with experimental work.  PLEXUS\nnetworks are built up from components representing \nindividual neurons, external stimuli, and interconnecting\nfibers, each component being of a relatively \ndetailed nature.  Provision is also made for the use of\nexperimental data as input to a network.  Convenient \nmeans for specification and modification of a network and\nextensive error-checking capabilities are provided. \nData resulting from the simulation of a network may be\nanalyzed by a variety of techniques ranging from \nexaminations of the gross characteristics of the data to\nthe determination of detailed statistical properties.\n biological modeling, data analysis, discrete system\nsimulation, library systems, modeling, network \nsimulation, neural networks, neurophysiological\nmodels, on-line simulation, simulation\n", "1696": "An Algorithm for Identifying the Ergodic Subchains An algorithm for identifying the ergodic subchains\nand transient states of a stochastic matrix\nis presented.  Applications in Markov renewal programming\nand in the construction of variable length \ncodes are reviewed, and an updating procedure for dealing\nwith certain sequences of stochastic matrices \nis discussed.  Computation times are investigated experimentally\nand compared with those of another recently \npropose method.\n stochastic matrix, ergodic, chain identification\n", "1697": "Graphical Input/Output of Nonstandard Characters A system developed at Harvard for graphically\ninputting and outputting nonstandard characters \non a computer is printed.  In principle, the system\ncan deal with any orthography, although at present \nit is limited to 4000 Chinese characters and some mathematical\nsymbols.  New characters can be added \nto the repertoire of the system by graphical input on\na display scope.  Text inputting is accomplished \nvia a display scope or a Rand Tablet.  The organization\nand operation of the current system are described, \nand a discussion of the relative merits of such a system\nis given.  Illustrations of the computer input \nand output of Chinese characters are included.  \n Chinese characters, input/output, orthography, Rand\nTablet, PDP-1, automatic typesetting, man-machine \ncommunication, computer graphics, graphical input, on-line editing\n", "1698": "A Statistical Model for Console Behavior in Multiuser Computers The ability of a computer system to communicate\nwith the outside world efficiently is as important \nas its ability to perform computations efficiently. \nIt is quite difficult to characterize a particular \nuser, but rather easy to characterize the entire user community.\n Based on the properties of this community \nwe have postulated a hypothetical \"virtual console.\"\n No claim is made that a virtual console behaves \nlike any actual console, but the entire collection of\nvirtual consoles models the collection of actual \nconsoles.  Using the model we answer questions like: \nHow many processes are suspended waiting for console \ninput?  What is the maximum rate at which a process can\nexecute?  What bounds can be set on overall buffer \nrequirements?  Answers to these and similar questions\nare needed in certain aspects of operating system \ndesign.\n statistical models for input-output, operating\nsystem design, input-output design\n", "1699": "Experimental Evaluation of Information Experiments designed to evaluate the capabilities\nof mechanized information retrieval systems, \nwith emphasis on interactive (man-machine) language and on\nsome of the mechanical and psychological limitations \nin their design, were conducted at the Moore School information\nSystems Laboratory.  The basic assumption \nof the research is that an information retrieval system\nthat provides for man-machine dialogue at a remote \ninquiry terminal should provide a searcher with many\nof the tools which would be available to him were \nhe actually performing his search at a library or repository\nof documents.  Factors involved in evaluation \nof such a system include ease of use, learning time, and\neffectiveness of actual retrieval.  Three experiments \nand the conclusions resulting from them are detailed.\n information retrieval testing,  information system\nevaluation, experimental document retrieval, \ndocument retrieval, document perusal, man-machine communication,\nremote console communication, teletypewriter \ncommunication, remote terminal communication, retrieval\ncommand language, symbolic command language, \ninteractive systems, user learning factors, on-line searching\n", "1700": "PEEKABIT, Computer Offspring of Punched The \"peekaboo\" idea from punched card information\nretrieval methods has been mated with the \nidea of superimposed punching to produce a programming\ntechnique which cuts computer run time in half \non a test search of 33,000 subject index entries.  A search\nprogram using the device has been operational \nsince late 1963.  As an item is entered in the store,\nan 18-byte mask is created from the item's meaningful \nwords using the inclusive OR operation.  If, at search\ntime, the logical product (using the AND operation) \nof this mask and a similarly constructed question mask\nis not equal to the question mask, then one or \nmore question words are not present in the store item.\n An equality is in conclusive; the words of the \nstore item must be unpacked and compared with question\nwords.  The present store is made up of over 600,000 \nsubject index entries estimated to average 60 characters\neach.  Longer texts, such as abstracts, could \nbe handled by multiple masks.\n peekaboo, superimposed coding, natural language\nsearching text searching, information compaction, \ncomputer search technique\n", "1701": "Synchronous Signaling Rates for Data", "1702": "Commentary on Mr. Mooers' Paper", "1703": "Accommodating Standards and Identification of Programming Languages The user public wants standardization and\nreliable identification of programming languages \nand related services.  One way of achieving these goals\nillustrated by the methods adopted for TRAC T-64 \ninteractive language, and its related family of languages.\n Oppressive rigidity usually associated with \nstandardization is avoided by a new accommodation technique\naccessible to the user to allow local variations \nwith the language.  Explicit standardization of the language\nis undertaken at the organizational source \nof the language.  Use of the organizational trademark\n(TRAC) on the published standards, and services \nrelying upon them, provides a reliable public identification.\n These methods can be usefully applied \nto other programming languages and computer services.\n standardization, programming languages, TRAC T-64\nlanguage, tranemark, public identification of \nprogramming languages, standards which accommodate\n", "1704": "Minimum Excess Cost Curve (ALgorithm 217 [H]) critical path scheduling, PERT, cost/time tradeoffs, network flows\n", "1705": "A Set of Basic Input-Output Procedures (Algorithm 335 [15]) By means of the primitives in symbol, outsymbol\nand length, as requested by this journal's \nAlgorithms Policy [Comm. ACM 10 (Nov. 67), 729] a basic\nset of input-output procedures is defined aiming \nat quality and flexibility.  Outreal, for instance, is\nwritten as a derived procedure; it outputs using \nthe fixed point or the floating point representation,\nand rounds properly.  Variants can easily be written \nbecause of the explicit call of the procedures decompose\ninteger and decompose real.  The highly recommended \npractice of echoing input is made easy with one subset\nof derived procedures (ioi, ior, iob, ioa).  The \ndocumentation of output in the form of equivalent ALGOL\nstatements is also provided when use is made \nof the subset oti, otr, otb, ota.  The Berkeley style\nof providing information on the form of output \nusing prior calls of procedures such as real format is\ndefined.  A use of the parameter outchannel to \nprovide information for simultaneous output to several\nchannels is suggested.  Interrelationship between \nthe declared procedures is furnished in tabular form.\n input output, transput, input output procedures,\ninput echo, quality output, decompose integer, \ndecompose real, style, Berkeley style, procedures relationship,\noutput documentation, equivalent ALGOL \nstatements, ALGOL, ALGOL 60, integer format, real format,out\ninteger, read real, input output Boolean, \ninput output array, fixed point representation, floating\npoint representation, output channel interpretation\n", "1706": "CHAMP-Character Manipulation Procedures A new programming language facility for symbol\nmanipulation is described.  String procedures \nmay be declared and called in a standard ALGOL context.\n ALGOL procedures can in turn be called by string \nprocedures so that numeric and symbolic processes may\nconveniently be programmed together.  Concatenation \nand a variant of SNOBOL's pattern matching make up\na set of primitive commands.  These are assembled \ntogether into conditional expressions which are to be\nused to provide alternative computational patterns. \n Arrays of strings are processed using quantifiers.\n The class of things which may be assigned to an \nidentifier can be restricted by a procedure expressed\nin the notation.  The language facilities have \nbeen implemented in the ALGOL compiler for the Burroughs B5500.\n symbol manipulation, string handling, character\nmanipulation, conditional expressions, procedures, \nstructure matching, recursive programming, quantifiers\n", "1707": "Generation of Positive Test Matrices with Known Positive Spectra Sufficient conditions are given for a real\nmatrix to be similar to a positive matrix.  This \nresult is used to construct a similarity transformation\nwhich, when applied to a particular upper triangular \nmatrix, yields a positive matrix with a preassigned positive spectrum.\n test matrices, positive matrices, similarity\ntransformation, positive eigenvalues\n", "1708": "A Note on the Efficiency of a LISP Computation in a Paged Machine The problem of the use of two levels of storage\nfor programs is explored in the context of \na LISP system which uses core memory as a buffer for\na large virtual memory stored on a drum.  Details \nof timing are given for one particular problem.\n storage management, list processor implementation,\nLISP, paging, secondary storage utilization, \nefficiency of paged computation\n", "1709": "A Modification of Efroymson's Technique for Stepwise Regression Analysis The computational technique conventionally used\nfor stepwise multiple linear regression requires \nthe storage of an n X n matrix of data.  When the number\nof variables, n, is large, this requirement \ntaxes the storage capacity of presently used machinery.\n The near symmetry of the matrices involved permits \na modification requiring only half the storage and computations\nof the conventional algorithm and this \nadditional storage allows the analysis of problems containing\nmore variables.  Alternatively, it permits \nthe analysis of problems containing the same number\nof variables but with all computations performed \nin double precision.\n multiple linear regression, statistical recurrence\nformulas, correlation, linear statistical models, \nstatistical computer programs, curve fitting\n", "1710": "ASP-A Ring Implemented Associative Structure Package ASP is a general purpose Associative Data\nStructure Package in which an arbitrary number of \ndata items and an arbitrary number of the relationships\nbetween these data items may be represented. \n A special picture language is described which has proved\nvery useful for drawing ASP structures on paper. \n ASP structures are built and manipulated by means\nof a series of macro calls, which are outlined in \nthe Appendix.  Emphasis is on the philosophy of the system\nrather than a particular implementation, though \nsufficient information is included to enable the\nreader to produce his own implementation of ASP.\n associative, data structure, ring structure lists,\nlist structure, set languages, modeling, graphics\n", "1711": "When Your Computer Needs a Lawyer Possible liability for negligence, for other\ntorts (such as slander of credit) and for liability \nunder theories of express or implied warranty (guarantees)\nare discussed, and legal complications are \nexplained, so that users, operators, owners, and leasors\nof computers may be alerted to potential legal \nproblems. Focus is also on trouble spots in contracting\nfor data processing services, in automating record \nkeeping operations, in deciding whether or not to automate\ncertain operations, and in complying with \nstatutes and regulation relating to record keeping.\n Information is given on patents, copyrights and \ntrade secret protection for programs, and the problem\nof using copyrighted material in information storage \nand retrieval systems, including the pending\ncopyright and patent revision bills.\n law, legal, lawyer, liability, torts, negligence,\ncontracts, warrantees, guarantees, accounting, \nregulations, simulation, income tax, copyrights, patents,\ntrade secrets, standard of care, slander of \ncredit, crime, criminals, record keeping records, evidence, copying\n", "1712": "Recovery of Disk Contents After System Failure A method is discussed by which, after a system\nmalfunction, the contents of disk files can \nbe restored to their status at the time of the failure.\n data acquisitition, disk file organization,\nerror recovery, file organization\n", "1713": "On Overcoming High-Priority Paralysis High-priority paralysis is the degradation\nthat can occur in multiprogramming systems when \nscheduling is based primarily on preassigned priorities.\n It can be alleviated by modifying the scheduling \nalgorithm to maximize the number of programs active\nat one time.  The case his tory given in this paper \nindicates two general methods by which simultaneity can\nbe increased.  Possible refinements in the scheduling \nalgorithm for future improvements are considered briefly.\n multiprogram scheduling, dynamic priority assignment scheduling\n", "1714": "Procedure for the Normal Distribution (Algorithm 272 [S15]) normal distribution function, error function,\nnormal function, normal curve integral\n", "1715": "Direct Search (Algorithm 178 [E4])  function minimization, search, direct search\n", "1716": "Normal Random Deviates (Algorithm 334 [G5]) normal deviates, normal distribution, random number,\nrandom number generator, simulation, probability \ndistribution, frequency distribution, random\n", "1717": "Generating Prime Implicants Via Ternary Encoding and Decimal Arithmetic Decimal arithmetic, ternary encoding of cubes,\nand topological considerations are used in an \nalgorithm to obtain the extremals and prime implicants\nof Boolean functions. The algorithm, which has \nbeen programmed in the FORTRAN language, generally requires\nless memory than other minimization procedures, \nand treats DON'T CARE terms in an efficient manner.\n prime implicants, extremal, switching function,\nminimization, cubical complexes, ternary encoding\n", "1718": "\"Logical\" Arithmetic on Computers Algorithms are presented for multiplication\nand division of unsigned integer operands in which \nthe digits normally reserved for signs participate as\nsignificant arithmetic digits with positive weight.\n binary arithmetic, unsigned operand arithmetic,\nmaximum significance arithmetic, full-precision \narithmetic\n", "1719": "A Methodology for Calculating and The continually increasing size, complexity,\nnumber of types, and cost of data processing systems \nare causing serious re-examination within government\nand industry of the criteria for and methods of \ncalculating and optimizing data processing system cost\nand performance.  Real-time data processing systems \nas typified by the automated airline reservation system\nare discussed in this paper.  Criteria for evaluating \nperformance are described; a methodology for calculating\nand optimizing is outlined; and the method is \nillustrated by carrying out a portion of the performance\ncalculation and the optimization of a drum-oriented \nmessage switching system.\n real-time system analysis, real-time system design,\nreal-time system performance criteria, real-time \nsystem cost performance ratio\n", "1720": "Master's Level Computer Science Curricula The results of a survey of the course work done\nby master's degree candidates at 25 US universities \nare presented, and some general comments concerning\nthe emphasis of these programs are given.  \n surveys, education, computer science curricula\n", "1721": "Determination of the Intersection Points of Two A new method is proposed to calculate the intersection\npoints of two plane curves.  The theory \nof singular points off a system of two differential equations\nis used in developing the method. The intersection \npoint to be determined is identified with such a singular\npoint and appropriate modifications are applied \nto the system to ensure that the singular point be stable,\ni.e. all integrals which start in the neighborhood \nof the singular point will always approach this point\nif the integral parameter tends to infinity.  In \naddition a method is described for systematically searching\nfor all intersection points in a prescribed \nrectangular area.\n plane curves, intersection points, intersections\nplane curves, integration, differential equations, \nmatrix iteration, singular points, nonlinear differential\nequations, eigenvalues, complex roots, roots, \nstationary points, Runge Kutta, stable singularity, unstable singularity\n", "1722": "Methods of Convergence Improvement for Some Improper Integrals In the numerical integration of an improper\nintegral of the first kind, it is customary to \ntruncate the integral when the change yielded by the last\niteration is less than some predetermined constant. \nThe efficiency of such integration schemes can often\nbe improved by use of recent advances in the theory \nof nonlinear transformations; however, for several important\nintegrals, e.g. integrals whose integrands \nare rational polynomials, these transformations fail\nto yield much improvement.  In this paper, several \nmethods of convergence improvement are developed which greatly\nimprove convergence of some improper integrals, \nincluding the integrals of rational polynomials.\n approximation, nonlinear, improper integral, convergence\nimprovement, numerical integration, rational \npolynomials, truncation\n", "1723": "Computer Construction of Project Networks Project networks are used in PERT and CPM.\n An algorithm is given for constructing project \nnetworks directly from the project precedence relations.\n The algorithm creates \"dummy\" activities and \ntopologically orders the arcs and nodes.  The number of\nnodes created is minimal for the given precedence \nrelations.  It has been experimentally programmed\nin FORTRAN II for the IBM 7094.\n project networks, PERT, CPM, topological\nordering, network construction by computer\n", "1724": "A Generalized Partial Pass Block Sort The design of a partial pass block sort with\narbitrary range of key and number of work files \nis described. The design is a generalization of the Partial\nPass Column Sort by Ashenhurst and the Amphisbaenic \nSort by Nagler. The power of the sort is tabulated for\nvarious sizes of input file and number of work \nfiles. consideration is given to the problem of combining\na block sort with internal sorts, and to the \nbest use of direct access storage devices.\n block sort, partial pass sort, direct access devices,\ncolumn sort, chaining, reverse chaining, \nsort, amphisbaenic\n", "1725": "A Simple Proof of Lewin's Ordered-Retrieval An efficient method of ordered retrieval of binary\nwords from an associative memory, as described\nby Lewin, is based on the use of special readout circuits\nwhich indicate the digit values present in \nthe individual digit columns of the memory.  Thus the\ncircuits indicate whether the individual digit \ncolumns contain digits of both values, or of only one\nvalue, or contain no digits at all (i.e. that the \nmemory is empty).  The use of these circuits, which\nin this paper are termed column value indicators, \nreduces considerably the number of memory accesses necessary\nto retrieve in order a number of distinct \nwords from the memory.  Lewin proves that, for the readout\nby the described method of m distinct binary \nwords, 2m - 1 memory accesses are necessary.  (Thus he\nproves that the number of necessary memory accesses \nof his method, unlike those of other methods, is independent\nof the word length.)  In this paper a very \nsimple proof of this theorem derived from some elementary\naspects of the structure of sets of binary \nnumbers is presented.\n associative memories, content-addressed memories,\nordered lists, ordered information retrieval, \nordered retrieval theorem, column digit values, digit\nvalue variety, column sensing arrangement, digit \nvalue readout, digit variety readout, memory access, memory\naccess frequency, ordered retrieval efficiency, \naccess frequency proof, retrieval theorem proof\n", "1726": "Preliminary Investigation of Techniques Methods for converting unstructured printed\nmaterial into computer code are experimentally \ninvestigated.  An operator-controlled mode, depending\non human demarcation of the various regions of \nthe page for guiding the scanner, is implemented by\nmeans of a joystick and a CRT display.  This mode, \nfor which some performance figures are obtained, is thought\nto be suitable for processing very complicated \nmaterial, such as technical journals.  For simpler material,\nfor instance the \"claims\" sections of patents, \nand in applications where the utmost accuracy is not necessary,\nan unsupervised mode is advocated.  Here, \nthe textual portions of the page are located during\na rapid prescan by a rudimentary form of frequency \nanalysis.  These areas are then rescanned at a higher\nresolution suitable for character recognition. \n Error rates of the order of 0.1 percent are obtained in\na simple problem involving photographs of telephone \ncompany meter boards.  Other matters related to the\ndesign of a general purpose page reader, such as \nthe segmentation of printed text, the possibility of\ntime-sharing the scanner, interactive man-machine \noperation, and the facsimile reproduction of illustrations, are discussed.\n pattern recognition, character recognition, text\nreading, information retrieval, unformatted text \noperator-controlled reader, online reader,\ntext-image discrimination, reading machine\n", "1727": "One Way of Estimating Frequencies of Jumps in a Program For the segmentation of a program it is useful\nto have a reasonable estimation of the values \nof S(ij), where S(ij) is the mean value of the number\nof jumps from the i-th instruction on to the j-th \ninstruction in the run time.  In the cases where the\nS(ij) are estimated directly, the structure of the \nwhole program must be generally taken into account;\ntherefore it is very difficult for the programmer \nand/or the translator to obtain a good estimation of\nthe S(ij).  It is easier to estimate not S(ij) but \nthe quantities P(ij)=S(ij)*C(i)/SUM[S(ij), j=1,N], where\nC(i) is an arbitrary positive constant for each \ni.  Although the P(ij) are, for each i, proportional to\nS(ij), the estimation of P(ij) is easier, because \nwe must estimate only the \"probabilities\" of events\nwhere instruction i is executed after instruction \nI(i).  This estimation can often be done without considering\nthe structure of the whole program.  In \nthe first part of the paper, using the theory of the\nMarkov chains, an algorithm for the computation \nof the S(ij) from the P(ij) is found, and some ways\nof obtaining estimates of the P(ij) are given.  In \nthe second part a variant of this algorithm is derived,\navoiding the necessity of computation involving \nlarge matrices.\n object program reduction, supervisor calls decreasing,\njump frequencies estimation, control transfers \nestimation, optimal program segmentation, Markov chain\nprogram correspondence, program graph, one-entry \nsubgraph, locally estimated jump frequencies, supervisor\noverhead decreasing, program segmentation algorithm, \njump frequencies, program segmentation problem\n", "1728": "Further Experimental Data on the Behavior Results are summarized from an empirical study\ndirected at the measurement of program operating \nbehavior in those multiprogramming systems in which\nprograms are organized into fixed length pages.  \nThe data collected from the interpretive execution of\na number of paged programs are used to describe \nthe frequency of page faults, i.e. the frequency of those\ninstants at which an executing program requires \na page of data or instructions not in main (core) memory.\n These data are used also for the evaluation \nof page replacement algorithms and for assessing the\neffects on performance of changes in the amount \nof storage allocated to executing programs.\n paging systems, paging, dynamic program behavior, program\nbehavior, virtual memory systems, single-level \nstorage, one-level storage, operating system simulation,\noperating systems, supervisor simulation, machine \nlanguage program interpretation\n", "1729": "Minit Algorithm for Linear Programming (Algorithm 333 [H]) linear programming, dual simplex method, primal problem, dual problem\n", "1730": "Jacobi Polynomials (Algorithm 332 [S22]) Jacobi polynomials, orthogonal polynomials,\nthree-term recurrences, special functions\n", "1731": "Gaussian Quadrature Formulas (Algorithm 331 [D1]) quadrature, Gaussian quadrature, numerical integration,\nweight function, orthogonal polynomials\n", "1732": "Factorial Analysis of Variance (Algorithm 330 [G1]) factorial variance analysis, variance, statistical analysis\n", "1733": "Distribution of Indistinguishable Objects object distributions, combinations, distribution numbers\n", "1734": "Chebyshev Solution to an Overdetermined Chebyshev solutions, overdetermined linear\nsystems, linear equations, exchange algorithm\n", "1735": "A Futures Market in Computer time An auction method is described for allocating\ncomputer time that allows the price of computer \ntime to fluctuate with the demand and the relative priority\nof users to be controlled so that more important \nprojects get better access.  This auction is free of the\nperiodic fluctuation in computer use often associated \nwith monthly time allocation schemes.\n computer scheduling, auction, time allocation, operating efficiency\n", "1736": "Heading Format for Data Transmission (A USAAI Tutorial -- Standards) data transmission heading format, heading format,\nmessage format, data transmission, message headings\n", "1737": "A Global Parser for Context-Free Phrase Structure Grammars", "1738": "Writing an Outline Debugging Program for the Experienced User Presently available online debugging routines\nare often unsatisfactory for the experienced \nuser because they require unnecessarily rigid and complicated\ntyping formats, make it difficult for the \nuser to correct typing errors, and consume excessive\nmemory with intricate features.  In a debugging \nprogram it is of prime importance that the program\nbe simple, flexible, and highly efficient to use. \n Communication between the user and the debugging program\ncan be improved by using certain techniques \napplicable to most online debugging programs.  These\ntechniques are presented and are illustrated by \ntheir use in OPAK (octal package), a debugging program coded\nfor the PDP-5/8 and the SDS-930.  The compromise \nbetween economy of utility program core storage and incorporation\nof elegant debugging features is discussed.\n debugging, utility program, programming languages\n", "1739": "Regular Expression Search Algorithm A method for locating specific character strings\nembedded in character text is described and \nan implementation of this method in the form of a compiler\nis discussed.  The compiler accepts a regular \nexpression as source language and produces an IBM 7094\nprogram as object language.  The object program \nthen accepts the text to be searched as input and produces\na signal every time an embedded string in \nthe text matches the given regular expression.  Examples,\nproblems, and solution are also presented.\n search, match, regular expression\n", "1740": "An Inexpensive Braille Terminal Device The active use of time-shared facilities for\nblind programmers requires a braille terminal \nsystem.  Details are given for the construction of a\nbrailler from a model 33 teletype by modifying the \nprint head and increasing the resiliency of the platen.\n A description of the programming needed to drive \nthe brailler is presented.\n blind communication, blind programming aid, braille,\nbraille computer communication, braille output, \nbraille teletype, braille terminal, braille type head,\nembosser, tactile computer communication, tactile \nteletype, tactile terminal\n", "1741": "BRAD: The Brookhaven Raster Display A multiconsole computer display system has\nbeen designed that provides very rich displays at \nlow unit cost.  Each BRAD (Brookhaven Raster Display)\nconsole can plot tens of thousands of points, or \nup to 4000 characters at 30 frames per second.  After\nan initial display system investment of $50,000 \neach display, with teletype, costs less than $3,000.\n The technique employed is that of programmatically \ngenerating a binary image of the desired display in a\ncomputer.  The image is written on a rotating drum \nmemory.  Independent read heads continuously display\nthe picture, which is generated by swept horizontal \nlines.  A standard TV monitor serves as the display device.\n The technique has two drawbacks.  A computer \nmust compute any image to be displayed.  Also, the \"pointing\"\ninteraction is more difficult.  This is \nbecause the pointing function gives only the coordinates\nof the point on the screen.  The inverse of \nthe map generation process is required to calculate\nthe coordinates of the point on the screen.  The \ninverse of the map generation process is required to\ncalculate the coordinates at the selected point \nin the input space.\n computer display, computer graphics, computer raster\ndisplay, TV display console, digital TV display, \nswept raster computer display, swept raster TV computer\ndisplay, TV graphics terminal, multiconsole computer \ngraphics, inexpensive graphic terminal\n", "1742": "On the Design of Display Processors The flexibility and power needed in the data\nchannel for a computer display are considered. \n To work efficiently, such a channel must have a sufficient number\nof instructions that it is best understood \nas a small processor rather than a powerful channel.\n As it was found that successive improvements to \nthe display processor design lie on a circular path, by\nmaking improvements one can return to the original \nsimple design plus one new general purpose computer for\neach trip around.  The degree of physical separation \nbetween display and parent computer is a key factor in display processor design.\n display processor design, display system, computer\ngraphics, graphic terminal, displays, graphics, \ndisplay generator, display channel, display programming,\ngraphical interaction, remote displays\n", "1743": "Reliable Full-Duplex file Transmission over Half-Duplex Telephone Lines A field-proven scheme for achieving reliable\nduplex transmission over a half-duplex communication \nline is presented, and to demonstrate the difficulty\nof the problem, another similar scheme, which is \nonly slightly unreliable, is also presented.  A flowchart\nfor the reliable scheme and some interesting \nexamples are given.\n telephone communication, half duplex, transmission,\nerror correction, full duplex, telephone errors\n", "1744": "Stable Numerical Methods for Obtaining the Chebyshev An implementation of Stiefel's exchange algorithm\nfor determining a Chebyshev solution to an \noverdetermined system of linear equations is presented,\nthat uses Gaussian LU decomposition with row \ninterchanges.  The implementation is computationally more\nstable than those usually given in the literature. \n A generalization of Stiefel's algorithm is developed which\npermits the occasional exchange of two equations \nsimultaneously.\n Chebyshev solutions, overdetermined linear\nsystems, linear equations,exchange algorithm\n", "1745": "A Position Paper on Computing and Communications The effective operation of free enterprise in\ncreating the envisioned information service industry \nis dependent upon three accomplishments: (1) the restructuring\nof our information processing industry \nso that a clear division of costs is made among computing,\ncommunications, and the development of information \nservices; (2) the wide use of multiaccess system concepts\nso that information services may share in the \nuse of computer installations and so that the cost of their\nconstruction is reasonable; and (3) the development \nof public, message-switched communications services so\nthat adequate provisions are made for information \nsecurity.\n information networks, information systems, computing\nand free enterprise, computing economics, \ncomputer installation management, government regulation,\ncommunications services, distributed data base, \nprogram leasing\n", "1746": "Protection in an Information Processing Utility One of the critical problems in the design\nof an information processing utility that permits \nflexible sharing of user information is privacy.\n One solution for this problem is discussed.\n protection, privacy, information processing utility,\ntime-sharing, multi-user, multiprogramming, \nmultiprocessing, security, shared information, controlled\naccess, reliable operation, segmentation\n", "1747": "Three Criteria for Designing Computing Systems to Facilitate Debugging The designer of a computing system should adopt\nexplicit criteria for accepting or rejecting \nproposed system features.  Three possible criteria of this\nkind are input recordability, input specifiability, \nand asynchronous reproducibility of output.  These criteria\nimply that a user can, if he desires, either \nknow or control all the influences affecting the content\nand extent of his computer's output.  To define \nthe scope of the criteria, the notion of an abstract\nmachine of a programming language and the notion \nof a virtual computer are explained.  Examples of applications\nof the criteria concern the reading of \na time-of-day clock,  the synchronization of parallel\nprocesses, protection in multiprogrammed systems, \nand the assignment of capability indexes.\n computer design, computer design criteria, computer\nsystems, computer systems design, input equipment, \ninput equipment design, operating systems, operating\nsystems design, multiprogramming, multiprogrammed \nsystems, multiprogrammed system design, virtual computers,\nprogramming languages, programming language \ndesign, program semantics, programming language semantics,\ndeterminism, reproducibility, repeatability, \ndeterministic computers, protection, memory protection,\ninformation security, information privacy, computing \nreliability, debugging, program debugging, program testing,\nparallel processing, parallel programming, \nmultiprocessing\n", "1748": "A Scheduling Philosophy for Multiprocessing Systems A collection of basic ideas is presented, which\nhave been evolved by various workers over the \npast four years to provide a suitable framework for the\ndesign and analysis of multiprocessing systems. \n The notions of process and state vector are discussed,\nand the nature of basic operations on processes \nis considered.  Some of the connections between processes\nand protection are analyzed.  A very general \napproach to priority-oriented scheduling is described,\nand its relationship to conventional interrupt \nsystems is explained.  Some aspects of time-oriented\nscheduling are considered. The implementation of \nthe scheduling mechanism is analyzed in detail and the\nfeasibility of embodying it in hardware established. \n Finally, several methods for interlocking the execution\nof independent processes are presented and compared.\n time-sharing, multiprocessing, process, scheduling,\ninterlocks, protection, priority, interrupt \nsystems\n", "1749": "The Structure of the \"THE\"-Multiprogramming System A multiprogramming system is described in\nwhich all activities are divided over a number of \nsequential processes.  These sequential processes are placed\nat various hierarchical levels, in each \nof which one or more independent abstractions have been\nimplemented.  The hierarchical structure proved \nto be vital for the verification of the logical soundness\nof the design and the correctness of its implementation.\n operating system, multiprogramming system, system\nhierarchy, system structure, real-time debugging, \nprogram verification, synchronizing primitives, cooperating\nsequential processes, system levels, input-output \nbuffering, multiprogramming, processor sharing, multiprocessing\n", "1750": "Considerations in the Design of a Multiple The use of large quantities of addressable\n(but not executable) fast random access memory to \nheighten the multiprogramming performance of a multicomputer system\nis discussed.  The general design \nof the hardware arrangement and the software components\nand functions of such a system are based on a \nplanned configuration of dual CDC 6600's that share one\nmillion words of extended core storage.  In the \ngeneralization of such a design, special emphasis is\nplaced on estimating expected gains when compared \nwith the traditional configuration of separate and independent\ncomputers without extended core storage. \n An observation is made on the use of conventional, slower\nspeed, random access storage devices in place \nof the faster memory.\n multiple computer systems, extended core storage,\nmultiprogrammed operating systems, multiprocessor \noperating systems, control data corporation 6600, operating system with ECS\n", "1751": "The Working Set Model for Program Behavior Probably the most basic reason behind the absence\nof a general treatment of resource allocation \nin modern computer systems is an adequate model for\nprogram behavior.  In this paper a new model, the \n\"working set model,\" is developed. The working set\nof pages associated with a process, defined to be \nthe collection of its most recently used pages, provides\nknowledge vital to the dynamic management of \npaged memories.  \"Process\" and \"working set\" are shown to\nbe manifestations of the same ongoing computational \nactivity; then \"processor demand\" and \"memory demand\"\nare defined; and resource allocation is formulated \nas the problem of balancing demands against available equipment.\n general operating system concepts, multiprocessing,\nmultiprogramming, operating systems, program \nbehavior, program models, resource allocation, scheduling, storage allocation\n", "1752": "Resource Management for a Medium Scale Time-Sharing Operating system Task scheduling and resource balancing for\na medium size virtual memory paging machine are \ndiscussed in relation to a combined batch processing\nand time-sharing environment.  A synopsis is given \nof the task scheduling and paging algorithms that were implemented,\nand the results of comparative simulation \nare given by tracing the development of the algorithms\nthrough six predecessor versions.  Throughout \nthe discussion particular emphasis is placed on balancing\nthe system performance relative to the characteristics \nof all the system resources.  Simulation results relative\nto alternate hardware characteristics and the \neffects of program mix and loading variations are also presented.\n time-sharing, operating systems, resource management,\ntask scheduling, paging, system simulation, \nmemory management, virtual memories\n", "1753": "Virtual Memory, Processes, and Sharing in MULTICS Some basic concepts involved in the design\nof the MULTICS operating system are introduced. \n MULTICS concepts of processes, address space, and virtual\nmemory are defined and the use of paging and \nsegmentation is explained.  The means by which users\nmay share procedures and data is discussed and the \nmechanism by which symbolic references are dynamically\ntransformed into virtual machine addresses is \ndescribed in detail.\n virtual memory, information sharing, shared procedures,\ndata sharing, dynamic linking, segmentation, \npaging, multiprogramming, storage management,\nstorage hierarchies, file maintenance\n", "1754": "Dynamic Storage Allocation Systems In many recent computer system designs, hardware\nfacilities have been provided for easing the \nproblems of storage allocation.  A method of characterizing\ndynamic storage allocation systems-according \nto the functional capabilities provided and the underlying\ntechniques used-is presented.  The basic purpose \nof the paper is to provide a useful perspective from\nwhich the utility of various hardware facilities \nmay be assessed.  A brief survey of storage allocation\nfacilities in several representative computer \nsystems is included as an appendix.\n segmentation, paging, multiprogramming, storage\nallocation, storage management, virtual memories, \nstorage fragmentation, storage hierarchies, addressing mechanisms\n", "1755": "Proceedings of the ACM Symposium on Operating system Principles", "1756": "Hollerith Punched Card Code* (Proposed USA Standard) USA Standard, card code, punched card, punched card\ncode, hole-patterns, hole-patterns assignment, \npunched card systems\n", "1757": "Data Code for Calendar Date for Machine-to-Machine USA Standard, data code, calendar date, machine-to-machine\ndata interchange, recording calendar \ndate, data group identifier\n", "1758": "Symmetric Polynomials, (Algorithm 305 [C1]) symmetric polynomials, symmetric sum, unitary\nsymmetric functions, Schur functions\n", "1759": "Transportation Problem (Algorithm 293 [H]) transportation problem, linear programming\n", "1760": "Normal Curve Integral (Algorithm 304 [S15]) normal curve integral, probability, special functions\n", "1761": "Chi-Squared Integral (Algorithm 299 [S15]) chi-squared integral, probability, special functions\n", "1762": "Dilogarithm (Algorithm 327 [S22]) dilogarithm function, special functions\n", "1763": "Roots of Low-Order Polynomial Equations (Algorithm 326 [C2]) root finders, polynomial equation roots, quadratic\nequation roots, cubic equation roots, biquadratic \nequation roots, polynomial zeros\n", "1764": "Panel Discussion on Computer Appreciation Session 19 of the ACM 20 th Anniversary Conference\non August 31, 1967, was entitled Education, \nDesign Experiments, and Computer Appreciation.  Its second\nhalf consisted of a panel discussion on computer \nappreciation, organized and chaired by Elliot I. Organick.\n The four panelists were Charles H. Davidson, \nBernard A. Galler, Richard, W. Hamming, and Alan J. Perlis.\n After making prepared statements, the panelists \nwere joined in discussion by Andries van Dam and Arthur\nB.Kohn, who had presented papers in the first \nhalf.  This is a transcript of the panel discussion,\ncondensed by Dr. Organick and edited by him and \nthe panelists.  Some remarks referred to papers by van\nDam and Kahn or to the discussion during the first \nhalf of the session.  Pertinent papers are included in the references.\n computer appreciation, students' liberal arts courses,\nsurvey courses, beginning programming, course \ncontent, computer courses dropout rates, college versus\nprecollege, teaching and social responsibility\n", "1765": "Expenditures, Sources of Funds, and Utilization The Southern Regional Education Board published\na complete report on a survey it conducted \nto determine the funding and characterize the utilization\nof computers used for research and instruction \nin institutions of higher education in the United States.\nThe sampling survey is described and the estimates \nfor this total population are presented.\n computing centers, research, instruction, utilization,\nexpenditures, support, sources of funds, \nhigher education, post secondary education, colleges, universities\n", "1766": "Quasilinearization and the Estimation Given a linear ordinary differential operator\ncontaining several unknown constants and a number \nof its eigenvalues, the values of the unknown constants\nare estimated.  A precise formulation is provided, \nand an effective numerical procedure for solution is indicated.\n  The results of some computational experiments \nare given.\n quasilinearization, eigenvalues, differential operators,\nnonlinear boundary-value problems, inverse \nproblems,differential equations, system identification\n", "1767": "A General Purpose Graphic Language Interactive use of computers with graphic terminals\nwill permit many new problems to be solved \nusing machines.  In order to handle a variety of applications,\nit is expedient to develop a general purpose \ngraphic language that is useful on a number of graphic\ndevices.  A system has been designed to produce \nsuch a language quickly and cheaply.  A model graphic\nlanguage which has been developed with the system \nis presented.\n graphic language, interactive, incremental compilation,\nlanguage design, metacompiler, syntax specified \nlanguage\n", "1768": "A Global Parser for Context-Free Phrase Structure Grammars An algorithm for analyzing any context-free phrase\nstructure grammar and for generating a program \nwhich can then parse any sentence in the language (or\nindicate that the given sentence is invalid) is \ndescribed. The parser is of the \"top-to-bottom\" type\nand is recursive . A number of heuristic procedures \nwhose purpose is to shorten the basic algorithm by quickly\nascertaining that certain substrings of the \ninput sentence cannot correspond to the target nonterminal\nsymbols are included.  Both the generating \nalgorithm and the parser have been implemented in RCA\nSNOBOL and have been tested successfully on a number \nof artificial grammars and on a subset of ALGOL.  A\nnumber of the routines for extracting data about \na grammar, such as minimum lengths of N-derivable strings\nand possible prefixes, are given and may be \nof interest apart from their application in this particular context.\n parser, syntax-directed compiler, context-free\ngrammars, syntactic analysis, translators\n", "1769": "The Expanding World of Computers The onward sweep of automatic processing of\ninformation is impeded by nine principal barriers: \ngeography, cost, problem complexity, man-machine communication,\ninadequate sensors, lack of understanding, \ndistance, time, and size.  The main incentive for breaching\nthese barriers is the universal need for \nprocessing information, ever more urgent as the greater\npart of human work activity changes from production \nto service.  Computer developments in hardware, programming,\ntime-sharing, education, data communication, \nand displays are judged by how effectively they remove these\nbarriers, and their barrier-smashing potentialities \nindicate continued rapid expansion.  Problem-oriented\nlanguages are particularly effective over the entire \nfront.  Online computers and time-sharing also rate high\nby this measure.  Education and increased understanding \nare basic to all progress with the computer.  This complex\nbut powerful tool is the most important one \navailable to governments and scientists to use in studying\nthe problems being created by the population \nexplosion, and in analyzing possible solutions.\n barriers, philosophy, developments, computer-aided design,\nproblem-oriented languages, data communication, \neducation, computer science, forecast, survey, introduction\n", "1770": "Rules of Ethics in Information Processing The background and motivation for the adoption\nby the ACM Council on November 11, 1966, of \na set of Guidelines for Professional Conduct in Information\nProcessing are described.  A brief his tory \nis given of ethical codes in other professions.  Some\nreasons for and against adoption of ethical rules \nare considered, and several sections of the ACM Guidelines\nare analyzed.  The purpose is to inform about \nthis important aspect of our profession, as\nwell as to stimulate thought and interest.\n ethics, professional conduct, code of ethics, ACM\nguidelines, professionalism, professional societies, \nunethical conduct\n", "1771": "CURRICULUM 68 -- Recommendations for Academic This report contains recommendations on academic\nprograms in computer science which were developed \nby the ACM Curriculum Committee on Computer Science.\n A classification of the subject areas contained \nin computer science is presented and twenty-two courses\nin these areas are described.  Prerequisites, \ncatalog descriptions, detailed outlines, and annotated\nbibliographies for these courses are included. \n Specific recommendations which have evolved from the\nCommittee's 1965 Preliminary Recommendations are \ngiven for undergraduate programs.  Graduate programs in computer\nscience are discussed and some recommendations \nare presented for the development of master's degree programs.\n Ways of developing guidelines for doctoral \nprograms are discussed, but no specific recommendations\nare made. The importance of service courses, \nminors, and continuing education in computer science is\nemphasized.  Attention is given to the organization, \nstaff requirements, computer resources, and other facilities\nneeded to implement computer science educational \nprograms.\n computer science courses, computer science curriculum,\ncomputer science education, computer science \nacademic programs, computer science graduate programs,\ncomputer science undergraduate programs, computer \nscience course bibliographies\n", "1772": "USASCSOCR Dual Case Keyboard Arrangement* (Proposed USA Standard)", "1773": "General Purpose Alphanumeric Keyboard Arrangement", "1774": "Program Overlay Techniques The general features of program overlay systems\nare described.  Three main types -- automatic, \nsemiautomatic and nonautomatic -- are classified, and the\nprogramming techniques are explained as a function \nof machine hardware and other system features.  The\nimplementation of semiautomatic overlay facility \nin a multiprogrammed system on the CDC 6600 is described\nin detail, with special reference to real time \napplications.\n loaders, multiprogramming, overlay techniques,\nstorage allocation and segmentation\n", "1775": "Adjustment of the Inverse of a Symmetric Matrix symmetric matrix, matrix inverse, matrix\nperturbation, matrix modification\n", "1776": "Maxflow (Algorithm 324 [H]) network,liner programming, maximum flow\n", "1777": "Generation of Permutations in Lexicographic Order (Algorithm 323 [G6]) permutations, lexicographic order, lexicographic\ngeneration, permutation generation\n", "1778": "F-Distribution (Algorithm 322 [S14]) Fisher's  F-distribution, Student's t-distribution\n", "1779": "t-Test Probabilities (Algorithm [S14]) T-test, Student's t-statistic, distribution function\n", "1780": "Harmonic Analysis for Symmetrically harmonic analysis, cosine series, sine series, function\napproximation, curve fitting, trigonometric \nseries\n", "1781": "Translator Writing systems A critical review of recent efforts to automate\nthe writing of translators of programming languages \nis presented.  The formal study of syntax and its application\nto translator writing are discussed in \nSection II.  Various approaches to automating the post syntactic\n(semantic) aspects of translator writing \nare discussed in Section III, and several related topics in Section IV.\n compiler, compiler-compiler, translator, translator\nwriting systems, metacompiler, syntax, semantics, \nsyntax-directed, meta-assembler, macroprocessor,\nparser, syntactic analysis, generator\n", "1782": "A Numerical Integration Formula Useful in Fourier Analysis A numerical integration formula is presented which\nuses unequal sampling intervals.  The intervals \nare equally spaced on a log scale.  Such a formulation\nis useful in Fourier analysis to improve accuracy \nand ease of usage.  A complete set of formulas\nfor numerical Fourier analysis is given.\n numerical integration, Fourier analysis, integration\n", "1783": "In-and-Out Conversions Byan in-and-out conversion we mean that a floating-point\nnumber in one base is converted into \na floating-point number in another base and then converted\nback to a floating-point number in the original \nbase.  For all combinations of rounding and truncation\nconversions the question is considered of how \nmany significant digits are needed in the intermediate\nbase to allow such in-and-out conversions to return \nthe original number (when possible), or at least significant digit.\n floating-point numbers, significance,\nbase conversion, rounding, truncation\n", "1784": "Practical Error Coefficients for Estimating All published error coefficients for estimating\nquadrature errors for analytic functions were \ncomputed on the assumption that the quadrature rule\nwas exact for polynomials up to a given degree.  \nSince these rules use rounded values for the abscissas and\nweights and since the true values of the integrals \nof some of the polynomials in question have an infinite\nbinary expression, the quadrature rule is not \nexact.  Hence these errors must be taken into consideration\nin computing practical error coefficients.\n numerical integration, quadrature, truncation\nerror, theoretical error coefficients, practical \nerror coefficients, integration analytical functions, roundoff error\n", "1785": "Scatter Storage Techniques Scatter storage techniques as a method for\nimplementing the symbol tables of assemblers and \ncompilers are reviewed and a number of ways of using\nthem more effectively are presented.  Many of the \nmost useful variants of the techniques are documented.\n scatter storage, hash addressing, searching,\nfile searching, file addressing, storage layout\n", "1786": "An Improved Hash Code for Scatter Storage Introduced is a hash coding method based on\nfixed-point division rather than multiplication \nor logical operations.  This new method allows the\nhash table to have almost any length.  Also a new \nmethod of handling collisions is discussed.  Known as\nquadratic search, this method is faster than random \nsearch and free from the \"clusters\" that build up with a linear search.\n hash code, hash table, scatter storage, searching \n", "1787": "Use of Transition Matrices in Compiling An algorithms is described which constructs\nfrom a suitable BNF grammar an efficient left-right \nrecognizer for sentences of the corresponding language.\n The type of recognizer, used in a number of \ncompilers, operates with a pushdown stack and with\na transition matrix.  Two examples illustrate how \nsuch recognizers may be used effectively for other\npurposes besides the usual syntax checking.\n transition matrices, compilation, translation,\ngrammar, context-free language, formal language, \nparsing\n", "1788": "Toward a General Processor for Programming Languages Many efforts have been made to develop a better\nway of implementing a higher level programming \nlanguage than by the construction of a whole new compiler,\nbut so far none has proved generally satisfactory. \n In this paper, it is contended that a programming\nlanguage is best described functionally as a body \nof macro instructions, and that the macro call constitutes\na canonical form in terms of which a programming \nnotation may be described.  A supporting discussion of the\nlogical and his torical role of the macro instruction \nis presented.  Also discussed are the conflict between\nmachine independence and object program efficiency, \nand the question of where the greatest difficulties\nlie in compiler construction.\n programming language translator, programming language\nprocessor, general translator, general processor, \nmacro instruction processor; meta processor, meta language\ntranslator, meta language processor, compiler-compiler, \nwriting system, translator writing system\n", "1789": "Logarithm of Gamma Function (Algorithm 291 [S14])", "1790": "Muller's Method for Finding roots of an equation roots, function zeros \n", "1791": "Triangular Factors of Modified Matrices (Algorithm 319 [F1]) matrix decomposition, matrix factors,\nmatrix modifier, matrix perturbation\n", "1792": "Exploratory Experimental Studies Comparing Two exploratory experiments were conducted at\nSystem Development Corporation to compare debugging \nperformance of programmers working under conditions\nof on-line and off line access to a computer.  These \nare the first known studies that measure programmers'\nperformance under controlled conditions for standard \ntasks.  Statistically significant results of both experiments\nindicated faster debugging under online \nconditions, but perhaps the most important practical finding\ninvolves the striking individual differences \nin programmer performance.  Methodological problems encountered\nin designing and conducting these experiments \nare described; limitations of the findings are pointed\nout; hypotheses are presented to account for results; \nand suggestions are made for further research.\n online vs. off line performance, programmer/computer\ncommunication, programming experimental-empirical \nstudies, programming cost effectiveness, programming\nperformance, debugging effectiveness, time sharing \nvs. batch processing, factor analysis application,\nprogrammer trainee performance, basic programming \nknowledge test, experienced programmer study, analysis\nof variance, programmer individual differences\n", "1793": "Presentation of Alphameric Characters for Information alphameric, handwritten input, encoding transcription,\nnumerals, upper case, hand printed\n", "1794": "A Fast Random Number Generator for IBM 360 pseudorandom number, modulus, period, float,\nnormalization, characteristic, chi-square test\n", "1795": "Optimal Code for Serial and Parallel Computation code optimization, sequencing of operations,\ndetection of common subexpressions\n", "1796": "Index by Subject to Algorithms, 1969 This 1969 index is the first supplement to the\nIndex by Subject to Algorithms, 1960 1968 (Comm. \nACM 11, 12 (Dec. 1968), 827 830).\n.N\nCA691216 JB February 15, 1978  2:03 PM\n.X\n1796\t5\t1796\n1796\t5\t1796\n1796\t5\t1796\n", "1797": "Solution of Linear programs in 0-1 (Algorithm 341 [H]) linear programming, zero-one variables, partial enumeration\n", "1798": "Coulomb Wave Functions (Algorithm 300 [S22]) Coulomb wave functions, wave functions,\nspecial functions, function evaluation\n", "1799": "Elementary Functions by Continued Fractions (Algorithm 229 [B1]) continued factions, Pade table\n", "1800": "PSIF (Algorithm 147 [S14]) gamma function, logarithmic derivative, factorial function, psi function\n", "1801": "Analysis of Variance for Balanced Experiments (Algorithm 367 [G2]) analysis of variance, analysis of covariance, regression\nanalysis, experimental design, balanced \nexperiment, missing data, interblock estimate, intra block estimate\n", "1802": "Regression Using Certain Direct Product Matrices (Algorithm 366 [G2]) analysis of variance, analysis of covariance,\nregression analysis, experimental design, matrix \ndirect product, protection operator, orthogonal matrix\n", "1803": "Complex Root Finding (Algorithm 365 [C5]) downhill method, complex relaxation method, complex\niteration, complex equation, transcendental \ncomplex equation, algebraic complex equation\n", "1804": "Coloring Polygonal Regions (Algorithm 364 [Z]) coloring polygonal regions, coloring planar surfaces,\ndrawing pictures, shading enclosed regions\n", "1805": "Productivity of Multiprogrammed Computers-Progress Multiprogramming as it is discussed here is\na mode of computer operation in which two or more\nprograms are concurrently in processor memory and proceeding,\neach using the same central processor unit \n(CPU) and input-output (I/O) channels.  These programs\nare actually proceeding intermittently and singly, \naccording to eligibility (readiness to proceed) and priority.\n It is useful to be able to represent them \nas proceeding continuously and simultaneously, each\nat an effective rate, which may be a fraction of \nthat which it would enjoy in the absence of the other\nprograms.  The effective progress rate of each \nprogram is sensitive to many detailed characteristics\nof itself and its co-residents and simulation has \nbeen the best available method of predicting it.  This\npaper presents the results of progress in developing \nan alternative to simulation, a simulation-tested iterative\ncomputation of these rates under certain \nsituations.  The algorithm is sensitive to most of the\nfactors that control the phenomenon, including \nnonquantitative or topological features of the programs' structures.\n productivity, prediction, multiprogramming, simulation,\nequipment  evaluation, hardware, evaluation, \nmonitor, operating system, system software, supervisors,\nperformance, time sharing, time slicing \n", "1806": "On the Downhill Method The downhill method is a numerical method for\nsolving complex equations f(z) = 0 on which the \nonly restriction is that the function w = f(z) must\nbe analytical.  An introduction to this method is \ngiven and a critical review of relating literature is\npresented.  Although in theory the method always \nconverges, it is shown that a fundamental dilemma exists\nwhich may cause a breakdown in practical applications. \n To avoid this difficulty and to improve the rate of\nconvergence toward a root, some modifications of \nthe original method are proposed and a program (FORTRAN)\nbased on the modified method is given in Algorithm \n365.  Some numerical examples are included.\n downhill method, complex relaxation method, complex\niteration, complex equation, transcendental \ncomplex equation, algebraic complex equation\n", "1807": "Optimization of Expressions in Fortran A method of optimizing the computation of\narithmetic and indexing expressions of a Fortran \nprogram is presented.  The method is based on a linear\nanalysis of the definition points of the variables \nand the branching and DO loop structure of the program.\n The objectives of the processing are (1) to \neliminate redundant calculations when references are\nmade to common subexpression values, (2) to remove \ninvariant calculations from DO loops, (3) to efficiently\ncompute subscripts containing DO iteration variables, \nand (4) to provide efficient index register usage.  The\nmethod presented requires at least a three-pass \ncompiler, the second of which is scanned backward.  It\nhas been used in the development of several FORTRAN \ncompilers that have proved to produce excellent object\ncode without significantly reducing the compilation \nspeed.\n FORTRAN, optimization, expressions, compilers,\ncompilation, subscripts, register allocation, DO \nloops, common subexpressions, invariant calculations\n", "1808": "Advanced Cryptographic Techniques for Computers Cryptographic techniques which can be used to\nmaintain the confidentiality of information processed \nby computers are dealt with.  Special emphasis is paid\nto the unique characteristics of computer files \nthat make many cryptographic methods of little use.\n Relative security, costs, and preferred methods \nare included in this paper.\n cryptographic, cryptanalysis, ciphers secrecy systems,\nsecurity systems, confidential information \nprocessing\n", "1809": "Numerical Analysis in a Ph.D. Computer Science Program Numerical Analysis is the study of methods and\nprocedures used to obtain \"approximate solutions\" \nto mathematical problems.  Much of the emphasis is on scientific\ncalculation.  The difficulties of education \nin such a broad area center around the question of background\nand emphasis.  The Numerical Analysis program \nin the Computer Science Department should emphasize an\nawareness of the problems of computer implementation \nand experimental procedures.  Nevertheless, there is a\nneed for a solid background in applied mathematics.\n Ph.D. program, numerical analysis, course separation, education\n", "1810": "Is Automatic \"Folding\" of Programs Efficient Enough To Displace Manual? The operation of \"folding\" a program into\nthe available memory is discussed.  Measurements \nby Brown et al. and by Nelson on an automatic folding\nmechanism of simple design, a demand paging unit \nbuilt at the IBM Research Center by Belady, Nelson,\nO'Neil, and others, permitting its quality to be \ncompared with that of manual folding, are discussed,\nand it is shown that given some care in use the \nunit performs satisfactorily under the conditions tested,\neven though it is operating across a memory-to-storage \ninterface with a very large speed difference.  The disadvantages\nof prefolding, which is required when \nthe folding is manual, are examined, and a number of\nthe important troubles which beset computing today \nare shown to arise from, or be aggravated by, this\nsource.  It is concluded that a folding mechanism \nwill probably become a normal part of most computing systems.\n paging, automatic paging, demand paging, folding,\nautomatic folding, storage hierarchies, memory \nhierarchies, replacement algorithms, performance, measurement\n", "1811": "A Case Study in Programming for Parallel-Processors An affirmative partial answer is provided to\nthe question of whether it is possible to program \nparallel-processor computing systems to efficiently decrease\nexecution time for useful problems.  Parallel-processor \nsystems are multiprocessor systems in which several of\nthe processors can simultaneously execute separate \ntasks of a single job, thus cooperating to decrease\nthe solution time of a computational problem. The \nprocessors have independent instruction counters, meaning\nthat each processor executes its own task program \nrelatively independently of the other processors.  Communication\nbetween cooperating processors is by \nmeans of data in storage shared by all processors.  A\nprogram for the determination of the distribution \nof current in an electrical network was written for a\nparallel-processor computing system, and execution \nof this program was simulated.  The data gathered from\nsimulation runs demonstrate the efficient solution \nof this problem, typical of a large class of important\nproblems.  It is shown that, with proper programming, \nsolution time when N processors are applied approaches\n1/N times the solution time for a single processor, \nwhile improper programming can actually lead to an increase\nof solution time with the number of processors. \n Stability of the method of solution was also investigated.\n parallel-processor, parallelism, parallel programming,\nmultiprocessor, multiprogramming, tasking, \nstorage interference, electrical network, simulation,\nrelaxation, Jacobi, Gauss-Seidel, convergence\n", "1812": "More on Fortran Random Number Generators random number generation, Monte Carlo, simulation\n", "1813": "Generation of Permutations in Pseudo-Lexicographic permutations, lexicographic order, lexicographic\ngeneration, permutation generation\n", "1814": "Direct Search (Algorithm 178 [E4]) function minimization, search, direct search\n", "1815": "Direct Search (Algorithm 178 [E4]) function minimization, search direct search\n", "1816": "Generalized Least Squares Fit By Orthogonal least squares, curve fitting, orthogonal polynomials,\nthree-term recurrence, polynomial regression, \napproximation, Forsythe's method\n", "1817": "Computation of Fourier Coefficients (Algorithm 255 [C6]) numerical integration, Fourier coefficients, Filon's method\n", "1818": "Associated Legendre Functions of the First Kind Legendre function, associated Legendre\nfunction, real or imaginary arguments\n", "1819": "Complex Error Function (Algorithm 363 [S15]) error function for complex argument, Voigt function,\nLaplace continued fraction, Gauss-Hermite \nquadrature, recursive computation\n", "1820": "Generation of Random Permutations (Algorithm 362 [G6]) permutation, random permutation, transposition\n", "1821": "Permanent Function of a Square Matrix I and II (Algorithm 361 [G6]) matrix, permanent, determinant\n", "1822": "Shortest-Path Forest with Topological Ordering (Algorithm [H]) shortest path, tree, network, directed graph\n", "1823": "Factorial Analysis of Variance (Algorithm [G1]) factorial variance analysis, variance, statistical analysis\n", "1824": "APAREL-A Parse-Request Language APAREL is described: this language is an extension\nto an algorithmic language (PL/I) that provides \nthe pattern-matching capabilities normally found only\nin special purpose languages such as SNOBOL4 and \nTMG.  This capability is provided through parse-requests\nstated in a BNF-like format.  These parse-requests \nform their own programming language with special sequencing\nrules.  Upon successfully completing a parse-request, \nan associated piece of PL/I code is executed.  This\ncode has available for use, as normal PL/I strings \nthe various pieces (at all levels) of the parse.  It\nalso has available as normal PL/I variables, the\ninformation concerning which of the various alternatives\nwere successful.  Convenient facilities for \nmultiple input-output streams, the initiation of sequences\nof parse-requests as a subroutine, and parse-time \nsemantic checks are also included.  APAREL has proven convenient\n in building a powerful SYNTAX and FUNCTION \nmacro system, an algebraic language preprocessor debugging\nsystem, an on-line command parser, a translator \nfor Dataless Programming, and as a general string manipulator.\n text processing, string processing, symbol manipulation,\nPL/I, BNF, syntax, parser, translator, \npattern matching\n", "1825": "A Practical Method for Constructing LR(k) Processors A practical method for constructing LR(k) processors\nis developed.  These processors are capable \nof recognizing and parsing an input during a single\nno-backup scan in a number of steps equal to the \nlength of the input plus the number of steps in its\nderivation.  The technique presented here is based \non the original method described by Knuth, but decreases\nboth the effort required to construct the processor \nand the size of the processor produced.  This procedure\ninvolves partitioning the given grammar into \na number of smaller parts.  If an LR(k) processor can be\nconstructed for each part (using Knuth's algorithm) \nand if certain conditions relating these individual\nprocessors are satisfied, then an LR(k) processor \nfor the entire grammar can be constructed for them.\n Using this procedure, an LR(1) parser for ALGOL \nhas been obtained.\n LR(k) grammar, syntactic analysis, parser, deterministic\nlanguage, syntax-directed compiler, language\nprocessor, context-free language ALGOL\n", "1826": "A LISP Garbage-Collector for Virtual-Memory Computer Systems In this paper a garbage-collection algorithm\nfor list-processing systems which operate within \nvery large virtual memories is described.  The object\nof the algorithm is more the compaction of active \nstorage than the discovery of free storage.  Because free\nstorage is never really exhausted, the decision \nto garbage collect is not easily made; therefore,\nvarious criteria of this decision are discussed.\n garbage-collector, virtual memory, list-processing, storage-allocation\n", "1827": "Performance Monitoring in a Time-Sharing System A software measurement facility which is part of\na general purpose time-sharing system is described. \n The Date Collection Facility (DCF) has been implemented\nin the Michigan Terminal System (MTS) for the \nSystem/360 model 67.  It exists for the purpose of monitoring\noperating system and user program behavior \nand performance.  The overall structure of MTS is outlined\nin order to explain the implementation of \nthe DCF.  Events in the system are identified and recorded\nfrom within the supervisor, and dumped to \nmagnetic tape by an auxiliary program for off-line processing.\n Events in user programs which are unrelated \nto system actions are recorded with a supervisor call.\n The time of occurrence of each event is accurately \nrecorded, and data items are further identified by job and\ntype.  The overhead associated with data collection \nand its interference with normal jobs is carefully analyzed,\nand both are shown to be minimal.  Several \nexamples are given of information obtained with the\nfacility and of applications in which it has been \nuseful.  Some general guidelines are offered for\nthe construction of future monitoring programs.\n performance monitoring, performance measurement,\nprogram behavior, performance data, multiprogramming \nperformance, software measurement, time-sharing performance,\nsystem evaluation, software monitor, software \ninstrumentation\n", "1828": "Synchronization in a Parallel-Accessed Data Base The following problem is considered:  Given\na data base which can be manipulated simultaneously \nby more than one process, what are the rules for synchronization\nwhich will maximize the amount of parallel \nactivity allowed.  It is assumed that the data base\ncan be represented as a graph.  An example of such \na data base is a hierarchy of directories for an on-line\nfile system.  Methods for synchronization of \nprocesses are examined; their validity is\ndiscussed and their performance compared.\n parallel accessing, parallel search, file search,\ndata base, synchronization, locking, deadlock\n", "1829": "An Interactive Graphical Display Monitor in A graphic monitor program is described.  It\nwas developed at Carnegie-Mellon University for \nthe CDC G21 computer, which is a general purpose, batch-processing\nsystem with remote entry.  The existing \nG21 system and the graphics hardware are described. \nThe graphic monitor is a resident auxiliary monitor \nwhich provides comprehensive managerial capability\nover the graphical system in response to commands \nfrom the human user.  It also will respond to commands\nfrom a user program through a similar interface, \nwhere routine calls take the place of manual actions.  Thus\nthe human and program can interact on a symmetrical \nand equal basis through the medium of the graphic monitor.\n The choice made in designing the graphic \nmonitor, given the constraints of the existing hardware\nand computer system, are discussed.  The structure \nof the monitor program and the human and program interfaces\nare described.  There is also a transient \nswapping version with a small resident part,\nand provision for swapped used submonitors.\n graphic monitor, man/machine interaction, graphic\ninterface, graphic in batch environment, design \nof graphical system\n", "1830": "Retrieval Times for a Packed Direct Access Inverted File information retrieval, direct access memory, data base, inverted list\n", "1831": "A Comment on Optimal Tree Structures information retrieval, file searching, tree structures, double chaining\n", "1832": "Minimax Logarithmic Error logarithmic error, transformed rational approximation, square root\n", "1833": "An Ambiguity in the Description of ALGOL 60 Ising problem, zero-one sequences\n", "1834": "An Axiomatic Basis for Computer Programming In this paper an attempt is made to explore\nthe logical foundations of computer programming \nby use of techniques which were first applied in the\nstudy of geometry and have later been extended to \nother branches of mathematics.  This involves the elucidation\nof sets of axioms and rules of inference \nwhich can be used in proofs of the properties of computer\nprograms.  Examples are given of such axioms \nand rules, and a formal proof of a simple theorem is\ndisplayed.  Finally, it is argued that important \nadvantages, both theoretical and practical, may\nfollow from a pursuance of these topics.\n axiomatic method, theory of programming, proofs of\nprograms, formal language definition, programming \nlanguage design, machine-independent programming, program documentation\n", "1835": "The IITRAN Programming Language The IITRAN language, developed to be used\nby students, and its important important features \nare described. IITRAN is a procedure-oriented language\nwith a one-level block structure and a variety \nof data types.  Several novel and powerful features\nare included.  A discussion of design principles \nto be followed in a student language is given.\n languages programming languages, student programming\nsystems, language design, high school programs, \ncollege courses\n", "1836": "A New Method for Determining Linear Precedence The precedence relations of a precedence grammar can\nbe precisely described by a two-dimensional \nprecedence matrix.  Often the information in the matrix\ncan be represented more concisely by a pair of \nvectors, called linear precedence functions.  A new algorithm\nis presented for obtaining the linear precedence\nfunctions when given the precedence matrix; this algorithm\nis shown to possess several computational \nadvantages.\n Boolean matrices, syntax, precedence grammar context-free\nparsing, transition matrix, precedence \nfunctions \n", "1837": "An Algol Convolution Procedure Based on the fast Fourier transform, complex Fourier transform,\nmultivariate Fourier transform, Fourier series, \nharmonic analysis, spectral analysis, orthogonal polynomials,\northogonal transformation, convolution, \nauto covariance, autocorrelation, cross-correlation,\ndigital filtering, permutation\n", "1838": "Normal Curve Integral (Algorithm 304 [S15]) normal curve integral, probability, special functions\n", "1839": "Singular Value Decomposition of a Complex singular values, matrix decomposition,\nleast squares solution, pseudoinverse\n", "1840": "An Efficient Prime Number Generator (Algorithm 357 [A1]) prime numbers, factoring, number theory\n", "1841": "A Prime Number Generator Using The prime numbers, number theory, sorting\n", "1842": "An Algorithm for Generating Ising Configurations (Algorithm 355 [Z]) Ising problem, zero-one sequences\n", "1843": "The Choice of Base A digital computer is considered, whose memory\nwords are composed on N r-state devices plus \ntwo sign bits (two state devices).  The choice of base\nB for the internal representation of floating-point \nnumbers on such a computer is discussed.  It is\nshown that in a certain sense B= r is best.\n floating-point, accuracy, base choice, number representations\n", "1844": "A Modular Computer Sharing System An alternative approach to the design and organization\nof a general purpose interactive multiterminal \ncomputing system is presented.  The system organization described\nis a conceptually simple arrangement \nof a bank of interchangeable computers, each of which\nis a memory/processor pair, that are assigned to \nprocess terminal jobs as they arrive.  One of the computers\nserves as the master or control computer \nand supervises the collection and distribution of messages\nfrom and to the remote terminals.  In the \nsimplest form there is a disk drive for each connected\nterminal.  A crosspoint switching network allows \nany such disk drive to be connected to any computer.\n Thus, while each active terminal user \"occupies\" \na dedicated disk drive, he may share the computer with\nmany other terminal users in a simple manner. \n The ratio of users to computers is dependent on both\nthe size and power of the machines used and the \ncomputation requirements of the particular mix of users.\n This system organization is inherently a simpler \nand therefore more reliable approach to time-sharing computers\nand has the potential of a highly available \nsystem at relatively low cost.  Economic configurations\nare possible for a range of systems sizes that \nspan at least one order of magnitude.  Finally, problem\nprograms developed by remote terminal users can \nbe run on a dedicated batch system if compatible computers are used.\n multiple terminal systems, terminal oriented systems,\nmultiple processor systems, high availability, \nconversational systems, general purpose time-sharing systems,\nreal-time response system, modular constructed \nsystems, modular computer-sharing systems, graphics,\nfile switch, intercomputer communications, control \ncomputer, problem computer, roll-in, roll-out\n", "1845": "Loader Standardization for Overlay Programs The overlay capability is described for four\nof the third generation computer systems: CDC-6000, \nGE-635, IBM-360, and UNIVAC-1108.  A critique of the\nfirst three systems is based on actual experience \nwith a large overlaid trajectory simulation program;\na short history and description of this program \nis presented.  A standardization of minimum capabilities\nfor loaders is recommended so that programs \nwhich must operate under more than one computer system\nmay be easily converted and maintained.  A proposal \nthat overlay software incorporates a memory occupation\nspecification concept instead of the conditional \ntree structure is delineated.  This concept provides\nmore efficient and cost-effective utilization of \nthe memory as well as increased flexibility in program structure.\n loader, overlay, partition, region, segmentation,\nlinkage, linkage editor, standardization, memory \nutilization, memory occupation, tree structure,\nCDC-6000, GE-635, IBM-360, UNIVAC-1108\n", "1846": "On Simulating Networks of Parallel Processes Some of the problems of simulating discrete\nevent systems, particularly computer systems, on \na conventional digital computer are dealt with.  The\nsystems are assumed to be described as a network \nof interconnected sequential processes.  Briefly reviewed\nare the common techniques used to handle such \nsimulations when simultaneous events do not occur, can\nbe ignored, or can be handled by simple priority \nrules.  Following this, the problem of dealing with simultaneous\nevents in separate processes is introduced. \n An abstraction of this problem is developed which admits\nsolution for a majority of commonly encountered\nproblems.  The technique will either find a method of\nsimulating the parallel events or report that none \ncan be found.  In some of the latter cases it is shown\nto be possible to find a solution by extending \nthe information available to the solution technique, but\nin many cases the technique becomes computationally \nunfeasible when the additional information is provided.\n simulation, parallel processes, simultaneous events,\npicture processing, computer system simulation\n", "1847": "An Algorithm for Finding a Fundamental Set of Cycles of a Graph A fast method is presented for finding a fundamental\nset of cycles for an undirected finite \ngraph.  A spanning tree is grown and the vertices examined\nin turn, unexamined vertices being stored \nin a pushdown list to await examination.  One stage\nin the process is to take the top element v of the \npushdown list and examine it, i.e. inspect all those\nedges (v,z) of the graph for which z has not yet \nbeen examined.  If z is already in the tree, a fundamental\ncycle is added; if not, the edge (v,z) is \nplaced in the tree.  There is exactly one such stage\nfor each of the n vertices of the graph.  For large \nn, the store required in creases as n^2 and the time as\nn^g where g depends on the type of graph involved. \n g is bounded below by 2 and above by 3, and it is shown\nthat both bounds are attained.  In terms of \nstorage our algorithm is similar to that of Gotlieb and\nCorneil and superior to that of Welch; in terms \nof speed it is similar to that of Welch and superior\nto that of Gotlieb and Corneil.  Testsshow our \nalgorithm to be remarkably efficient (g=2) on random graphs.\n fundamental cycle set, graph, algorithm, cycle, spanning tree\n", "1848": "The Damped Taylor's Series Method for Minimizing solution of equations, least squares approximation, Newton's method\n", "1849": "Function Minimization (Algorithm 251 [E4]) function minimization\n", "1850": "Generation of Permutations in Lexicographic Order (Algorithm 323 [G6]) permutations, direct lexicographic order, reverse\nlexicographic order, lexicographic generation\n", "1851": "Generator of Spanning Trees (Algorithms 354 [H]) spanning trees, trees, graphs\n", "1852": "A Base for a Mobile Programming System An algorithm for a macro processor which has\nbeen used as the base of an implementation, by \nbootstrapping, of processors for programming languages is\ndescribed.  This algorithm can be easily implemented \non contemporary computing machines.  Experience with\nprogramming languages whose implementation is based\non this algorithm indicates that such a language can\nbe transferred to a new machine in less than one \nman-week without using the old machine.\n bootstrapping, macro processing, machine independence,\nprogramming languages, implementation techniques\n", "1853": "Compact List Representation: Definition, Compact lists are stored sequentially in memory,\nrather than chained with pointers.  Since \nthis is not always convenient, the Swym system permits\na list to be chained, compact, or any combination \nof the two.  A description is given of that list representation\nand the operators implemented (most are \nsimilar to those of LISP 1.5).  The system garbage collector\nattempts to make all lists compact; it relocates \nand rearranges all of list storage using temporary storage.\n This unique list-compacting garbage collection \nalgorithm is presented in detail.  Several classes of the\nmacros used to implement the system are described. \n Finally, consideration is given to those design factors\nessential to the success of a plex processing \nsystem implementation.\n data structure, data representation, list structure,\nlist representation, list, compact list, garbage \ncollection, relocation, storage reclamation, macro,\nprimitive list operations, plex processing, plex, \npointer, list processing system, LISP, free storage\n", "1854": "On Multiprogramming, Machine Coding, and Computer Organization The author feels that the interrupt feature\nwhich is available in most modern computers is \na potent source of programming pitfalls and errors, and\nthat it therefore may heavily contribute to the \nunreliability of programs making use of it.  A programming\nscheme is presented which avoids the concept \nof the interrupt and permits the specification of concurrent\n(or pseudoconcurrent) activities in a supposedly \nmore perspicuous manner.  It is intended to serve as\na basis for the construction of operating systems, \nwhich are prime examples of programs with concurrent\nactivities.  The scheme includes a set of basic \ninstructions for the generation, termination, and synchronization\nof parallel processes.  A set of routines \nrepresenting these instructions and thereby simulating a\nhypothetical machine organization has been implemented \nand test on the IBM System/360.  Two programs using these\ninstructions, written in PL360, are presented. \n multiprogramming, parallelism, interrupt, input-output,\ncomputer organization, file handling, PL360\n", "1855": "A Program for the Syntactic Analysis of English Sentences A program is described which produces syntactic\nanalyses of English sentences with respect \nto a transformational grammar.  The main features of the\nanalyzer are that it uses only a limited dictionary \nof English words and that it pursues all analysis paths\nsimultaneously while processing the sentence \nfrom left to right.  The form of representation used\nfor the dictionary and the grammar is indicated \nand an outline account is given of the analysis procedure.\n Techniques for keeping the size of the analysis \nrecord within reasonable limits and for avoiding the need\nfor dynamic application of certain transformational \nrules are described.   A number of examples of output\nproduced by the program are given.  The output \nincludes timing information.\n syntactic analysis, language processing, language\nanalysis, parsing, analysis procedure, recognition \nprocedure, English sentences, linguistics, psycholinguistics,\ntransformational grammar, limited dictionary, \npredictive analysis\n", "1856": "The Teachable Language Comprehender:  The Teachable Language Comprehender (TLC) is\na program designed to be capable of being taught \nto \"comprehend\" English text.  When text which the program\nhas not seen before is input to it, it comprehends \nthat text by correctly relating each (explicit or implicit)\nassertion of the new text to a large memory. \n This memory is a \"semantic network\" representing factual\nassertions about the world.  The program also \ncreates copies of the parts of its memory which have\nbeen found to relate to the new text, adapting and \ncombining these copies to represent the meaning of the\nnew text.  By this means, the meaning of all text \nthe program successfully comprehends is encoded into\nthe same format as that of the memory.  In this \nform it can be added into the memory.  Both factual\nassertions for the memory and the capabilities for \ncorrectly relating text to the memory's prior content\nare to be taught to the program as they are needed. \n TLC presently contains a relatively small number of\nexamples of such assertions and capabilities, but \nwithin the system, notations for expressing either of these\nare provided.  Thus the program now corresponds \nto a general process for comprehending language, and\nit provides a methodology for adding the additional \ninformation this process requires to actually comprehend\ntext of any particular kind.  The memory structure \nand comprehension process of TLC allow new factual assertions\nand capabilities for relating text to such \nstored assertions to generalize automatically.  That\nis, once such an assertion or capability is put \ninto the system, it becomes available to help comprehend\na great many other sentences in the future. \n Thus the addition of a single factual assertion or\nlinguistic capability will often provide a large \nincrement in TLC's effective knowledge of the world and\nin its overall ability to comprehend text.  The \nprogram's strategy is presented as a general theory of language comprehension.\n natural language processing, natural language comprehension,\nteachable computer program, psychological \nsimulation, human memory simulation, computer\nlinguistics, linguistic performance theory\n", "1857": "Filon Quadrature (Algorithm [D1]) quadrature, Filon quadrature, integration, Filon\nintegration, Fourier coefficients, Fourier series\n", "1858": "An Algorithm for Filon Quadrature An algorithm for Filon quadrature is described.\n Considerable attention has been devoted to \nan analysis of the round-off and truncation errors.\n The algorithm includes an automatic error control \nfeature.\n quadrature, Filon quadrature, integration, Filon\nintegration, Fourier coefficients, Fourier series\n", "1859": "Error Bounds for Periodic Quintic Splines Explicit error bounds for periodic quintic spline\ninterpolation are developed.  The first (third) \nderivative of the periodic spline is shown to be a sixth\n(fourth) order approximation at the mesh points \nto the first (third) derivative of the function being interpolated.\n spline, interpolation, error bounds\n", "1860": "An Algol-Based Associative Language A high level programming language for large,\ncomplex associative structures has been designed \nand implemented.  The underlying data structure has\nbeen implemented using a hash-coding technique.  \nThe discussion includes a comparison with other work\nand examples of applications of the language.\n ALGOL, associative, programming language, data structure\n", "1861": "The MAD Definition Facility One of the first definition facilities for\nhigher level languages is described.  Users of the \nlanguage can define new operators and/or data types\ninto the MAD language, so that their use appears \nas if they were predefined.  Information is given on\nhow one writes definitions, as well as on much of \nthe motivation behind the form in which definitions are\nwritten. Some conclusions are drawn about future \ndefinitional facilities.\n MAD, definitions, operators, macros, higher level language\n", "1862": "Computing Capabilities at Argentine and Chilean Universities The author reports on a trip to universities in\nArgentina and Chile during November 1968, describing \nuniversity conditions and computing activities.  As elsewhere,\nthese universities are experiencing student \ndiscontent with the status quo and the solutions they\nare attempting contrast: Argentina is excluding \nstudents from participating in university government;\nChile is allowing such participation.  University \ncomputing service and academic activities are limited.\n The number of computers is small and so is the \ncapacity, none larger than an IBM 360/40; with some\nexception, computing science academic programs are \nrare. This situation is by no means attributable to\nthose responsible for computing developments, who \nstrive for excellence; rather the \"system\" is hard to\nover-come.  Universities, especially those with \nstrong European traditions, adapt slowly to new academic\nresources and disciplines; superimposed are \nthe severe technological and economic constraints of the\ndeveloping nation.  Consequently, in the absence \nof conscious government emphasis on strengthening computing\ncapabilities, future progress may be retarded.\n university education, computing science academic\nprograms, university computing centers, surveys \nof computing centers, university computing capabilities, university-student\nrelationship, Argentine universities, \nChilean universities, South American universities, developing nations\n", "1863": "Minit Algorithm for Linear Programming (Algorithm 333 [H]) linear programming, dual simplex method, primal problem, dual problem\n", "1864": "Generation of Hilbert Derived Test Matrix (Algorithm 274 [F1]) test matrix, Hilbert matrix\n", "1865": "Algol 60 Reference Language Editor (Algorithm 268 [R2]) symbol manipulation\n", "1866": "Characteristic Values and Associated Solutions Mathieu's differential equation, Mathieu function,\ncharacteristic value, periodic solution, radial \nsolution\n", "1867": "On the Expected Lengths of Sequences Generated In the replacement-selecting technique of sorting,\none is interested in the ratio L(j) of the \nexpected length of the j-th sequence generated by the\ntechnique to the number of memory cells used.  \nUsing complex-variable theory, it is shown that L(j)\n-> 2 and that, asymptotically, the average interval \nbetween sign changes of L(j)-2 is 2.6662.\n replacement selecting, sorting, sequence lengths,\nasymptotic expected length, recursion relation, \ngenerating function, meromorphic function\n", "1868": "On Obtaining Correct Input:A New Approach Most information put into machine readable\nform, whether from scientific or business origins, \nis still keypunched.  This paper is addressed toward\nthe difficulty of obtaining correctly keypunched \nand key verified data and an alternative method is suggested\nin which the computer itself is used to rule \nout the possibility of errors in input.  This technique\nis explained and illustrated by reference to \na working program which involves essentially two phases:\nin the first phase errors are detected by the \nmachine, and subsequently, in the second phase, they are corrected by it.\n correct data, correct input, data correction,\nkeypunch, key verifier, verifier\n", "1869": "Block Structures, Indirect Addressing, and Garbage Collection Programming languages have included explicit\nor implicit block structures to provide a naming \nconvenience for the programmer.  However, when indirect\naddressing is used, as in SNOBOL, naming constraints \nmay be introduced.  Two modifications to SNOBOL are described,\nresulting in two desirable consequences: \n(1) naming constraints disappear even when there is\nindirect addressing within function definitions; \nand (2) there is a significant saving in the number of\ncalls to the garbage collector, because some garbage \nis collected, at little expense, each time a function\nreturns to its calling program.  These modifications \nhave been implemented as an extension to a SNOBOL dialect.\n block structures, indirect addressing,\ngarbage collection, local names, SNOBOL\n", "1870": "Some Techniques for Using Pseudorandom Numbers in Computer Simulation An algorithm is described by which uniform pseudorandom\nintegers may be used to construct binary \n\"numbers\" in which the probability that each bit in the\nword is a 1-bit and can assume any desired parameter \nvalue.  Techniques for making use of such \"numbers\"\nin simulation programming are described.\n random numbers,  simulation, Boolean algebra, bit manipulation\n", "1871": "Automatic Contour Map Some methods for contour mapping by means of\na digital plotter are discussed, and a new method \nis presented that is simple enough to be implemented by\nprograms with a rather small number of instructions \n(about 120 FORTRAN IV instructions are required).  Comparisons\nwith some methods proposed by other authors \nare also performed,  A FORTRAN IV program implementing\nthe proposed method is available at the Istituto \ndi Elettrotecnica ed Elettronica, Politencnico di Milano.\n contour map, level lines, digital plotting, function scanning\n", "1872": "Chebyshev Interpolation and Quadrature", "1873": "Accelerating LP Algorithms It is shown how a novel method for computing\n(related) inner products can accelerate the pricing \nphase of LP algorithms.  Other LP applications are indicated.\n linear programming, revised simplex\nmethod, multiple pricing, inner product\n", "1874": "Generating Pseudorandom Numbers on a Two's The familiar multiplicative congruential generator\nis examined in the context of the type of \ntwo's complement arithmetic used in the IBM 360 series.\n Different sequences of residues are considered \nand relationships established among them.  It is shown\nthat a sequence of positive and negative residues \nmay be produced more simply and economically than with\nthe conventional approach and yet have twice the \nperiod of the latter without loss of desirable statistical\nproperties.  Another easily generated sequence \ninvolving absolute values is also shown to have twice\nthe period but with less attractive statistical \nproperties.  The statistical properties of these sequences\nare given and related to previously established \ncriteria.\n random number, uniform distribution, pseudo-random\nnumber, random number generator, multiplicative \ncongruential generator, power residue, two's\ncomplement arithmetic, IBM 360 arithmetic\n", "1875": "Polynomial and Spline Approximation by Quadratic Programming The problem of approximation to a given function,\nor of fitting a given set of data, where \nthe approximating function is required to have certain\nof its derivations of specified sign over the \nwhole range of approximation, is studied.  Two approaches\nare presented, in each of which quadratic programming \nis used to provide both the constraints on the derivatives\nand the selection of the function which yields \nthe best fit.  The first is a modified Bernstein polynomial\nscheme, and the second is a spline fit.\n constant sign derivatives, Bernstein polynomials,\nlinear concavity constraints, quadratic programming \nsplines\n", "1876": "Generation of Test Matrices Having Certain A class of orthogonal transformations is presented\nwhose members transform a given positive \ndiagonal matrix into a matrix having one of four special sign patterns.\n test matrices, positive matrices, sign patterns,\northogonal transformations, positive eigenvalues\n", "1877": "Prevention of System Deadlocks A well-known problem in the design of operating\nsystems is the selection of a resource allocation \npolicy that will prevent deadlock.  Deadlock is the\nsituation in which resources have been allocated \nto various tasks in such a way that none of the tasks\ncan continue.  The various published solutions \nhave been somewhat restrictive: either they do not handle\nthe problem in sufficient generality or they \nsuggest policies which will on occasion refuse a request\nwhich could have been safely granted.  Algorithms \nare presented which examine a request in the light of\nthe current allocation of resources and determine \nwhether or not the granting of the request will introduce\nthe possibility of a deadlock.  Proofs given \nin the appendixes show that the conditions imposed by\nthe algorithms are both necessary and sufficient \nto prevent deadlock.  The algorithms have been successfully used in the THE system.\t\n multiprogramming, time-sharing, scheduling, resource allocation\n", "1878": "Recovery of Reentrant List Structures in SLIP One consequence of the reference-count-based\nspace-recovery system employed by SLIP is that \nreentrant list structures are not recovered even when\nexplicitly erased.  LISP-like garbage-collection \nschemes are free of this impediment.  They however,\ndepend on being able to find and mark nodes that \nare reachable from program variables.  By tracing all\ndescendants from program variables may then be \nidentified and collected.  The list-creating function\nLIST of SLIP may be amended to mark those lists \nfor which the programmer wishes to assume responsibility.\n Given this modification, a LISP-like garbage \ncollector that recovers abandoned reentrant list structures\nmay then be appended to the SLIP system.\n list processing, SLIP, garbage-collection\n", "1879": "A Note on Storage Fragmentation and Program Segmentation The main purpose of this paper is the presentation\nof some of the results of a series of simulation \nexperiments investigating the phenomenon of storage fragmentation.\n Two different types of storage fragmentation \nare distinguished: (1) external fragmentation, namely the\nloss in storage utilization caused by the inability \nto make use of all available storage after it has been\nfragmented into a large number of separate blocks; \nand (2) internal fragmentation, the loss of utilization\ncaused by rounding up a request for storage, \nrather than allocating only the exact number of words required.\n The most striking result is the apparently \ngeneral rule that rounding up requests for storage,\nto reduce the number of different sizes of blocks \ncoexisting in storage, causes more loss of storage\nby increased internal fragmentation than is saved \nby decreased external fragmentation.  Described also are\na method of segment allocation and an accompanying \ntechnique for segment addressing which take advantage\nof the above result.  Evidence is presented of \npossible advantages of the method over conventional paging techniques.\n storage allocation, storage fragmentation,\npaging, segmentation, addressing\n", "1880": "Chebyshev Solution to an Overdetermined Chebyshev solutions, over-determined linear\nsystems, linear equations, exchange algorithm \n", "1881": "Transpose Vector Stored Array (Algorithm 302 [K2]) matrix transposition, array transposition, vector stored array\n", "1882": "Determination of the Square Root of a Positive matrix, symmetric matrix, positive definite matrix, matrix square root\n", "1883": "Modified Romberg Quadrature(Algorithm [D1]) numerical integration, Romberg quadrature,\ntrapezoid values, rectangle values, error bound\n", "1884": "An Anomaly in Space-Time Characteristics of The running time of programs in a paging machine\ngenerally increases as the store in which \nprograms are constrained to run decreases.  Experiments,\nhowever, have revealed cases in which the reverse \nis true: a decrease in the size of the store is accompanied\nby a decrease in running time.  An informal \ndiscussion of the anomalous behavior is given, and for\nthe case of the FIFO replacement algorithm a formal \ntreatment is presented.\n paging machines, demand paging, replacement algorithm\n", "1885": "A Computer System for Transformational Grammar A comprehensive system for transformational\ngrammar has been designed and implemented on the \nIBM 360/67 computer.  The system deals with the transformational\nmodel of syntax, along the lines of \nChomsky's Aspects of the Theory of Syntax. The major\ninnovations include a full,formal description of \nthe syntax of a transformational grammar, a directed random\nphrase structure generator, a lexical insertion \nalgorithm, an extended definition of analysis, and\na simple problem-oriented programming language in \nwhich the algorithm for application of transformations\ncan be expressed.  In this paper we present the \nsystem as a whole, first discussing the general attitudes underlying\nthe development of the system, then \noutlining the system and discussing its more important\nspecial features.  References are given to papers \nwhich consider some particular aspect of the system in detail.\n transformational grammar, natural language syntax,\nlanguage processing, language analysis, sentence \ngeneration, lexical insertion, computational linguistics, syntax\n", "1886": "Generation of Optimal Code for Expressions via Factorization Given a set of expressions which are to be\ncompiled, methods are presented for increasing the \nefficiency of the object code produced by first factoring\nthe expressions, i.e. finding a set of subexpressions \neach of which occurs in two or more other expressions\nor subexpressions.  Once all the factors have been \nascertained, a sequencing procedure is applied which\norders the factors and expressions such that all \ninformation is computed in the correct sequence and factors\nneed be retained in memory a minimal amount \nof time.  An assignment algorithm is then executed in\norder to minimize the total number of temporary \nstorage cells required to hold the results of evaluating\nthe factors.  In order to make these techniques \ncomputationally feasible, heuristic procedures are\napplied, and hence global optimal results are not \nnecessarily generated.  The factorization algorithms\nare also applicable to the problem of factoring \nBoolean switching expressions and of factoring polynomials\nencountered in symbol manipulating systems.\n factorization algorithms, code optimization, sequencing\nof operations, detection of common subexpressions, \nfactorization of Boolean expressions\n", "1887": "A Recursive Relation for the Determinant of a Pentadiagonal Matrix A recursive relation, relating leading principal\nminors, is developed for the determinant of \na pentadiagonal matrix.  A numerical example is included\nto indicate its use in calculating eigenvalues.\n pentadiagonal matrix, quindiagonal matrix, quindiagonal\nmatrix, band matrix, determinant, characteristic \npolynomial, eigenvalues\n", "1888": "Spline Function Methods for Nonlinear Boundary-Value Problems The solution of the nonlinear differential equation\nY\"=F(x,Y,Y') with two-point boundary conditions \nis approximated by a quintic or cubic spline function\ny(x).  The method is well suited to nonuniform \nmesh size and dynamic mesh size allocation.  For uniform\nmesh size h, the error in the quintic spline \ny(x) is O(h^4), with typical error one-third that from\nNumerov's method.  Requiring the differential \nequation to be satisfied at the mesh points results\nin a set of difference equations, which are block \ntridiagonal and so are easily solved by relaxation or other standard methods.\n boundary value problems, differential equations,\nfinite differences, functional approximation, \niterative methods, nonlinear equations, spline functions\n", "1889": "Introducing Computing to Smaller Colleges By technical means that are now routine, computer\nservice for smaller colleges and universities \ncan be provided by remote terminals of a central facility.\n Access, however, is not enough-effective \norganizational and educational methodology for introducing\ncomputing at such institutions must also be \ndeveloped.  The experience of two years with a statewide\nnetwork involving-41 institutions is discussed. \n Lessons include the importance of a separate organization\nrepresenting the small colleges, the necessity \nfor on-campus training for the institutions, the need\nfor some special programming and documentation \nto support such users,and the development of curriculum by evolutionary means.\n regional network, introducing computing, under-graduate\neducation, instructional usage, academic \napplications, curriculum development, orientation project,\nregional center, consortium, remote computing\n", "1890": "Simulation of Traffic Flows in a Network A computer simulation program which deals\nwith traffic flows in the network of a large area \nis described.  Each road is segmented into blocks of\nseveral ten-meter lengths and is represented by \na bidirectional list in computer memory.  The movement\nof cars, i.e. the transfer of cars from one block \nto the next, is expressed by a proper formula.  This\nformula is based on the supposition that the speed \nof cars in a block is determined only by the density of\ncars in the block, and this speed-versus-density \ncurve is empirically given the numerical values.  This\nsimulation scheme has its excellent point in that \nit makes it possible to trace the dynamic behavior\nof traffic flows in a variety of situations, some \nexamples of which are given for an actual area of the city of Kyoto, Japan.\n traffic simulation, traffic flow, traffic network\ntraffic control, traffic density, intersection, \nsignal setting, vehicle, road network, list structure, computer simulation\n", "1891": "Three-Dimensional Computer Display A stereographic display terminal has been\nproduced using the raster display (BRAD) recently \ndeveloped at Brookhaven.  The system uses a rotating refresh\nmemory to feed standard television monitors. \n To produce a stereographic display the computer calculates\nthe projected video images of an object, \nviewed from two separate points.  The resulting video\nmaps are stored on separate refresh bands of the \nrotating memory.  The two output signals are connected\nto separate color guns of a color television monitor, \nthus creating a superimposed image on the screen.  Optical\nseparation is achieved by viewing the image \nthrough color filters.  The display is interactive and\ncan be viewed by a large group of people at the \nsame time.\n computer graphics, three-dimensional display, swept\nraster display, interactive stereographic terminal, \nvideo map, color separation\n", "1892": "Degree of Multiprogramming in Page-on-Demand Systems A simple stochastic model is described which\noffers a base for understanding the relationship \nbetween the number of programs permitted to share memory\n(the degree of multiprogramming), drum traffic \nrates, and central processing unit utilization in page-on-demand,\nmultiprogrammed, time-shared computer \nsystems.  The model preserves, as a key feature, the\nproperty of page-demand statistics which implies \na \"burst\" of page demands at the beginning of any job\nor quantum execution.  The model, a Markov chain, \nis analyzed numerically and the results are presented graphically\nfor a wide range of key environment-descriptive \nparameters.  Implications of the results to time-shared\nsystem design and programming are discussed, \nand a calculation of the optimal degree of multiprogramming\nfor a wide range of parameters is presented \ngraphically. \n page-on-demand, demand paging, time-sharing multiprogramming,\nMarkovian computer models, scheduling \nstrategies, operating systems, memory management\n", "1893": "Roots of Polynomials by a Root-Squaring root finders, roots of polynomial equations, polynomial\nzeros, root-squaring operations, Graeffe \nmethod, resultant procedure, subresultant procedure,\ntesting of roots, acceptance criteria\n", "1894": "Normal Random Deviates (Algorithm 334 [G5]) normal deviates, normal distribution, random number,\nrandom number generator, simulation, probability \ndistribution, frequency distribution, random\n", "1895": "Gaussian Quadrature Formulas (Algorithm 331 [D1]) quadrature, Gaussian quadrature, numerical integration,\nweight function, orthogonal polynomials\n", "1896": "Regular Coulomb Wave Functions (Algorithm 292 S22]) Coulomb wave functions, wave functions, regular Coulomb wave functions\n", "1897": "Coulomb Wave Functions (Algorithm 300 [S22]) Coulomb wave functions, wave functions\n", "1898": "Regular Coulomb Wave Functions (Algorithm 292 [S22]) Coulomb wave functions, wave functions, regular Coulomb wave functions\n", "1899": "Simplex Method Procedure Employing Lu Decomposition (Algorithm 350 [H]) simplex method, linear programming, LU decomposition,\nround-off errors, computational stability\n", "1900": "Clarification of Fortran Standards-Initial Progress In 1966 after four years of effort, FORTRAN\nbecame the first programming language standardized \nin the United States.  Since that initial achievement,\nstudy and application of the standard specifications \nhave revealed the need for maintenance of the standards.\n As the result of work initiated in 1967, an \ninitial set of clarifying interpretations has been prepared.\n The nature of the maintenance, corrections \nto the standard specifications, and completed interpretations are reported.\n USA Standard, FORTRAN, Basic FORTRAN, programming\nlanguage, standardization, language standard \nspecification, language standard maintenance, language standard\nclarification, language standard interpretation, \nstandardization committee\n", "1901": "Dynamic Space-Sharing in Computer Systems A formalization of relationships between space-shading\nprogram behavior, and processor efficiency \nin computer systems is presented.  Concepts of value and\ncost of space allocation per task are defined \nand then value and cost are combined to develop a single\nparameter termed value per unit cost.  The intent \nis to illustrate a possible analytic approach to the\ninvestigation of the problems of space-sharing and \nto demonstrate the method on sample problems.\n space-sharing, storage allocation, memory allocation,\nstorage management, memory management, program \nbehavior, multiprogramming, computer system design, allocation\nstrategies, replacement strategies, demand-paging, \ntime-sharing\n", "1902": "An Automatic Grading Scheme for Simple Programming Exercises A discussion is given of alterations that were\nmade to a typical university operating system \nto record the results of programming exercises in three\ndifferent languages, including assembly language. \n In this computer-controlled grading scheme provision\nis made for testing with programmer-supplied data \nand for final runs with system-supplied data.  Exercises\nrun under the scheme may be mixed with other \nprograms, and no special recognition of exercises by the operators is necessary.\n automatic grading program, programming exercises\n", "1903": "Chebyshev Interpolation and Quadrature Formulas of Very High Degree Chebyshev polynomials, Chebyshev interpolation,\nChebyshev quadrature, Chebyshev points, Chebyshev \nzeros, interpolation, quadrature, definite integrals\n", "1904": "Rough and Ready Error Estimates in Gaussian numerical integration, analytic functions, error\nestimates, Gaussian integration, tabulated error \ncoefficients, computable error coefficients, Cauchy\nintegral formula, Chebyshev polynomials\n", "1905": "The Simplex Method of Linear Programming Using LU Decomposition Standard computer implementations of Dantzig's\nsimplex method for linear programming are based \nupon forming the inverse of the basic matrix and updating\nthe inverse after every step of the method. \n These implementations have bad round-off error properties.\n This paper gives the theoretical background \nfor an implementation which is based upon the LU decomposition,\ncomputed with row interchanges, of the \nbasic matrix.  The implementation is slow, but has good\nround-off error behavior.  The implementation \nappears as CACM Algorithm 350.\n simplex method, linear programming, LU decomposition,\nround-off errors, computational stability\n", "1906": "Automated Printed Circuit Routing with a Stepping Aperture A computer program for routing interconnections\non a two-sided printed circuit board with a \nregular pattern of lines, pins (terminals), and vias\n(feed-through holes) is described.  In this program, \neach interconnection is given a planned routing-typically,\ndown from the upper pin, through a via, and \nhorizontally to the lower pin.  From the top, a virtual\naperture (i.e. a long horizontal slit) is stepped \ndown the board.  The planned routing is the basis for\nrerouting interconnections within the aperture \nto resolve conflicts for lines and vias below the aperture\nand to maximize the effective line usage. \n If a conflict has not been resolved before the aperture\narrives at the lower pin,interconnections are \ndeleted to resolve the conflict.  Extensions of this technique\nto the control of crosstalk between routed \ninterconnections and to the problem of obtaining\n100 percent interconnect are also discussed.\n routing, printed circuit, interconnections, aperture,\nstepping aperture, computer program, circuit \nboard, lines, vias, pins\n", "1907": "A Note on Reliable Full-Duplex Transmission over Half-Duplex Links A simple procedure for achieving reliable full-duplex\ntransmission over half-duplex links is \nproposed. The scheme is compared with another of the\nsame type, which has recently been described in \nthe literature.  Finally, some comments are made on\nanother group of related transmission procedures \nwhich have been shown to be unreliable under some circumstances.\n data transmission, error correction, full-duplex,\nhalf-duplex, transmission control, communications\n", "1908": "Time-Sharing and Batch-Processing:  An Experimental An experimental comparison of problem-solving\nusing time-sharing and batch-processing computer \nsystems conducted at MIT is described in this paper.\n This study is the first known attempt to evaluate \ntwo such systems for what may well be the predominant user\npopulation within the next decade-the professionals \nwho, as nonprogrammers, are using the computer as an\naid in decision-making and problem-solving rather \nthan as a programming end in itself.  Statistically\nand logically significant results indicate equal \ncost for usage of the two computer systems; however,\na much higher level of performance is attained by \ntime-sharing users.  There are indications that significantly\nlower costs would have resulted if the \ntime-sharing users had stopped work when they reached\na performance level equal to that of the batch \nusers.  The users' speed of problem-solving and their\nattitudes made time-sharing the more favorable \nsystem.\n time-sharing vs batch-processing, user performance,\nman/machine communications, cost effectiveness, \non-line vs off-line performance, decision-making performance,\nuser/programmer behavior, programming experimental \nempirical studies, problem-solving, research in man/machine\ncommunications, man/machine symbiosis\n", "1909": "Computation of Jn(x) by Numerical Integration It is shown to be practical to compute Jn(x) by\nnumerical integration of its integral representation \nusing the trapezoidal rule. The error in this\napproximation was studied empirically.\n Bessel Function, numerical integration, trapezoidal rule\n", "1910": "An Algorithm for Solving a Special Class An algorithm is presented for solving a system\nof linear equation Bu=k where B is tridiagonal \nand of a special form.  It is shown that this algorithm\nis almost twice as fast as the Gaussian elimination \nmethod usually suggested for solving such systems. \nIn addition, explicit formulas for the inverse and \ndeterminant of the matrix B are given.\n tridiagonal, Gaussian elimination, central difference\n", "1911": "On Coordination Reduction and Sentence Analysis A class of coordination phenomena in natural\nlanguages is considered within the frame work \nof transformational theory.  To account for these phenomena\nit is proposed that certain machinery be \nadded to the syntactic component of a transformational\ngrammar. This machinery includes certain rule \nschemata, the conditions under which they are to be\napplied, and conditions determining the sequence \nof subtrees on which they are to be performed.  A solution\nto the syntactic analysis problem for this \nclass of grammars is outlined.  Precise specification\nof both the generative procedure of this paper \nand its inverse is given in the form of LISP function definitions.\n natural languages, generative grammar, transformational\ntheory, syntax, coordination, sentence \ncoordination, sentence coordination, coordination reduction,\nsyntactic analysis, grammar testing program, \nrule testing\n", "1912": "Simulation of Outpatient Appointment Systems An experimental computer program is described\nwhich simulates appointment systems employed \nby outpatient departments of hospitals.  Both major kinds\nof appointment systems-individual and block-can \nbe simulated.  The purpose of the Simulator is to enable\nthe user to evaluate the effectiveness of alternative \nappointment systems in a given clinical environment.\n simulation, scheduling, appointment system, outpatient\ndepartment, medicine, health, management\nscience, operations research\n", "1913": "Polygamma Functions with Arbitrary Precision (Algorithm 349 [S14]) polygamma function, psi function, digamma function,\ntrigamma function, tetragamma function, pentagamma \nfunction, special functions\n", "1914": "Matrix Scaling by Integer Programming (Algorithm 348 [F1]) integer programming, linear algebra, mathematical\nprogramming, matrix condition, matrix scaling\n", "1915": "An Algorithm for Hidden Line Elimination The algorithm presented causes the elimination of\nhidden lines in the representation of a perspective \nview of concave and convex plane-faced objects on the\npicture plane.  All the edges of the objects are \nconsidered sequentially, and all planes which hide every\npoint of an edge are found.  The computing time \nincreases roughly as the square of the number of edges.\n The algorithm takes advantage of a reduced number \nof concave points and automatically recognizes if only\none object with no concave points is considered. \nIn this last case, the result is obtained in a much simpler way.\n hidden line elimination, back line recognition, three-dimensional\nrepresentation, plane-faced objects, \nperspective view, machine rendering of solids, automatic\ndrawing, displaying techniques, computer graphics, \nman/machine interaction, man/machine communication, computer-aided design\n", "1916": "Analysis of Boolean Program Models for Time-Shared, Paged Environments Directed graphs or their associated matrices are\nfrequently used to represent the logical structure \nof sequences of computer instructions.  Such techniques\nare used and, in addition, data references are \nrepresented in a nondirected model. The complete structural\nspecification of a program is represented \nby a combined model.  A transformation of the combined\nmodel yields a new model in which additional timing \ninformation is also contained.  Analysis of these models\nprior to execution yields information valuable \nin determining segmentation of instructions and data for\na time-shared environment, as well as for initial \npage loading; during execution, the analysis may be\nused for \"look ahead\" control of page turning.\n time-sharing, paging, segmentation, executive,\ncompiler, monitor, program model\n", "1917": "An Algol Procedure for the Fast Fourier Transform fast Fourier transform, complex Fourier transform,\nmultivariate Fourier transform, Fourier series, \nharmonic analysis, spectral analysis, orthogonal polynomials,\northogonal transformation, virtual core \nmemory, permutation\n", "1918": "Distribution of Indistinguishable Objects", "1919": "An Efficient Algorithm for Sorting with sorting, minimal storage sorting, digital computer sorting\n", "1920": "F-Test Probabilities (Algorithm 346 [S14]) F-test, Snedecor F-statistic, Fisher Test, distribution function\n", "1921": "An Algol Convolution Procedure Based on the fast Fourier transform, complex Fourier transform,\nmultivariate Fourier transform, Fourier series, \nharmonic analysis, spectral analysis, orthogonal polynomials,\northogonal transformation, convolution, \nauto covariance, autocorrelation, cross-correlation,\ndigital filtering, permutation\n", "1922": "Proposed USA Standard (Data Communication Control data communication, data communication control procedures,\ndata communication establishment/termination \nprocedures, data communication message transfer procedures,\ndata communication error control procedures, \ndata communication polling/selection procedures, communication,\ncommunication control procedures, communication \nestablishment/termination procedures, communication\nmessage transfer procedures, communication error \ncontrol procedures, communication polling/selection procedures,\nlink, link control procedures, link establishment/termination \nprocedures, link message transfer procedures, link error\ncontrol procedures, link polling/selection procedures, \ndata link, data link control procedures, data link  establishment/termination\nprocedures, data link message \ntransfer procedures, data link error control procedures,\ndata link polling/selection procedures\n", "1923": "Pseudofiles An approach to system interfaces for high\nlevel languages using basic input/output support \nfacilities is described.  It is shown that this technique\ncan provide potentially inexpensive methods \nfor programs to communicate with deeply embedded\nfacilities such as command language processors.\n operating systems, interfaces input-output,\nhigh level languages, command language\n", "1924": "Organizing Matrices and Matrix Operations for Paged Memory Systems Matrix representations and operations are examined\nfor the purpose of minimizing the page faulting \noccurring in a paged memory system.  It is shown that\ncarefully designed matrix algorithms can lead to \nenormous savings in the number of page faults occurring\nwhen only a small part of the total matrix can \nbe in main memory at one time.  Examination of addition,\nmultiplication, and inversion algorithms shows \nthat a partitioned matrix representation (i.e. one submatrix\nor partition per page) in most cases induced \nfewer page faults than a row-by-row representation.\n The number of page-pulls required by these matrix \nmanipulation algorithms is also studied as a function\nof the number of pages of main memory available \nto the algorithm.\n matrix algorithms, array processing, paging algorithms,\npaged memory systems, virtual memory systems, \narray storage allocation, storage allocation\n", "1925": "Concepts of Use in Contour Map Processing Generalized techniques whose use can simplify\nthe solution of problems relating to contour \nmaps.  One of these techniques makes use of the topological\nproperties of contour maps.  The topology \nis represented by a graphical structure in which adjacent\ncontour lines appear as connected nodes.  Another \ngeneralized technique consists of utilizing geometrical\nproperties to determine the characteristics of \nstraight lines drawn on the contour map.  Both of these\ntechniques have been applied to the problem of \nlocating the ground track of an aircraft from\nelevation readings obtained during a flight.\n map, contour map, contour lines, topological properties,\ngeometrical properties, graph of contour \nmap, navigation\n", "1926": "Description of FORMAT, a Text-Processing Program FORMAT is a production program which facilitates\nthe editing and printing of \"finished\" documents \ndirectly on the printer of a relatively small (64k) computer\nsystem.  It features good performance, totally \nfree-form input, very flexible formatting capabilities\nincluding up to eight columns per page, automatic \ncapitalization, aids for index construction, and a\nminimum of nontext items.  It is written entirely \nin FORTRAN IV.\n text processing, indexing, printing, documentation,\ntext editing, formatting, frequency dictionary, \nright justification, vocabulary\n", "1927": "Information Science in a Ph.D. Computer Science Program This report contains recommendations on a sample course\ncurriculum in the general area of information \norganization and information system design in a Ph.D.\nComputer Science Program.  The subject area is \nfirst briefly described, followed by a listing of some desirable\ngraduate-level courses.  Suitable bibliographies \nare appended.\n course curriculum, graduate courses, university\ncourses,computer science curriculum, information \nscience, information organization, information retrieval,\ndata retrieval, language analysis, information \nprocessing\n", "1928": "Exclusive Simulation of Activity in Digital Networks A technique for simulating the detailed logic\nnetworks of large and active digital systems \nis described.  Essential objectives sought are improved\nease and economy in model generation, economy \nin execution time and space, and a facility for handling\nsimultaneous activities.  The main results obtained \nare a clear and useful separation of structural and behavioral\nmodel description, a reduction of manual \ntasks in converting Boolean logic into a structural model,\nthe elimination of manual processes in achieving \nexclusive simulation of activity, an event-scheduling\ntechnique which does not deteriorate in economy\nas the event queue grows in length, and a simulation\nprocedure which deals effectively with any mixture \nof serial and simultaneous activities.  The passage of\ntime is simulated in a precise, quantitative fashion \nand systems to be simulated may be combinations of synchronous\nand asynchronous logic.  Certain aspects \nof the techniques described may be used for the simulation\nof network structures other than digital networks.\n simulation, logical simulation, digital simulation,\nlarge systems simulation, network structures, \nscheduling, queuing, simultaneous activities, parallel events\n", "1929": "Images from Computers and Microfilm Plotters Digital computers are widely used for the\nprocessing of information and data of all kinds, \nincluding the pictorial information contained in photographs\nand other graphical representations.  Efficient \nconversion facilities for putting graphical information\ninto the computer and retrieving it in graphical \nform are therefore much needed.  One of the most commonly\nemployed devices for obtaining permanent graphical \noutput from digital computers is the microfilm plotter.\n Regrettably, present models have no provision \nfor producing images with a continuous gray scale or \"half tones.\"\n In this note several programming techniques \nare described for obtaining half tone pictures from a\nmicrofilm plotter under the control of a digital \ncomputer.  Illustrative examples of several methods are given.\n computer images, half tone pictures, microfilm plotters; processing\n", "1930": "Extremely Portable Random Number Generator Extremely portable subroutines are sometimes\nneeded for which moderate quality and efficiency \nsuffice.  Typically, this occurs for library functions\n(like random number generation and in core sorting) \nwhich are not entirely universal or are not used in a\nstandardized way.  The literature on random number \ngenerators does not seem to contain an algorithm that\nmeets requirements of this sort.  An extremely \nportable 8-line FORTRAN program is provided which based\non an important paper by Coveyou and MacPherson \n(1967).Using their methods, Fourier analysis is applied\nto the probability function for the consecutive \nn-tuples provided by our generator (with n less than\nor equal to 4).  While the small modulus which must \nbe used to maintain portability prevents the quality\nof the generator from being high, the generator \ncompares well with the bounds established in the above mentioned paper.\n random number generators, random numbers, random\nnumber analysis, random generators, linear sequential \ngenerators, random number program, pseudo random numbers \n", "1931": "Interval Arithmetic Determinant Evaluation Two recent papers, one by Hansen and one by\nHansen and R. R. Smith, have shown how Interval \nArithmetic (I.A.) can be used effectively to bound errors\nin matrix computations.  In the present paper \na method proposed by Hasen and R. R. Smith is compared\nwith straightforward use of I.A. in determinant \nevaluation.  Computational results show the accuracy\nand running times that can be expected when using \nI.A. for determinant evaluation.  An application using\nI.A. determinants in a program to test a set of \nfunctions to see if they form a Chebyshev system is then presented.\n interval arithmetic, range arithmetic, error bounds,\ndeterminant evaluation, Chebyshev system, \nmathematical proof by computer\n", "1932": "The Logarithmic Error and Newton's Method for the Square Root The problem of obtaining optimal starting values\nfor the calculation of the square root using \nNewton's method is considered.  It has been pointed out\nelsewhere that if relative error is used as the \nmeasure of goodness of fit, optimal results are not\nobtained when the initial approximation is a best \nfit.  It is shown here that if, instead, the so-called\nlogarithmic error is used, then a best initial \nfit is optimal for both types of error.  Moreover, use\nof the logarithmic error appears to simplify the \nproblem of determining the optimal initial approximation.\n square root, Newton's method, relative error, logarithmic\nerror, best fit, optimal approximation, \nmaximal error, recurrence relation, integer root, error curve\n", "1933": "Coding the Lehmer Pseudo-random Number Generator An algorithm and coding technique is presented\nfor quick evaluation of the Lehmer pseudo-random \nnumber generator modulo 2**31 - 1, a prime Mersenne\nnumber with produces 2**31 - 2 numbers, on a p-bit \n(greater than 31) computer.  The computation method is\nextendible to limited problems in modular arithmetic. \n Prime factorization for 2**61 - 2 and a primitive root\nfor 2**61 - 1, the next largest prime Mersenne \nnumber, are given for possible construction of a pseudo-random\nnumber generator of increased cycle length.\n pseudo-random number, random number, modular arithmetic,\nuniform probability density, uniform frequency \nfunction, simulation, prime factorization, primitive roots\n.N\nCA690205 JB February 20, 1978  11:07 AM\n.X\n1933\t5\t1933\n1933\t5\t1933\n1933\t5\t1933\n", "1934": "On Arithmetic Expressions and Trees A description is given of how a tree representing the\nevaluation of an arithmetic expression \ncan be drawn in such a way that the number of accumulators\nneeded for the computation can be represented \nin a straightforward manner.  This representation reduces\nthe choice of the best order of computation \nto a specific problem under the theory of graphs.\n An algorithm to solve this problem is presented.\n arithmetic expression, compiler design, graph theory,\nprogramming, storage minimization, topological \nordering,tree\n", "1935": "Randomized Binary Search Technique A mathematical model is developed for the mean\nand variance of the number of trials to recover \na given document in a randomly received list of files.\n The search method described is binary in nature \nand offers new potential for information retrieval systems.\n binary pattern, file examination, graph theory, information\nretrieval, mathematical model, partitioning, \nprobabilistic method, random sequencing, search techniques, tree structures\n", "1936": "Variable Length Tree Structures Having Minimum Average Search Time Sussenguth suggests in a paper (1963) that a\nfile should be organized as a doubly-chained tree \nstructure if it is necessary both to search and to update\nfrequently.  Such a structure provides a compromise \nbetween the fast search/slow update characteristics of\nbinary searching and the slow search/fast update \ncharacteristics of serial searching.  His method, however,\ncontains the limiting restriction that all \nterminal nodes lie on the same level of the tree.  This paper\nconsiders the effect of relaxing this restriction. \n First, trees which have the property that a priori the\nfilial set of each node is well defined are studied. \n It is proved that coding the nodes within each filial\nset with respect to the number of terminal nodes \nreachable from each is necessary and sufficient to guarantee\nminimum average search time.  Then the more \ngeneral case (that is, where the entire structure of\nthe tree is changeable) is treated.  A procedure \nis developed for constructing a tree with a minimum\naverage search time.  A simple closed expression \nfor this minimum average search time is obtained as\na function of the number of terminal nodes.  The \nstorage capacity required to implement the doubly-chained\ntree structure on a digital computer is also \ndetermined.  Finally, the total cost of the structure,\nusing Sussenguth's cost criterion, is computed. \n It is shown that significant improvements in both\nthe average search time and the total cost can be \nobtained by relaxing Sussenguth's restriction that all\nterminal nodes lie on the same level of the tree.\n information retrieval, file searching, tree structures, double chaining\n", "1937": "CODAS: A Data Display System CODAS, a Customer Oriented Data System, is\na user-oriented data retrieval and display system. \n The command language of the system provides the user\nwith an easy means for specifying data retrieval \nand display requests.  Data is displayed as tables and\ngraphs produced in a format ready for publication. \n In this paper the statements of the request language\nand the general system design are described.\n data display, information retrieval, graphic display,\ncommand languages, report program generation, \nmanagement data processing\n", "1938": "Some Criteria for Time-Sharing System Performance Time-sharing systems, as defined in this article,\nare those multiaccess systems which permit \na terminal user to utilize essentially the full resources\nof the system while sharing its time with other \nterminal users.  It is each terminal user's ability\nto utilize the full resources of the system that \nmakes quantitative evaluation of time-sharing systems\nparticularly difficult.  Six criteria are described \nwhich have been successfully used to perform first-level\nquantitative time-sharing system performance \nevaluation.\n time-sharing performance criteria, time-sharing\nsystem operation, time-sharing performance analysis\n", "1939": "Directed Random Generation of Sentences The problem of producing sentences of a transformational\ngrammar by using a random generator \nto create phrase structure trees for input to the lexical\ninsertion and transformational phases is discussed. \n A purely random generator will produce base trees\nwhich will be blocked by the transformations, and \nwhich are frequently too long to be of practical interest.\n A solution is offered in the form of a computer \nprogram which allows the user to constrain and direct\nthe generation by the simple but powerful device \nof restricted subtrees.  The program is a directed\nrandom generator which accepts as input a subtree \nwith restrictions and produces around it a tree which\nsatisfies the restrictions and is ready for the \nnext phase of the grammar.  The underlying linguistic\nmodel is that at Noam Chomsky, as presented in \nAspects of the Theory of Syntax.  The program is written\nin FORTRAN IV for the IBM 360/67 and is part\nof a unified computer system for transformational grammar.\n It is currently being used with several partial \ngrammars of English.\n transformational grammar, natural language syntax, language\nprocessing, sentence generation, computational \nlinguistics, syntax\n", "1940": "Calculation of a Polynomial and its Derivative function, evaluation, polynomial evaluation,\nALGOL procedure, Horner's scheme\n", "1941": "F-Distribution (Algorithm 322 [S14]) Fisher's F-distribution, Students's t-distribution\n", "1942": "Finding a Solution of N Functional Equations functional equations, interpolation, nonlinear equations, secant method\n", "1943": "Complete Elliptic Integrals (Algorithm 165 [S21]) special functions, complete elliptic integral\nof the first kind, complete elliptic integral of \nthe second kind\n", "1944": "Student's t-Distribution (Algorithm 344 [S14]) Student's t-Distribution, t-test, small-sample\nstatistics, distribution function\n", "1945": "The Role of Programming in a Ph.D. Computer Science Program In this general paper the role of programming\nin advanced graduate training is discussed.  \nSubject matter related to programming as well as programming\nper se is considered.  The  importance and \napplication of formalism are considered and also the\nneed for good empirical experimentation.  A brief \noutline for a sequence of courses is included, and subject\nheadings that have been obtained from an extensive \nbibliography are given.  A bibliography of programming references is included.\n graduate-level programming, graduate programs, course\ncontent, course sequence, graduate curriculum, \nprogramming research topics, programming bibliography\n", "1946": "Computing Polynomial Resultants: Bezout's Determinant Algorithms for computing the resultant of two\npolynomials in several variables, a key repetitive \nstep of computation in solving systems of polynomial\nequations by elimination, are studied.  Determining \nthe best algorithm for computer implementation depends\nupon the extent to which extraneous factors are \nintroduced, the extent of propagation of errors caused by\ntruncation of real coefficients, memory requirements, \nand computing speed.  Preliminary considerations narrow\nthe choice of the best algorithm to Bezout's \ndeterminant and Collins' reduced polynomial remainder sequence\n(p.r.s.) algorithm.  Detailed tests performed \non sample problems conclusively show that Bezout's determinant\nis superior in all respects except for \nunivariate polynomials, in which case Collins' reduced\np.r.s. algorithm is somewhat faster.  In particular \nBezout's determinant proves to be strikingly superior in\nnumerical accuracy, displaying excellent stability \nwith regard to round-off errors. Results of tests are reported in detail.\n resultant algorithm, g.c.d. algorithm, polynomial\nresultant, elimination, Bezout's determinant, \nSylvester's determinant, reduced p.r.s. algorithm, Euclidean\nalgorithm, multivariate polynomial equations\n", "1947": "Object code Optimization Methods of analyzing the control flow and data\nflow of programs during compilation are applied \nto transforming the program to improve object time efficiency.\n Dominance relationships, indicating which \nstatements are necessarily executed before others, are\nused to do global common expression elimination \nand loop identification.  Implementation of these and other\noptimizations in OS/360 FORTRAN H are described.\n compilers, data flow analysis, dominance, efficiency,\nFORTRAN,  graph theory, loop structure, machine \ninstructions, object code, optimization, redundancy\nelimination, register assignment, System/360\n", "1948": "Computers in Group Theory: a Survey Computers are being applied to an increasingly\ndiverse range of problems in group theory.  \nThe most important areas of application at present are\ncoset enumeration, subgroup lattices, automorphism \ngroups of finite groups, character tables, and commutator\ncalculus.  Group theory programs range from \nsimple combinatorial or numerical programs to large\nsymbol manipulation systems.  In this survey the \nmore important algorithms in use are described and contrasted,\nand results which have been obtained using \nexisting programs are indicated.  An extensive bibliography is included.\n group theory, coset enumeration, subgroup lattices,\nautomorphism groups, character tables, commutator \ncalculus, topology, crystallography, permutation groups,\nAbelian groups, discrete mathematics, non-numerical \nprogramming, symbol manipulation, survey\n", "1949": "Finiteness Assumptions and Intellectual Isolation of Computer Scientists Algol vs. Fortran, finiteness assumptions, intellectual isolation,\ninteger variable range, memory finiteness, finite word size\n", "1950": "Efficient Handling of Binary Data binary variables, dummy variables, bit strings, cross-tabulations\n", "1951": "Estimates of Distributions of Random Variables A study of multiaccess computer communications has\ncharacterized the distributions underlying an elementary\n model of the user-computer interactive process.  The model used is\nelementary in the sense that many of the random variables that\ngenerally are of interest in computer communications studies can be\ndecomposed into the elements of this model.  Data were examined\nfrom four operational multiaccess systems, and the model is shown to\nbe robust; that is each of the variables of the model has the\nsame distribution independent of which of the four systems is being examined. \nIt is shown that the gamma distribution can be used to\ndescribe the discrete variables.  Approximations to the gamma distribution\nby the exponential distribution are discussed for the systems studied.\n computer communications, time-sharing,\noperating systems, optimization models\n", "1952": "Index by Subject to Algorithms, 1970", "1953": "Exponential Integral Ei(x) (Algorithms 385 $S13)) ANSI Fortran standard\n", "1954": "Eigenvalues and Eigenvectors of a Real real symmetric matrix, eigenvalues, eigenvectors, QR algorithm\n", "1955": "Characteristic Values and Associated Solutions of Mathieu's differential equation, Mathieu function, characteristic\nvalue, periodic solution, radial solution\n", "1956": "Optimum Merging from Mass Storage An algorithm is displayed which yields the merge orders such that the total\nread time, defined to be the sum of seek time plus data-transfer\ntime, is minimized for a sort using mass storage. The analysis is\nparameterized in terms of the ratio of seek time to the time it takes\nto fill available core with records, and the file size in units\nof core lengths; and thus it can be applied to any conventional\nCPU/mass storage combination.  An explicit formula for total read\ntime is derived, in terms of the parameters, which correlates very\nwell with the total read time calculated using the optimum merge\norders yielded by the algorithm.  The formula involves the roots of a simple \ntranscendental equation.  A short table of these roots\nis included.  Numerical results are graphically displayed for a wide\nrange of the parameters.  It is found that the normalized read\ntime for optimum merging on a given hardware configuration is proportional\nto the file length times the logarithm of the file length.\n sorting, merging, optimum merging, mass storage,\nsort timing, drum-merging, access time\n", "1957": "The List Set Generator: A Construct for Evaluating Set Expressions The list set generator is defined and algorithms\nfor its use are given.  The list set generator is\na construct which may be added to a list processing system or any\nsystem that handles sets.  It efficiently generates the set which\nresults from any expression involving sets and set operators.  The\nefficiency derives from evaluating the expression as a whole and\nin parallel, rather than evaluating subexpressions and\nthen using those sets to arrive at the final result.\n set manipulating, list processing, set\ngeneration, sets, lists, file processing\n", "1958": "Improving Round-off in Runge-Kutta Computations with Gill's Method A Runge-Kutta-Gill scheme in common use is based on an incomplete\nadaptation for floating point operations of Gill's method.  An\nimproved version reduces round-off error significantly.  In this note\nthe heart of the scheme is presented in Fortran language.  It is\nthen shown how an improved version of the method can be obtained with\nthe addition of two Fortran statements.  The two version is a\nsignificant improvement.  A numerical example comparing the two is included.\n Runge-Kutta methods, ordinary differential\nequations, round-off error, error analysis\n", "1959": "An Interrupt Based Organization for Management Information Systems A programming structure, language constructs, and a supervisory system \norganization are proposed\nfor the design and coding of large shared data base systems.  The\nbases for this organization are a generalized interrupt structure\nand the newly introduced concept of \"file tagging,\" which is the\nprocess of associating program structures and interrupt generating\nconditions with items in the data base.  An algorithm for resolving\nconflicts which arise in scheduling the interrupt processing routines\nis presented.  DPL, a programming language and supervisory\nsystem in which these concepts are implemented, is used to illustrated\nthe new organization which is proposed for management information systems.\n management information systems, integrated data processing,\nsupervisors, interrupts monitoring systems, supervisory\nsystems, interrupt scheduling, parallel processing\n", "1960": "Process Management and Resource Sharing in the Multiaccess System ESOPE The main design principles of the multiaccess system ESOPE are described.\nEmphasis is placed on basic ideas underlying the design rather\nthan on implementation details.  The main features of the system\ninclude the ability given to any user to schedule his own parallel\nprocesses using system primitive operations, the file-memory relationship,\nand the allocation-scheduling policy, which dynamically\ntakes into account recent information about user behavior.\n time-sharing, multiprogramming, process scheduling, resource allocation\n", "1961": "An Efficient Search Algorithm to Find the Elementary Circuits of a Graph A theoretically most efficient search algorithm is presented\nwhich uses an exhaustive search to find all of the elementary\ncircuits of a graph.  The algorithm can be easily modified to find all\nof the elementary circuits with a particular attribute such as\nlength.  A rigorous proof of the algorithm is given as well as an example\nof its application.  Empirical bounds are presented relating\nthe speed of the algorithm to the number of vertices and the number\nof arcs.  The speed is also related to the number of circuits\nin the graph to give a relation between speed and complexity.\nExtensions to undirected and s-graphs are discussed.\n algorithm, graph theory, circuit search\nalgorithm, path search algorithm, searching\n", "1962": "GROOVE-A Program to Compose, Store, and Edit Functions of Time A program which makes possible creating, storing, reproducing,\nand editing functions of time is described.  The functions are typical\nof those generated by human beings.  Multiple functions (up to 14)\nare produced for long periods of time (up to several hours) at\nsufficiently high sampling rates to describe fast human reactions\n(up to 200 samples per second).  The functions can be used for a\nvariety of purposes such as the control of machine tools or sound\nsynthesizers or anything a person normally controls.  The program\noperates on a small computer (DDP-224).  Functions are stored on a\ndisk file.  Functions may be created by real-time human inputs to\nthe computer which can interact with already stored functions and\ncomputed functions.  Real-time feedback from the process being\ncontrolled is an important link in the system.  The environment for\neffective man-machine interaction has been carefully nurtured.\n computer music, music, real-time control, digital control, time\nfunctions, interactive software, hybrid systems, conductor program\n", "1963": "Condition Numbers of PEI Matrices matrices, condition numbers, Pei matrices, eigenvectors, eigenvalues\n", "1964": "Comment on the Working Set Model for Program Behavior demand paging, working set, paging rate, multiprogramming\n", "1965": "Correction to \"Logical\" Arithmetic on Computers binary arithmetic, unsigned operand arithmetic, maximum\nsignificance arithmetic, full-precision arithmetic\n", "1966": "A Generalized Method for Generating Argument/Function Values mapping function, decision hierarchy, table look-up\n", "1967": "An Improved Algorithm to Produce Complex Primes (Algorithm 401 $A1)) number theory, prime numbers, complex numbers\n", "1968": "Eigenvalues and Eigenvectors of a Real eigenvalues, eigenvectors, latent roots, Householder's\nmethod, QR algorithm, inverse iteration\n", "1969": "Increasing the Efficiency of Quicksort (Algorithm 402 $M1)) sorting, quicksort \n", "1970": "Unrecorded Magnetic Tape for Information Interchange (9 Track-200 and input-output, magnetic tape, information interchange,\nmeasurement, instrumentation, phase encoded recording \n", "1971": "Recorded Magnetic Tape for Information Interchange (1600 input-output, magnetic tape, information interchange,\nmeasurement, instrumentation, phase encoded recording \n", "1972": "A  Nonrecursive List Compacting Algorithm  A simple nonrecursive list structure compacting scheme or garbage \ncollector suitable for both compact and LISP-like list structures is presented.\nThe algorithm avoids the need for recursion by using the partial structure as \nit is built up to keep track of those lists that have been copied.\n list compacting, garbage collection, compact list, LISP\n", "1973": "The Linear Quotient Hash Code A new method of hash coding is presented and\nis shown to possess desirable attributes.  Specifically, the algorithm\nis simple, efficient, and exhaustive, while needing little\ntime per probe and using few probes per lookup.  Performance\ndata and implementation hints are also given.\n hashing, hash code, scatter storage, calculated\naddress, search, table, lookup, symbol table, keys\n", "1974": "NEATER2: A PL/I Source Statement Reformatter NEATER2 accepts a PL/I source program and operates on it to produce\na reformatted version.  When in the LOGICAL mode, NEATER2 indicates\nthe logical structure of the source program in the indentation\npattern of its output.  Logic errors discovered through NEATER2\nlogical analysis are discovered much more economically than is possible\nthrough compilation and trial runs.  A number of options are\navailable to give the user full control over the output format and\nto maximize the utility of NEATER2 as an aid during the early\nstages of development of a PL/I source deck.  One option, USAGE, causes\nNEATER2 to insert into each logical unit of coding a statement\nwhich will case the number of times each one is executed to be recorded\nduring execution.  This feature is expected to provide a\nmajor aid in optimization of PL/I programs.\n logical analysis of PL/I source, reformatting of PL/I\nsource, documentation aid, execution time usage data\n", "1975": "A Multiple-Precision Division Algorithm A generalized division algorithm for use with positive integral operands is \npresented.  Depending upon the algebraic relationship of the first\ntwo ciphers of the divisor, one or at most two adjustments to the original \ndivisor and dividend must be performed before the division operation can be \ninitiated. The uniqueness of this method will cause each trial cipher in the \nquotient to be either equal to or one greater than its final replacement.\n multiple-precision, division, adjustment, generalize\n", "1976": "Multi-attribute Retrieval with Combined Indexes In this paper a file organization scheme designed to\nreplace the use of the popular secondary index filing scheme\n(or inverted files on secondary key fields) is described.\nThrough the use of redundancy and storing \nkeys (or access numbers of the records) that satisfy different combinations\nof secondary index values in \"buckets,\" it is possible to retrieve\nall keys satisfying any input query derived from a subset of\nfields by a single access to an index file, although each bucket may\nbe used for many combinations of values and a combination of\nbuckets may be required for a given query.  The method which, in its\ndegenerate case, becomes the conventional secondary index filing\nscheme works similarly but has the following advantages: (1) the elimination\nof multiple accesses in many cases; (2) the elimination\nof false drops; (3) the elimination of computer time to perform intersection\nof key sets each qualified for one secondary index field\nonly; and (4) the avoidance of long strings of keys when an index\nfield appearing in a query has very few possible values.  Redundancy, in some \ncases, is the same as the secondary indexing method. In the general case, \ntrade-off between the number of accesses for query and redundancy exists.\n file organization, secondary index files, inverted files, information\nretrieval, data management, access method, secondary \nkeys, storage with buckets, rapid retrieval, balanced filing scheme, elimination\nof false drops, combining indexes, query, multi-attribute retrieval\n", "1977": "An Interactive Display for Approximation by Linear Programming An interactive program\nwith a graphical display has been developed for the approximation of\ndata by means of a linear combination of functions (including\nsplines) selected by the user.  The coefficients of the approximation\nare determined by linear programming so as to minimize the error\nin either the L1 or L-infinity norm.  Auxiliary conditions such as\nmonotonicity or convexity of the approximation can also be imposed. This\ninteractive system is described and several examples of its use are given.\n approximation, data fitting, functional approximation, linear\nprogramming, interactive graphical display, spline functions\n", "1978": "The Use of Interactive Graphics To Solve Numerical Problems With the advent of on-line (time-sharing) computer systems\nand graphic terminals, we have available a new dimension\nin numerical problem solving capabilities.  Rather than simply use\nthe new power to achieve fast turnaround, we can develop interactive\nroutines which are easy to use and also take advantage of the\ninsight and visual capabilities of the human problem solver.  Several\non-line systems for general purpose mathematical problem solving\nhave already been implemented as well as some special purpose\nsystems for solving problems in a particular area such as ordinary\ndifferential equations.  The advantage of restricting the problem\narea is that the interface with a user can be greatly simplified.\nIn this paper we discuss some of the advantages accrued by such\nsystems and design considerations for interactive routines.  Furthermore,\nan implementation of an on-line least squares data-fitting\nprogram, PEG, is presented with results obtained from empirical\ndata.  In conclusion, area for future work in this field are discussed.\n interactive graphics, computer graphics, graphics, least squares,\ndata-fitting, interactive computing, on-line mathematics\n", "1979": "Numerical Inversion of Laplace Transforms (Algorithm 368 $D5)) Laplace transform inversion, integral transformations, integral equations\n", "1980": "An Efficient Algorithm for Sorting with sorting, ranking, minimal storage sorting, digital computer sorting\n", "1981": "Normal Curve Integral (Algorithm 304 $S15)) normal curve integral, probability, special functions\n", "1982": "Modified Havie Integration (Algorithm 400 $D1)) numerical integration, Havie integration, Romberg quadrature,\nmodified Romberg-quadrature, trapezoid values, rectangle values\n", "1983": "Spanning Tree $H) (Algorithm 399) graph, tree, spanning tree\n", "1984": "Tableless Date Conversion $Z) (Algorithm 398) date, calendar\n", "1985": "An Integer Programming Problem $H) (Algorithm 397) integer programming, change making problem\n", "1986": "Student's t-Quantiles $S14) (Algorithm 396) Student's t-statistic, quantile, asymptotic approximation\n", "1987": "Student's t-Distribution $S14) (Algorithm 395) Student's t-statistic, distribution function,\napproximation, asymptotic expansion\n", "1988": "A Formalism for Translator Interactions A formalism is presented for describing the actions\nof processors for programming languages-compilers,\ninterpreters, assemblers-and their interactions in complex systems\nsuch as compiler-compilers or extendible languages.\nThe formalism here might be used to define and answer such a\nquestion as \"Can one do bootstrapping using a meta-compiler \nwhose metaphase is interpretive?\"  In addition an algorithm\nis presented for deciding whether or not a given system can\nbe produced from a given set of component processors.\n translator, compiler, interpreter, bootstrapping,\nlanguage processor, compiler-compiler\n", "1989": "Transition Network Grammars for Natural Language Analysis The use of augmented transition network grammars for the analysis\nof natural language sentences is described.  Structure-building\nactions associated with the arcs of the grammar network allow for the reordering,\nrestructuring, and copying of constituents necessary to produce\ndeep-structure representations of the type normally obtained from a\ntransformational analysis, and conditions on the arcs allow for a\npowerful selectivity which can rule out meaningless analyses and take\nadvantage of semantic information to guide the parsing.  The\nadvantage of this model for natural language analysis are discussed\nin detail and illustrated by examples.  An implementation of an\nexperimental parsing system for transition network grammars is briefly \ndescribed.\n computational linguistics, grammars, grammar models, linguistics,\nnatural language analysis, parsing, semantic interpretation,\ntransition network grammars, transformational grammars\n", "1990": "Numerical Constants (Algorithm) numerical algorithm, numerical constants\n", "1991": "On the Number of Automorphisms of a Singly Generated Automaton automata, finite automata, singly generated automata, automorphisms,\ngenerators, length of state, minimal-length generators, orbit\n", "1992": "Comment on Bell's Quadratic Quotient Method for Hash Code Searching hashing, hash code, scatter storage, calculated address,\nclustering, search, symbol table, keys, table look-up\n", "1993": "Regular Coulomb Wave Functions (Algorithm 292 $S22)) Coulomb wave functions, wave functions, regular Coulomb wave functions\n", "1994": "Decision Table Translation $H) (Algorithm 394) Decision table, decision table translation\n", "1995": "Special Series Summation with Arbitrary Precision $C6) (Algorithm 393) function evaluation, series summation, approximation\n", "1996": "Systems of Hyperbolic PDE $D3) (Algorithm 392) hyperbolic p.d.e., characteristic, extrapolation,\nsecond order p.d.e., quasilinear p. d. e.\n", "1997": "Increasing the Efficiency of Quicksort A method is presented for the analysis of various generalizations of\nquicksort.  The average asymptotic number of comparisons needed is shown\n to be an log^2(n).  A formula is derived expressing a in terms of\nthe probability distribution of the \"bound\" of a partition.  This\n formula assumes a particularly simple form for a generalization already\nconsidered by Hoare, namely, choice of the bound as median\nof a random sample. The main contribution of this paper is another\ngeneralization of quicksort, which uses a bounding interval instead\nof a single element as bound.  This generalization turns out to\nbe easy to implement in a computer program.  A numerical approximation\nshows that a = 1.140 for this version of quicksort compared with\n1.386 for the original.  This implies a decrease in number of comparisons of \n18 percent; actual tests showed about 15 percent saving in computing time.\n sorting, quicksort, information content, entropy, distribution of median\n", "1998": "Complex Matrix Inversion Versus Real A comparison of complex matrix with real matrix inversion\nis made.  It is shown that the complex inversion can be up to \ntwice as fast as the real inversion.  Further, the rounding error\nbound for complex inversion is about one-eighth that of real,\nfor Gaussian elimination.  Using extended inner product\naccumulation the bound is half of the real system.\n complex matrix inversion, matrix inversion, inversion, rounding errors,\nrounding error bound, error bounds, complex rounding error bounds\n", "1999": "Optimal Starting Approximations for Generating On machine with slow or no division, it is preferable to\nuse an iterative scheme for the square root different from\nthe classical Heron scheme.  The problem of optimal initial \napproximants is considered, and some optimal polynomial initial \napproximations are tabulated.\n square root, Newton-Raphson iteration, optimal approximants\n", "2000": "A Variation of the Goodman-Lance Method for A recently published method for the interpolative\nsolution of nonlinear equations is improved,\nand applied to give a significant variation of the Goodman-Lance\nmethod for the solution of two-point boundary value problems. \nThe resulting method applies in particular to the numerical solution\nof optimal control problems in the Euler-Lagrange formulation.\nQuantitative estimates are presented which indicate that the variation\nis nearly twice as fast on some problems in the latter context.\n Goodman-Lance, boundary-value problems,\nNewton's method, nonlinear equations,\noptimal control, optimization, ordinary differential equations,\nsecant method, interpolative solution, orthogonal matrices\n", "2001": "Integrating Square Roots Differential equation of the (y')^2 = f(y) are difficult to integrate \nnumerically because of the singularity at points where f(y) vanishes.  A \nsimple trick removes the singularity.\n quadrature, differential equations\n", "2002": "AMESPLOT-A Higher Level Data Plotting Software System AMESPLOT is an extensible software system designed to make the display of \ndata as simple, painless, and neat as possible.  The system described is \nhardware-independent and has been implemented on a variety of installations,\nof different manufacturers, having diverse configurations.  The elements \ncommon to all types of data plots are outlined and the way in which these \nelements may be combined into a system based on simple modules is demonstrated.\nThese modules are specified independently and are independent of the axis\nsystems or other attributes of the plot.  This enables plots of any\ncomplexity to be constructed by adding or replacing modules.  The\nbasic syntax of AMESPLOT is outlined, and a brief description is given\nof its current utility software, consisting of \"macros\" to produce\nself-scaled plots, formal tablets of text-interspersed with subplots,\nmap coastlines, and 3-D plots.  The system was formulate\nd in a way such that the user could supply the minimum of information,\nand it should be fully integrable with user's program written\nin most conventional higher languages.  The functions of positioning,\nlocating, and scaling (in the layout of multiple subplots) of\naxes, labels, and all other elements of the plot are handled automatically\nby the software system unless the user specifies otherwise.  The structuring \nof plots from multiple, independent, self-contained subplots is described.\nTransformation, projection, scaling, rotation, or shifting of entire plots or \nsubplots by the action of one or more simple modules is possible.  The user \nmay interact freely with AMESPLOT at three levels, enabling him to construct \nhis own data markers, alphabetic characters, and transformations, and\nto produce a variety of artistic and other effects.\n computer graphics, data potting, data display\nsyntax, hardware independent software,\ndisplay device independent software, plot elements, self-scaled plots,\nuser interaction, tablet organization, map display, projection\n", "2003": "An Interactive Software System for Computers-Aided The characteristics of an interactive software system, intended to constitute \nan interface between designer and computer during various steps of\nthe design process, are presented.  The main emphasis is given to the\ndescription of the features of the two high level user oriented\nlanguages, operating at different levels, on which the interaction\nis based.  The first one is IMOL, an interactive monitor language,\nwhich is designed to perform the overall and control functions\nof the software system; its design criteria provide the user with\ncommands which are both simple and efficient in order to perform all\nthe functions needed in computer-aided circuit design.  The second one is \nCOIF, a circuit oriented graphic language, which is designed\nto describe, generate, and manipulate graphic problem specifications; \nit is an  extension of Fortran with graphic-type variables,\nso that the designer who is familiar with Fortran need not learn a new \nlanguage.  The application to computer-aided circuit design\nis in particular examined; on the other hand, the adopted design\ncriteria provide sufficient generality to extend the use of the two languages \nto different computer-assisted applications.\n interaction, graphics, computer graphics, computer-aided design, circuit\ndesign, software system, software organization, language,\nmonitor language, graphic language, extended Fortran\n", "2004": "A Procedure for Generation of Three-dimensional A description is given of an algorithm for producing computer generated \nhalf-tone presentations of three-dimensional polygonal surface structures.  \nThis algorithm achieves a significant increase in speed of computation over \nthe Warnock algorithm developed at the University of Utah and implemented\nalso on the Coordinated Science Laboratory CDC 1604 computer\nsystem at the University of Illinois.  The history leading to the algorithm\ndevelopment and then the algorithm itself are described.\nResults are presented and are compared with computer runs achieved\nby the Warnock approach.  An extension of the procedure to variable position\nillumination sources is also given.\n half-tone computer graphics, line-scan image processing,\nhidden surface, polygonal surface structure presentations\n", "2005": "Proposed Revision of American National Standard X3.21-1967, tabulating-card, Hollerith card, keypunch, information processing\n", "2006": "Proposed American National Standard State identifiers, State abbreviation, States of the United States, data \nelements, data codes, numeric codes, geopolitical subdivisions, geographic codes\n", "2007": "Algorithms Policy/Revised August 1970", "2008": "Gaussian Quadrature Formulas (Algorithm 331 $D1)) quadrature, Gaussian quadrature, numerical integration, weight function,\northogonal polynomials, Newton's method, successive deflation\n", "2009": "Simpson's Rule for Multiple Integration (Algorithm 233 $D1)) numerical integration, multiple integration, Simpson's rule\n", "2010": "Unitary Symmetric Polynomials $Z) (Algorithm 391) symmetric polynomials, unitary symmetric polynomials\n", "2011": "Sequency Ordered Walsh Functions $S22) (Algorithm 390) Walsh functions, sequency ordered Walsh functions\n", "2012": "Binary Ordered Walsh Functions $S22) (Algorithm 389) Walsh functions, binary ordered Walsh functions\n", "2013": "Rademacher Function $S22) (Algorithm 388) Rademacher function\n", "2014": "Function Minimization and Linear Search $E4) (Algorithm 387) function minimization, relative minimum, quasi-Newton method\n", "2015": "A Technique for Generating Almost Optimal A technique is developed for generating almost optimal Floyd-Evans productions \ngiven a precedence grammar. A graph formulation is used for the problem of \nmerging productions.  The productions generated correspond to the minimum cost \ninverse-arborescence of that graph.  The validity of the technique is\ndemonstrated for weak precedence grammars defined here, but the productions\nmechanically generated for any precedence grammar can often be modified in \nsuch a way that correct, almost optimal parsers are obtained.\n translator writing systems, syntactic analysis, Floyd-Evans\nproductions, precedence grammars, translator optimization,\nmerger algorithm, minimum cost inverse-arborescence, graph theory\n", "2016": "The Instrumentation of Multics An array of measuring tools devised to aid in the implementation of a prototype\ncomputer utility is discussed.  These tools include special hardware\nclocks and data channels, general purpose programmed probing\nand recording tools, and specialized measurement facilities.  Some\nparticular measurements of interest in a system which combines demand \npaging with multiprogramming are described in detail.  Where appropriate, \ninsight into effectiveness (or lack there of) of individual tools is provided.\n instrumentation, performance measurement,\nmultiprogramming systems, measuring tools, system analysis, Multics,\nmetering, event tracing, demand paging, script driven\nmeasurement\n", "2017": "Sorting in a Paging Environment This sorting study was part of an extensive measurement project\nundertaken on the M44/44X, an experimental paging system which was\nconceived and implemented at IBM Research in order to explore the\nvirtual machine concept.  The study was concerned with the implementation \nof sorting procedures in the context of the dynamic paging\nenvironment characteristic of virtual memory machines.  Descriptions of \nthe experimental sort programs and analysis of the performance\nmeasurement results obtained for them are presented. The insight gained \nfrom the experimental effort is used to arrive at a set of\nbroad guidelines for writing sort programs for a paging environment.\n sorting, merging, virtual machines, paging systems, dynamic\nstorage allocation, measurement of systems program behavior,\nperformance evaluation, memory management\n", "2018": "Full Table Quadratic Searching for Scatter Storage The quadratic residue search method for hash tables avoids much\nof the clustering experienced with a linear search method.  The simple\nquadratic search only accesses half the table.  It has been shown\nthat when the length of the table is a prime of the form 4n+3, where n \nis an integer, the whole table may be accessed by two quadratic\nsearches plus a separate access for the original entry point. A search \nmethod is presented which is computationally simple, has all the advantages \nof the quadratic search, and yet accesses all the table in one sweep.\n quadratic residue, search method, hash tables, scatter storage,\ndictionary look-up, quadratic search, searching, hashing,\nhash code, clustering, collisions\n", "2019": "Normalization Techniques for Hand printed Numerals Family of pattern standardization\ntechniques based on geometrical projection is applied to a file of\ndigitized hand printed numerals obtained from sales clerks. The\nprinciple involves transforming a quadrilateral specified in terms\nof the convex hull of each pattern into a square. The amount of\noverlap within each class of characters versus the amount between classes\nis used to evaluate the degree of normalization achieved with respect to other \npublished methods including size and shear normalization through moments.\n pattern recognition, character recognition, normalization,\nprojective transformation, central projection, hand\nprinted characters, handwriting, linear transformation,\nsize normalization, mapping, pattern preprocessor\n", "2020": "The Allocation of Computer Resources-Is Pricing the Answer? The widespread use of complex third generation computing systems has led to a \nmuch broader concern about the means by which the resources of these systems\nare allocated among the user community.  One means that is suggested\nmore and more frequently is a pricing procedure.  In this\npaper the manner in which one would like to allocate computing resources\nis considered, and then the extent to which a pricing mechanism fits this mold \nis discussed.  Inasmuch as pricing must serve as a rationing mechanism at \ntimes, consideration is given to the means by which prices can be adjusted \nflexibly in order to make a dynamic allocation of resources.  Consideration is \nalso given to the means by which users can be insulated from the harmful \neffects of frequent price fluctuations.  Although the subject of pricing has\nbeen given a lot of attention recently, a number of misconceptions\npersist about its purpose and its operation.  An attempt is made to clarify \nsome of these misunderstandings and to highlight the advantages and \ndisadvantages and to highlight the advantages and disadvantages of pricing. Two\nillustrative pricing systems are also discussed in order to demonstrate the \napplicability of pricing in quite different environments.\n allocation mechanisms, charging, computer pricing,\ncosting, flexible pricing, pricing, priority charges,\nresource allocation, user motivation\n", "2021": "A Comment on Axiomatic Approaches to Programming axiomatic method, proofs of programs,\nhomomorphic structure in programming\n", "2022": "Note on an Anomaly in Paging paging machines, demand paging, replacement algorithm\n", "2023": "A Note on Data Base Deadlocks data base, synchronization, locking, deadlock, reference count\n", "2024": "Comments on a Paper by Lowe automatic segmentation, program connectivity\n", "2025": "Student's t-Distribution; Jacobi Polynomials; Fortran standards\n", "2026": "Exponential Integral (Algorithm 385 $S13))", "2027": "Ricatti-Bessel Functions of First and Second Kind (Algorithm 22 $S17)) Ricatti-Bessel functions, Bessel functions\nof fractional order, spherical Bessel functions\n", "2028": "Greatest Common Divisor of n Integers greatest common divisor, Euclidean algorithm,\nnumber theory, diophantine equations\n", "2029": "Exponential Integral $S13) (Algorithm 385) exponential integral, special functions, rational Chebyshev approximation\n", "2030": "Context-Sensitive Parsing This paper presents a canonical form for context-sensitive\nderivations and a parsing algorithm which finds\neach context-sensitive analysis once and only once.  The amount of memory\nrequired by the algorithm is essentially no more than the required to \nstore a single complete derivation.  In addition, a modified\nversion of the basic algorithm is presented which blocks infinite analyses \nfor grammars which contain loops.  The algorithm is\nalso compared with several previous parsers for context-sensitive\ngrammars and general rewriting systems, and the difference between\nthe two types of analyses is discussed.  The algorithm appears to\nbe complementary to an algorithm by S. Kuno in several respects, including \nthe space-time trade-off and the degree of context dependence involved.\n context-sensitive grammars, context-sensitive parsing, formal grammars,\nformal language theory, parsing, parsing algorithms, recognition algorithms\n", "2031": "Algorithm and Bound for the Greatest Common Divisor of n Integers A new version of the Euclidean\nalgorithm for finding the greatest common divisor of n integers a(i)\nand multipliers x(i) such that gcd = x(1)a(1) + ... + x(n)a(n)\nis presented.  The number of arithmetic operations and the number\nof storage locations are linear in n.  A theorem of Lame that gives a bound \nfor the number of iterations of the Euclidean algorithm for two integers \nis extended to the case of n integers.  An algorithm to construct a minimal \nset of multipliers is presented.  A Fortran program for the algorithm appears \nas Comm. ACM Algorithm 386.\n greatest common divisor, Euclidean algorithm,\nnumber theory, diophantine equations\n", "2032": "File Structures Using Hashing Functions A general method of file structuring is proposed which uses a hashing\nfunction to define tree structure.  Two types of such trees are examined, \nand their relation to trees studied in the past is explained.Results for the \nprobability distributions of path lengths are derived and illustrated.\n Data structures, tree structures, file structures, scatter\ntables, hashing functions, information retrieval\n", "2033": "Space/Time Trade-offs in Hash Coding with Allowable Errors In this paper trade-offs among certain computational factors\na given set of messages.  Two new hash-coding methods are examined\nand compared with a particular conventional hash-coding method.\nThe computational factors considered are the size of the hash area\n(space), the time required to identify a message as a nonmember of the \ngiven set (reject time), and an allowable error frequency.  The new methods \nare intended to reduce the amount of space required to contain the hash-coded \ninformation from that associated with conventional methods.  The reduction in \nspace is accomplished by exploiting the possibility that a small fraction of \nerrors of commission may be tolerable in some applications, in particular, \napplications in which a large amount of data is involved and a core resident\nhash area is consequently not feasible using conventional methods.  In such \napplications, it is envisaged that overall performance\ncould be improved by using a smaller core resident hash area in\nconjunction with the new methods and, when necessary, by using some\nsecondary and perhaps time-consuming test to \"catch\" the small\nfraction of errors associated with new methods.  An example is discussed\nwhich illustrates possible areas of application for the new\nmethods.  Analysis of the paradigm problem demonstrates that allowing\na small number of test messages to be falsely identified as\nmembers of the given set will permit a much smaller hash\narea to be used without increasing reject time.\n hash coding, hash addressing, scatter storage, searching, storage\nlayout, retrieval trade-offs, retrieval efficiency, storage efficiency\n", "2034": "The Mobile Programming System: STAGE2 STAGE2 is the second level of a bootstrap sequence which\nis easily implemented on any computer.  It is a flexible,\nprovided by STAGE2 are summarized, and the implementation techniques\nwhich have made it possible to have STAGE2 running on a new\nmachine with less than one man-week of effort are discussed.  The approach\nhas been successful on over 15 machines of widely varying\ncharacteristics.\n bootstrapping, macro processing, machine independence,\nprogramming languages, implementation techniques\n", "2035": "Conversational Access to a 2048-Word Machine LAP6 is an on-line system running on a 2048-word LINC which provides full \nfacilities for text editing, automatic filing and file maintenance, and \nprogram preparation and assembly.  It focuses on the preparation and editing \nof continuously displayed 23,040-character text strings (manuscripts) which\ncan be positioned anywhere by the user and edited by simply adding\nand deleting lines as though working directly on an elastic scroll.\nOther features are available through a uniform command set which itself can \nbe augmented by the user.  The machine, although small,\naids program design by providing display scope and premarked\nrandomly addressable LINC tapes as standard items, in an environment\nsimilar to that of a sophisticated terminal.  The tapes are logically \nsimilar to a disk.  Priority was given to the design of efficient\ntape algorithms to minimize the limitations of the small memory.  Techniques \ndeveloped for handling scroll editing, filing, and the layered system \nstructure are outlined.  LAP6 is used by about 2000 people in 11 countries.  \nIts design was strongly influenced by performance criteria established in \ninterviews held with LINC users themselves during the specification period.\n conversational computer access,\ndisplay editing, display oriented system, filing algorithms, LAP6,\nlayering, LINC, man-machine communication, on-line editing, on-line efficiency,\non-line environment, scroll editing, small machine system, tape filing, tape \noriented system, text editing\n", "2036": "An Interactive Command Generating Facility A facility to permit conversationally controlled tasks\nto be executed in a noninteractive environment is proposed.\nA means by which programs can generate interactive time-sharing commands\nand receive the corresponding output response is presented.  The commands \nwill be invoked as if they had been typed at a console keyboard.  It is \nargued that this facility will help overcome some of the current limitations \nin man-computer communication. A set of functions to accomplish the above \nwhich could be embedded into any string processing language is suggested, \nand necessary information pertinent to implementation of the facility on \nexisting time-sharing systems is given.\n time-sharing, command languages, pseudo-teletype, interaction,\nconditional job control, operating systems\n", "2037": "Permutations of a Set with Repetitions (Algorithm 383 $G6)) permutations and combinations, permutations\n", "2038": "Combinations of M Out of N Objects (Algorithm 382 $G6)) permutations and combinations, permutations\n", "2039": "Permanent Function of a Square Matrix I and II (Algorithm 361 $G6)) matrix, permanent, determinant\n", "2040": "Modified Romberg Quadrature (Algorithm 351 $D1)) numerical integration, Romberg quadrature, modified Romberg quadrature, \ntrapezoid values, rectangle values\n", "2041": "Shellsort (Algorithm 201 $M1)) sorting, minimal storage sorting, digital computer sorting\n", "2042": "Treesort 3 (Algorithm 245 $M1)) The certification of an algorithm can take\nthe form of a proof that the algorithm is correct.  As an illustrative\nbut practical example, Algorithm 245, TREESORT 3 for sorting\nan array, is proved correct.\n proof of algorithms, debugging, certification,\nmetatheory, sorting, in-place sorting\n", "2043": "Eigenvalues and Eigenvectors of a Real real symmetric matrix, eigenvalues, eigenvectors, QR algorithm\n", "2044": "Permutations of a Set with Repetitions (Algorithm 383 $G6)) permutations and combinations, permutations\n", "2045": "Combinations of M Out of N Objects (Algorithm 382 $G6)) permutations and combinations, permutations\n", "2046": "A Relational Model of Data for Large Shared Data Banks Future users of large data banks must be protected from having to know how the \ndata is organized in the machine (the internal representation).  A prompting\nservice which supplies such information is not a satisfactory\nsolution.  Activities of users at terminals and most application\nprograms should remain unaffected when the internal representation\nof data is changed and even when some aspects of the external representation \nare changed.  Change in data representation will often be needed as a result \nof changes in query, update, and report traffic and natural growth in the \ntypes of stored information.  Existing noninferential, formatted data systems \nprovide users with tree-structured files or slightly more general network \nmodels of the data.  In Section 1, inadequacies of these models are discussed.\nA model based on n-ary relations, a normal form for data base relations,\nand the concept of a universal form for data base relations,\nand the concept of a universal data sublanguage are introduced.  In\nSection 2, certain operations on relations (other than logical\ninference) are discussed and applied to the problems\nof redundancy and consistency in the user's model.\n data bank, data base, data structure, data organization,\nhierarchies of data, networks of data, relations, derivability, \nredundancy, consistency, composition, join, retrieval\nlanguage, predicate calculus, security, data integrity\n", "2047": "Incorporating Origin Shifts into the QR The QR iteration for the eigenvalues of a symmetric tridiagonal matrix can \nbe accelerated by incorporating a sequence of origin shifts.  The origin shift\nmay be either subtracted directly from the diagonal elements of\nthe matrix or incorporated by means of an implicit algorithm.  Both\nmethods have drawbacks: the direct method can unnecessarily degrade small \neigenvalues, while the implicit method can effectively loose the shift and \nthereby retard the convergence.  This paper presents a new method which has \nneither drawback.\n eigenvalues, eigenvectors, QR method, origin\nshifts, symmetric tridiagonal matrix\n", "2048": "Comparison of Several Adaptive Newton-Cotes Quadrature Routines This report compares the performance of five different adaptive quadrature \nschemes, based on Newton-Cotes (2N + 1) point rules (N = 1, 2, 3, 4, 5), in\napproximating the set of definite integrals INTEGRAL$1/(x^2 + p^2)) dx with \nrelative accuracy e.\n adaptive Newton-Cotes quadrature, quadrature scheme comparison,\ndefinite integral evaluation, adaptive numerical in tegration, Newton-Cotes \nintegration, peaked integrand integration, quadrature efficiently\nplot, New-Cotes rules applications, Newton-Cotes rules modifications\n", "2049": "Accurate Floating-Point Summation This paper describes an alternate method for summing a set\nof floating-point numbers.  Comparison of the error bound for\nthis method with that of the standard summation method shows that it\nis considerably less sensitive to propagation of round-off error.\n summation, floating-point addition,\nround-off error, round-off propagation\n", "2050": "Automatic Parsing for Content Analysis Although automatic syntactic and semantic analysis is not yet possible for\nall of an unrestricted natural language text, some applications, of which \ncontent analysis is one, do not have such a stringent coverage requirement.\nPreliminary studies show that the Harvard Syntactic Analyzer can\nproduce correct and unambiguous identification of the subject and\nobject of certain verbs for approximately half of the relevant occurrences. \nThis provides a degree of coverage for content analysis variables which \ncompares favorably to manual methods, in variables which compares favorably \nto manual methods, in which only a sample of the total available text is \nnormally processed.\n Content analysis, parsing, syntactic analysis, natural language processing,\ninformation retrieval, language analysis, text processing\n", "2051": "A PL/I Program to Assist the Comparative Linguist A practical PL/I program is described which\ncan assist comparative linguists to determine\nthe regular sound correspondences between genetically related languages.\nThe investigator must arrange data for input by aligning pairs\nof suspected cognates.  The program tabulates the correspondences,\nand uses list processing techniques to sort and count them.\nEach pair of words is then assigned a relative value that is a function\nof the total frequency in the data of each correspondence found\nin that pair of words.  The output is a list of all correspondence\ntypes with their frequency of occurrence in the data, and a\nseparate listing of each correspondence with all word-pairs showing\nthat correspondence (unless their relative value is below an arbitrarily \nchosen cutoff point).  The article explains the usefulness,\nas well as the limitations, of the programs, and illustrates its\nuse with a small portion of hypothetical data.\n comparative linguistics, natural\nlanguage processing, comparative method, historical linguistics, diachronic\nlinguistics, genetic relationship, sound change, sound\ncorrespondence, regular correspondence, list processing\n", "2052": "Scheduling to Reduce Conflict in Meetings Conflicts in scheduling can be treated as defining an undirected linear graph \nindependently of the relation of the activities in conflict to additional \nconstraints of time and space.  Each connected component of such a graph,\nwhich can be found by an algorithm described by Gotlieb and Corneil, \ncorresponds to a set of events that must be scheduled at different times.\n allocation, conflict matrix, connected component, scheduling, spanning\ntree, undirected linear graph\n", "2053": "On the Conversion of Decision Tables to Computer Programs The use of execution time diagnostics in pinpointing ambiguities in decision\ntables is discussed.  It is pointed out that any attempt at resolving\nambiguities at compile time will, in general, be impossible.  It\nis shown that, as a consequence, tree methods of converting decision\ntables to programs are inadequate in regard to ambiguity detection.\nTwo algorithms for programming decision tables whose merits\nare simplicity of implementation and detection of ambiguities at\nexecution time are presented. The first algorithm is for limited entry\ndecision tables and clarifies the importance of proper coding\nof the information in the decision table.  The second algorithm programs\na mixed entry decision table directly without going through\nthe intermediate step of conversion to a limited entry form, thereby\nresulting in storage economy.  A comparison of the algorithms and others \nproposed in the literature is made.  Some features of a decision table\nto Fortran IV translator for the IBM 7044 developed by the authors are given.\n decision tables, diagnostic aids, system analysis, business applications\n", "2054": "On the Feasibility of Voice Input to An on-line digital computer processing system is considered in which an \nordinary telephone is the complete terminal device, input to the computer \nbeing provided as a sequence of spoken words, and output to the user being \naudio responses from the machine.  The feasibility of implementing such a \nsystem with a FORTRAN-like algebraic compiler as the object processor is \nconsidered.  Details of a specific word recognition program are given.  This \ntechnique depends on three simplifying restrictions, namely, a \"small\"\nvocabulary set, \"known\" speakers, and a \"moment of silence\"\nbetween each input word.  Experimental results are presented giving\nerror rates for different experimental conditions as well as the machine \nresources required to accommodate several users at a time. The results show \nthat at this time it is both economically and logically feasible to handle at \nleast 40 users at a time with an IBM 360/65 computer.\n speech recognition, word recognition, pattern-matching, pattern\nrecognition, time-sharing, remote access, voice input, speech input,\ntelephone input/output, acoustic signal, spoken-word input, talking to \ncomputers, man-machine interaction\n", "2055": "Subroutine to Perform In-Situ Transposition rectangular matrix, transpose\n", "2056": "Gomory (Algorithm 263A $H)) linear programming, integer variables, dual method\n", "2057": "Random Vectors Uniform in Solid Angle (Algorithm 381 $G5)) random number, random vector, random number generator, probability\ndistribution, frequency distribution, simulation, Monte Carlo\n", "2058": "In-Situ Transposition of a Rectangular Matrix (Algorithm 380 $F1)) rectangular matrix, transpose\n", "2059": "A Language for Treating Graphs A language for the representation of graph is described, and the formulation of \ngraph operations such as node and/or link deletion or insertion, union, \nintersection, comparison, and traversal of graphs is given.  Graphs\nare represented by linked lists.  The language is syntactically defined\nas an extension to ALGOL 60, and it is translated into ALGOL\nby means of a syntax-driven compiler.  Application areas for this language are\noperation research, network problems, control theory, traffic problems, etc.\n graphs, oriented, nonoriented, multiple,\ncolored graph, language extended ALGOL,\noperator-precedence, syntax-driven compiler,\noperation research, network, traffic\n", "2060": "GEDANKEN-A Simple Typeless Language Based on the GEDANKEN is an experimental programming language with the following \ncharacteristics.  (1) Any value which is permitted in some context of the \nlanguage is permissible in any other meaningful context.  In particular,\nfunctions and labels are permissible  results of functions and values\nof variables.  (2) Assignment and indirect addressing are formalized\nby introducing values, called reference, which in turn possess\nother values.  The assignment operation always affects the relation\nbetween some reference and its value,  (3) All compound data\nstructures are treated as functions.  (4) Type declarations are\nnot permitted.  The functional approach to data structures and the\nuse of references insure that any process which accepts some data\nstructure will accept any logically equivalent structure, regardless\nof its internal representation.  More generally, any data structure\nmay be implicit; i.e. it may be specified by giving an arbitrary\nalgorithm for computing or accessing its components.  The existence of \nlabel variables permits the construction of coroutines,\nquasi-parallel processes, and other unorthodox control mechanisms.\nA variety of programming examples illustrates the generality of the language.\nLimitations and possible extensions are discussed briefly.\n programming language, data structure, reference, assignment, coroutine,\nquasi-parallel process, typeless language, applicative language,\nlambda calculus, list processing, nondeterministic algorithm\n", "2061": "An Algorithm for the Construction Of Bounded-Context Parsers An algorithm is described which accepts an arbitrary context-free\ngrammar and constructs a bounded-context parser for\nit whenever such a parser exists.  In the first part of the paper\nthe definition of a context-free grammar and the working of a\nbounded-context parser are recalled.  The notion of reduction class for\na context-free grammar is then introduced and its connection with\nthe structure of a bounded-context parser is indicated.  Next,\npushdown automata which generate the different reduction classes\nof a context-free grammar are defined.  Finally, the algorithm is described;\nit essentially carries out an exhaustive study of all possible\nruns of the pushdown automata generating the reduction classes.\nIn the second part, the utility of the algorithm is discuss\ned in the light of the experience gained from its use in compiler design.\nThe algorithm is claimed to be particularly useful in the\nsimultaneous design of a language and a compiler for it.\n bounded-context parsing, bounded-context syntactic analysis, parser \nconstruction, syntactical analyzer construction, generators, compiler \ncompilers, compiler writing systems, translator writing systems metacompilers,\ncontext-free grammars, formal languages, pushdown automata\n", "2062": "The Application of Sequential Sampling Four different sequential sampling procedures are applied\nto the analysis of data generated by a computer simulation\nexperiment with a multi-item inventory model.  For each procedure\nthe cost of computer time required to achieve given levels of\nstatistical precision is calculated.  Also the cost of computer time\nusing comparable fixed sample size methods is calculated.  The\ncomputer costs of fixed sample size procedures versus\nsequential sampling procedures are compared.\n simulation, inventory models, sequential\nsampling, models, experimental design\n", "2063": "Translation Equations (Errata)", "2064": "Operations on Generalized Arrays with the Genie Compiler Operations on vectors, matrices, and higher dimensional storage arrays are \nstandard features of most compilers today.  The elements of such structures are\nusually restricted to be scalars.  For many sophisticated applications\nthis restriction can impose cumbersome data representations.\nAn efficient system has been devised and implemented which allows\nthe elements of multidimensional arrays to themselves be multidimensional\narrays.  This system was developed from a storage structure\nin which the location, length, and content of each array is described\nby a codeword which can be interpreted by the system.  Code words may describe \narrays containing more codewords, thus providing\nall needed descriptive information for hyperstructures of any form.\n multidimensional arrays, matrix operations,\nstorage control, subscripting, compilers\n", "2065": "A Programming System for the On-line Analysis of Biomedical Images A preliminary description of the software for a computer-display\nsystem is given with special emphasis on the  man-machine interaction. This \nsystem is intended for a wide variety of biomedical applications.\nAs an example, the methods are applied to the karyotyping of chromosomes.  The \nsystem is separated into four programming tasks: picture transformations, file \nmaintenance, picture structuring, and display management.  Picture structuring\nis considered as the vehicle for man-machine communication.\nA prototype data format for pictures, called a picture-form, is developed.\nStructure operators are defined which manipulate picture-forms to produce \nnew pictures-forms.  Many of the ideas are taken from the symbolic mathematical \nlaboratory at MIT conceived by Marvin Minsky.\n image processing, biomedical image processing, on-line image processing,\nsemiautomatic image processing, data structure, structure operators,\npicture processing, biomedical picture processing, on-line picture\nprocessing, semiautomatic picture processing, semiautomatic\nkaryotyping, karyotyping, list processing picture processing\n", "2066": "An Algol Construction for Procedures as Parameters of Procedures Algol, procedures, parameters, side effects\n", "2067": "Comment on Lawler's Multilevel Boolean Minimization multilevel logic design, generalized prime implicants,\nminimal forms, minimization, incompletely\nspecified functions\n", "2068": "Comment on Multiprogramming Under a Page on Demand Strategy multiprogramming, paging, modeling\n", "2069": "Comments on a Paper by Wallace and Mason page-on-demand, demand paging, time-sharing multiprogramming,\nMarkovian computer models, scheduling strategies,\noperating systems, memory management\n", "2070": "A Formal System for Information Retrieval from Files", "2071": "Filon Quadrature (Algorithm 353 $D1)) quadrature, Filon quadrature, integration, Filon\nintegration, Fourier coefficients, Fourier series\n", "2072": "Modified Romberg Quadrature (Algorithm 351 $D1)) numerical integration, Romberg quadrature,\ntrapezoid values, rectangle values, error bound\n", "2073": "Solution of Linear Programs in 0-1 Variables linear programming, zero-one variables, partial enumeration\n", "2074": "Sqank (Algorithm 379 $D1)) numerical integration, integration rule, adaptive integration,\nautomatic integration, Simpson's rule, numerical quadrature, quadrature, \nquadrature rule, adaptive quadrature, \nautomatic quadrature, round-off error control\n", "2075": "Discretized Newton-Like Method for Solving a System Newton's method, nonlinear equations, interpolating polynomials\n", "2076": "Cubic Splines on Uniform Meshes A very simple procedure is presented for constructing cubic splines,\nperiodic or nonperiodic, on uniform meshes.  Arcs of two cubics suffice\nto construct a basis of cardinal splines.  An algorithm is given which \nrequires only minimal storage and computation and permits easy trade-off \nof one against the other.\n simple spline representation, cardinal splines, uniform mesh splines\n", "2077": "The Cyclical Majority Problem The problem of the cyclical majority is presented and some new, simulated\nresults for 3, 4, 5, ..., 40 issues ad 3, 5, 7, ..., 37 judges are reported.\n Arrow's paradox, cyclical majority, simulation,\nvoter's paradox, voting paradox\n", "2078": "Representations for Space Planning Problems involving the arrangement of objects in two- \nor three-space where the objective function primarily consists\nof derivatives of the distance between objects or their arrangement\nare called space planning problems.  The representational\nrequirements for this problem area are defined and compared with current\ncomputer graphic languages.  Four alternative data structures\nthat allow automated space planning are described and compared.\n automated design, data structures, computer graphics, computer-aided\ndesign, engineering design, architectural design, robots\n", "2079": "On Multiprogramming, Machine Coding, and Computer Organization", "2080": "The Nucleus of a Multiprogramming System This paper describes the philosophy and structure of a multiprogramming system \nthat can be extended with a hierarchy of operating systems to suit diverse \nrequirements of program scheduling and resource allocation.  The system\nnucleus simulates an environment in which program execution and input/output\nare handled uniformly as parallel, cooperating process\nes.  A fundamental set of primitives allows the dynamic creation and control\nof a hierarchy of processes as well as the communication among them.\n multiprogramming, operating systems, parallel processes, process concept,\nprocess communication, message buffering, process\nhierarchy, process creation, process removal\n", "2081": "Some Complete Calculi for Matrices A matrix calculus is introduced with the intention of developing data structures\nsuitable for a high level algorithmic language for mathematical programming.  \nThe paper investigates how the special structure of matrices can be described\nand utilized for efficient computing by saving memory space and\nsuperfluous operations.  Sequences of Matrices (and sequences of sequences\nof matrices) are considered, and matrix operators areext\nended to sequence operators and cumulative operators.  Algorithms\nare given which use symbol manipulation of matrix expressions so\nas to find the forms best suited for computation.  These forms are\ncalled normal forms.  Several completeness results are obtained\nin the sense that for each expression an equivalent expression\nin normal form can be found within a specified calculus.\n complete calculus, data structures, linear\nprogramming, matrix, matrix concatenation,\nmatrix sequences, programming languages,\nsequence operations, symbol manipulation\n", "2082": "Syntax-Directed Documentation For PL 360 The language PL 360, together with its phrase structure grammar, is used as a \nconcrete basis for illustrating an idea called syntax-directed documentation. \nThis idea is (1) to use the phrase structure of a program to define the \nstructure of a formal documentation for that program; (2) to use the syntactic \ntypes and identifiers in the resulting structure to trigger the automatic\nformation of questions to the programmer, whose answers will\nbecome part of that documentation; and (3) to provide automatic storage\nand retrieval facilities so that other programmers who want\nto understand or modify the program can access the resulting documentation,\nwhich is cross-indexed in various ways by syntactic types\nand objects.  A small PL 360 program, already found\nin the literature, is worked out as an example.\n documentation, syntax analysis, PL 360, enforced documentation,\nindexed documentation, automatic interrogation,\nphase structured grammar, syntax-directed documentation, syntax processing\n", "2083": "Creation and Control of Internal Data Bases A method is described for the definition of a user's COMMON structure\nand the automatic generation of the necessary COMMON, DIMENSION, EQUIVALENCE,\nand type declarations for each of the user's routines.  The definition\nfor the COMMON is contained in an easy to modify form, thus\nallowing the control of general communications of data between routines.\nThe described system has been implemented on the IBM 7094,\nCDC 6000 series, and the IBM 360.  The method has proved to be invaluable\nfor the definition and control of COMMON in many large-scale programs.\n data base, Fortran, common, common equivalencing,\nsubroutine communication, data communication\n", "2084": "A Note on the Complement of Inherently Ambiguous Context-Free Languages ambiguity, inherent ambiguity, complement, context-free language,\nChomsky-language, phrase structure language, production system,\ntype 2 language, bounded language\n", "2085": "Comment on a Paging Anomaly paging machines, demand paging, replacement algorithm\n", "2086": "Another Method of Converting from Hexadecimal to Decimal binary-decimal conversion, computer arithmetic categories\n.N\nCA700312 JB February 13, 1978  3:41 PM\n.X\n2086\t5\t2086\n2086\t5\t2086\n2086\t5\t2086\n", "2087": "A Number System for the Permutations permutation, ordering, number, number system, p-number, combinatorial\n", "2088": "Netflow (ALgorithm 336 $H)) capacitated network, linear programming, minimum-cost\nflow, network flow, out-of-kilter\n", "2089": "Prime Number (Algorithm 310 $A1)) prime numbers, generator\n", "2090": "Symbolic Expansion of Algebraic Expressions (Algorithm 377 $R2)) algebra, symbolic algebra, symbolic\nmultiplication, algebraic distribution,\nalgebraic multiplication, distribution algorithm,\nmultiplication algorithm, product \nalgorithm, polynomial distribution, polynomial expansion\n", "2091": "PDEL-A Language for Partial Differential Equations Conventional computer methods available to solve\ncontinuous system problems characterized by partial\ndifferential equations are very time-consuming and cumbersome.  A\nconvenient, easy to learn and to use, high level problem oriented\nlanguage to solve and study partial differential equation problems\nhas been designed; a practical translator for the language has also\nbeen designed, and a working version of it has been constructed\nfor a significant portion of the language.  This Partial Differential\nEquation Language, PDEL, is outlined, and the highlights\nof the translator are briefly summarized.\n problem oriented or digital simulation language,\npartial differential equations, translator,\nPL/1, preprocessor PL/1, finite difference algorithms\n", "2092": "A Deductive Question-Answer for Natural Language Inference The question-answering aspects of the Protosynthex III pro\ntotype language processing system are described and exemplified in\ndetail.  The system is written in LISP 1.5 and operates on the Q-32\ntime-sharing system.  The system's data structures and their semantic\norganization, the deductive question-answering formalism of\nrelational properties and complex-relation-forming operators, and\nthe question-answering procedures which employ these features in\ntheir operation are all described and illustrated.  Examples of the\nsystem's performance and of the limitations of its question-answering \ncapability are presented and discussed.  It is shown that the\nuse of semantic information in deductive question answering greatly \nfacilitates the process, and that a top-down procedure which works\nfrom question to answer enables effective use to be made of this\ninformation.  It is concluded that the development of Protosynthex\nIII into a practically useful system to work with large data\nbases is possible but will require changes in both the data\nstructures and the algorithms used for question answering.\n question answering, natural language, Protosynthex III, LISP,\nsemantics, artificial intelligence, computational\nlinguistics, language processing, fact retrieval\n", "2093": "A Comparison of Error Improvement Estimates Various simple choices of error improvement estimates for the trapezoid\nrule are studied to demonstrate a comparison procedure which is\nrelatively independent of the profusion of adaptive search and stopping\nstrategies.  Comparisons are based on x^r, `; the inclusion\nof the noninteger powers makes this more realistic than the usual polynomial\nbased comparison.  Behavior near the singularity was found\nto be the dominant factor, and a new estimate, based on a constant\ncurvature assumption and parametric differences, was considered\nslightly better than the other choices considered.\n adaptive integration, error improvement estimate,\ntrapezoid rule, nonpolynomial error criteria\n", "2094": "On an Algorithm for Nonlinear Minimax Approximation Certain nonlinear minimax approximation problems are characterize\nd by properties which permit the application of special algorithms,\nmainly based on the exchange algorithms of Remes (1934, 1935), for\ntheir solution.  In this paper the application to problems of this\ntype of a general nonlinear algorithm due to Osborne and Watson\n(1969) is considered.  Examples are given to illustrate that this\nalgorithm can give satisfactory results and, in particular, can\nsuccessfully solve problems which lead to difficulties\nwith the more conventional specialist method.\n minimax approximation, nonlinear approximation, linear programming\n", "2095": "Measurements of Segment Size Distributions of segment sizes measured under routine operating con\nditions on a computer system which utilizes variable sized segments\n(the Burroughs B5500) are discussed.  The most striking feature\nof the measurements is the large number of small segments-about 60\npercent of the segments in use contain less than 40 words.  Although\nthe results are certainly not installation independent, and although they \nare particularly influenced by features of the B5500 ALGOL system, they \nshould be relevant to the design of new computer systems,\nespecially with respect to the organization of paging schemes.\n storage allocation, segmentation, segment sizes, page sizes,\npaging, resource allocation, memory allocation, core utilization\n", "2096": "Experiments with the M & N Tree-Searching Program The M & N procedure is an improvement to the mini-max\nbacking-up procedure widely used in computer program for game-playing\nand other purposes.  It is based on the principle that it is\ndesirable to have many options when making decisions in the face of\nuncertainty.  The mini-max procedure assigns to a MAX (MIN) node\nthe value of the highest (lowest) valued successor to that node. \nThe M & N procedure assigns to a MAX (MIN) node some function of\nthe M (N) highest (lowest) valued successors.  An M & N procedure was\nwritten in LISP to play the game of kalah, and it was demonstrated that \nthe M & N procedure is significantly superior to the mini-max\nprocedure.  The statistical significance of important conclusions is given. \nSince information on statistical significance has often been lacking in papers \non computer experiments in the artificial intelligence field, these experiments \ncan perhaps serve as a model for future work.\n artificial intelligence, heuristic program, tree searching,\nLISP, kalah, game playing, decision theory, \nmini-max backing-up procedure, backing-up procedures\n", "2097": "A Program to Teach Programming The TEACH system was developed at MIT to ease the cost and improve the results \nof elementary instruction in programming.  To the student, TEACH offers loosely \nguided experience with a  conversational language which was designed with\nteaching in mind.  Faculty involvement is minimal.  A term of experience\nwith TEACH is discussed.  Pedagogically, the system appears to be successful; \nstraightforward reimplementation will make it economically successful as well. \nSimilar programs of profound tutorial skill will appear only as the results of\nextended research.  The outlines of his research are beginning to become clear.\n elementary programming, computer-assisted learning, UNCL, TEACH\n", "2098": "t-Test Probabilities (Algorithm 321); t-test, Student's t-statistic, distribution function, approximation\n", "2099": "Eigenvalues and Eigen vectors of a norm, characteristic equation, degenerate eigen-system,\ndiagonalizable matrix, defective matrix  \n", "2100": "Ortho (Algorithm 127 $F5)) orthogonalization, approximation\n", "2101": "Least Squares Fit By f(x) = Acos(Bx+C) (Algorithm 376 $E2)) nonlinear least squares fit\n", "2102": "Fitting Data To One Exponential (Algorithm 375 $E2)) nonlinear least squares fit\n", "2103": "Restricted Partition Generator (Algorithm 374 $A1)) partitions, restricted partitions, sums of integers, restricted sums\n", "2104": "Number of Doubly Restricted Partitions (Algorithm 373 $A1)) partitions, restricted partitions, sums of integers, restricted sums\n", "2105": "An Interactive Computer System Using Graphical Flowchart Input An interactive computer system operational on a graphical computer terminal is \ndescribed.  This system was designed to demonstrate a method of programming by \ncomputer interpretation of a flowchart.  The user draws a description of a\nsampled-data system and specifies description is transmitted to a large\nscale computer.  The design is simulated, and a graphic representation of the \nprocessed signal is returned to the scope.  A successful design may require \nnumerous modifications of the original design.  A graphical interactive system \nprovides an environment to perform this iterative process efficiently and \neffectively.\n simulation program, graphical input-output sampled data systems\n", "2106": "Computer Education in a Graduate School of Management Several years of experience have led to the belief that the creative\ndesign and evaluation of management information systems requires\na thorough understanding of the related computer technology.  Concepts\nsuch as paging and priority interrupt systems can best be explained at the \nmachine language level.  Any machine used for exposition\nshould fulfill several criteria.  It should: (1) raise as few\nspurious issues as possible; (2) allow, without undue effort, the\nsolution of interesting problems; (3) be capable of exposing all\noutstanding issues of significance, capable of exposing all outstanding\nissues of significance, within the chosen machine; (4) be\nseful for pursuing issues in great depth when appropriate; (5) not\nbe committed to the equipment provided by any manufacturer; (6) be able to \nprovide the student with diagnostic aids to a great depth;\n(7) allow the student ready access to the machine; (8) be capable\nof extension to expose new issues as they come along.  We have\nconstructed a simulated machine and its associated software which\nmeets these criteria.  This system, called the PRISM system,\nis documented by a primer and a reference manual.\n education, simulation, machine language,\nmanagement information systems, interpreters\n", "2107": "The Quadratic Quotient Method: A Hash Secondary clustering as a cause of hash code inefficiency is discussed, and a \nnew hashing method based on its elimination is presented.  Comparisons with \nprevious methods are made both analytically and empirically.\n hashing, hash code, scatter storage, calculated address, clustering,\nsearch, symbol table, collisions, keys, table look-up \n", "2108": "A Variation on Sorting by Address Calculation The principles of address calculation and merging are combined to yield an\nefficient sorting technique. Detailed flowcharts of the most important program\nsteps are included. The characteristics of the proposed sort are discussed.\n sorting, address calculation, merging, order, sequence creation\n", "2109": "The Use of Quadratic Residue Research A quadratic residue search method has previously been suggested\nto avoid the clustering usually encountered when hash address collisions\noccur and linear search methods are used.  The search size, because\nof the property of quadratic residues, is limited to one half of\nthe storage table.  It is shown that for some classes of prime numbers\nthe complement of the set of quadratic residues can easily be determined and \nhence the entire table of size p, where p is that prime number, can be searched.\n quadratic residue, search method, hash addressing, address\nclustering, scatter storage, file searching, file\naddressing, hash coding, quadratic search,\nrandom search, storage layout, searching\n", "2110": "An Efficient Context-free Parsing Algorithm A parsing algorithm which seems to be the most efficient general context-free \nalgorithm known is described.  It is similar to both Knuth's LR(k) algorithm \nand the familiar top-down algorithm.  It has a time bound proportional to \nn^3 (where n is the length of the string being parsed) in general; it has a \nn^2 bound for unambiguous grammars; and it runs in linear time on a large \nclass of grammars, which seems to include most practical context-free\nprogramming language grammars.  In an empirical comparison it appears\nto be superior to the top-down and bottom-up algorithms studied by Griffiths \nand Petrick.\n syntax analysis, parsing, context-free grammar,\ncompilers, computational complexity\n", "2111": "Spelling Correction in Systems Programs Several specialized techniques are shown for efficiently\nincorporating spelling correction algorithms in\nto compilers and operating systems.  These include the use of syntax\nand semantics information, the organization of restricted keyword\nand symbol tables, and the consideration of a limited class of spelling\nerrors.  Sample 360 coding for performing spelling correction\nis presented.  By using systems which perform spelling correction,\nthe number of debugging runs per program has been decreased,\nsaving both programmer and machine time.\n spelling correction, error correction, debugging, compilers,\noperating systems, diagnostics, error detection, \nmisspelling, lexical analysis systems programming\n", "2112": "Translation Equations Input limited transduction expressions, or translation equations,\nare used to describe the syntax and left-context sensitive semantics for \ncontext-free languages.  A formal procedure is given for deriving from\na set of translation equations the specifications for a pushdown translator.\nThe translator consists of Mealy form finite-state automata interacting\nby means of a pushdown stack.  Within the framework described string \nrecognition and parsing may be treated as special cases of the translation \nproblem.\n automata, Turing machines, regular expression, transduction\nexpression, context-free languages, translation, recognizers,\nparsing, meta-compilers, pushdown transducer, syntax\ndirected compilers, finite state automata\n", "2113": "The Multistore Parser for Hierarchical Syntactic Structures A syntactic parser is described for hierarchical concatenation patterns\nthat are presented to the analyzer in the form of linear strings.  Particular\nemphasis is given to the system of \"significant addresses\" by means\nof which processing times for large-scale matching procedures\ncan be substantially reduced.  The description makes frequent use\nof examples taken from the fully operational implementation of the\nparser in an experimental English sentence analyzer.  By structuring\nan area of the computer's central core storage in such a way\nthat the individual locations of bytes and bits come to represent the\ndata involved in the matching procedure, the shifting of information\nis reduced to a minimum, and the searching of lists is eliminated\naltogether.  The matches are traced by means of binary masks\nand the state of single bits determines the operational flow of the\nprocedure.  The method could be implemented with any interpretive\ngrammar, provided it can be expressed by the functional classification\nof the items composing the input hierarchical structures.\n parsing, syntactic analysis, natural-language analysis, linguistic data\nprocessing, computational linguistics, correlational grammar, structure\nrecognition, pattern recognition, matching procedures, tree-structure \ninterpretation, machine translation, automatic abstracting\n", "2114": "A Formal System for Information Retrieval from Files A generalized file structure is provided\nby which the concepts of keyword, index, record, file, directory,\nfile structure, directory decoding, and record retrieval are defined\nand from which some of the frequently used file structures such\nas inverted files, index-sequential files, and multilist files are\nderived.  Two algorithms which retrieve records from the generalized file \nstructure are presented.\n attribute-value pair, index, keyword, record, record address,\nK-pointer, K-list, file, directory, generalized file\nstructure, inverted file, index-sequential-file, multilist file,\ndescription, file search, directory search, serial processing of\nlists, prime keyword, parallel processing of lists \n", "2115": "Fortran Tausworthe Pseudorandom Number Generator random numbers, pseudorandom numbers, shift register sequences\n", "2116": " Interchange Rolls of Perforated Tape for Information interchange, rolls, perforated tape, tape, information\ninterchange, directional markers, leaders, \ntrailers, roll-up tape, 9-track paper tape, dimensions\n", "2117": "Representation for Calen calendar date, machine-to-machine interchange,\nmonth, year, day, representation coded\n", "2118": "An Efficient Algorithm for Sorting with sorting,minimal storage sorting, digital computer sorting\n", "2119": "Derivatives (Algorithm 282 $S22)) recursive computation, successive derivatives, error control\n", "2120": "An Algorithm to Produce Complex Primes, Csieve (Algorithm 372 $A1)) primes, complex numbers\n", "2121": "Partitions in Natural Order (Algorithm 371 $A1)) partitions,number theory\n", "2122": "General Random Number Generator (Algorithm 370 $G5)) random number generator, probability density function,\ntransformation, cumulative density function\n", "2123": "Generator of Random Numbers Satisfying the Poisson distribution, random number generator\n", "2124": "Numerical Inversion of Laplace Transforms (Algorithm 368 $D5)) Laplace transform inversion, integral transformations, integral equations\n", "2125": "A Note on Minimal Length Polygonal Approximation to a Digitized Contour A method for extracting a smooth polygonal\ncontour from a digitized image is illustrated.\nThe ordered sequence of contour points and the connection graph of\nthe image are first obtained by a modified Ledley algorithm in one\nimage scan.  A minimal perimeter polygon subjected to specified constraints\nis then chosen as the approximating contour.  The determination of the minimal \npolygon can be reduced to a nonlinear programming\nproblem, solved by an algorithm which takes into account\nthe weak bonds between variables.  Some examples are presented,\nand the corresponding computing times are listed.\n digitized image, connection tree, minimal polygon,\noptimal approximation, nonlinear programming\n", "2126": "Experience with an Extensible Language An operational extensible language system is described.\nThe system and its base language are appraised with \nrespect to efficiency, flexibility, and utility\nfor different categories of users.\n programming languages, extensible, compiler, bootstrapping, ambiguity\n", "2127": "Natural Language Question-Answering Systems: 1969 Recent experiments in programming natural\nlanguage question-answering systems are reviewed\nto summarize the methods that have been developed for syntactic, semantic,\nand logical analysis of English strings.  It is concluded\nthat at least minimally effective techniques have been devised for\nanswering questions from natural language subsets in small scale\nexperimental systems and that a useful paradigm has evolved to guide\nresearch efforts in the field.  Current approaches to semantic\nanalysis and logical inference are seen to be effective beginnings\nbut of questionable generality with respect either to subtle aspects of \nmeaning or to applications over large subsets of English. \nGeneralizing from current small-scale experiments to language-processing \nsystems based on dictionaries with thousands of entries-with\ncorrespondingly large grammars and semantic systems-may entail\na new order of complexity and require the invention and development\nof entirely different approaches to semantic analysis and questions answering.\n question-answering, natural language, artificial intelligence,language\nprocessing, fact retrieval, semantics \n", "2128": "A Processor Allocation Method for Time-Sharing A scheduling algorithm is proposed which is intended to minimize changes of \ntasks on processors and thereby reduce over-head.  The algorithm also has\napplication to more general resource allocation problems.  It is implemented \nby means of a method for efficiently handling dynamically changing segmented \nlists.\n time sharing, resource allocation, scheduling algorithms,\nmonitors, dynamic allocation, processor\nallocation, multiprogramming, multiprocessing, time\nslicing, scheduling, conversational systems, \ninteractive systems \n", "2129": "Recursive Computation of Certain Derivatives-A A brief study is made of the propagation of errors\nin linear first-order difference equations.  The\nrecursive computation of successive derivatives of (e^x)/x\nand (cos x)/x is considered as an illustration.\n recursive computation, successive derivatives, error propagation\n", "2130": "Automatic Segmentation of Cyclic Program Structures Time-shared, multiprogrammed, and overlayed batch systems frequently\nrequire segmentation of computer programs into discrete portions.  \nThese program portions are transferred between executable and\nperipheral storage whenever necessary; segmentation of program\ns in a manner that  reduces the frequency of such transfers is the\nsubject of this paper.  Segmentation techniques proposed by C. V.\nRamamoorthy are subject to limitations that arise when the preferred\nsegment size is not compatible with the physical restrictions\nimposed by the available computing equipment.  A generalization of\nRamamoorthy's suggestions is made in order to allow their application \nwhen circumstances are other than ideal.\n automatic segmentation, cyclic program structures, loops, paging, \nmultiprogramming, loaders, assemblers, compilers, time-sharing, program \nconnectivity\n", "2131": "Rapid Computation of Weights of Interpolatory divided differences\n", "2132": "Rapid Computation of Coefficients of Interpolation divided differences, Newton's interpolation formula\n", "2133": "Algorithm for the Assignment Problem operations research, optimization theory,\nassignment problem, rectangular matrices\n", "2134": "An Extension of the Munkres Algorithm for The assignment problem, together with Munkres\nproposed algorithm for its solution in square \nmatrices, is presented first.  Then the authors develop\nan extension of this algorithm which permits \na solution for rectangular matrices.  Timing results\nobtained by using an adapted version of Silver's \nAlgol procedure are discussed, and a relation between\nsolution time and problem size is given.\n operations research, optimization theory, assignment\nproblem, rectangular matrices, algorithm\n", "2135": "Rapid Computation of General Interpolation Let f have n continuous on a closed interval\n[a,b] and let L be a linear functional.  The attempt \nis made to approximate L (f) with L (Q) where Q is a polynomial,\napproximating f.  Algorithms are developed \nfor rapid computation of L (Q) for a wide class of\nselections of Q which includes the Lagrangian and \nHermitian rules as special cases.\n linear functionals, divided differences, Newton's interpolation formula\n", "2136": "A Note on \"A Modification of Nordsieck's ordinary differential equations, multi-step methods,\npredictor, corrector, round-off error, Nordsieck's \nmethod, Gragg-Stetter modification\n", "2137": "New LISP Techniques for a Paging Environment The system described herein employs the block\nconcept, and that of global and local variables, \nin addition to the methods applied in most LISP systems.\n Also, a new means of list representation is \nused: \"local sequential\" for lists created during compilation,\nand \"block level sequential\" for those \ncreated dynamically.  A new garbage collection algorithm\nhas been introduced to make lists as compact \nas possible; partial garbage collection is performed after\neach block exit instead of total garbage collection \nwhen storage is exhausted.  The algorithm does not use\nthe customary flagging procedure.  This combination \nof features has eliminated the need for a free list,\nand effectively minimizes the number of pages used \nat any moment.\n LISP, list processing, paging, virtual memory,\ngarbage collection, core fragmentation, compact \nlist structures, block, segment\n", "2138": "BLISS: A Language for Systems Programming A language, BLISS, is described.  This language\nis designed so as to be especially suitable \nfor use in writing production software systems for a\nspecific machine (the PDP-10): compilers, operating \nsystems, etc.  Prime design goals of the design are the\nability to produce highly efficient object code, \nto allow access to all relevant hardware features of\nthe host machine, and to provide a rational means \nby which to cope with the evolutionary nature of systems\nprograms.  A major feature which contributes \nto the realization of these goals is a mechanism permitting\nthe definition of the representation of all \ndata structures in terms of the access algorithm for elements of the structure.\n programming languages, implementation language,\nsystems programming, data structures\n", "2139": "Implementation of the Substring Test by Hashing A technique is described for implementing the\ntest which determines if one string is a substring \nof another.  When there is low probability that the test\nwill be satisfied, it is shown how the operation \ncan be speeded up considerably if it is preceded by\na test on appropriately chosen hash codes of the \nstrings.\n substring, hashing, subset, signature, information\ncompression, information retrieval, searching\n", "2140": "Retrieval-Update Speed Tradeoffs Using Combined Indices In a paper in the November 1970 Communications\nof the ACM, V. Y. Lum introduced a technique \nof file indexing named combined indices.  This technique\npermitted decreased retrieval time at the cost \nof increased storage space.  This paper examines combined\nindices under conditions of file usage with \ndifferent fractions of retrieval and update.  Tradeoff\ncurves are developed to show minimal cost of file \nusage by grouping various partially combined indices.\n file organization, combined index files, inverted\nfiles, information retrieval, query, multi-attribute \nretrieval, file update\n", "2141": "Algorithmic Selection of the Best The best of a dozen different methods for\ncompressing map data is illustrated.  The choices \nare generated by encoding data strings-sequence of like\ncodes-by three methods and in four directions. \n Relationships are developed between compression alternatives\nto avoid comparing all of them.  The technique \nhas been used to compress data from forest resource maps,\nbut is widely applicable to map and photographic \ndata reduction.\n data compression, map storage, information retrieval,\ninput/output, run coding, data reduction\n", "2142": "Reconstruction of Pictures from Their Projections There are situations in the natural sciences\nand medicine (e.g. in electron microscopy and \nX-ray photography) in which it is desirable to estimate the\ngray levels of a digital picture at the individual \npoints from the sums of the gray levels along straight\nlines (projections) at a few angles.  Usually, \nin such situations, the picture is far from determined\nand the problem is to find the \"most representative\" \npicture.  Three algorithms are described (all using\nMonte Carlo methods) which were designed to solve \nthis problem.  The algorithms are applicable in a large\nand varied number of fields.  The most important \nuses may be the reconstruction of possibly asymmetric particles\nfrom electron micrographs and three-dimensional \nX-ray analysis.\n approximation, biomedical image processing, efficient\nencoding, image processing, linear programming, \nmathematical programming, Monte Carlo techniques, optimization,\npicture compression, picture description, \npicture processing, stereology, X-ray analysis\n", "2143": "Chebyshev Approximation of Continuous Functions approximation, Chebyshev approximation, Remex algorithm\n", "2144": "On Accurate Floating-Point Summation The accumulation of floating-point sums is\nconsidered on a computer which performs t-digit \nbase B floating-point addition with exponents in the range\n-m to M.  An algorithm is given for accurately \nsumming N t-digit floating-point numbers.  Each of\nthese N numbers is split into q parts, forming qN \nt-digit floating-point numbers.  Each of these is then\nadded to the appropriate one of n auxiliary t-digit \naccumulators.  Finally, the accumulators are added together\nto yield the computed sum.  In all, qN+n-1 \nt-digit floating-point additions are performed.  Under\nusual conditions, the relative error in the computed \nsum is at most [(t+1)/v]B^(1-t) for some v.  Further,\nwith an additional q+n-1 t-digit additions, the \ncomputed sum can be corrected to full t-digit accuracy.\n For example, for the IBM/360 (B=16, t=14, M=63, \nm=64), typical values for q and n are q=2 and n=32. \nIn this case, (*) becomes N <= 32,768, and we have \n[(t+1)/v]B^(1-t) = 4x16^-13.\n floating-point summation, error analysis\n", "2145": "Automation of Etching-Pattern Layout HELP (Heuristic Etching-Pattern Layout Program)\nis an application program developed to computerize \nthe tedious and error-prone although vitally important\nwiring design of printed circuit boards.  HELP \nhelps automate a design stage one step closer to production\nthan logical design.  It can be used to design \nwiring patterns of two-layer circuit boards on which\nICs in dual-in-line packages as well as discrete \ncomponents such as transistors and resistors have been\nplaced.  HELP employs two methods of wiring.  \nOne is the heuristic method, which simulates human\napproaches to wiring design, and the other is the \ntheoretically interesting but time-consuming method of\nmaze-running, based on the Lee's algorithm.  HELP \nperforms more than 90 percent of required wiring by\nthe heuristic path with respect to a performance \nfunction for each point-to-point, and point-to-line\nconnection.  It can bring the number of successful \nwiring connections very close to 100 percent.\n heuristic etching-pattern layout, wiring design of\nprinted circuit board, maze-running, Lee's algorithm\n", "2146": "Optimizing the Polyphase Sort Various dispersion algorithms for the polyphase\nsorting procedure are examined.The optimum \nalgorithm based on minimizing the total number of unit\nstrings read is displayed.  The logic of this \nalgorithm is rather complicated; hence, several other\nnew dispersion algorithms with more straightforward \nlogic are presented.  Of the simple dispersion algorithms\ndiscussed, the  Horizontal is best.  It does \napproximately one-fourth to one and one-half percent\nless reading and writing than most algorithms in \nuse today.  An additional two and one-fourth to three\npercent improvement can be achieved by utilizing \nthe Modified Optimum Algorithm.  This algorithm is relatively\nstraightforward, but it requires a fairly \nclose estimate of the total number of unit strings before the dispersion begins.\n sorting, polyphase sorting, dispersion algorithms,\noptimum dispersion algorithm, repetition operator\n", "2147": "Using Computers in Higher Education: Data from a survey conducted with National\nScience foundation support, which was published \nin December 1970, is reviewed, and it is pointed out\nthat, with regard to computers in higher education, \nnational goals stated in the Rosser and Pierce Reports\nhave not been attained.  Quality was lacking in \nhardware or courses in nearly half of the associate\nand bachelor's degree programs in data processing, \ncomputer science, etc., offered in 1966-67.  A plea\nis made for continuing studies on status and goals \nfor computing in higher education, improvement of degree\nprograms, and a national testing laboratory \nfor educational technology.\n higher education, computers, degree programs, national\ngoals, testing laboratory, educational technology\n", "2148": "The Composition of Semantics in Algol 68 The main features of Algol 68 are explained\nfrom a semantic point of view.  It is shown how \nthe language permits the composition of values and actions,\ni.e. ultimately programs, from a minimum \nset of primitives with a few fundamental recursive rules\nof composition.  The associated syntax is briefly \nreviewed.  An attempt has been made to obtain a structured\nand simple introduction to both Algol 68 and \nits orthogonal design.\n programming primitives, programming languages,\nAlgol, semantics, recursive composition, design \nof programming languages, data structures\n", "2149": "ENTCAF and ENTCRE: Evaluation of Normalized Taylor coefficients, Taylor series, Cauchy integral,\nnumerical integration, numerical differentiation, \ninterpolation, complex variable, complex arithmetic, fast Fourier transform\n", "2150": "Concurrent Control with \"Readers\" and \"Writers\" The problem of the mutual exclusion of several\nindependent processes from simultaneous access \nto a \"critical section\" is discussed for the case where\nthere are two distinct classes of processes known \nas \"readers\" and \"writers.\"  The \"readers\" may share\nthe section with each other, but the \"writers\" must \nhave exclusive access.  Two solutions are presented:\none of the case where we wish minimum delay for \nthe readers; the other for the case where we wish\nwriting to take place as early as possible.\n mutual exclusion, critical section, shared access to resources\n", "2151": "User Program Measurement in a Time-Shared Environment A general discussion of the measurement of\nsoftware systems is followed by a description of \na hardware and software scheme for measuring user programs\nin a time-shared environment.  The TX-2 computer \nat MIT Lincoln Laboratory was used for the implementation\nof such a system and the characteristics of \nthis implementation are reported.  A scenario showing\nthe system in use is presented.  Finally, it is \nshown how other time-sharing systems may provide similar measuring facilities.\n operating systems, multiprogramming systems, time-sharing\nsystems, software measurement, user program \nmeasurement, measurement technology, TX-2 computer,\nvirtual computers, performance improvement\n", "2152": "Display Procedures Although the use of structured display files\nis widespread in interactive computer graphics, \nthese structures present a number of problems which\ntend to restrict their generality and usefulness. \n This paper discusses some of these problems, and suggests an\nalternative approach to display system \ndesign which avoids the use of structured display files.\n This technique employs display procedures to \ngenerate information for display.  By including transformations\nwithin calls to these procedures it is \npossible both to simplify the specification of pictures\nand to speed up their generation.  Display procedures \npermit picture elements to be defined conditionally\nand also facilitate the processing of inputs from \npointing devices.  The paper is illustrated by examples\nfrom aversion of the EULER language in which \ndisplay procedures were implemented.\n computer graphics, programming languages, display files\n", "2153": "Experiments with an Automated Instructional System for Numerical Methods A computer system was developed at Purdue\nUniversity to teach portions of an undergraduate \ncourse in numerical methods.  Each instructional unit\nor lesson is divided into three modes of instruction \nwhich allow the student to press from a computer-controlled\npresentation to a student-controlled investigation. \nThe system is designed as a classroom-independent course\nof study, and has been used for two semesters \nby students in lieu of conventional classroom instruction.\n Initial measures of effectiveness, student \nacceptance, and operational cost are the result of testing\nthe system independent of instructor intervention. \n The system is operational on a CDC 6500 with teletype terminals. \n computer-assisted instruction, numerical\nmethods, CAI, instructional systems\n", "2154": "Clarification of Fortran Standards-Second Report In 1966, after four years of effort, Fortran\nbecame the first programming language standardized \nin the United States.  Since that initial achievement\nstudy and application of the standard specifications \nhave revealed the need for maintenance of the standards.\n As the result of work initiated in 1967, an \ninitial set of clarifying interpretations was prepared and\nthis clarification was published in Communications \nof the ACM in May 1969.  That work has continued and\nhas resulted in the preparation of this second set \nof clarifying interpretations.  The nature of the maintenance\nand the new set of corrections to and interpretations \nof the standard specifications are reported.\n American National Standard, Fortran, Basic Fortran,\nprogramming language, standardization, language \nstandard specification, language standard maintenance,\nlanguage standard clarification, language standard \ninterpretation, standardization committee\n", "2155": "Toward an Understanding of Data Structures This paper presents a notation and formalism\nfor describing the semantics of data structures. \n This is based on directed graphs with named edges and\ntransformations on these graphs.  In addition, \nan implementation facility is described which could\nbe part of a programming language, which allows a \nprogrammer who has expressed the semantics of an algorithm\nin terms of the graphs to then specify the \nimplementation of some of his data structures in order to gain efficiency.\n data structures, graph, implementation,\nsemantic formalism, programming language\n", "2156": "Comment on Cheney's List-Compaction Algorithm LISP, garbage collector, virtual memory,\nlist processing, storage allocation \n", "2157": "Average Binary Search Length for Dense Ordered Lists searching, binary searching, record retrieval\n", "2158": "A Stopping Criterion for the Newton-Raphson Method ordinary differential equations, linear multistep\nformulas, Newton-Raphson method, stopping criterion\n", "2159": "A Note on Best One-Sided Approximations best approximation, one-sided approximation,\nlogarithmic, error, relative error\n", "2160": "Canonical Structure in Attribute Based File Organization A new file structure for attribute based retrieval\nis proposed in this paper.  It allows queries \ninvolving arbitrary Boolean functions of the attribute-value\npairs to be processed without taking intersections \nof lists.  The structure is highly dependent on the\nway in which the file is to be used and is uniquely \ndetermined by the specification of the allowed queries.\n Thus, for example, the structure for retrieval \non the basis of ranges of values of a given attribute would\nbe very different from one where only retrieval \non the basis of a single value is permitted.  The file\norganization being proposed is based on the atoms \nof a Boolean algebra generated by the queries.  The desirable\nproperties claimed for this structure are \nproved, and file maintenance questions are discussed.\n address calculation, atoms of Boolean algebra,\nattributes, Boolean functions, Boolean queries, \nfile organization, information retrieval, inverted\nfile, key words, multilist, queries, searches \n", "2161": "An Algorithm for the Blocks and Cutnodes of a Graph (Corrigendum)", "2162": "An Efficient Bit Table Technique for Dynamic An efficient bit table technique for dynamic storage\nallocation of 2^n-word blocks, which requires \na minimized amount of memory for bookkeeping purposes,\nis described. The technique has been tested in \nan implementation of the list processing language L^6.\n A number of ideas incorporated in the processor \nare also described.\n bit table, dynamic storage allocation, buddy\nsystem, L^6, list processing, free storage\n", "2163": "Education Related to the Use of Computers in Organizations The ACM Curriculum Committee on Computer Education\nfor Management has been carrying out a study \non \"Curriculum Development in Management Information\nSystems Education in Colleges and Universities\" \nunder a grant from the National Science Foundation.\n This position paper provides a framework for the \nstudy.  Preliminary conclusions are presented on the\nneed for education in administrative information \nsystems, and appropriate college curricula and courses\nare suggested.  Also, the role of professional \nsocieties and organizations using computers is discussed,\nand the plans of the Committee are outlined. \n The initial approach of the Committee has been to describe\nthe education necessary for the effective \nuse of computers in organizations, to classify the\npositions for which education is required, and to \nsurvey educational programs now available.\n education, information analysis, systems design, business data processing\n", "2164": "Symbolic Integration: The Stormy Decade Three approaches to symbolic integration in the\n1960's are described.  The first, from artificial \nintelligence, led to Slagle's SAINT and to a large\ndegree to Moses' SIN.  The second, from algebraic \nmanipulation, led to Manove's implementation and to\nHorowitz' and Tobey's reexamination of the Hermite \nalgorithm for integrating rational functions.  The third,\nfrom mathematics, led to Richardson's proof \nof the unsolvability of the problem for a class of functions\nand for Risch's decision procedure for the \nelementary functions.Generalizations of Risch's algorithm\nto a class of special functions and programs \nfor solving differential equations and for finding\nthe definite integral are also described.\n integration, symbolic integration, definite integrals, rational functions\n", "2165": "General Relativity and the Application of Algebraic Manipulative Systems The paper describes some applications of symbolic\nalgebra systems to problems of general relativity \nincluding the derivation of the field equations, the\nPetrov classification of a metric, and the solution \nof the field equations in the presence of matter in\na simple case.  Attention is drawn to the strictly \nalgebraic difficulties encountered in this work.\n symbolic mathematics,nonnumerical mathematics, general\nrelativity, algebraic manipulation, equation \nmanipulation\n", "2166": "Automated Algebraic Manipulation in Celestial Mechanics In this paper we consider some of the applications\nof automated algebraic manipulation which \nhave been made in celestial mechanics.  Particular attention\nis paid to the use of Poisson series, and \na typical problem in perturbation theory is described.\n The requirements of processors for use in celestial \nmechanics are considered and compared with those for general\nmanipulation packages.  Some future directions \nfor research using these systems are briefly outlined.\n To illustrate the relative simplicity of the \nalgorithm required in celestial mechanics, a typical\nintegration problem is considered in an appendix. \n series manipulation, automated algebra, celestial mechanics\n", "2167": "Algebraic Simplification: A Guide for the Perplexed Algebraic simplification is examined first from\nthe point of view of a user who needs to comprehend \na large expression, and second from the point of view\nof a designer who wants to construct a useful and \nefficient system.  First we describe various techniques\nakin to substitution.  These techniques can be \nused to decrease thesize of an expression and make it\nmore intelligible to a user.  Then we delineate \nthe spectrum of approaches to the design of automatic simplification\ncapabilities in an algebraic manipulation \nsystem.  Systems are divided into five types.  Each type\nprovides different facilities for the manipulation \nand simplification of expressions. Finally we discuss\nsome of the theoretical results related to algebraic \nsimplification.  We describe several positive results\nabout the existence of powerful simplification \nalgorithms and the number-theoretic conjectures on which\nthey rely.  Results about the nonexistence of \nalgorithms for certain classes of expressions are included.\n algebraic manipulation, algebraic simplification,\ncanonical simplification\n", "2168": "List Tracing in Systems Allowing Multiple Cell-Types List-processing systems have each allowed the\nuse of only a single size and configuration of \nlist cell.  In this paper a system is described which\nallows the use of arbitrarily many different sizes \nand configurations of list cells, possibly not specified until run time.\n list-processing, storage allocation, LISP, SLIP, based storage, pointers\n", "2169": "The Altran System for Rational Function Manipulation-A Survey Altran is a complete system for symbolic computation\nwith rational functions in several variables \nwith integer coefficients.  It has been designed and\nimplemented to handle large problems with ease and \nefficiency.  Considerable effort has been spent to ensure\na minimum amount of machine dependence in the \nimplementation, thus permitting the system to be installed\nquickly and easily on a variety of computing \nmachines.  In this paper a brief description of the language,\nrun time data structures, and implementation \nis given.\n symbolic algebra, rational function manipulation,\npolynomial manipulation, interpreters, translators\n", "2170": "Applications of Symbol Manipulation in Theoretical Physics This paper surveys the applications of symbolic\ncomputation techniques to problems in theoretical \nphysics.  Particular emphasis is placed on applications\nin quantum electrodynamics where the most activity \nhas occurred.\n symbol manipulation, algebraic simplification,\ncomputational physics, quantum electrodynamics\n", "2171": "Solution of Simultaneous Nonlinear Equations nonlinear equations\n", "2172": "Graph Plotter [J6] (Algorithm 412) plot, graph, line printer plot\n", "2173": "Three Procedures for the Stable Marriage Problem [H] (Algorithm 411) assignment problems, assignment procedures, combinatorics,\ndiscrete mathematics, operations research, \nstable marriage problem, university entrance\n", "2174": "The Stable Marriage Problem The original work of Gale and Shapley on an assignment\nmethod using the stable marriage criterion \nhas been extended to find all the stable marriage assignments.\n The algorithm derived for finding all \nthe stable marriage assignments is proved to satisfy\nall the conditions of the problem.  Algorithm 411 \napplies to this paper.\n assignment problems, assignment procedures, combinatorics,\ndiscrete mathematics, operational research, \nstable marriage problem, university entrance\n", "2175": "Subexpression Ordering in the Execution of Arithmetic Expressions An arithmetic expression can often be broken\ndown into its component subexpressions.  Depending \non the hardware environment in which the expression is\nto be executed, these subexpressions can be evaluated \nin serials, in parallel, or in a combination of these\nmodes.  This paper shows that expression execution \ntime can be minimized only if consideration is given to\nthe ordering of the subexpressions.  In particular, \nsubexpressions should be executed in order of decreasing\nmemory and processor time requirements.  This \nobservation is valid for configurations ranging from\na uniprocessor with an unbuffered main memory to \nmultiprocessor with a \"cache\" buffer memory.  If the\nnumber of subexpressions which can be executed in \nparallel exceeds the number of available processors,\nthen execution of some of these subexpressions must \nbe postponed.  A procedure is given which combines this\nrequirement with the earlier ordering considerations \nto provide an optimal execution sequence.\n parallel processing, cache, arithmetic expressions,\nsubexpression ordering, computational trees, \ncompilers\n", "2176": "Buffer Allocation in Merge-Sorting A fixed buffer allocation for merge-sorting\nis presented here which minimizes the number of \ninput-output operations for a given order of merge.\n When sorting on movable arm disks, the number of \nseeks is equal to the number of input-output operations,\nand the seek time usually controls the sort \ntime.  First some standard terminology is introduced. \nThen the input buffer allocation method is described, \nfollowed by an analysis of the improvement to be expected\nover more conventional allocation.  This analysis \nmakes use of a particular distribution function.  An\nanalysis of a completely different distribution \nis given which yields similar results.  This suggests\nthat the results do not depend on a particular \ndistribution function.  An optimum output buffer size\nis also determined.  It is concluded that this \nbuffering allocation can significantly reduce the time\nof merge sorting on movable arm disks when the \ninput data are not random, and that this output buffer\nallocation should be used whether the data is \nrandom or not.\n file, item, string, merge sort, seek time, gamma distribution function\n", "2177": "An Algorithm for the Blocks and Cutnodes of a Graph An efficient method is presented for finding\nblocks and cutnodes of an arbitrary undirected \ngraph.  The graph may be represented either (i) as an\nordered list of edges or (ii) as a packed adjacency \nmatrix.  If w denotes the word length of the machine\nemployed, the storage (in machine words) required \nfor a graph with n nodes and m edges increases essentially\nas 2(m+n) in case (i), or (n^2)/win case \n(ii).  A spanning tree with labeled edges is grown,\ntwo edges finally bearing different labels if and \nonly if they belong to different blocks.  For both representations\nthe time required to analyze a graph \non n nodes increases as n^G where G depends on the type\nof graph, 1 <= G <= 2, and both bounds are attained. \n Values of G are derived for each of several suitable\nfamilies of test graphs, generated by an extension \nof the web grammar approach.  The algorithm is compared\nin detail with that proposed by Read for which \n1 <= G <= 3.\n algorithm, block, block-cutpoint-tree, cutnode, fundamental\ncycle set, graph, lobe, lobe decomposition \ngraph, separable, spanning tree, web grammar\n", "2178": "A Language Extension for Graph Processing and Its Formal Semantics A simple programming language \"extension,\"\nGraspe, for processing directed graphs is defined. \n Graspe consists of a type of directed graph data structure\nand a set of primitive operations for manipulating \nthese structures.  Graspe may be most easily implemented\nby embedding it in a host language.  Emphasis \nis placed both on Graspe itself and on its method of\ndefinition.  Commonly, the definition of a language \ninvolves definition of the syntactic elements and explanation\nof the meaning to be assigned them (the \nsemantics).  The definition of Graspe here is solely in\nterms of its semantics; that is, the data structures \nand operations are defined precisely but without assignment\nof a particular syntactic representation. \n Only when the language is implemented is assignment\nof an explicit syntax necessary.  An example of \nan implementation of Graspe embedded in Lisp is given as\nan illustration.  The advantages and disadvantages \nof the definition of a language in terms of its semantics are discussed.\n graph processing, programming language, formal semantics,\ndirected graph, Lisp, network, data structure, \nflowchart, syntax, language definition\n", "2179": "Simple LR(k) Grammars A class of context-free grammars, called the\n\"Simple LR(k)\" or SLR(k) grammars is defined. \n This class has been shown to include weak precedence\nand simple precedence grammars as proper subsets. \n How to construct parsers for the SLR(k) grammars is\nalso shown.  These parser-construction techniques \nare extendible to cover all of the LR(k) grammars of\nKnuth; they have been implemented and by direct \ncomparison proved to be superior to precedence techniques,\nnot only in the range of grammars covered, \nbut also in the speed of parser construction and\nin the size and speed of the resulting parsers.\n context-free grammar, LR(k) grammar, precedence\ngrammar, syntactic analysis, parsing algorithm, \nparser, finite-state machine, deterministic pushdown automaton\n", "2180": "A Programmer Training Project A project is described whose purpose is to train\nselected black residents of the Albany-Schenectady \narea in computer programming and arrange for jobs for\nthem in the computer field. Both the organization \nand curriculum of the course are discussed.\n programmer training, job opportunities, Fortran\n", "2181": "The State of Computer Oriented Curricula in Business Schools 1970 The ACM Committee on Computer Education for Management,\nsupported by a National Science Foundation \nGrant, is established to appraise the state of the art\nand to develop a series of recommendations for \nimproving computer education for management.  To provide\nthe Committee with material for its study of \ncurricular needs, five regional meetings in the United\nStates were held in 1970, at each of which a broad \ncross section of invited academicians and practitioners\nconsidered the state of curricula in business \nschools.  Three topics were covered: curricula for\nthe general manager; computer-related material in \nrequired and functional courses; and curricula for students\nconcentrating on computer-based information \nsystems.  An analysis of the minutes of the meetings\nrevealed a common set of experiences which raised \nsimilar pedagogic and economic issues.  This presentation\ngives a summary of the discussions; a condensation\nof the pedagogic and substantive concerns raised; and\nconsideration of the resource allocation issues \ninvolved.  Preliminary to the Committee's recommendations\nfor improving computer education for management, \nthis report has been prepared to provide the participants\nand the administrators of their institutions \nwith background information for the ongoing task of course\ndevelopment.  Chairman of the ten-man Committee \nis Daniel Teichroew (The University of Michigan).\n university programs, management education, curriculum\ndesign, business administration curricula, \ngraduate business school resource planning\n", "2182": "Interrupt Driven Programming interrupts, supervisors, monitors, debugging, parallel\nprocessing, associative memories, microprogramming\n", "2183": "Binary Summation summation, binary summation, floating-point addition, round-off errors\n", "2184": "On the Meaning of Names in Programming Systems It is assumed that there is a similarity of\nfunction between the data names of a programming \nlanguage and the file names of an operating system.\n The two functions are discussed in terms of the \nsame basic concepts in order to identify the extent\nto which they overlap. It is suggested that there \nis some similarity between the idea of a file directory\nand a storable object of type context.  Manipulations \nwith contexts are then discussed at length.  It is noted\nthat there is a simple extension of Church's \nLambda notation that deals nicely with these ideas of\ncontext manipulation.  Whereas a function can be \nregarded as the abstraction based upon the first two terms of\nthe expression Lambda(name list)(expression)(value list), \nit is found that a context can be viewed as an abstraction\nbased upon the first two terms in the equivalent \nexpression Mu(name list)(value list)(expression).\n file, operating system, programming language, functions,\nnames, context, file directory, file dictionary, \nlambda calculus, theory of programming\n", "2185": "A Note on Compiling Fixed Point Binary Multiplications An algorithm is developed for compiling, as\na sequence of shifts, additions,and subtractions, \nmany fixed point binary multiplications involving a\nconstant.  The most significant characteristics of \nthe algorithm are the simplicity of the test which\ndetermines if the algorithm should be applied and \nthe degree to which it \"suggests\" efficient object code.\n compiling multiplications, fixed point arithmetic\n", "2186": "Numerical Properties of the Ritz-Trefftz Algorithm for Optimal Control In this paper the Ritz-Trefftz algorithm is applied\nto the computer solution of the state regulator \nproblem.  The algorithm represents a modification of\nthe Ritz direct method and is designed to improve \nthe speed of solution and the storage requirements to\nthe point where real-time implementation becomes \nfeasible.  The modification is shown to be more stable\ncomputationally than the traditional Ritz approach. \n The first concern of the paper is to describe the\nalgorithm and establish its properties as a valid \nand useful numerical technique.  In particular such useful\nproperties as definiteness and reasonableness \nof condition are established for the method.  The second\npart of the paper is devoted to a comparison \nof the new techniques with the standard procedure of\nnumerically integrating a matrix Riccati equation \nto determine a feedback matrix.  The new technique is\nshown to be significantly faster for comparable \naccuracy.\n splines, regulator problem, control theory, numerical analysis\n", "2187": "Computer Science: A Conceptual Framework for Curriculum Planning Two views of computer science are considered:\na global view which attempts to capture broad \ncharacteristics of the field and its relationships to\nother fields, and a local view which focuses on \nthe inner structure of the field.  This structure is presented\nin terms of the kinds of knowledge, problems, \nand activities that exist within the discipline, as\nwell as the relations between them.  An approach \nto curriculum planning in computer science is presented\nwhich is guided by the structure of the field, \nby the fact that change is an important feature of the\nsituation, and by the expectation that computer\nscience will continue to increase its working contacts with other disciplines.\n computer science, curriculum planning, education\n", "2188": "An Approach to the Optimum Design of Computer Graphics Systems Display system designers are faced with the\ndifficult task of selecting major subsystems in \nan intelligent way.  Each subsystem is chosen from large\nnumbers of alternatives; the selection is based \non considerations such as system response time, system\ncost, and the distribution of data storage and \nprocessing between the graphics processor and its supporting\ndata processing system.  The work reported \nhere develops an objective, quantitative design procedure\nand helps give a better understanding of now \nto  configure display systems.  This is accomplished by\nmeans of a mathematical model of a computer driven \ngraphics system.  The parameters of the model are functions\nof the capabilities of the graphics hardware \nand of the computational requirements of the graphics application.\n The model can be analyzed using numerical \nqueueing analysis or simulation to obtain an average\nresponse time prediction.  By combining the model \nwith an optimization, the best graphics system configuration,\nsubject to a cost constraint, is found \nfor several applications.  The optimum configurations\nare in turn used to find general display system \ndesign guidelines.\n design guidelines, graphic display systems, mathematical\nmodel, optimum system design, queueing \nmodel\n", "2189": "Generation of Rosary Permutations Expressed in Hamiltonian Circuits Systematic generation of a specific class\nof permutations fundamental to scheduling problems \nis described.  In a nonoriented complete graph with\nn vertices, Hamitonian circuits equivalent to .5(n \n- 1)! specific permutations of n elements, termed rosary\npermutations, can be defined.  Each of them \ncorresponds to two circular permutations which mirror-image\neach other, and is generated successively \nby a number system covering 3*4*...*(n-1) sets of edges.\n Every set of edges {E[k]}, 1 <= E[k] <= k, \n3 <= k <= (n-1) is determined recursively by constructing\na Hamiltonian circuit with k vertices from \na Hamiltonian circuit with k-1 vertices, starting with\nthe Hamiltonian circuit of 3 vertices.  The basic \noperation consists of transposition of a pair of adjacent\nvertices where the position of the pair in \nthe permutation is determined by {E[k]}.  Two algorithms\ntreating the same example for five vertices \nare presented.  It is very easy to derive all possible n!\npermutations  from the .5(n - 1 )! rosary permutations \nbe cycling the permutations and by taking them in the\nreverse order-procedures which can be performed \nfairly efficiently by computer. \n permutation, graph theory, scheduling, combinatorial algebra\n", "2190": "Function Minimization", "2191": "ALGORITHM 410 Partial Sorting [M1] sorting, partial sorting order statistics\n", "2192": "Another Recursion Induction Principle An inductive method for proving things about\nrecursively defined functions is described.  It \nis shown to be useful for proving partial functions equivalent\nand thus applicable in proofs about interpreters \nfor programming languages.\n recursion, induction, correctness, proofs, compiler correctness\n", "2193": "On Implementation of Label Variables Variables of label mode are conventionally\nimplemented with a technique which fails to trap \ncertain programming errors.  Fine-grained calendar clocks\nhave recently become available; these allow \nimplementation of label variables via a new technique\nwhich traps all programming errors of this variety.\n labels, compiler, interpreter, go to, transfer\n", "2194": "How To Keep the Addresses Short An algorithm is presented for minimizing the\nsum of the lengths of the blocks of coding produced \nby an assembler or compiler when (1) the length of\neach computer instruction is assumed to be either \n\"long\" or \"short\" (\"long,\" if the memory location addressed\nis more than a predetermined distance from \nthe current location; \"short,\" otherwise), and (2)\nthere are blocks of instructions whose beginnings \n(origins) are separated by prespecified amounts. For example,\nsome computers permit either 8-bit addressing \n(interpreted relative to the location counter) or full\n16-bit addressing of all of memory.  When assembling \nor compiling two or more blocks of instructions which\nhave many mutual references in such a computer, \nthere is no simple iterative procedure for keeping\nas many of the addresses short as possible.  This \npaper demonstrates that a wide class of problems of\nthis type can be formulated as covering problems \nsolvable by means of elementary arithmetic operations\non the column vectors of a ternary matrix.\n addressing, assembler, covering problem, integer\nprogramming, variable-length addressing\n", "2195": "On the Optimal Detection of Curves in Noisy Pictures A technique for recognizing systems of lines\nis presented.  In this technique the heuristic \nof the problem is not embedded in the recognition algorithm\nbut is expressed in a figure of merit.   \nA multistage decision process is then able to recognize\nin the input picture the optimal system of lines \naccording to the given figure of merit.  Due to the\nglobal approach, greater flexibility and adequacy \nin the particular problem is achieved.  The relation\nbetween the structure of the figure of merit and \nthe complexity of the optimization process is then discussed.\n The method described is suitable for parallel \nprocessing because the operations relative to each\nstate can be computed in parallel, and the number\nof stages is equal to the length N of the curves (or\nto log2 N if the approximate method is used).\n picture processing, picture recognition, picture\ndescription, curve detection, line detection, \nedge detection,optimal detection, heuristic methods,\nglobal recognition, parallel processing, dynamic \nprogramming, interaction graph, secondary optimization problem\n", "2196": "A Man-Machine Approach Toward Solving the Traveling Salesman Problem The traveling salesman problem belongs to an\nimportant class of scheduling and routing problems. \n It is also a subproblem in solving others, such as\nthe warehouse distribution problem.  It has been \nattacked by many mathematical methods with but meager\nsuccess.  Only for special forms of the problem \nor for problems with a moderate number of points can\nit be solved exactly, even if very large amounts \nof computer time are used.  Heuristic procedures have\nbeen proposed and tested with only slightly better \nresults.  This paper describes a computer aided heuristic\ntechnique which uses only a modest amount of \ncomputer time in real-time to solve large (100-200)\npoint problems.  This technique takes advantage of \nboth the computer's and the human's problem-solving\nabilities.  The computer is not asked to solve the \nproblem in a brute force way as in many of today's heuristics,\nbut it is asked to organize the data for \nthe human so that the human can solve the problem easily.\n The technique used in this paper seems to \npoint to new directions in the field of man-machine interaction\nand in the field of artificial intelligence.\n heuristic procedures, computer-aided heuristic technique,\nman-machine interaction, artificial intelligence, \nassignment problem, mask of the assignment, rubber band\ntour generator, interaction process, traveling \nsalesman problem\n", "2197": "The Merit of Regional Computing Networks One of the suggested means for stimulating the\nspread of computing capabilities in institutions \nof higher learning is through the construction of regional\ncomputing networks.  One such network has \nbeen constructed in the San Francisco Bay Area by Stanford\nUniversity.  This paper reports upon the lessons \nlearned from the operation of the network over the past\ntwo years.  A major impact of the network was \nnot so much the computer power delivered to the schools\nas the awakening of computing awareness and the \nfostering of capability development at these schools. The\nexpertise and assistance from the central facility\nas well as the sharing of ideas among the participants\nwere other important benefits.  Both the quality \nand variety of services provided by the central facility\nwere found to play a key role in the effectiveness \nof the network.  A regional network brings many benefits\nand should not be judged as a purveyor of raw \ncomputer power alone.\n computer sharing, computer utility, cooperative networks,\ncurriculum development, educational computing, \nnetwork computing, regional computing networks,\nremote computing, shared computing\n", "2198": "Introduction to \"Feature Analysis of This paper is a separately published introduction\nto a main report which analyzes the features \nof generalized data base management systems.  This introduction\ngives a review of the current state of \nthe art in these systems and discusses the differences\nand similarities between capabilities found in \nhost language systems and those found in self-contained\nsystems.  After some discussion of the problems \nof data independence and binding,the four user levels\nare identified and described.  Technical problems \nfacing future designers are described.  The first of\nthese is that of handling existing stored data and \nthe next is that of providing more complex data structures\nthan those already available in conventional \nprogramming languages.  The problem of high level interrogation\nand update functions acting on network \nstructures is mentioned, followed by a discussion of the\nproblem of catering to a high volume of transactions \ninitiated from terminals by parametric users-the lowest\nlevel of user.  The use of Cobol as a basis for \nfurther development work is considered at some length\nwith respect to data structures, host language \ncapabilities, and self-contained capabilities.  This\nsection also assesses the effect of the Data Base \nTask Group proposals.  The final section outlines the\nten major topics in the main body of the full report.\n data base management systems, programming languages,\ndata structures, storage structures, information \nretrieval, transaction processing\n", "2199": "A Sparse Matrix Package (Part I) [F4] (Algorithm 408) matrix, sparse matrix, matrix manipulation\n", "2200": "On Complement Division The division algorithm theorem is expressed\nin a form that permits it to serve as the basis \nfor devising division operations that produce both quotient\nand remainder in complement form.  Algorithms \nfor division yielding complement results are derived\nfor numbers represented in any base greater than \none.  Both radix and radix-less-one complementation schemes\nare considered.  The binary form of the algorithms \nthus includes both two's and one's complement implementation.\n The problem of quotient overflow for complement \nresults is dealt with as is that of selecting an appropriate\nform of the remainder condition for complement \ndivision. \n division algorithm, complement arithmetic, complement\ndivision, one's complement arithmetic, two's \ncomplement arithmetic\n", "2201": "Animator: An On-Line Two-dimensional Film Animation System Animator is a computer animation system which\nwas designed to overcome some of the inherent \ndisadvantages associated with conventional computer animation\ntechniques.The DEC-338 serves as an input \nterminal for movie making, allowing the trial and error\ndesign of picture sequences in a conversational \nmode.  During all stages on the system input elements\n(light pen, pushbuttons, and teletype) is maintained. \n At the user's request, this record is sent to the IBM\n360/75 where the S-D 4020 instructions necessary \nto produce the same sequence of pictures can be generated.\n It is anticipated that one of the primary \ncontributions of Animator will be the provision of a\nfacility which will allow any professor to produce \nhis own expository film strips.\n computer graphics, computer animation, on-line\nsystems, two-dimensional languages, CRT, microfilm \nrecorder\n", "2202": "Dynamic Microprogramming: Processor Organization and Programming A dynamically microprogrammed processor is characterized\nby a small (4^k 64-bit word) read-write \n\"micro\" storage.  The access time of this storage is\nsimilar to the cycle time of the machine (50-100 \nnsec).  This microstorage is used to contain both data\nand subroutines.  The (micro) instructions in \nsuch a processor differ from the conventional in that\nthey perform only purely combinatorial operations; \nsequencing is under the control of the microinstruction.\nThe presence of the read-write microstorage \npermits a more flexible assignment of resources than the\nread-only storage.  In particular, the processor \ndeveloped in this paper stresses the simultaneous operation\n(within the microinstruction) of the adder, \nshifter, masker, and testing facilities of the processor.\n A microassembly language is developed and \nthe overhead involved in subroutine linkages is analyzed.\n The efficiency of a flexible software linkage \nscheme is examined as to its overhead for various subroutine\ncharacteristics.  Finally, three examples \nof problem-oriented programming are considered and the\nresulting coding is compared against a System/360 \nassembly language version, with the technology normalized.\n microprogramming,read-write microstorage,\nsubroutine linkage, execution speed \n", "2203": "Key-to-Address Transform Techniques: A Fundamental The results of a study of eight different\nkey-to-address transformation methods applied to \na set of existing files are presented.  As each method\nis applied to a particular file, load factor and \nbucket size are varied over a wide range.  In addition,\nappropriate variables pertinent only to a specific \nmethod take on different values.  The performance of\neach method is summarized in terms of the number \nof accesses required to get to a record and the number\nof overflow records created by a transformation. \n Peculiarities of each method are discussed.  Practical\nguidelines obtained from the results are stated. \n Finally, a proposal for further quantitative fundamental study is outlined.\n hashing, hashing techniques, hashing methods, hash\ncoding, keys, key transformation, key-to-address \ntransformation, direct addressing, direct access method,\nrandomizing, random access,file addressing, \nfile organizations, file structures, scatter storage,\nsearch, collisions, clusters, information retrieval\n", "2204": "Program Development by Stepwise Refinement The creative activity of programming-to be distinguished\nfrom coding-is usually taught by examples \nserving to exhibit certain techniques.  It is here considered\nas a sequence of design decisions concerning \nthe decomposition of tasks into subtasks and of data\ninto data structures.  The process of successive \nrefinement of specifications is illustrated by a short\nbut nontrivial example, from which a number of \nconclusions are drawn regarding the art and the instruction of programming.\n education in programming, programming\ntechniques, stepwise program construction\n", "2205": "DIFSUB for Solution of Ordinary Differential differential equations, stiff differential equations\n", "2206": "Exact Solution of Linear Equations Using residue arithmetic, symmetric residue, modulus,\nmixed-radix representation, symmetric mixed-radix \nrepresentation, mixed-radix conversion, prime number,\nlinear equations, Gaussian elimination, matrix \ninversion, determinant, adjoint matrix, ill-condition\n", "2207": "The Automatic Integration of Ordinary Differential Equations An integration technique for the automatic\nsolution of an initial value problem for a set of \nordinary differential equations is described.  A criterion\nfor the selection of the order of approximation \nis proposed.  The objective of the criterion is to increase\nthe step size so as to reduce solution time. \nAn option permits the solution of \"stiff\" differential\nequations.  A program embodying the techniques \ndiscussed appears in Algorithm 407.\n differential equations, stiff equations,\nintegration, step control, order control\n", "2208": "Storage Utilization in a Memory Hierarchy When Storage The utilization of storage is studied in a two-level\nmemory hierarchy.  The first storage level, \nwhich is the fast store, is divided into a number of\nstorage areas.  When an entry is to be filed in \nthe hierarchy, a hashing algorithm will attempt to\nplace the entry into one of these areas.  If this \nparticular area is full, then the entry will be placed\ninto the slower second-level store, even though \nother areas in the first-level store may have space\navailable.  Given the N entries have been filed in \nthe entire hierarchy, an expression is derived for the\nexpected number of entries filed in the first-level \nstore.This expression gives a measure of how effectively\nthe first-level store is being used.  By means \nof examples, storage utilization is then studied as a\nfunction of the hashing algorithm, the number of \nstorage areas into which the first-level store is divided\nand the total size of the first-level store. \n hashing algorithms, memory allocation, memory hierarchy,\nmemory utilization, storage allocation, \nstorage hierarchy, storage utilization\n", "2209": "A Scheduling Algorithm for a Computer Assisted Registration System This paper presents the scheduling algorithm\nused in the Computer Assisted Registration System \nat the University of Tennessee.  Notation is defined and\nthe logic of the algorithm necessary to implement \neducational policy is described.  Results from\nthe first term's implementation are presented.\n computer assisted registration, scheduling algorithm, timetable\n", "2210": "Toward Automatic Program Synthesis An elementary outline of the theorem-proving\napproach to automatic program synthesis is given, \nwithout dwelling on technical details.  The method is\nillustrated by the automatic construction of both \nrecursive and iterative programs operating on natural\nnumbers,lists, and trees,  In order to construct \na program satisfying certain specifications a theorem\ninduced by those specifications is proved, and \nthe desired program is extracted from the proof.  The\nsame technique is applied to transform recursively \ndefined functions into iterative programs, frequently\nwith a major gain inefficiency.  It is emphasized \nthat in order to construct a program with loops or with\nrecursion, the principle of mathematical induction \nmust be applied. The relation between the version of\nthe induction rule used and the form of the program \nconstructed is explored in some detail.\n artificial intelligence, answer extraction, automatic\nprogram synthesis, mathematical induction \nprinciple, problem solving, theorem proving\n", "2211": "Scanned-Display Computer Graphics A television-like scanned-display system has\nbeen successfully implemented on a Honeywell DDP-224 \ncomputer installation.  The scanned image is stored\nin the core memory of the computer, and software \nscan conversion is used to convert the rectangular coordinates\nof a point to the appropriate word and \nbit in an output display array in core storage.  Results\nthus far indicate that flicker-free displays \nof large amounts of data are possible with reasonably\nfast graphical interaction.  A scanned image of \nsize 240 X 254 points is displayed at a 30 frame-per-second rate.\n computer graphics, scanned-display, scan conversion, raster displays\n", "2212": "F-DISTRIBUTION Fisher's F-distribution, Student's t-distribution\n", "2213": "Roots of Matrix Pencils: The Generalized eigenvalues, matrix roots, pencil roots\n", "2214": "Complex Interval Arithmetic Complex interval arithmetic is defined using\nreal interval arithmetic.  Complex interval division \nis defined so as to assure smallest possible resulting intervals.\n real intervals, real interval arithmetic,\ncomplex intervals, complex interval arithmetic\n", "2215": "Application of Game Tree Searching Techniques A sequential pattern recognition (SPR) procedure\ndoes not test all the features of a pattern \nat once.  Instead, it selects a feature to be tested.  After\nreceiving the result of that test, the procedure \neither classifies the unknown pattern or selects another\nfeature to be tested, etc.  Medical diagnosis \nis an example of SPR.  In this paper the authors suggest\nthat SPR be viewed as a one-person game played \nagainst nature (chance).  Virtually all the powerful techniques\ndeveloped for searching two-person, strictly \ncompetitive game trees can easily be incorporated either\ndirectly or by analogy into SPR procedures. \n In particular, one can incorporate the \"mini average\nbacking-up procedure\" and the \"gamma procedure,\" \nwhich are the analogues of the \"minimax backing-up procedure\"\nand the \"alpha-beta procedure,\" respectively. \n Some computer simulated experiments in character recognition\nare presented.  The results indicate that \nthe approach is promising.\n sequential pattern recognition, game tree searching,\ngame against nature, gamma procedure, mini average \nbacking-up procedure, dynamic programming, branch-and-bound\napproach, optimal solution\n", "2216": "On the Probability Distribution of the Values of Binary Trees An integral equation is derived for the generating\nfunction for binary tree values, the values \nreflecting sorting effort. The analysis does not assume\nuniformly distributed branching ratios, and \ntherefore is applicable to a family of sorting algorithms\ndiscussed by Hoare, Singleton, and van Emden. \n The solution to the integral equation indicates that\nusing more advanced algorithms in the family makes \nonly minor reductions in the expected sorting effort,\nbut substantially reduces the variance in sorting \neffort.  Statistical tests of the values of several\nthousand trees containing up to 10,000 points have \ngiven first, second, and third moments of the value distribution\nfunction in satisfactory agreement with \nthe moments computed from the generating function.  The\nempirical tests, as well as the analytical results, \nare in agreement with previously published results for the\nfirst moment in the cases of uniform and nonuniform \ndistribution of branching ratio, and for the second moment\nin the case of uniform distribution of branching \nratio.\n binary trees, sorting, statistical analysis\n", "2217": "Experiments in Automatic Learning for a Multipurpose Heuristic Program An automatic learning capability has been developed\nand implemented for use with the MULTIPLE \n(MULTIpurpose Program that LEarns) heuristic tree-searching\nprogram, which is presently being applied \nto resolution theorem-proving in predicate calculus.\nMULTIPLE's proving program (PP) uses two evaluation \nfunctions to guide its search for a proof of whether\nor not a particular goal is achievable.  Thirteen \ngeneral features of predicate calculus clauses were created\nfor use in the automatic learning of better \nevaluation functions for PP.  A multiple regression\nprogram was used to produce optimal coefficients \nfor linear polynomial functions in terms of the features.\n Also, automatic data-handling routines were \nwritten for passing data between the learning program\nand the proving program, and for analyzing and \nsummarizing results.  Data was generally collected for\nlearning (regression analysis) from the experience \nof PP.  A number of experiments were performed to test\nthe effectiveness and generality of the learning \nprogram. Results showed that the learning produced dramatic\nimprovements in the solutions to problems \nwhich were in the same domain as those used for collection\nlearning data.  Learning was also shown to \ngeneralize successfully to domains other than those used\nfor data collection.  Another experiment demonstrated \nthat the learning program could simultaneously improve\nperformance on problems in a specific domain and \non problems in a variety of domains.  Some variations\nof the learning program were also tested.\n learning, theorem-providing, heuristic, automatic\nlearning, self-modifying,tree-searching, artificial \nintelligence, problem-solving, adaptive, LISP, multiple regression, resolution\n", "2218": "An Analysis of Some Time-Sharing Techniques The effectiveness of certain time-sharing techniques\nsuch as program, relocation, disk rotational \ndelay minimization, and swap volume minimization is\ninvestigated.  Summary data is presented, and the \nfindings are discussed.  The vehicle for this investigation\nwas a SIMULA based simulation model reflecting \nan early framework for a planned Burroughs B6500 time-sharing\nsystem.  Inasmuch as the B6500 system is \nbased upon the use of variable sized segments and a\ndynamic overlay procedure, data is also presented \nwhich provides some indication of the effectiveness of this\ntype of organization in a time-sharing environment. \n The design characteristics and operational capabilities\nof the simulation model are also described.\n B6500, bulk core usage, operating system model, relocation,\nrotational delay minimization, simulation, \nswap volume minimization, system simulation, time-sharing\n", "2219": "A Policy-Driven Scheduler for a Time-Sharing System The service received by a process from a time-sharing\noperating system can be characterized \nby a resource count SUM{w[i]R[ij]} where R[ij] is the\nnumber of units of service received by process \ni from resource i and w[i] is the cost per unit of the\nservice.  Each class of users can be characterized \nby a policy function which specifies the amount of service\na user who belongs to this class should receive \nas a function of time.  Priority changes dynamically\nas a function of the difference between the service \npromised to the user by the policy function and the service\nhe actually receives.  A scheduling and swapping \nalgorithm which keeps the resource count of each process\nabove its policy function will provide the specified \nlevel of service.  Overhead can be reduced by avoiding\nswaps of process which have received at least \nhis level of service.  The algorithm has been implemented\nin a general purpose operating system, and \nit has provided significantly better service to interactive\nand to batch jobs than the previous scheduler.\n scheduler, time-sharing, operating system,\nresource allocation and swapping\n", "2220": "Conversion of Limited-Entry Decision Tables to Computer Pollack has proposed an algorithm for converting\ndecision tables into flowcharts which minimize \nsubsequent execution time when compiled into a computer\nprogram.  Two modifications of this algorithm \nare proposed.  The first relies on Shannon's noiseless\ncoding theorem and the communications concept \nof entropy but does not completely test the ELSE Rule.\n The second modification completely tests the \nELSE Rule but results in more executions than the first modification.\n Both modifications result in modification \nguarantees a globally optimal solution.\n coding, decision table, entropy, information\ntheory, noiseless channel, sorting\n", "2221": "Comment on the Conversion of Decision Tables to Computer Programs decision tables, diagnostic aids, system analysis, business applications\n", "2222": "Comment on London's Certification of Algorithm 245 proof of algorithms, debugging, certification,\nmetatheory,  sorting, in-place sorting\n", "2223": "Minit Algorithm For Linear Programming (Algorithm 222 [H]) linear programming, dual simplex method, primal problem, dual problem\n", "2224": "Complex Gamma Function [S14] (Algorithm 404) gamma function, poles of gamma function, Stirling's\nasymptotic series, recursion formula, reflection \nformula\n", "2225": "Circular Integer Partitioning [A1] (Algorithm 403) partitions, combinatorics, statistical design of experiments\n", "2226": "Further Evidence for the Analysis of Algorithms The purpose of this note is to report computational\nexperience additional to that recently \nsummarized by Gue et al, with two algorithms for the\nzero-one linear programming problem.  An error in \nGue's paper is corrected.  The utility of one of\nthe algorithms as a suboptimizer is indicated.\n operations research, integer programming, zero-one variables, algorithms\n", "2227": "Proof of a Program: FIND A proof is given of the correctness of the\nalgorithm \"Find.\"  First, a informal description \nis given of the purpose of the program and the method\nused.  A systematic technique is described for \nconstructing the program proof during the process of coding\nit, in such a way as to prevent the intrusion \nof logical errors.  The proof of termination is treated\nas a separate exercise.  Finally, some conclusions \nrelating to general programming methodology are drawn.\n proofs of programs, programming methodology, program\ndocumentation, program correctness, theory \nof programming\n", "2228": "Comments on Prevention of System Deadlocks Habermann's method of deadlock prevention is\ndiscussed, where deadlock is defined as a system \nstate from which resource allocations to certain processes\nare not possible.  It is shown that the scheduler \nmay introduce \"artificial\" deadlocks which Habermann's\nmethod does not prevent.  Permanent blocking is \nthe situation where certain processes never receive their\nresource requests.  It is shown that deadlock \nprevention does not necessarily eliminate permanent blocking.\n A method of preventing permanent blocking \nis given.\n multiprogramming, time-sharing, scheduling, resource\nallocation, deadlock, lockout, deadly embrace, \nknotting \n", "2229": "Construction of Rational and Negative Powers of a Formal Series Some methods are described for the generation\nof fractional and negative powers of any formal \nseries, such as Poisson series or Chebyshev series.  It\nis shown that, with the use of the three elementary \noperations of addition, subtraction, and multiplication,\nall rational (positive and negative) powers \nof a series can be constructed.  There are basically two\napproaches: the binomial theorem and the iteration \nmethods.  Both methods are described here, and the relationship\nbetween them is pointed out.  Some well-known \nclassical formulas are obtained as particular cases,\nand it is shown how the convergence properties of \nthese formulas can be improved with very little additional\ncomputations.  Finally, at the end of the \narticle, some numerical experiments are described\nwith Chebyshev series and with Fourier series.\n series expansion, series inversion, root extraction,\nbinomial theorem, Newton iterations, Chebyshev \nseries, Poisson series, Fourier series\n", "2230": "A Language for Treating Geometric Patterns in a Two-dimensional space In this paper CADEP, a problem-oriented language\nfor positioning geometric patterns in a two-dimensional \nspace, is presented.  Although the language has been\nspecifically designed for the automatic generation \nof integrated circuit masks, it turns out to be well\nsuited also for such other placement problems as \narchitecture design, urban planning, logical and block\ndiagram representation.  The design criteria, \nthe structure, and the specific features of CADEP are illustrated.\n graphic language, problem-oriented language, two-dimensional\npatterns, graphic display, Fortran \nextension, layout problems, integrated circuit,\narchitecture design, urban planning\n", "2231": "The Reconstruction of Binary Patterns from Their Projections Given the horizontal and vertical projections\nof a finite binary pattern f, can we construct \nthe original pattern f?  In this paper we give a characterization\nof patterns that are reconstructable \nfrom their projection.  Three algorithms are developed\nto reconstruct both unambiguous and ambiguous \npatterns.  It is shown that an unambiguous pattern can\nbe perfectly reconstructed in time m X n and that \na pattern similar to an ambiguous pattern can also be constructed\nin time m X n, where m, n are the dimensions \nof the pattern frame.\n pattern reconstruction, image reconstruction, data\ncompression, pattern recognition, integral geometry\n", "2232": "Pattern Width at a Given Angle That the pattern feature \"width as a function\nof angle\" possesses several possible interpretations \nis demonstrated in this paper, which is a review of\nthe width concept in pattern recognition and the \ngeometrical concept itself.  The object of the work\nis to clarify how the word description can be made \nprecise so that computer algorithms for feature extraction\nmay be obtained; the focus is on the theoretical \nsubject matter.  The results consist of a set-theoretic\ndefinition of width-at-angle, a theorem relating \nit to the pattern boundary radius vector, and descriptions\nof alternate widths.  All widths are calculated \nfor an illustrative example; graphical and tabular comparisons\nare given.  Substantial variation in width-at-angle \nmagnitude is found.  The principal conclusion is that\nthe set-theoretic width-at-angle is a useful pattern \nfeature when it can be easily computed.  Further investigation\nof the information contained in only part \nof a width function is recommended for cases where\ncomputation of width-at-angle is difficult.\n feature extraction, pattern recognition,figure\nproperties, picture processing, integral geometry, \nwidth-at-angle, extent, integral projections,\nlinear pattern measures, width functions\n", "2233": "Signature Simulation and Certain Cryptographic Codes Three cyphers allegedly authored by Thomas\nJefferson Beale in 1822 have been the subject of \nintensive study for over 100 years.  Generations of\ncryptanalysts have expended untold man-years, thus \nfar without success, attempting tode code them; vast armies\nof fortune hunters and treasure seekers have \ndevoted Herculean labors to digging up the rolling hills\nof Virginia trying to locate the promised bonanza. \n The history of pertinent activities would fill volumes,\nyet serious students of cryptography have always \nhad nagging doubts about the cyphers' authenticity.\n It has been alleged that the \"known solution\" to \nCypher Number Two: 115, 73, 24, 818, 37, 52, 49,...(\"I\nhave deposited in the County of Bedford about \nfour miles from Buford's in an excavation or vault...\")\nwith the aid of an unsanitized version of the \nDeclaration of Independence was merely a superb, imaginative,\nand grandiose hoax perpetrated ages ago \nfor whatever reasons.  Modern computer technology could\nobviously perform signature analyses the process \nof encoding itself so as to yield new clues and deeper\ninsights into their construction.  For the benefit \nof the uninitiated, the encoding method used in the\nsecond cypher employs a specified document whose \nwords are simply numbered consecutively, and first letters\nof these words are sought out at random to \nmatch the letters of these words are sought out at random\nto match the letters of the clear text or message. \n The sequence of numbers corresponding to these matches\nis then written down as the final code.  While \nprimitive, the process has the advantage of relative\nsecurity until the source document becomes known; \nat that moment the cypher can be decoded even by second\ngraders.  The work now completed with the help \nof our UNIVAC 1108 includes numerous analytical studies\nof the Beale cyphers and various types of simulations. \n For example, we have turned the entire process of\nsimulated encoding by various schemes over to the \nmachine and analyzed the signatures of these synthetic\ncodes; we have also encoded various messages by \nhand, using different texts and a variety of methods to\nobtain their signatures. These simulations provide \nconvincing evidence that the signatures are both process\nand data dependent; they indicate also very \nstrongly that Mr. Beale's cyphers are for real and that\nit is merely a matter of time before someone \nfinds the correct source document and locates the\nright vault in the common-wealth of Virginia.\n Thomas Jefferson Beale, codes, cryptanalysis, cyphers,\ndecoding, Declaration of Independence, encoding, \nMagna Carta, pseudotext, signature, simulation\n", "2234": "Roots of Matrix Pencils (Algorithm R405) eigenvalues, matrix roots, pencil roots\n", "2235": "Decision Table Translation (Algorithm R394) decision table, decision table translation\n", "2236": "Remarks on Characteristic Values and Associated ANSI Fortran standard\n", "2237": "BANDSOLVE (Algorithm R195)", "2238": "Least Squares Surface Fit (Algorithm R176)", "2239": "Squank (Algorithm C379) numerical integration, integration rule, adaptive\nintegration, automatic integration, Simpson's \nrule, numerical quadrature, quadrature rule, adaptive\nquadrature, automatic quadrature, round-off error \ncontrol\n", "2240": "Pseudo-Random Numbers [G5] (Algorithm C266) pseudo-random numbers, testing random number generators\n", "2241": "Product Type Three-point Gauss-Legendre-Simpson's numerical integration, product type quadrature,\nGaussian quadrature, Simpson's rule\n", "2242": "Product Type Two-Point Gauss-Legendre-Simpson's numerical integration, product type quadrature,\nGaussian quadrature, Simpson's rule\n", "2243": "Product Type Simpson's Integration [D1] (Algorithm A437) numerical integration, product type quadrature, Simpson's rule\n", "2244": "Product Type Trapezoidal Integration (Algorithm A436) numerical integration, product type quadrature, trapezoidal integration\n", "2245": "Trace-Driven Modeling and Analysis of Microscopic level job stream data obtained in\na production environment by an event-driven software \nprobe is used to drive a model of a multiprogramming\ncomputer system.  The CPU scheduling algorithm of \nthe model is systematically varied.  This technique,\ncalled trace-driven modeling, provides an accurate \nreplica of a production environment for the testing of variations\nin the system.  At the same time alterations \nin scheduling methods can be easily carried out in a\ncontrolled way with cause and effects relationships \nbeing isolated.  The scheduling methods tested included\nthe best possible and worst possible methods, \nthe traditional methods of multiprogramming theory, round-robin,\nfirst-come-first-served, etc., and dynamic \npredictors.  The relative and absolute performances of\nthese scheduling methods are given.  It is concluded \nthat a successful CPU scheduling method must be preemptive\nand must prevent a given job from holding \nthe CPU for too long a period.\n scheduling, CPU scheduling,multiprogramming,\nperformance measurement, trace driven models\n", "2246": "Levels of Language for Portable Software An increasing amount of software is being\nimplemented in a portable form.  A popular way of \naccomplishing this is to encode the software in a specially\ndesigned machine-independent language and \nthen to map this language, often using a macro processor,\ninto the assembly language of each desired \nobject machine.  The design of the machine-independent\nlanguage is the key factor in this operation. \n This paper discusses the relative merits of pitching\nthis language at a high level or a low level, and \npresents some comparative results.\n portable software, level of language, machine\nindependent, macro processor, efficiency\n", "2247": "On the Criteria To Be Used in Decomposing Systems into Modules This paper discusses modularization as a mechanism\nfor improving the flexibility ad comprehensibility \nof a system while allowing the shortening of its development\ntime.  The effectiveness of a \"modularization\" \nis dependent upon the criteria used in dividing the\nsystem into modules.  A system design problem is\npresented and both a conventional and unconventional\ndecomposition are described.  It is shown that the \nunconventional decompositions have distinct advantages\nfor the goals outlined.  The criteria used in \narriving at the decompositions are discussed.  The\nunconventional decomposition, if implemented with \nthe conventional assumption that a module consists of\none or more subroutines, will be less efficient \nin most cases.  An alternative approach to implementation\nwhich does not have this effect is sketched.\n software, modules, modularity, software\nengineering, KWIC index, software design\n", "2248": "A New Method for the Solution of the An integral equation representation is given\nfor parabolic partial differential equations. \n When the equations are defined in unbounded domains, as\nin the initial value (Cauchy) problem, the solution \nof the integral equation by the method of successive\napproximation has inherent advantages over other \nmethods.  Error bounds for the methods are of order h^(3/2)\nand h^(7/2) (his the increment size) depending \non the finite difference approximations involved.\n parabolic equations, the Cauchy problem,\nmethod of successive approximations\n", "2249": "A Comparison of Multivariate Normal Generators Three methods for generating outcomes on multivariate\nnormal random vectors with a specified \nvariance-covariance matrix are presented.  A comparison\nis made to determine which method requires the \nleast computer execution time and memory space when utilizing\nthe IBM 360/67.  All methods use as a basis \na standard Gaussian random number generator.  Results\nof the comparison indicate that the method based \non triangular factorization of the covariance matrix\ngenerally requires less memory space and computer \ntime than the other two methods. \n random number generator, normal distribution, multivariate\nnormal distribution, multivariate normal \ngenerator\n", "2250": "Computer Methods for Sampling from the Exponential", "2251": "Weighted Increment Linear Search for Scatter Tables A new linear search for hash tables whose increment\nstep is a function of the key being addressed \nis presented.  Comparisons with known methods are given,\nin terms of efficiency and computation complexity. \n In particular, the new method applies to tables of\nsize n = 2^r.  It allows full table searching, and \npractically eliminates primary clustering at a very low cost.\n linear search, weighted increment search, scatter\nstorage, hash table, key, hash address, clustering, \nsearch length\n", "2252": "A Method for Incrementally Compiling A method of incremental compilation is presented\nwhich applies especially to programming languages \nin which statements can be nested (such as Algol and\nPL/I).  The method permits editing of the source \nlanguage using a general purpose text editor, and incremental\nprocessing of changes without frequent \nrecompilation of entire routines.  The essential points\nof the method are: (1) the syntax of the language \nis restricted insof ar as which constructs may occur\non lines; (2) an internal data structure (called \nthe skeleton) is maintained to represent the statement\nstructure; (3) the recompilation is partially \nbatched in the sense that recompilation of modified lines\ndoes not occur until the last of a set of editing \ncommands has been received; and (4) the parsing and\ncompilation are factored into two parts, that done \non individual lines and that done globally to\nhandle the relationships between the lines.\n incremental compiler, interactive programming language \n", "2253": "Index Ranges for Matrix Calculi The paper describes a scheme for symbolic\nmanipulation of index expressions which arise as \na by-product of the symbolic manipulation of expressions\nin the matrix calculi described by the authors \nin a previous paper.  This scheme attempts program optimization\nby transforming the original algorithm \nrather than the machine code.  The goal is to automatically\ngenerate code for handling the tedious address \ncalculations necessitated by complicated data structures.\n The paper is therefore preoccupied with \"indexing \nby position.\"  The relationship of \"indexing by\nname\" and \"indexing by position\" is discussed.\n address calculations, algorithm transformation,\ncompilation, data structures, indexing by name, \nindexing by position, index domain, index map, index\nrange, matrix expressions, normal form, programming \nlanguages, program optimization, range operations, symbolic\nmanipulation, syntactic analysis, well-formed \nexpressions\n", "2254": "Dynamic Partitioning for Array Languages The classical process of partitioning an array\ninto subarrays is extended to a more useful \narray language operation.  Various modes of partitioning\nare defined for different types of arrays, so \nthat subarrays may vary over the original array in\na nearly arbitrary manner.  These definitions are \nmotivated with several realistic examples to illustrate\nthe value of partitioning for array languages. \n Of general interest is the data structure for partitioning.\n This consists of dynamic tree structures \nwhich are used to derive and maintain the array control\ninformation.  These are described in sufficient \ndetail to be of value in the design of other array languages.\n The description presented in this paper \nis implemented in a new array language, OL/2, currently\nunder development at the University of Illinois.\n dynamic partitioning, array partitioning array language,\ndata structure, tree structure, programming \nlanguage design, array control blocks, partition control blocks\n", "2255": "Comments on Moorer's Music and Computer Composition artificial intelligence, heuristic programming,\nmodels of cognitive processes, computer music, \ncomputer composition, music theory\n", "2256": "Further Comments on Dijkstra's Concurrent Programming Control Problem critical section, concurrent programming control, multiprocessing\n", "2257": "A Note on Optimal Doubly-Chained Trees file searching, doubly-chained tree, binary search tree\n", "2258": "Additional Results on Key-to-Address Transform hashing, hashing techniques, hashing methods, hash\ncoding, keys, key transformation, key-to-address \ntransformation, direct addressing, direct access method,\nrandomizing, random access file organization, \nfile search, scatter storage, information retrieval\n", "2259": "Modified Incomplete Gamma Function [S14] (Algorithm A435) modified incomplete Gamma function, incomplete\nGamma function, chi-square distribution function, \nPoisson distribution function\n", "2260": "Exact Probabilities for R x C Contingency Tables [G2] (Algorithm A434) probability, contingency table, test of significance\n", "2261": "An Approximate Method for Generating Symmetric Random Variables A method for generating values of continuous\nsymmetric random variables that is relatively \nfast, requires essentially no computer memory, and is\neasy to use is developed.  The method, which uses \na uniform zero-one random number source, is based on\nthe inverse function of the lambda distribution \nof Turkey.  Since it approximates many of the continuous\ntheoretical distributions and empirical distributions \nfrequently used in simulations, the method should\nbe useful to simulation practitioners.\n simulation, Monte Carlo, probability, statistics,\napproximations, random variables, random numbers, \nmoments, distribution\n", "2262": "Garbage Collection for Virtual Memory Computer Systems In list processing there is typically a growing\ndemand for space during program execution. \n This paper examines the practical implications of this\ngrowth within a virtual memory computer system, \nproposes two new garbage collection techniques for virtual\nmemory systems, and compares them with traditional \nmethods by discussion and by simulation.\n garbage collection, virtual memory, list\nprocessing, paging, segmentation, page tables\n", "2263": "The Conversion of Limited-Entry Decision Tables Two new algorithms for deriving optimal and\nnear-optimal flowcharts from limited entry decision \ntables are presented.  Both take into account rule frequencies\nand the time needed to test conditions. \n One of the algorithms, called the optimum-finding algorithm,\nleads to a flowchart which truly minimizes \nexecution time for a decision table in which simple rules\nare already contracted to complex rules.  The \nother one, called the optimum-approaching algorithm, requires\nmany fewer calculations but does not necessarily \nproduce the optimum flowchart.  The algorithms are first\nderived for treating decision tables not containing \nan ELSE-rule, but the optimum-approaching algorithm\nis shown to be equally valid for tables including \nsuch a rule.  Both algorithms are compared with existing\nones and are applied to a somewhat large decision \ntable derived from a real case.  From this comparison two\nconclusions are drawn.  (1) The optimum-approaching \nalgorithm will usually lead to better results than comparable\nexisting ones and will not require more, \nbut usually less, computation time.(2) In general, the\ngreater computation effort needed for applying \nthe optimum-finding algorithm will not be justified\nby the small reduction in execution time obtained.\n decision table, flowcharting, preprocessor, optimal programs, search\n", "2264": "Derived Semantics for Some Programming Language Constructs The constructs of a simple programming language\nare introduced and described informally in \nterms of values and side-effects.  A translator is defined\nwhich translates the language into flowcharts \nfor a simple machine.  The action of the machine in executing\na flowchart is defined.  A proof is constructed \nthat the effect of translating and executing any program\ncan be expressed solely in terms of the value \nand side-effect of the program.  During the course of\nconstructing the proof, formal definitions of the \nconcepts of value and side-effect are derived in order\nto make the proof rigorous.  Correctness of the \nimplementation involves checking that the definitions derived\nin the step above are an acceptable formalization \nof the informal description given in the first step.\n lambda calculus, formal description, program\ncorrectness, programming languages, semantics\n", "2265": "A Model for Type Checking Most current programming languages treat computation\nover different classes of objects (e.g. \nnumbers, strings, labels and functions).  For correct\ncompilation and execution, the following question \nthen arises: is a program properly constructed so that\nits operations and operands are compatible?  The \nactivity of answering this question is usually called\ntype checking.  This paper attempts to isolate \nthe notion of type checking and presents a partial\nsolution to the type checking problem based on the \nnotions of abstraction and application of functions. \nIn particular, a program is mapped into an expression \nwithin a decidable subset of the Lambda calculus, which\ncharacterizes the type relations within the program \nand eliminates all other information.  The determination\nof the type-wise correctness or incorrectness \nof the program is resolved by reducing its corresponding\nLambda calculus expression to one of two normal \nforms, the constant \"correct\" for a type-wise correct\nprogram or the constant \"error\".  An application \nto type checking in Algol 60 is made, and the attendant\nproblems faced for any notion of type checking \nare discussed.\n type checking, types, Lambda calculus, models for\nprogramming languages, syntax, semantics, compiler \nwriting, language implementation, formal definition\n", "2266": "A Highly Parallel Algorithm for Approximating An algorithm is described based on Newton's\nmethod which simultaneously approximates all zeros \nof a polynomial with only real zeros.  The algorithm, which\nis conceptually suitable for parallel computation, \ndetermines its own starting values so that convergence\nto the zeros is guaranteed.  Multiple zeros and \ntheir multiplicity are readily determined.  At no\npoint in the method is polynomial deflation used.\n parallel numerical algorithms, real polynomials,\nreal zeros, Newton's method, starting values, \nguaranteed convergence\n", "2267": "Algorithms To Reveal Properties of Floating-Point Arithmetic Two algorithms are presented in the form of\nFortran subroutines.  Each subroutine computes \nthe radix and number of digits of the floating-point\nnumbers and whether rounding or chopping is done \nby the machine on which it is run.  The methods are\nshown to work on any \"reasonable\" floating-point \ncomputer.\n floating-point arithmetic, high-level\nlanguages, philosophy of language design\n", "2268": "A Comparative Study of Computer Programs A study comparing the performance of several computer\nprograms for integrating systems of ordinary \ndifferential equations is reported.  The integration methods represented\ninclude multistep methods (predictor-correctors), \nsingle-step methods (Runge-Kutta) and extrapolation methods\n(both polynomial and rational).  The testing \nprocedure is described together with the evaluation\ncriteria applied.  A set of test problems on which \nthe programs were tested is included in an appendix.\n For the particular problems and criteria used in \nthe investigation it was found that a program based on\nrational extrapolation showed the best performance.\n ordinary differential equations, integration,\nprogram comparison, certification, validation\n", "2269": "Tableless Date Conversion (Algorithm R398) date, calendar, Fortran statement function, arithmetic statement function\n", "2270": "Interpolation and Smooth Curve Fitting Based interpolation, polynomial, slope of curve, smooth curve fitting\n", "2271": "Aesthetics and the Human Factor in Programming (Corrigendum)", "2272": "Sorting by Natural Selection A family of sorting algorithms is proposed,\nthe members of which make fuller use of the memory \nspace and thus yield longer sorted strings.  Extensive\nsimulation results are presented, and various \nimplications and further applications are discussed.\n algorithms, sorting by replacement selection, expected string length\n", "2273": "Conversion of Decision Tables By Rule Mask Method Without Rule Mask Two algorithms for generating computer programs\nfrom decision tables are described.  The algorithms \nallow handling limited entry, extended entry, and mixed\nentry tables.  The algorithms are based on the \nrule mask method but need not have the masks at execution\ntime.  They perform the logical operations \nimmediately rather than at the end of the interpreting\nprocess.  Execution time can be considerably reduced \nby instantly marking rules which are not applicable (Algorithms\n1 and 2) or conditions which are already \ntested (Algorithm 2).  The new algorithms combine to a\ncertain degree the advantages of mask methods with \nthose of tree methods.\n decision tables, rule mask, rule mask method,\nrule mask technique, program generator\n", "2274": "Generating English Discourse from Semantic Networks A system is described for generating English\nsentences from a form of semantic nets in which \nthe nodes are word-sense meanings and the paths are\nprimarily deep case relations.  The grammar used \nby the system is in the form of a network that imposes\nan ordering on a set of syntactic transformations \nthat are expressed as LISP functions.  The generation\nalgorithm uses the information in the semantic \nnetwork to select appropriate generation paths through\nthe grammar.  The system is designed for use as \na computational tool that allows a linguist to develop\nand study methods for generating surface strings \nfrom an underlying semantic structure.  Initial finding\nwith regard to form determiners such as voice, \nform, tense, and mood, some rules for embedding sentences,\nand some attention to pronominal substitution \nare reported.  The system is programmed in LISP\n1.5 and is available from the authors.\n semantic nets, grammars, deep case relations,\nsemantic generation, discourse generation\n", "2275": "Integral Equations of Immunology The inversion of a particular integral equation\nof the first (Fredholm) kind is the basic problem \nconsidered.  The strategy which yielded success consisted\nof three essential points: (1) fit the known \nexperimental data by a curve with properties which derive\nfrom properties of the (as yet unknown) function; \n(2) stabilize the computation for the unknown function\nby using singular value decomposition; (3) constrain \nthe unknown function approximation (since it represents\na probability distribution) to be nonnegative. \n A number of test cases are presented. One set of actual\nexperimental data is analyzed with the procedures \npresented.\n integral equations of the first kind, nonnegative\nconstraints, singular value analysis\n", "2276": "Computer Methods for Sampling from Various methods are known for transforming uniformly\ndistributed random numbers into exponentially\nand normally distributed quantities.  The most efficient\nones are compared, in terms of memory requirements \nand speed, with some new algorithms.  A number of procedures\nconvert Taylor series expansions directly \ninto sampling steps, an approach which may be used for\nsampling from any continuous distribution.  For \nthe exponential distribution a definite recommendation\ncan be made, whereas in the case of the normal \ndistribution there remains a choice between slower and\nshorter algorithms and faster but space consuming \nmethods.\n random numbers, pseudorandom, normal distribution,\nexponential distribution, exponential distribution, \nsimulation, numerical analysis\n", "2277": "Demand Paging Through Utilization of Working Sets on the MANIAC II A hardware implementation on the Maniac II computer\nof the working set model for demand paging, \nas introduced by Denning, is discussed.  Characteristics\nof the Maniac II are given, along with a description \nof the basic demand paging scheme and the associate memory\nwhich has been added to the Maniac II hardware. \n Finally, a description of the hardware design for implementation\nof the working set model is discussed \nand a specification of the actions taken under various\nconditions which may arise during the operation \nof the full working set model, demand paging system is given.\n demand paging, dynamic storage allocation, Maniac\nII, memory allocation, one-level store, paging, \npaging associative memory, storage allocation,\nthrashing, virtual memory, working set model\n", "2278": "On Foster's Information Storage and Retrieval Using AVL Trees binary trees, search trees, information storage, information retrieval\n", "2279": "A Controller for a Braille Terminal blind programming aid, braille, braille character\nset, braille character translation, braille computer \ncommunication, braille computer terminal, braille terminal,\ntactile computer communication, tactile terminal\n", "2280": "Comment on Deadlock Prevention Method multiprogramming, time-sharing, scheduling, resource\nallocation, deadlock, interlock, lockout, \ndeadly embrace, knotting\n", "2281": "The Eigen problem of Block Tridiagonal Matrices linear algebra, eigenvalues and eigenvectors,\npartial differential equations\n", "2282": "A Comparison of Floating Point Summation Methods summation, floating-point addition, truncation error, error propagation\n", "2283": "Thinning Algorithms on Rectangular, Hexagonal, and Triangular Arrays In this report three thinning algorithms are\ndeveloped: one each for use with rectangular, \nhexagonal, and triangular arrays.  The approach to the\ndevelopment of each algorithm is the same.  Pictorial \nresults produced by each of the algorithms are presented\nand the relative performances of the algorithms \nare compared.  It is found that the algorithm operating\nwith the triangular array is the most sensitive \nto image irregularities and noise, yet it will yield\na thinned image with an overall reduced number of \npoints.  It is concluded that the algorithm operating in\nconjunction with the hexagonal array has features \nwhich strike a balance between those of the other two arrays.\n thinning algorithms, rectangular, hexagonal,\ntriangular arrays, image processing, skeleton\n", "2284": "Solution of the Matrix Equation AX+XB=C [F4] (Algorithm A432) linear algebra, matrices, linear equations\n", "2285": "Computer Routine for Quadratic and Linear A computer program based on Lemke's complementary\npivot algorithm is presented.  This can be \nused to solve linear and quadratic programming problems.\n The program has been extensively tested on\na wide range of problems and the results have been extremely satisfactory.\n linear program, quadratic program, complementary\nproblem, Lemke's algorithm, simplex method\n", "2286": "Automatic Error Analysis for Determining Precision The problem considered is that of evaluating a\nrational expression to within any desired tolerance \non a computer which performs variable-precision floating-point\narithmetic operations.    An automatic \nerror analysis technique is given for determining, directly\nfrom the results of a trial low-precision \ninterval arithmetic calculation, just how much precision\nand data accuracy are required to achieve a \ndesired final accuracy.  The technique given generalize\neasily to the evaluation of many nonrational \nexpressions.\n error analysis, interval arithmetic, precision control\n", "2287": "A New Approach to Automatic Scanning of Contour Maps The problem of automatic digitizing of contour\nmaps is discussed.  The structure of a general \ncontour map is analyzed, and its topological properties\nare utilized in developing a new scanning algorithm. \n The problem of detection and recognition of contour\nlines is solved by a two color labeling method. \n It is shown that for maps containing normal contour lines\nonly, it suffices to distinguish between so-called \n\"even\" and \"odd\" lines.  The \"tangency problem\" involved\nin practical scanning is discussed, and a solution \nbased on minimizing computer memory space and\nsimplifying control program is suggested.\n automatic scanning, contour maps, digitizing,\ncontour lines, topology, detection and recognition\n", "2288": "File Organization: The Consecutive Retrieval Property The consecutive retrieval property is an important\nrelation between a query set and record \nset.  Its existence enables the design of an information\nretrieval system with a minimal search time \nand no redundant storage.  Some important theorems on\nthe consecutive retrieval property are proved in \nthis paper.  Conditions under which the consecutive retrieval\nproperty exists and remain invariant have \nbeen established.  An outline for designing an information\nretrieval system based on the consecutive \nretrieval property is also discussed.\n file organization, consecutive storage, consecutive\nretrieval, information retrieval, record organization, \nquery structure, record structure, storage on\ntapes, storage space, minimum access time\n", "2289": "Cellular Arrays for the Solution of Graph Problems A cellular array is a two-dimensional, checkerboard\ntype interconnection of identical modules \n(or cells), where each cell contains a few bits of\nmemory and a small amount of combinational logic, \nand communicates mainly with its immediate neighbors\nin the array.  The chief computational advantage \noffered by cellular arrays is the improvement in speed\nachieved by virtue of the possibilities for parallel \nprocessing.  In this paper it is shown that cellular\narrays are inherently well suited for the solution \nof many graph problems.  For example, the adjacency\nmatrix of a graph is easily mapped onto an array; \neach matrix element is stored in one cell of the array,\nand typical row and column operations are readily \nimplemented by simple cell logic.  A major challenge\nin the effective use of cellular arrays for the \nsolution of graph problems is the determination of algorithms\nthat exploit the possibilities for parallelism, \nespecially for problems whose solutions appear to be inherently\nserial.  In particular, several parallelized \nalgorithms are presented for the solution of certain\nspanning tree, distance, and path problems, with \ndirect applications to wire routing, PERT chart analysis,\nand the analysis of many types of networks. \n These algorithms exhibit a computation time that in\nmany cases grows at a rate not exceeding log2 n, \nwhere n is the number of nodes in the graph.  Straightforward\ncellular implementations of the well-known \nserial algorithms for these problems require about n\nsteps, and noncellular implementations require from \nn^2 to n^3 steps.\n graph theory, cellular logic-in-memory arrays,\nparallel processing, special purpose computers, \nalgorithms for distance and spanning tree problems\n", "2290": "Immediate Predominators in a Directed Graph [H] (Algorithm A430) predominator, immediate predominator, graph theory,\ndirected graph, shortest path, articulation, \nconnectivity, program optimization, optimizing compiler\n", "2291": "Localization of the Roots of a Polynomial [C2] (Algorithm A429) polynomials, roots of polynomials,theory\nof equations, Routh-Hurwitz criterion\n", "2292": "A Note on the Generation of Rosary Permutations permutation, permutation generation\n", "2293": "Comment on Average Binary Search Length searching, binary searching, record retrieval\n", "2294": "A Bonus from van Wijngaarden's Device non-local transfers, procedure returns\n", "2295": "Comment on the Composition of Semantics in Algol 68 programming primitives, programming languages,\nAlgol, semantics, recursive composition, design \nof programming languages, data structures\n", "2296": "Compiling Fixed-Point Multiplications compiling multiplications, fixed-point arithmetic\n", "2297": "A Model of Memory Contention in a Paging Machine This paper is concerned with certain aspects of contention\nfor main memory resources in a multiprogrammed \ncomputer system operating under demand paging.  In\nthe model presented, the number of page-frames of \nmain memory allocated to a problem program varies in\ntime.  These changes in memory configuration are \nrepresented explicitly in the model, CPU requirements and\npage exception characteristics of program material \nbeing described statistically.  Expressions for the distribution\nof the number of page-frames allocated \nto an executing program, the long run expected fraction\nof a program's execution time in a given number \nof page-frames, and the average execution interval of the\nmultiprogrammed load are obtained.  It is pointed \nout heuristically and demonstrated numerically that\nan increase is obtain able in the average execution \ninterval of the multiprogrammed load over that resulting\nfrom equal fixed partitioning of main memory.\n paging machines, demand paging, operating systems\nstudies, queuing analysis, memory contention, \nmemory management\n", "2298": "An Environment for Research in Microprogramming and Emulation The development of the research project in\nmicroprogramming and emulation at State University \nof New York at Buffalo consisted of three phases: the\nevaluation of various possible machines to support \nthis research; the decision to purchase one such machine,\nwhich appears to be superior to the others \nconsidered; and the organization and definition of goals\nfor each group in the project.  Each of these \nphases is reported, with emphasis placed on the\nearly results achieved in this research.\n microprogramming, emulation, computer systems, language\nprocessors, input-output systems, nano-program, \nproject management, hardware evaluation\n", "2299": "An Extensible Editor for a Small Machine with Disk Storage A design philosophy for developing a sophisticated\nutility program is illustrated by the actual \ndesign and implementation of a text editor.  A versatile\ndata structure is employed so that only a small \nnumber of programmed subroutines are necessary for all\ntypes of data manipulation.  Such a data structure \nis described, and its merits are illustrated by the ease\nwith which powerful extensions can be implemented \nin terms of a few basic editing function.\n command processing, context searching, executive\nprogram, garbage collection, interpreter, list \nprocessing, macro language, paging, parameter substitution,\nrecursion, state table, storage allocation, \nstring manipulation, text editing, virtual memory\n", "2300": "Political Redistricting by Computer The problems of political redistricting are\nconsidered and a computer method for redistricting \nis presented.  Criteria for acceptable redistricting are\ndiscussed, including population equality, compactness, \ncontiguity, and preservation of natural and/or political\nboundaries.  Only nonpartisan criteria are considered. \n Using 1970 Bureau of Census population data, specific\nresults are given for the ten Congressional Districts \nin the state of Missouri and for the seven St. Louis\nCounty Council seats.  Results from the use of the \nalgorithm indicate the feasibility of political\nredistricting with the aid of a computer.\n political redistricting, reapportionment, compactness,\nequal population, contiguity, transportation \nalgorithm, legislative districts, population units\n", "2301": "Generating Parsers for Affix Grammars Affix grammars are two-level grammars which\nare similar to van Wijngaarden's two-level grammars \nused in the definition of Algol 68.  Affix grammars are shown\nby Koster to be equal in power to van Wijngaarden \ngrammars.  They are much more suited to parsing than\nare the latter, however.  Koster, the inventor of \naffix based on recursive procedures.  This paper presents\na bottom-up scheme for parsing them, based \non an extension of Floyd Production Language (FPL).  Included\nis an algorithm, similar to that of DeRemer's, \nfor converting a large class of affix grammars into FPL.\n The paper concludes by discussing briefly the \napplicabilities of the conversion algorithm and affix\ngrammars in general, and some possible extensions \nto Koster's definition of affix grammars.\n algorithmic language processing,bottom-up parsing,\nFloyd Production Language, parsing, syntax \ndirected compiling, translator writing systems, two-level grammars\n", "2302": "Computers and Employment The relationship of computers and automation\nto employment is part of the more general relation \nof technological change to employment.  The most obvious\neffect is that increase in productivity due \nto technology can eliminate jobs.  Technology affects\nthe individual worker, in the nature and amount \nof his work, and in his attitudes toward that work.  Technological\nchange affects the occupational structure \nof the entire labor force.  Because of the central importance\nof these effects, the impact of technology \nhas been the subject of extensive study by economists, sociologists,\npolitical scientists, and psychologists. \n Even within a single discipline, studies are often contradictory,\nand conclusions are colored by political \novertones.  We wish to delineate some of the issues,\nand present arguments given to support different \nviewpoints.\n employment, unemployment, social implications, attitudes,\nskills, obsolescence, technology, unions, \ndisplacement\n", "2303": "Archaeology of Computers - Reminiscences, 1945-1947 The period preceding the founding of ACM was\ndominated by the first large computer ENIAC.  \nIts characteristics, described here, foreshadow later developments.\n history of computers\n", "2304": "A Western View of Computer History Many U.S. histories of the digital computer\nfield have tended to be impersonal, with heavy \nemphasis on eastern universities and commercial developments.\n This article records the events of the \nearly years in a personal way.  The people, organizations,\ntechnologies, and computers of the 1945-55 \nperiod in the western part of the United Statesare described as they happened.\n history, computer history\n", "2305": "The \"Plankalkul\" of Konrad Zuse: A Forerunner Plankalkul was an attempt by Korrad Zuse in\nthe 1940's to devise a notational and conceptual \nsystem for writing what today is termed a program.  Although\nthis early approach to a programming language \ndid not lead to practical use, the plan is described\nhere because it contains features that are standard \nin today's programming languages.  The investigation\nis of historical interest; also, it may provide \ninsights that would lead to advancements in the state\nof the art.  Using modern programming terminology, \nthe Plankalkul is presented to the extent it has possible\nto reconstruct it from the published literature.\n higher programming languages, programming,\ntheory of programming, history of programming\n", "2306": "Ancient Babylonian Algorithms The early origins of mathematics are discussed,\nemphasizing those aspects which seem to be \nof greatest interest from the standpoint of computer\nscience.  A number of old Babylonian tablets, many \nof which have never before been translated into English, are quoted.\n history of computation, Babylonian tablets,\nsexagesimal number system, sorting \n", "2307": "Dynamic Document Processing The current role of computers in automatic\ndocument processing is briefly outlined, and some \nreasons are given why the early promise of library automation\nand of the mechanization of documentation \nprocesses has not been fulfilled.  A new dynamic document\nenvironment is then outlined in which clustered\nfiles are searched and information is retrieved following\nan interactive user-controlled search process. \n Methods are described for an automatic query modification\nbased on user needs, and for a continuous \nreorganization of the stored information as a function of\nearlier file processing and of normal collection \ngrowth.  The proposed procedures provide powerful tools\nfor information retrieval and for the control \nof dynamic library collections in which new items\nare continually added and old ones are retired.\n automatic indexing, automatic search and retrieval,\niterative searching, mechanized library processing, \ncollection growth, collection retirement, feedback search\n", "2308": "Computers and Urban Society This brief survey of the use of computers in\nurban society covers the broad range of activities \nfound in any city.  The future scope of applications is\nlimited only by the imagination and inventiveness \nof future system designers, programmers, analysts, and\ndecision makers.  The computer can be, if properly \nused, with respect for human dignity and civil liberty,\na significant factor in improving the efficiency \nof the urban process.  It is expected that the benefits\nof such computer usage will outweigh the costs \nand that we may look forward to an expansion of such usage.\n urban systems, urban applications, data acquisition,\ndata management, engineering analysis, information \nsystems\n", "2309": "Computers in the Instructional Process: A survey is given of computer applications\nto the instructional process which suggests how \nthe computer professional can contribute to effective educational systems.\n education\n", "2310": "Language Analysis in the Humanities The use of the computer in the language-oriented\nhumanities for exhaustive listing of detail \n(as in indices and concordances) is widespread and accepted\nas desirable.  The implications of the computer \nfor a \"science\" of the humanities-a science entailing\ngathering data for the construction and testing \nof models-are neither widely recognized nor accepted.\n This paper argues that the computer's  major role \nas to language analysis in the humanities will be the\nestablishing of such a science.Thus, for those \nareas of the humanities for which rigor and precision\nare necessary (e.g. analyzing literature or teaching \na student to write a composition) the computer\ncan be a critically important facilitator.\n language analysis, humanities, science of the humanities,\npattern recognition, pattern generation, \ninterdisciplinary cooperation\n", "2311": "A Generational Perspective of Information System Development System development is categorized from a generational\npoint of view that parallels the commonly \ndescribed computing system generations.  For each generation,\nthe scope of development projects and the \ntechnological world view of the system developer are examined.\n computing milieu, management data processing, hardware\nsystems, software systems, systems development \nprocess, functional systems, management systems\n", "2312": "On the Present and Future of Scientific Computation A pessimistic forecast is given of what can be\nexpected to happen in the application of computers \nto the physical sciences.\n scientific computation\n", "2313": "The Evolution of Storage Structures Data base management systems have grown rapidly\nin their power and complexity over the 15-year \nhistory of data processing on commercially available\ncomputers.  The original concepts have split, and \nnew terms have been adopted to name and refer to these\nconcepts.  The Data Structure Diagram graphic \ntechnique is used to illustrate the splitting of the\nconcepts and the structural relations which exist \nbetween these concepts at each point in the evolution.\n block, cylinder, device, field, extent file, page,\nrecord, physical record, logical record, track, \nvolume, entity, set, entity class, set class, data structure\ndiagram, storage structure, physical storage \nstructure, logical storage structure, storage allocation\nstructure, Integrated Data Store, index sequential, \nhash, randomize, item\n", "2314": "Requirements for Advanced Programming Systems for List Processing List processing systems should be designed to\nfacilitate production of large programs to manipulate \nlarge complex symbolic data stores.  This paper presents\nan overview of a number of system features which \nthe author feels are important to improve the productivity\nof programmers working in such domains.  A \nsystem view it taken, rather than focusing just on language\nfeatures, since algorithms must be not only \ncoded in a language form, but debugged, modified, made\nefficient, and run on data.  Because of this general \nframework,the requirements specified are applicable\nto the design of advanced programming systems for \na wide range of applications.  Three aspects of programming\nsystems are highlighted: good interactive \nfacilities, programmable control structures, and sophisticated\ndata communication mechanisms.  Interactive \nfeatures are described to facilitate program composition,\nentry, testing, debugging, editing, optimization, \nand packaging.  Implementation of a generalized environment\nstructure model specified would allow programming \nof various control regimes including multiprocesses,\ncoroutines and backtracking.  Alternative methods \nof procedure invocation required include invocation\nby pattern and by monitoring condition.  The  need \nfor extended data forms, storage management, and extensibility\nare stressed, as is the duality of data \nretrieval and function evaluation.  Syntax directed\ninput and output of data would facilitate use of \ncomplex data stores.\n list processing, programming languages, design of\nprogramming languages, interactive systems, control \nstructures, data structures, programming primitives,\nsemantics, advanced programming systems\n", "2315": "The Production of Better Mathematical Software Some observations are made on steps to be\ntaken toward the creation of better mathematical \nsoftware.  These steps suggest the need for a coordinated\neffort and the creation of a center to focus \nactivities in this area.\n mathematical software, programming\n", "2316": "Programming Languages: History and Future This paper discusses both the history and future\nof programming languages (= higher level languages). \n Some of the difficulties in writing such a history\nare indicated.  A key part of the paper is a tree \nshowing the chronological development of languages and their\ninterrelationships.  Reasons for the proliferation \nof languages are given.  The major languages are listed\nwith the reasons for their importance.  A section \non chronology indicates the happenings of the significant\nprevious time periods and the major topics \nof 1972.  Key concepts other than specific languages are discussed.\n programming languages, higher level languages,\nlanguages, history, future directions, language \ninterrelationships, programming language tree, programming\nlanguage history, programming language future\n", "2317": "Programming Systems and Languages 1965-1975 In spite of impressive gains by PL/I, Fortran\nand Cobol remain the languages in which most \nof the world's production programs are written and will\nremain so into the foreseeable future.  There \nis a great deal of theoretical interest in Algol 68\nand in extensible languages, but so far at least \nthey have had little practical impact.  Problem-oriented\nlanguages may very well become the most important \nlanguage development area in the next five to ten years.\n In the operating system area all major computer \nmanufacturers set out to produce very ambitious multiprogramming\nsystems, and they all ran into similar \nproblems.  A number of university projects,though not\ndirectly comparable to those of the manufacturers, \nhave contributed greatly to a better understanding\nof operating system principles.  Important trends \ninclude the increased interest in the development of\nsystem measurement and evaluation techniques,and \nincreased use of microprogramming for some programming system functions.\n languages, operating systems, programming\nsystems, multiprogramming, history\n", "2318": "The Role of Computer System Models in Performance Evaluation Models constitute a useful means of investigating\ncomputer system performance.  This paper \nexamines the interrelationships between models and other\nmethods for evaluating the performance of computer \nsystems and establishes circumstances under\nwhich the use of a model is appropriate.\n modeling, evaluation, performance, analytic-models,\nsimulation-models, system-models\n", "2319": "Operating System Performance An overview of the current and future positions\nwith respect to operating system performance \nis given.  While a great deal of information and a large\nnumber of models for subsystems have been developed, \ngaps still exist in out knowledge.  Because of the\nsevere interactions between the various subsystems \nof an operating system, an overall model of the total\nsystem must be developed to be able to analyze \nand design the performance aspects of an operating system\nalthough such total system designs are exceptional \ntoday, it is projected that they will become increasingly\nmore common and necessary in the near future. \n Such a design philosophy will clearly have a severe impact\non the way we go about modularizing operating \nand computer systems.\n computer system, operating system, performance\nevaluation, performance measurement, measurement, \ntechniques, modularity, layering, structured programming,\npaging, virtual memory, input/output, disk \nstorage facility, drum storage facility, sector queueing\n", "2320": "Structured Multiprogramming This paper presents a proposal for structured\nrepresentation of multiprogramming in a high \nlevel language.  The notation used explicitly associates\na data structure shared by concurrent processes \nwith operations defined on it.  This clarifies the meaning\nof programs and permits a large class of time-dependent \nerrors to be caught at compile time.  A combination of\ncritical regions and event variables enables the \nprogrammer to control scheduling of resources among\ncompeting processes to any degree desired.  These \nconcepts are sufficiently safe to use not only within\noperating systems but also within user programs.\n structured multiprogramming, programming languages,\noperating systems, concurrent processes, shared \ndata, mutual exclusion, critical regions, process\ncommunication, synchronizing events.\n", "2321": "On the Interface Between Computers and Data Communications Systems Future systems that combine computers, digital\nterminals, and communications equipment present \ndesign optimization problems that require reconsideration\nof the traditional functional responsibilities \nof the respective subsystems.  Several \"standard\" interfaces,\nby means of which computers and digital \nterminals connect to the communications systems will\nbe required.  When specifying these interfaces, \nconsideration must be given to problems of coordination,\nsynchronization, error control, signaling, stream \nmultiplexing, and switch control, in addition to minimizing\nthe technological interdependence of specific \nsubsystem designs.  A focus on some of the problems is\nobtained in a discussion of a detailed specification \nfor a particular computer-communications system interface.\n communications, standard interface communications\nprotocol, virtual channel, multiplexed input/output, \ncoordination of input/output\n", "2322": "A View of computer Architecture An attempt is made to predict the developments\nof the next 25 years in the field of computer \narchitecture.  Standardized, inexpensive microcomputers\non a single chip are predicted.  These will be \nused extensively to provide logical functions for noncomputational\ndevices and incidentally for the design \nof superscale computers. \n computer architecture, projection, microcomputers,\ncomputer design, computer organization\n", "2323": "Toward a General Theory of Special Functions A list of a number of natural developments\nfor the field of algebraic manipulation is given. \n Then the prospects for a general theory of functions\ndefined by ordinary differential equations are \ndiscussed.  The claim is made that recent developments\nin mathematics indicate that it should be possible \nto algorithmically generate many properties of solutions\nto differential equations.  Such a theory is \npreferable to a less general effort to make algebraic\nmanipulation systems knowledgeable about the usual \nspecial functions (e.g. exponential, hypergeometric).\n algebraic manipulation, special functions, algebraic\nsimplification, symbolic integration, algebraic \ngeometry, differential algebra\n", "2324": "Management Science: A View from Nonlinear Programming A brief history of integer and continuous\nnonlinear programming is presented as well as the \ncurrent obstacles to practical use of these mathematical\nprogramming techniques.  It is forecast that \nthe useful contributions to nonlinear programming actually\nmade in the next few years are more likely \nto be consolidations than theoretical breakthroughs.  These\ncontributions are likely to be the documentation \nof standard test problems, construction of user oriented\nsoftware, and comparisons of currently known \nalgorithms to demonstrate which techniques are best for specific problems.\n integer programming, linear programming, mathematical\nprogramming, nonlinear programming, quadratic \nprogramming, management science, operations research, algorithms\n", "2325": "Numerical Mathematics and Computer Science Numerical mathematics is viewed as the analysis\nof continuous algorithms.  Four of the components \nof numerical mathematics are discussed.  These are: foundations\n(finite precision number systems, computational \ncomplexity), synthesis and analysis of algorithms,\nanalysis of error, programs and program libraries.\n numerical mathematics, computer science, mathematics\nof computation, algorithms, continuous algorithms\n", "2326": "Fix point Approach to the Theory of Computation  Following the fix point theory of Scott, the\nsemantics of computer programs are defined in terms \nof the least fix points of recursive programs.  This\nallows not only the justification of all existing \nverification techniques, but also their extension to the\nhandling, in a uniform manner of various properties \nof computer programs, including correctness, termination, and equivalence.\n verification techniques, semantics of programming\nlanguages, least fix points, recursive programs, \ncomputational induction\n", "2327": "Toward an Automata Theory of Brains A source of ideas for automata theory-the study\nof the brain-has been pushed aside in mathematical \ndevelopment of the theory.  This paper suggests the ways\nin which automata theory might evolve over the \nnext 25 years if it is to contribute to an understanding\nof how the brain processes information.\n automata theory, brain theory, network complexity,\nresolution of redundancy of potential command, \nfrog visual system, reticular formation mode selection\n", "2328": "Individualizing Instruction in a Generative CAI Tutor computer-assisted instruction, generative CAL, adaptive instruction\n", "2329": "Computer Science-A Vicious Circle education, computer engineering, computer\nscience curriculum, systems design\n", "2330": "Calculation of Fourier Integrals (Algorithm R418) quadrature, Filon quadrature, integration, Filon integration,\nFourier coefficients, Fourier integrals, \nFourier series, spline,spline approximation, spline\nquadrature, extrapolation, Richardson extrapolation\n", "2331": "An Integer Programming Problem (Algorithm R397) integer programming, change-making problem\n", "2332": "Special Series Summation with Arbitrary Precision (Algorithm R393) function evaluation, series summation, approximation\n", "2333": "Random Vectors Uniform is Solid Angle (Algorithm R381) random vector generator, points uniform on sphere,\nspherically symmetric probability distribution\n", "2334": "General Random Number Generator (Algorithm R370) random number generator, probability density function,\ntransformation, cumulative distribution \nfunction\n", "2335": "Eigenvalues and Eigenvectors of a Real General matrix (Algorithm R343) eigenvalues, eigenvectors, QR-algorithm,\nnonsymmetric matrices, general matrices \n", "2336": "Complex Error Function (Algorithm C363) error function for complex argument, Voigt function,\nspecial functions, function evaluation\n", "2337": "A Sorting Problem and Its Complexity A technique for proving min-max norms of sorting\nalgorithms is given.  One new algorithm for \nfinding the minimum and maximum elements of a set with\nfewest comparisons is proved optimal with this \ntechnique.\n sorting, computational complexity, computational combinatorics\n", "2338": "A Starting Method for Solving Nonlinear Volterra A fourth-order starting method is given for\nVolterra integral equations of the second kind \nand numerical examples are presented.\n algorithm, Volterra integral equations, starting method\n", "2339": "Computer-Assigned Codes from Verbal Responses It is often desirable to convert verbal responses\nto multidigit codes. This conversion is generally \naccomplished by clerk-coders.  A study was conducted to test\nthe feasibility of translating verbal descriptions \nto numerical codes in a computer program.  Primary emphasis\nwas placed on computerized construction of \na reference file of verbal descriptions for use by the\nprogram.  The results of the study clearly show \nthat such procedures are feasible.\n verbal responses, computer coding, reference list,\nhistorical response patterns, word strings, \nconcept translation, word coding\n", "2340": "A Boolean Matrix Method for the Computation A modified version of Bell's Boolean matrix\nmethod for the computation of linear precedence \nfunctions associated with a conflict-free matrix of\nprecedence relations is given.  This algorithm not \nonly detects when the precedence functions do not  exist,\nbut also provides an indication of why they \ndo not exist, so that corrective action can be taken\nif possible.  Necessary and sufficient conditions \nfor the existence of precedence functions are given.\n The use of Boolean matrices to prove the existence \nof precedence functions associated with classes of conflict-free\ngrammars is illustrated through an example.\n precedence grammars, context-free parsing\n", "2341": "Blocks-A New Data type for SNOBOL4 A new data type, called a block, has been implemented\nfor SNOBOL4.  A block is a three-dimensional \naggregate of characters in the form of a right parallelepiped,\nbest thought of as a three-dimensional \nextension to a string.  (The third dimension is used for\noverstriking.)  Blocks may be printed, concatenated \nin any of three dimensions, and merged on the basis\nof program-defined connection points.  Some blocks \nadapt in size and shape to their environment.  Blocks\nand their operations are mainly used for composing \nprintable output.  A variety of graphical problems (including\nflowcharting, bargraphs, logic diagrams, \nmathematical-equation formation, and text justification\nand preparation) have been programmed on a printer \nin what appears to be an easy and natural way.  In addition\nto these somewhat specialized applications, \nblocks appear to be a good general purpose device-independent\noutput formation mechanism especially suitable \nfor nonnumerical work.  The concept of a block is largely\nlanguage independent.That is, blocks require \nlittle in the way of specialized syntax and could readily\nbe absorbed into the external structure of \nmost programming languages.\n character manipulation, output formatting, string\nprocessing, graphics, nonnumerical programming, \nSNOBOL4, data types, two-dimensional mathematics, test processing, flowcharting\n", "2342": "Interference Between Communicating Parallel Processes Various kinds of interference between communicating\nparallel processes have been examined by \nDijkstra, Knuth, and others.  Solutions have been given\nfor the mutual exclusion problem and associated \nsubproblems, in the form of parallel programs, and informal\nproofs of correctness have been given for \nthese solutions.  In this paper a system of parallel\nprocesses is regarded as a machine which proceeds \nfrom one state S (i.e. a collection of pertinent data\nvalues and process configurations) to a next state \nS' in accordance with a transition rule S --> S'.  A\nset of such rules yields sequences of states, which \ndictate the system's behavior.  The mutual exclusion problem\nand the associated subproblems are formulated \nas questions of inclusion between sets of states, or\nof the existence of certain sequences.  A mechanical \nproof procedure is shown, which will either verify (prove\nthe correctness of ) or discredit (prove the \nincorrectness of) an attempted solution, with respect\nto any of the interference properties.  It is shown \nhow to calculate transition rules from the \"partial\nrules\" by which the individual processes operate. \n The formation of partial rules and the calculation of\ntransition rules are both applicable to hardware \nprocesses as well as to software processes, and\nsymmetry between processes is not required.\n concurrent programming control, cooperating processes,\nformal programs, interference, mutual exclusion, \noperating systems, parallel processes\n", "2343": "A Proposal To Establish a Pseudo Virtual Memory via Writable Overlays Many computer systems solve executable storage\nsize problems for large programs by using overlays. \n However, it appears that no one overlay scheme contains\na well-balanced combination of the most useful \ncapabilities which are found in various existing techniques.\n A proposal is presented which utilizes \nseveral of the best capabilities from existing schemes\nand is complemented by several additional features, \ne.g. writable overlays.  The writable overlay capability\nprovides a virtual memory effect, although the \nprogrammer may still be required to design the overlay\nconfiguration.  Since overlay structuring is a \ncomplex task, several tools (including a graphic display)\nare included in the proposal in order to aid \nthe programmer in the design.  The content of overlays\nis briefly discussed, and it is noted that many \nof the details of the final overlay configuration may be decided after the fact.\n overlay, overlay structure, segment, segmentation,\nfolding, paging, linkage editor, collector, \nloader, virtual memory\n", "2344": "On the Optimization of Performance of Time-Sharing Systems by Simulation A simulation model of a time-sharing system\nwith a finite noncontiguous store and an infinite \nauxiliary store is used to study the variation of system\nparameters such as store size, number of jobs \nallowed to execute simultaneously, job-scheduling algorithm,\netc.  The effects of these variations on \na measure of system performance is used to ascertain which\nof the parameters controllable by the job-scheduling \nalgorithm, including the scheduling itself, require optimization,\nand which of the parameters not normally \ncontrollable by the scheduling algorithm have a marked\neffect on system performance.  System performance \nis based upon the mean cost of delay to all jobs processed.\n It is shown that significant improvements \nin the measure of system performance can be obtained by\nusing variable time-slice techniques and by selecting \nthe optimum round-robin cycle time.  It appears that these\nfeatures would benefit from optimization whereas \nother parameters controllable by the scheduling algorithm\naffect system performance in a predictable \nmanner and would not benefit from optimization.  Features\nnot normally under the control of the scheduling \nalgorithm can also have a marked effect on the measure\nof performance; in particular, supervisor overheads, \nthe size of the store, and the speed of the CPU.  A comparison\nis made between the results of the simulation \nmodel and two analytical equations for quantum-oriented\nnonpreemptive time-sharing systems.  The comparison \nis found to be very favorable.\n time-sharing, simulation studies, optimization,\nmeasure of performance, scheduling algorithms\n", "2345": "Curriculum Recommendations for Graduate The need for education related to information\nsystems in organizations is discussed, and a \ncurriculum is proposed for graduate professional programs\nin universities, at the Master's level.  Material \nnecessary for such programs is identified, and courses\nincorporating it are specified.  Detailed course \ndescriptions are presented, program organization discussed,\nand implementation questions considered.\n education, management systems, systems analysis,\nmanagement information systems, information systems \ndevelopment, information analysis, system design\n", "2346": "Hu-Tucker Minimum Redundancy Alphabetic information theory, coding theory, Hu-Tucker\nmethod, minimum redundancy coding\n", "2347": "Fourier Cosine Integral [D1] (Algorithm A427) numerical integration, quadrature, adaptive quadrature,\nFilon quadrature, Fourier coefficients, \nFourier integrals\n", "2348": "Merge Sort Algorithm [M1] (Algorithm A426) sort, merge\n", "2349": "Generation of Random Correlated Normal Variables [G5] (Algorithm A425) random number, normal density, normal distribution,\nGaussian density, Gaussian distribution, simulation, \nMonte Carlo\n", "2350": "Clenshaw-Curtis Quadrature [D1] (Algorithm A424) quadrature, Chebyshev series, cosine transform, fast Fourier transform\n", "2351": "The Optimality of Winograd's Formula inner product, Winograd's formula\n", "2352": "Minimax Nonlinear Approximation by Approximation on Subsets minimax approximation, nonlinear approximation, subset\n", "2353": "Fast Finite-Difference Solution of Biharmonic Problems Setting the Reynolds number equal to zero, in\na method for solving the Navier-Strokes equations \nnumerically, results in a fast numerical method for\nbiharmonic problems.  The equation is treated as \na system of two second order equations and a simple\nsmoothing process is essential for convergence.  \nAn application is made to a crack-type problem.\n numerical analysis, partial differential equations,\nbiharmonic equation, boundary value problem\n", "2354": "Implementing Clenshaw-Curtis Quadrature, In a companion paper to this, \"I Methodology\nand Experiences,\" the automatic Clenshaw-Curtis \nquadrature scheme was described and how each quadrature\nformula used in the scheme requires a cosine \ntransformation of the integrand values was shown. \nThe high cost of these cosine transformations has \nbeen a serious drawback in using Clenshaw-Curtis quadrature.\n Two other problems related to the cosine \ntransformation have also been trouble some.  First, the\nconventional computation of the cosine transformation \nby recurrence relation is numerically unstable, particularly\nat the low frequencies which have the largest \neffect upon the integral.  Second, in case the automatic\nscheme should require refinement of the sampling, \nstorage is required to save the integrand values after\nthe cosine transformation is computed.  This second \npart of the paper shows how the cosine transformation can\nbe computed by a modification of the fast Fourier \ntransform and all three problems overcome.  The modification\nis also applicable in other circumstances \nrequiring cosine or sine transformations, such as polynomial\ninterpolation through the Chebyshev points.\n fast Fourier transformation, cosine transformation,\nClenshaw-Curtis quadrature, Chebyshev series\n", "2355": "Implementing Clenshaw-Curtis quadrature, I Methodology and Experience Clenshaw-Curtis quadrature is a particularly\nimportant automatic quadrature scheme for a variety \nof reasons, especially the high accuracy obtained from\nrelatively few integrand values.  However, it \nhas received little use because it requires the computation\nof a cosine transformation and the arithmetic \ncost of this has been prohibitive.  This paper is in\ntwo parts; a companion paper, \"II Computing the \nCosine Transformation,\" shows that this objection can\nbe overcome by computing the cosine transformation \nby a modification of the fast Fourier transform algorithm.\n This first part discusses the strategy and \nvarious error estimates, and summarizes experience\nwith a particular implementation of the scheme.\n Clenshaw Curtis, numerical integration, automatic\nquadrature, error estimates, Chebyshev series\n", "2356": "A Technique for Software Module Specification with Examples This paper presents an approach to writing\nspecifications for parts of software systems.  The \nmain goal is to provide specifications sufficiently\nprecise and complete that other pieces of software \ncan be written to interact with the piece specified without\nadditional information.  The secondary goal \nis to include in the specification no more information\nthan necessary to meet the first goal.  The technique \nis illustrated by means of a variety of examples from a tutorial system.\n software, specification, modules, software engineering, software design\n", "2357": "MUX, a Simple Approach to On-Line Computing An on-line system operating as part of a normal\nbatch system for the CDC 6600 computer is described. \n The system, which required one man-year for initial\nsoftware implementation, although basically simple,\nprovides the necessary elements to input and modify files,\nsubmit them for batch execution, and provide \nresults at the user's terminal.  A multiplexer designed\nand developed as part of the project cost one \nman-year for design and checkout, and $16,000 for parts\nand fabrication.  All aspects of the system are \ndescribed, including design criteria, implementation,\ncost, overhead, and user reactions.\n time-sharing, remote computing, on-line access,\non-line computing, remote file manager, real time, \nmultiplexer, implementation effort, operating overhead,\nuser reactions, remote terminals, operating system\n", "2358": "The Multics Virtual Memory: Concepts and Design As experience with use of on-line operating\nsystems has grown, the need to share information \namong system users has become increasingly apparent.\n Many contemporary systems permit some degree of \nsharing.  Usually, sharing is accomplished by allowing\nseveral users to share data via input and output \nof information stored in files kept in secondary storage.\n Through the use of segmentation, however, \nMultics provides direct hardware addressing by user and\nsystem programs of all information, independent \nof its physical storage location.  Information is stored\nin segments each of which is potentially sharable \nand carries its own independent attributes of size and access\nprivilege.  Here, the design and implementation \nconsiderations of segmentation and sharing in Multics\nare first discussed under the assumption that all \ninformation resides in large, segmented main memory. \nSince the size of main memory on contemporary systems \nis rather limited, it is then shown how the Multics\nsoftware achieves the effect of a large segmented \nmain memory through the use of the Honeywell\n645 segmentation and paging hardware.\n operating system, Multics, virtual memory, segmentation,\ninformation sharing, paging, memory management, \nmemory hierarchy\n", "2359": "An Improved Index Sequential Access Method Using Hashed Overflow The Index Sequential Access Method (ISAM) is\none of the most important file management systems \nused with moveable head disk devices.  This study investigates\nthe use of an unconventional method of \ntreating overflow records.  The method is to use hashing\ntechniques to allocate space for such records. \n If certain conditions are satisfied, this is superior\nto the conventional ISAM method of chaining the \noverflow records via linked list techniques.  These conditions are:\nlong overflow chains with significant \noverflow; lack of tight disk space constraints; record\nkeys which are small compared to the total record \nsize; and significant use of the file in the index as opposed\nto the sequential mode.  Using hashed overflow, \nthe time to locate a record is dependent not on the total\nvolume of overflow records as in conventional \nISAM, but on the percentage use of space dedicated to overflow records.\n ISAM, index sequential, hashing, scatter\nstorage, disk, cylinder, overflow\n", "2360": "A Comment on the Double-Chained Tree file searching, double-chained tree, binary search tree\n", "2361": "A Note on Cheney's Nonrecursive List-Compacting Algorithm list compacting, garbage collection\n", "2362": "Linear Equation Solver [F4] (Algorithm A423) matrix algorithms, linear equations, Fortran,\npaged memory, virtual memory, array processing\n", "2363": "Minimal Spanning Tree [H] (Algorithm A422) spanning tree, minimal spanning tree, maximal spanning tree\n", "2364": "Complex Gamma Function with Error Control [S14] (Algorithm A421) complex gamma function, gamma function, complex\nlog gamma function, loggamma function, round-off \nerror control, inherent error control, run-time error\nestimates, error estimates, special functions\n", "2365": "Matrix Computations with Fortran and Paging The efficiency of conventional Fortran programs\nfor matrix computations can often be improved \nby reversing the order of nested loops.  Such modifications\nproduce modest savings in many common situations \nand very significant savings for large problems run\nunder an operating system which uses paging.\n matrix algorithms, linear equations, Fortran,\npaged memory, virtual memory, array processing\n", "2366": "Complex Gamma Function with Error Control An algorithm to compute the gamma function and\nlog gamma function of a complex variable is presented. \n The standard algorithm is modified in several respects\nto insure the continuity of the function value \nand to reduce accumulation of round-off errors.  In\naddition to computation of function values, this \nalgorithm includes an object-time estimation of round-off\nerrors.  Experimental data with regard to the \neffectiveness of this error control are presented. \nA Fortran program for the algorithm appears in the \nalgorithms section of this issue.\n complex gamma function, gamma function, complex\nlog gamma function, loggamma function, round-off \nerror control, inherent error control, run-time error estimates, error estimates\n", "2367": "Computers and Society: A Proposed Course for Computer Scientists The purpose of this paper is to describe a course\nconcerned with both the effects of computers \non society and the responsibilities of computer scientists\nto society.  The impact of computers is divided \ninto five components: political, economic, cultural, social,\nand moral; the main part of the paper defines \neach component and presents examples of the relevant\nissues.  In the remaining portions the possible \nformats for such a course are discussed, a topic by topic\noutline is given, and a selected set of references \nis listed.  It is hoped that the proposal will make\nit easier to initiate courses on this subject.\n computers and society, social implications, course proposal\n", "2368": "An Implemented Graph Algorithm for Winning Shannon Switching games In this tutorial paper a computer program\nwhich wins Shannon Switching Games is described.\n Since these games are played on graphs, the program\nis a good example of the implementation of graph \nalgorithms.  The two players in a Shannon Switching Game,\nCONNECT and CUT, have nonsimilar goals.  Either \nCONNECT, CUT, or the player moving first is guaranteed\nthe existence of a winning strategy.  The simple \nstrategy explained in this paper is valid in all three\ncases.  In fact, the major routines never need \nto know whether the computer is CONNECT or CUT.\n graph algorithms, graph processing, Shannon Switching\nGames, game playing, graph theory, positional \ngames, demonstration programs, game theory, spinning trees\n", "2369": "Hidden Lines Elimination for a Rotating Object A method is presented of determining which\nparts of three-dimensional objects are visible and \nwhich are invisible when the objects are rotated about\nsome axis.  This paper describes a polygon comparison \nscheme in which the relationships of two polygons can\nbe classified into tree types, and also discusses \nhow the relationship is changed for each pair of polygons\nunder rotation about some axis.  A rotation \ntable is defined for each pair of polygons, which remains\nfixed as long as rotation is about one axis \nand provides a means of rapidly determining the visible\nand hidden line relationship between two polygons. \n Additional work must be done to extend this approach\nto simultaneous rotation about several axes.\n hidden line problem, display programming, computer\ngraphics, displays, graphics, computer drawn \npicture\n", "2370": "An Experimental Laboratory for Pattern Recognition and Signal Processing An interactive computer-controlled scanning\nand display system has been in operation at the \nIBM Thomas J. Watson Research Center for three years.\n The system includes two flying-spot scanners and \na TV camera specially interfaced to a process control\ndigital computer, dot-mode and vector displays, \nanalog input and output facilities, and a variety of\nother experimental equipment.  The system design \nand programming support are described and typical applications\nin scanner control, optical character \nrecognition,and image processing are presented.\n scanners, pseudorandom displays, interactive\nterminal, image processing, pattern recognition\n", "2371": "A System for Interprocess Communication A system of communication between processes in a\ntime-sharing system is described and the communication \nsystem is extended so that it may be used between processes\ndistributed throughout a computer network. \n The hypothetical application of the system to an existing network is discussed.\n interprocess communication, time-sharing,\ncomputer networks, resource sharing\n", "2372": "On the Implementation of Security Measures in Information Systems The security of an information system may be\nrepresented by a model matrix whose elements are \ndecision rules and whose row and column indices are\nusers and data items respectively.  A set of four \nfunctions is used to access this matrix at translation\nand execution time.  Distinguishing between data \ndependent and data independent decision rules enables\none to perform much of the checking of security \nonly once at translation time rather than repeatedly\nat execution time.  The model is used to explain \nsecurity features of several existing systems, and serves\nas a framework for a proposal for general security \nsystem implementation within today's languages and operating systems.\n security, privacy, access control confidentiality,\noperating systems, access management, data banks, \nmanagement information systems\n", "2373": "Properties of the Working-Set Model A program's working set W(t,T) at time t is\nthe set of distinct pages among the T most recently \nreferenced pages.  Relations between the average working-set size,\nthe missing-page rate, and the interreference-interval \ndistribution may be derived both from time-average definitions\nand from ensemble-average (statistical) \ndefinitions. An efficient algorithm for estimating these\nquantities is given.  The relation to LRU (least \nrecently used) paging is characterized.  The independent-reference\nmodel, in which page references are \nstatistically independent, is used to assess the effects\nto interpage dependencies on working-set size \nobservations. Under general assumptions, working-set\nsize is shown to be normally distributed.\n working-set model, paging, paging algorithms,\nprogram behavior, program modeling\n", "2374": "A Study of Storage Partitioning Using a Mathematical Model of Locality Both fixed and dynamic storage partitioning\nprocedures are examined for use in multiprogramming \nsystems.  The storage requirement of programs is modeled\nas a stationary Gaussian process.  Experiments \njustifying this model are described.  By means of this\nmodel dynamic storage partitioning is shown to \nprovide substantial increases in storage utilization\nand operating efficiency over fixed partitioning. \n storage partitioning, memory management, dynamic\nstorage allocation, space sharing, multiprogrammed \nstorage, working-sets, program behavior models, mathematical modeling\n", "2375": "A Comparative Analysis of Disk Scheduling Policies Five well-known scheduling policies for movable\nhead disks are compared using the performance \ncriteria of expected seek time (system oriented)and expected\nwaiting time (individual I/O request oriented). \n Both analytical and simulation results are obtained.\n The variance of waiting time is introduced as \nanother meaningful measure of performance, showing possible\ndiscrimination against individual requests. \n Then the choice of a utility function to measure total\nperformance including system oriented and individual \nrequest oriented measures is described.  Such a function\nallows one to differentiate among the scheduling \npolicies over a wide range of input loading conditions.\n The selection and implementation of a maximum \nperformance two-policy algorithm are discussed.\n access time, analytical models, auxiliary storage,\ndirect access storage, disk analysis, disk scheduling, \nperformance criteria, peripheral memory devices, real-time\nsystems, response time, rotational delay, \nscheduling policies, seek time, simulation, storage\nunits, time-sharing systems, waiting time\n", "2376": "Synchronization of Communicating Processes Formalization of a well-defined synchronization\nmechanism can be used to prove that concurrently \nrunning processes of a system communicate correctly.\n This is demonstrated for a system consisting of \nmany sending processes which deposit messages in a buffer\nand many receiving processes which remove messages \nfrom that buffer.  The formal description of the synchronization\nmechanism makes it very easy to prove \nthat the buffer will neither overflow nor underflow,\nthat senders and receivers will never operate on \nthe same message frame in the buffer nor will they run into a deadlock. \n parallel programming, multiprogramming, program correctness,\nprocess communication, process scheduling\n", "2377": "A Hardware Architecture for Implementing Protection Rings Protection of computations and information\nis an important aspect of a computer utility.  In \na system which uses segmentation as a memory addressing\nscheme, protection can be achieved in part by \nassociating concentric rings of decreasing access privilege\nwith a computation.  This paper describes \nhardware processor mechanisms for implementing these rings\nof protection.  The mechanisms for implementing \nthese rings of protection. The mechanisms allow cross-ring\ncalls and subsequent returns to occur without \ntrapping to the supervisor.  Automatic hardware validation\nof references across ring boundaries is also \nperformed.  Thus, a call by a user procedure to a protected\nsubsystem (including the supervisor) is identical \nto a call to a companion user procedure.  The mechanisms\nof passing and referencing arguments are the \nsame in both cases as well.\n protection, protection rings, protection hardware,\naccess control, hardware access control, computer \nutility, time-sharing, shared information, segmentation, virtual memory, Multics\n", "2378": "An Operating System Based on the Concept of a Supervisory Computer An operating system which is organized as a\nsmall supervisor and a set of independent processes \nare described.  The supervisor handles I/O with external\ndevices-the file and directory system-schedules \nactive processes and manages memory, handle errors, and\nprovides a small set of primitive functions which \nit will execute for a process.  A process is able to\nspecify a request for a complicated action on the \npart of the supervisor (usually a wait on the occurrence\nof a compound event in the system) by combining \nthese primitives into a \"supervisory computer program.\"\n The part of the supervisor which executes these \nprograms may be viewed as a software implemented \"supervisory\ncomputer.\"  The paper develops these concepts \nin detail, outlines the remainder of the supervisor, and\ndiscusses some of the advantages of this approach.\n operating systems, supervisors, multiprogramming,\ntime-sharing, cooperating processes\n", "2379": "The Design of the Venus Operating System The Venus Operating System is an experimental\nmultiprogramming system which supports five or \nsix concurrent users on a small computer.  The system was\nproduced to test the effect of machine architecture \non complexity of software.  The system is defined by\na combination of microprograms and software.  The \nmicroprogram defines a machine with some unusual architectural\nfeature; the software exploits these features \nto define the operating system as simply as possible.\n In this paper the development of the system is \ndescribed, with particular emphasis on the principles which guided the design.\n operating systems, system design, levels of abstraction,\nmachine architecture, microprogramming, \nsegments, semaphores, multiprogramming, virtual machines,\nprocesses, process communication, virtual devices, \ndata sharing, resource management, deadlock\n", "2380": "TENEX, a Paged Time Sharing System for the PDP-10 TENEX is a new time sharing system implemented\non DEC PDP-10 augmented by special paging hardware \ndeveloped at BBN.  This report specifies a set of goals\nwhich are important for any time sharing system. \n It describes how the TENEX design and implementation\nachieve these goals.  These include specifications \nfor a powerful multiprocess large memory virtual machine,\nintimate terminal interaction, comprehensive \nuniform file and I/O capabilities, and clean flexible\nsystem structure.  Although the implementation \ndescribed here required some compromise to achieve a\nsystem operational within six months of hardware \ncheckout, TENEX has met its major goals and provided\nreliable service at several sites and through the \nARPA network.\n TENEX, paging, virtual machines, time sharing\nsystem, scheduling algorithm, process structure, \nPDP-10\n", "2381": "Average Binary Search Length for Dense Ordered Lists (Corrigendum)", "2382": "Reconstruction of Pictures from Their Projections (Corrigendum)", "2383": "Music and Computer Composition The problem discussed is that of simulating human\ncomposition of Western popular music by computer \nand some relevant theories of music and harmony are given.\n Problems with this kind of program and several \nschemes that are known not to work are discussed.  Several\nprevious computer compositions are discussed, \nincluding the ILLIAC Suite.  A program to generate short\nmelody fragments was written to simulate some \nof the aspects of human composition.  Five samples of\nits output are presented and discussed.  It was \ndiscovered that although the fragments show many of\nthe characteristics of popular melodies, they have \na strangely alien sound.  It is theorized that this\nis because the relevant probabilities which would \ndiscriminate against unfamiliar sequences were not used.\n artificial intelligence, heuristic programming,\nmodels of cognitive processes, computer music, \ncomputer composition, music theory\n", "2384": "Hidden-Line Plotting Program [J6] (Algorithm A420) hidden-line plot, surface plot \n", "2385": "Zeros of a Complex Polynomial [C2] (Algorithm A419) roots, roots of a polynomial, zeros of a polynomial\n", "2386": "Dynamic Microprogramming: Processor Organization", "2387": "Maximum Computing Power and Cost Factors in the Centralization Problem A simple analysis of some computer-economic factors\ninvolved in comparing multimachine installations \nversus large single machine installations is given, and\na mathematical model is derived to assist policy \ndecisions. \n centralization, decentralization, economics of\ncomputers, computer management, economies of scale\n", "2388": "Optimizing Binary Trees Grown With a Sorting Algorithm Items can be retrieved from binary trees grown\nwith a form of the Algorithm Quicksort in an \naverage time proportional to log n, where n is the number\nof items in the tree.  The binary trees grown \nby this algorithm sometimes have some branches longer\nthan others; therefore, it is possible to reduce \nthe average retrieval time by restructuring the tree to\nmake the branches as uniform in length as possible. \n An algorithm to do this is presented.  The use of this\nalgorithm is discussed, and it is compared with \nanother which restructures the tree after each new item is added.\n retrieving information from binary trees, global\nand local optimization, sorting, recursion\n", "2389": "Preliminary Report on a System for General Space Planning A computer language and a set of programs within\nthat language are described which allow the \nformulating and solving of a class of space planning\nproblems.  The language is an extension of Algol \nand includes means to represent spaces and objects, to manipulate\nthem, and to test the resulting arrangements \naccording to a variety of constraints.  The algorithms\nused to solve problems expressed in this language \nrely on heuristic programming.  Both the language\nand the search algorithms are detailed.\n automated design, architecture, heuristic programs, space planning\n", "2390": "A Proposal for a Computer-Based Interactive Scientific Community Because of the problems created by the explosion\nof papers in the mathematical sciences and \nthe drawbacks that this places on research, it is suggested\nthat a tree of all mathematical results and \nterminology be maintained in a multiterminal computer system.\n Users of the system can store in the computer \nan updated file of their current knowledge, and on selecting\na paper to read, they can obtain from the \ncomputer the minimum subtree of theorems required to bring\nthem from what they already know to the background \nknowledge which the paper assumes.  Under certain conditions,\nmeans are also provided for the contribution \nof useful comments by the readers of a work and for interaction\nbetween commentators and with the author. \n This paper describes how the system can be organized\nand the role required of readers, writers, and \ncommentators. \n interactive system, organization of scientific community,\nreaders, writers, commentators, computer \nutility, information retrieval, trees, data structures\n", "2391": "Unitary Symmetric Polynomials [Z] (Algorithm R391) symmetric polynomials, elementary symmetric polynomials,\nunitary symmetric polynomials, polynomial \nsynthesis, reverse Horner scheme, reverse\nsynthetic division, binomial coefficients\n", "2392": "In-Situ Transposition of a Rectangular Matrix [F1] (Algorithm C380) rectangular matrix, transpose\n", "2393": "Calculation of Fourier Integrals [D1] (Algorithm A418) quadrature, Filon quadrature, integration, Filon integration,\nFourier coefficients, Fourier integrals, \nFourier series, spline, spline approximation, spline\nquadrature, extrapolation, Richardson extrapolation\n", "2394": "Ordering +-f(+-f(+-f(...+-f(x)..))) When f(x) Is Positive Monotonic ordering, storage, retrieval, positive functions,\nmonotonic functions, increasing functions, decreasing \nfunction, binary system, Chebyshev zeros, square rots, continued fractions\n", "2395": "Quadratic Programming for Nonlinear Regression A quadratic programming algorithm is described\nfor use with the magnified diagonal method of \nnonlinear regression with linear constraints.  The\nregression method is published in JACM, July 1970.\n nonlinear equations, nonlinear regression, nonlinear\nprogramming, quadratic programming, least \nsquares, inequality, constraints, iteration\n", "2396": "MUSE: A Model To Understand Simple English MUSE is a computer model for natural language\nprocessing, based on a semantic memory network \nlike that of Quillian's TLC.  MUSE, from a Model to Understand\nSimple English, processes English sentences \nof unrestricted content but somewhat restricted format.\n The model first applies syntactic analysis to \neliminate some interpretations and then employs a simplified\nsemantic intersection procedure to find \na valid interpretation of the input.  While the semantic\nprocessing is similar to TLC's, the syntactic \ncomponent includes the early use of parse trees and special\npurpose rules.  The \"relational triple\" notation \nused during interpretation of input is compatible with MUSE's\nmemory structures, allowing direct verification \nof familiar concepts and the addition of new ones. \nMUSE also has a repertoire of actions, which range \nfrom editing and reporting the contents of its own\nmemory to an indirect form of question answering. \n Examples are presented to demonstrate how the model interprets\ntext, resolves ambiguities, adds information \nto memory, generalizes from examples and performs various actions.\n natural language processing, semantic memory, text\ncomprehension, question answering, artificial \nintelligence, human memory simulation\n", "2397": "Optimizing the Polyphase Sort (Corrigendum)", "2398": "Teacher/Student Authored CAI Using the NEWBASIC System The pedagogical advantages of a general purpose\ninteractive system called NEWBASIC/CATALYST \nare discussed.  NEWBASIC/CATALYSTincorporates an advanced\nimplementation of BASIC, system-level interactive \nfeatures, and a general capability for extension through\nuser oriented function attachment,  Application \nof this last feature to provide a flexible CAI scan capability\nis illustrated.  An example of interaction \nat the system level shows how students can mix the advantages\nof independent or \"solo\" mode computing \nwith those of guided or \"dual\" mode interaction.  Preliminary\nexperience with the system in an urban \nsecondary school setting is discussed.\n CAI, BASIC, CATALYST, NEWBASIC, education, computers\nin education, extended languages, interactive \nsystems\n", "2399": "A CRT Editing System A test-editing and manipulation program is described.\n The program operates from low-cost cathode-ray \ntube entry and display stations with keyboard and 13\nfunction buttons. Applications, potential economy \nof operation, and some aspects of implementation are discussed.\n editing, text, cathode-ray tube entry display, time-sharing\n", "2400": "Use of the Hough Transformation ToDetect Lines and Curves in Pictures Hough has proposed an interesting and computationally\nefficient procedure for detecting lines \nin pictures.  This paper points out that the use of angle-radius\nrather than slope-intercept parameters \nsimplifies the computation further.  It also shows\nhow the method can be used for more general curve \nfitting, and gives alternative interpretations\nthat explain the source of its efficiency.\n picture processing, pattern recognition, line detection,\ncurve detection, colinear points, point-line \ntransformation, Hough transformation\n", "2401": "On Shrinking Binary Picture Patterns A parallel processing algorithm for shrinking\nbinary patterns to obtain single isolated elements, \none for each pattern, is presented.  This procedure\nmay be used for counting patterns on a matrix, and \na hardware implementation of the algorithm using large\nscale integrated technology is envisioned.  The \nprincipal features of this method are the very small\nwindow employed (two-by-two elements), the parallel \nnature of the process, and the possibility of shrinking\nany pattern, regardless of the complexity of \nits configuration.  Problems regarding merging and disconnection\nof patterns during the process as well \nas the determination of the maximum number of steps\nnecessary to obtain a single isolated element from \na pattern, are reviewed and discussed.  An analogy with a\nneural network description, in terms of McCulloch-Pitts \n\"neurons\" is presented.\n counting binary patterns, shrinking, parallel\nprocessing, multiple connected pictures\n", "2402": "Pictorial Pattern Recognition and the The availability of interactive, three-dimensional,\ncomputer graphics systems coupled to powerful \ndigital computers encourages the development of algorithms\nadapted to this environment.  Pictorial pattern \nrecognition techniques make possible a number of approaches\nto X-ray structure determination based on \nmolecular model building, i.e. the use of chemical information\nto frame \"structural hypotheses\" which \ncan computationally be tested and refined by reference\nto the experimental data.  Application of standard \npattern recognition algorithms is hindered by the fact\nthat the cross-correlation between a model and \nthe correct structure cannot be computed because of\na fundamental incompleteness in the measured data. \n However, it is possible to compute an upper bound to such\na cross-correlation.  A simple example demonstrates \nthat this information can be the basis of a technique\nfor structure determination that can make effective \nuse of an interactive graphics system. Model building\nby cross-correlations has intrinsic advantages \nover usual crystallographic techniques based on the\nautocorrelation or Patterson function, especially \nfor large structures.  This is significant, for crystallography\nof biological macromolecules hasbeen \nand will continue to be a field of intense interest.\n pictorial pattern recognition, phase problem,\nX-ray crystallography, interactive graphics\n", "2403": "Procedures for Natural Spline Interpolation [E1] (Algorithm A472) approximation, interpolation, spline, natural\nspline, spline approximation, cubic natural spline\n", "2404": "Exponential Integrals [S13] (Algorithm A471) exponential integral, recurrence relations,\nrecursive computation, continued fractions\n", "2405": "Linear Systems with Almost Tridiagonal Matrix [F4] (Algorithm A470) system of linear equations, almost tridiagonal matrix, sparse matrix\n", "2406": "A Data Definition and Mapping Language A data definition language i sa declarative\ncomputer language for specifying data structures. \n Most data definition languages concentrate on the declaration\nof logical data structures with little \nconcern for how these structures are physically realized\non a computer system.  However, the need for \ndata definition languages which describe both the logical\nand physical aspects of data is increasingly \napparent.  Such languages will be a key systems, as well\nas in advanced data management systems and distributed \ndata bases.  This paper reviews past work in the data\ndefinition language for describing both logical \nand physical aspects of data.  Applications of these\n\"generalized\" data definition languages are also \ndiscussed.\n data definition language, data and storage structure,\ndata translation, data base management systems, \nfile translation\n", "2407": "Curriculum Recommendations for Undergraduate The need for education related to information\nsystems in organizations is discussed, and a \ncurriculum is proposed for an undergraduate program. \nMaterial necessary for such programs is identified, \nand courses incorporating it are specified.Detailed course\ndescriptions are presented.  Program organization \nand a problems of implementation are discussed.\n education, undergraduate curricula, management systems,\ninformation systems, information analysis, \nsystem design, systems analysis\n", "2408": "Solving the Biharmonic Equation in a Square: Two methods for solving the biharmonic equation\nare compared.  One method is direct, using \neigenvalue-eigenvector decomposition.  The other method\nis iterative, solving a Poisson equation directly \nat each iteration.\n biharmonic, direct method, block iterative,\neigenvector-eigenvalue decomposition\n", "2409": "An Algorithm for the Approximate Solution An explicit approximate solution is given for\nan equation.  Where it is assumed that the classical \nWiener-Hopf technique may be applied.  It is furthermore\nassumed that Fourier transforms are known explicitly. \n The approximate solution depends on two positive parameters.\n integral equations, Wiener-Hopf, convolution, approximate solution\n", "2410": "A Recurrence Scheme for Converting from A generalization of a scheme of Hamming for\nconverting a polynomial Pn(x) into a Chebyshev \nseries is combined with a recurrence scheme of Clenshaw\nfor summing any finite series whose terms satisfy \na three-term recurrence formula.  \n orthogonal expansions, series interconversion,\nrecurrence schemes, Hamming recurrence, Clenshaw \nrecurrence, three-term recurrence, five-term recurrence, Chebyshev series\n", "2411": "Tree-Structured Programs control structures, flowcharts, goto statements,\ninductive assertion, least fix points, optimization \nin compilers, program documentation, program flow graphs,\nprogramming language design, proof of programs, \nsemantics of programming languages, structured programming.\n", "2412": "Comment on Brent's Scatter Storage Algorithm Hashing, information storage and retrieval,\nscatter storage, searching, symbol table\n", "2413": "A Note on Subexpression Ordering in A counterexample to the supposed optimality\nof an algorithm for generating schedules for trees \nof tasks with unequal execution times is presented.\n A comparison with the \"critical path\" heuristic \nis discussed.\n scheduling, tree scheduling, task scheduling, multiprocessor scheduling\n", "2414": "Arithmetic Overa Finite Field [A1] (Algorithm A469) algebra\n", "2415": "Algorithm for Automatic Numerical Integration automatic integration, numerical integration,\nautomatic quadrature, numerical quadrature\n", "2416": "Matrix Transposition in Place [F1] (Algorithm A467) transposition, matrix operations, permutations,\nprimitive roots, number theory\n", "2417": "Four Combinatorial Algorithms [G6] (Algorithm A466) permutations and combinations\n", "2418": "Student's t Frequency [S14] (Algorithm A465) Student's t statistic, density function, series approximation\n", "2419": "Eigenvalues of a Real, Symmetric, Tridiagonal eigenvalues, QR Algorithm\n", "2420": "Experiments with an Automatic Theorem-Prover Automatic theorem-provers need to be made much\nmore efficient.  With this in mind, Slagle has \nshown how the axioms for partial ordering can be replaced\nby built-in inference rules when using a particular \ntheorem-proving algorithm based upon hyper-resolution and\nparamodulation.  The new rules embody the transitivity \nof partial orderings and the close relationship between\n predicates.  A program has been developed using \na modified version of these rules.  This new theorem-prover\nhas been found to be very powerful for solving \nproblems involving partial orderings.  This paper presents\na detailed description of the program and \na comprehensive account of the experiments that have been performed with it.\n theorem-proving, partial ordering, resolution,\nhyper-resolution, P1-resolution, paramodulation,\ninference rules, heuristics\n", "2421": "A Scan Conversion Algorithm with Reduced Storage Requirements Most graphics systems using a raster scan output\ndevice (CRT or hardcopy) maintain a display \nfile in the XY or random scan format.  Scan converters,\nhardware or software, must be provided to translate \nthe picture description from the XY format to the raster\nformat.  Published scan conversion algorithms \nwhich are fast will reserve a buffer area large enough\nto accommodate the entire screen.  On the other \nhand, those which use a small buffer area are slow because\nthey require multiple passes through the XY \ndisplay file.  The scan conversion algorithm described\nhere uses a linked list data structure to process \nthe lines of the drawing in strips corresponding to\ngroups of scan lines.  A relatively small primary \nmemory buffer area is used to accumulate the binary image\nfor a group of scan lines.  When this portion \nof the drawing has been plotted, the buffer is reused for\nthe next portion.  Because of the list processing \nprocedures used, only a single pass through the XY display\nfile is required when generating the binary \nimage and only a slight increase in execution time over\nthe fully buffered core results.  Results slow \nthat storage requirements can be reduced by more than\n80 percent while causing less than a 10 percent \nincrease in execution time.\n graphics, scan conversion, raster plotter,\nline drawing, discrete image, dot generation\n", "2422": "Adaptive Correction of Program Statements (Corrigendum)", "2423": "A Parser-Generating System for Constructing Compressed Compilers This paper describes a parser-generating system\n(PGS) currently in use on the CDC-6500 computer \nat Purdue University.  The PGS is a Fortran-coded compiler.\n In the input translation grammar, each BNF \nsyntactic rule corresponds to a (possibly empty) \"code\ngenerator\" realizable as an assembly language, \nFortran or Algol, subroutine that is called whenever\nthat syntactic rule is applied in the parse of a \nprogram.  Typical one-pass compilers constructed by the\nPGS translate source programs at speeds approaching \n14,000 cards per minute.  For an XPL compiler, the parser\nprogram and its tables currently occupy 288 \nwords of 60-bit core memory of which 140 words are parsing\ntable entries and 82 words are links to code \ngenerators.\n parser generators, translator writing systems,\nsyntactic analysis, normal-form grammars, pushdown \nautomata, translation grammars, translator optimization, compression algorithm\n", "2424": "Dynamic Verification of Operating System Decisions Dynamic verification of a decision implies\nthat every time the decision is made there is a \nconsistency check performed on the decision using independent\nhardware and software.  The dynamic verification \nof operating system decisions is used on the PRIME system\nbeing designed and constructed at the University \nof California, Berkeley.  PRIME is an experimental time-sharing\nwhich is to have the properties of continuous \navailability, data privacy, and cost effectiveness.\n The technique of dynamic verification allows the \nconstruction of an operating system which does not make certain\ndecisions improperly even in the presence \nof a single hardware or software fault.  Furthermore,\nmultiple faults lead to unreliable operation only \nif the faults happen to reinforce each other.  On PRIME,\ndynamic verification is used to ensure that \none user's information cannot become available to another\nuser gratuitously even in the presence of a \nsingle hardware or software fault.the amount of additional\nhardware and software required for dynamic \nverification can be modest.\n operating systems, data security, fault tolerance,\nsoftware reliability, data privacy, program \nverification, modular computer systems\n", "2425": "The Programmer as Navigator", "2426": "Algorithms SCALE1, SCALE2, and SCALE3 for Determination plotting, scaling for plotting\n", "2427": "Bivariate Normal Distribution [S15] (Algorithm A462) bivariate, normal Gaussian, frequency distribution\n", "2428": "Cubic Spline Solutions to a Class of Functional differential equation, spline approximation\n", "2429": "Calculation of Optimum Parameters for Alternating elliptic difference equations, Peaceman-Rachford,\nDouglas-Rachford, W. B. Jordan, optimum parameters, \nalternating-direction-implicit, ADI\n", "2430": "The Elementary Circuits of a Graph [H] (Algorithm A459) algorithm, graph theory, circuit search\nalgorithm, path search algorithm, searching\n", "2431": "Discrete Linear L1 Approximation by interval discrete approximation, L1 approximation\n", "2432": "Addendum to a Multiple-Precision Division Algorithm multiple-precision, division, overflow\n", "2433": "Control Structures in Illiac IV Fortran As part of an effort to design and implement\na Fortran compiler on the ILLIAC IV, an extended \nFortran, called IVTRAN, has been developed.  This language\nprovides a means of expressing data and control \nstructures suitable for exploiting ILLIAC IV parallelism.\n This paper reviews the hardware characteristics \nof the ILLIAC and singles out unconventional features\nwhich could be expected to influence language (and \ncompiler) design.  The implications of these features for\ndata layout and algorithm structure are discussed, \nand the conclusion is drawn that data allocation rather than\ncode structuring is the crucial ILLIAC optimization \nproblem.  A satisfactory method of data allocation is\nthen presented.  Language structures to utilize \nthis storage method and express parallel algorithms are described.\n array processing, parallelism detection, explicit\nparallelism, array allocation, parallel control \nstructures, ILLIAC IV Fortran\n", "2434": "Using Page Residency To Select the Working Set Parameter Denning's method for selecting the working set\nparameter, which uses interreference intervals, \nis examined.  Several omissions in his model are noted,\nand new assumptions are introduced to overcome \nthese omissions.  Using this modified model, Dening's results\non page residency are rederived and reconsidered \nfor selecting the working set parameter.\n working set model, paging, program behavior,program modeling\n", "2435": "A Class of Dynamic Memory Allocation Algorithms Anew dynamic memory allocation algorithm, the\nFibonacci system, is introduced.  This algorithm \nis similar to, but seems to have certain advantages over,\nthe \"buddy\" system.  A generalization is mentioned \nwhich includes both of these systems as special cases.\n dynamic storage allocation, buddy system,\nsimulation, Fibonacci, fragmentation\n", "2436": "A Note on the Confinement Problem This note explores the problem of confining\na program during its execution so that it cannot \ntransmit information to any other program except its\ncaller.  A set of examples attempts to stake out \nthe boundaries of the problem.  Necessary conditions\nfor a solution are stated and informally justified.\n protection, confinement, proprietary program,\nprivacy, security, leakage of data\n", "2437": "General Performance Analysis of Key-to-Address This paper presents a new approach to the analysis\nof performance of the various key-to-address \ntransformation methods.  In this approach the keys in\na file are assumed to have been selected from the \nkey space according to a certain probabilistic selection\nalgorithm.  All files with the same number of \nkeys selected from this key space will be suitably weighted\nin accordance with the algorithm, and the \naverage performance of the transformation methods on\nthese files will be used as the potential of these \nmethods.  Using this analysis, methods with the same overall\nperformance can be classified and key distributions \npartial to certain transformations can be identified.\n All this can be done analytically.  The approach \nis applied to a group of transformation methods\nusing files whose keys are selected randomly.\n hashing, hashing techniques, hashing methods, hash coding,\nkey transformation, key-to-address transformation, \ndirect addressing, randomizing, random access, scatter\nstorage, information retrieval, hashing analysis, \nrandomization performance analysis\n", "2438": "A Model and Stack Implementation of Multiple Environments Many control and access environment structures\nrequire that storage for a procedure activation \nexist at times when control is not nested within the\nprocedure activated.  This is straightforward to \nimplement by dynamic storage allocation with linked\nblocks for each activation, but rather expensive \nin both time and space.  This paper presents an implementation\ntechnique using a single stack to hold \nprocedure activation storage which allows retention\nof that storage for durations not necessarily tied \nto control flow.  The technique has the property that,\nin the simple case,it runs identically to the \nusual automatic stack allocation and deallocation procedure.\n Applications of this technique to multitasking, \ncoroutines, backtracking, label-valued variables, and\nfunctional arguments are discussed.  In the initial \nmodel, a single real processor is assumed, and the implementation\nassumes multiple-processes coordinate \nby passing control explicitly to one another.  A multiprocessor\nimplementation requires only a few changes \nto the basic technique, as described.\n control structures, environments, stack allocation,\ndendrarchy, retention, dynamic storage allocation, \naccess environments, FUNARG problem, multitasking,\ncoroutines, backtracking, label-valued variables, \nfunctional arguments, multiprocessor systems, extensible control structures\n", "2439": "Multiple Terminals Under User Program User-written programs on the Dartmouth Time-Sharing\nsystem can communicate with many remote \nterminals simultaneously and can control the interactions\nbetween these terminals.  Such programs can \nbe written using standard input and output instructions\nin any language available on the system.  This \npaper describes how this multiple-terminal facility\nwas implemented without requiring any changes in \nthe system executive or in any of the system's compilers or interpreters.\n DTSS, multiple terminals, remote terminals, remote\nconsoles, time-sharing, on-line interaction, \non-line games\n", "2440": "Localization of the Roots of a Polynomial (Algorithm R429)", "2441": "Hidden-Line Plotting Program (Algorithm R420)", "2442": "A Sparse Matrix Package (Algorithm R408)", "2443": "Generation of Permutations in Lexicographic Order (Algorithm R323)", "2444": "Finding All Cliques of an Undirected Graph (Algorithm A457) cliques, maximal complete subgraphs, clusters, backtracking\nalgorithm, branch and bound technique, \nrecursion\n", "2445": "Routing Problem (Algorithm A456) routing problem, shortest path, traveling\nsalesman problem, Hamiltonian circuit\n", "2446": "Analysis of Skew Representations of the Symmetric Group (Algorithm A455) symmetric group, skew representation, partition,\nYoung diagram, lattice permutation, binary model, \nouter product\n", "2447": "Sard Kernels for Certain Bivariate Cubatures An error analysis for some bivariate cubatures\nis given.  The remainders are obtained by the \nuse of Sard kernels.  Numerical results and computer\ngraphs are given for some of the kernel functions.\n cubatures, Sard kernels, numerical integration, remainder formulas\n", "2448": "Reversible Execution debugging, PL/I, reversible execution, backtracking\n", "2449": "A Simple Technique for Structured Variable Lookup A simple technique for the symbol-table lookup\nof structured variables based on simple automata \ntheory is presented. The technique offers a deterministic\nsolution to a problem which is currently handled \nin a nondeterministic manner in PL/I and COBOL compilers.\n symbol table organization, PL/I and COBOL structured variables\n", "2450": "Empirical Working Set Behavior The working set model for program behavior\nhas been proposed in recent years as a basis for \nthe design of scheduling and paging algorithms.  Although\nthe words \"working set\" are now commonly encountered \nin the literature dealing with resource allocation, there\nis a dearth of published data on program measurements, \nin the hope that workers in the field might find experimental\nevidence upon which to substantiate and \nbase theoretical work.\n virtual memory, paging, working set,\nsoftware measurement, program behavior\n", "2451": "Design of Tree Structures for Efficient Querying A standard information retrieval operation is\nto determine which records in a data collection \nsatisfy a given query expressed in terms of data values.\n The process of locating the desired responses \ncan be represented by a tree search model.  This paper\nposes an optimization problem in the design of \nsuch trees to serve a well-specified application. The\nproblem is academic in the sense that ordinarily \nthe optimal tree cannot be implemented by means of practical\ntechniques.  On the other hand, it is potentially \nuseful for the comparison it affords between observed\nperformance and that of an intuitively attractive \nideal search procedure.  As a practical application\nof such a model this paper considers the design of \na novel tree search scheme based on a bit vector representation\nof data and shows that essentially the \nsame algorithm can be used to design either an ideal\nsearch tree or a bit-vector tree.  An experimental \nstudy of a small formatted file illustrates the concepts.\n tree file, information storage and retrieval, clustering,\nsearch, data structure, data management, \nquery answering\n", "2452": "Evaluation and Selection of File Organization-A Model and System This work first discusses the factors that\naffect file (data base) organization performance, \nan elusive subject, and then presents a methodology, a\nmodel and a programmed system to estimate primarily \ntotal storage costs and average access time of several\nfile organizations, given a specific data base, \nquery characterization and device-related specifications.\n Based on these estimates, an appropriate file \nstructure may be selected for the specific situation.\n The system is a convenient tool to study file \nstructures and to facilitate as much as possible the process\nof data base structure design and evaluation.\n file organization, file structures, file management,\nfile organization performance, file organization \nmodel, file structure design, secondary index organization,\nsimulation, data base, access time, storage \nrequirement, data base analysis, data management\n", "2453": "Information Theory Applied to the Conversion Using ideas from information theory, this paper\ndevelops a heuristic algorithm that converts \na limited entry decision table to a tree structured computer\nprogram with near minimum average processing \ntime.  The method is applicable to any limited entry\ndecision table and does not require that actions \nhave single rules or that the cost of testing conditions\nbe equal.  It is thus more general than the \npreviously published heuristic algorithms.  Compared\nto the optimal algorithm of Reinwald and Soland, \nthis algorithm is easy to code and takes a much smaller\ntranslation time; it is thus felt that it is \nmore useful in practice.  The algorithm is well suited for\nmanual conversion of decision tables to flowcharts.\n decision tables, optimum computer programs, information measure\n", "2454": "Computational Algorithms for Closed Queueing Methods are presented for computing the equilibrium\ndistribution of customers in closed queueing \nnetworks with exponential servers.  Expressions for\nvarious marginal distributions are also derived. \n The computational algorithms are based on two-dimensional\niterative techniques which are highly efficient \nand quite simple to implement.  Implementation considerations\nsuch as storage allocation strategies and \norder of evaluation are examined in some detail.\n queueing theory, queueing networks, equilibrium\ndistributions, steady state distributions\n", "2455": "A Generalization of AVL Trees A generalization of AVL trees is proposed in\nwhich imbalances up to (triangle shape) is a small \ninteger.  An experiment is performed to compare these\ntrees with standard AVL trees and with balanced \ntrees on the basis of mean retrieval time, of amount\nof restructuring expected, and on the worst case \nof retrieval time.  It is shown that, by permitting\nimbalances of up to five units, the retrieval time \nis increased a small amount while the amount of restructuring\nrequired is decreased by a factor of ten. \n A few theoretical results are derived, including the correction\nof an earlier paper, and are duly compared \nwith the experimental data.  Reasonably good correspondence is found.\n AVL trees, balanced trees, information storage and retrieval\n", "2456": "On the Capabilities of While, Repeat, and Exit Statements A well-formed program is defined as a program\nin which loops and if statements are properly \nnested and can be entered only at their beginning.  A\ncorresponding definition is given for a well-formed \nflowchart.  It is shown that a program is well formed if\nand only if it can be written with if, repeat, \nand multi-level exit statements for sequence control. \nIt is also shown that if,while, and repeat statements \nwith single-level exit do not suffice.  It is also shown\nthat any flowcharts can be converted to a well-formed \nflowchart by node splitting.  Practical implications are discussed.\n well-formed program, while statement, repeat statement,\nexit statement, go to statement, flowchart, \nnode splitting, software reliability\n", "2457": "Inductive Methodsfor Proving Properties of Programs There are two main purposes in this paper:\nfirst, clarification and extension of known results \nabout computation of recursive programs, with emphasis\non the difference between the theoretical and \npractical approaches; second, presentation and examination\nof various known methods for proving properties \nof recursive programs.  Discussed in detail are two\npowerful inductive methods computational induction \nand structural induction, including examples of their applications.\n recursive programs, least fixed point, computational\ninduction, structural induction\n", "2458": "Localization of the Roots of a Polynomial (Algorithm R429)", "2459": "Hu-Tucker Minimum Redundancy Alphabetic Coding Method (Algorithm R428)", "2460": "Clenshaw-Curtis Quadrature (Algorithm R424)", "2461": "Graph Plotter (Algorithm R412)", "2462": "An Efficient Prime Number Generator (Algorithm R357)", "2463": "Complex Gamma Function (Algorithm R404,C404)", "2464": "The Complex Method for Constrained Optimization [E4] (Algorithm A454) optimization, constrained optimization, Box's algorithm\n", "2465": "Gaussian Quadrature formulas for Bromwich's Gaussian quadrature, Bromwich's integral, complex\nintegration, numerical inversion of the Laplace \ntransform\n", "2466": "Enumerating Combinations of m Out of n Objects [G6] (Algorithm A452) permutations, combination\n", "2467": "Chi-Square quantiles [G1] (Algorithm A451) Chi-square, asymptotic approximation, normal\ndeviate, chi-square deviate, degrees of freedom\n", "2468": "Rosenbrock Function Minimization [E4] (Algorithm A450) function minimization, Rosenbrock's method\n", "2469": "Petri Nets and Speed Independent design Petri nets are investigated as one method of\nmodeling speed independent asynchronous circuits. \n A study of circuit realizations of Petri nets leads\nto a demonstration of their usefulness in modeling \nspeed independent operation.  This usefulness is emphasized\nby the design of a speed independent processor \nfrom modules developed in the investigation of Petri net implementation.\n speed independent asynchronous, Petri net\n", "2470": "Fen-An Axiomatic Basis for Program Semantics A formal system is presented which abstracts\nthe notions of data item, function, and relation. \n It is argued that the system is more suitable than set\ntheory (or its derivatives) for the concise and \naccurate description of program semantics.  It is shown\nhow the system can be used to build composite \ndata types out of simper ones with the operations of rowing,\nstructuring, and uniting.  It is also demonstrated \nthat completely new primitive types can be introduced\ninto languages through the mechanism of singleton \ndata types.  Both deterministic and nondeterministic\nfunctions are shown to be definable in the system. \n It is described how the local environment can be modeled\nas a data item and how imperative statements \ncan be considered functions on the environment.  The\nnature of recursive functions is briefly discussed, \nand a technique is presented by which they can be introduced\ninto the system.  The technique is contrasted \nwith the use of the paradoxical combinator, Y.  The\nquestions of local and global environments and of \nvarious modes of function calling and parameter passing\nare touched upon. The theory is applied to the \nproof of several elementary theorems concerning the semantics\nof the assignment, conditional, and iterative \nstatements.  An appendix is included which presents in\ndetail the formal system governing webs and fen, \nthe abstractions used informally in the body of the paper.\n semantics, formal systems, lambda-calculus, extensible\nlanguages, data types, modes, axioms, correctness, \nformal language definition, formal description, data structures,\ndescription languages, models of computation\n", "2471": "A Learning Program Which Plays Partnership Dominoes A learning program has been written is BASIC\nto play four-player partnership dominoes.  Because \ndominoes is a game of incomplete information, the program\nuses somewhat different principles of artificial \nintelligence from those used in programs for games\nof complete information, such as checkers, chess, \nand go.  The program was constructed to use a \"strategy\nsignature table\" which classifies board situations \nthrough the interactions of game parameters. Each entry\nin the table contains adaptively determined \nweights indicating the advi sability of various strategies.\n Once chosen, a strategy then employs probability \nanalysis and linear polynomial evaluation to choose\na move.  Our program wins approximately two-thirds \nof its games in tournament situations, and has defeated championship players.\n artificial intelligence, intelligence learning,\nheuristic procedures, heuristic programming, game \nplaying, problem solving,dominoes, incomplete information,\nmachine learning, signature table, learning \nprograms, strategy learning\n", "2472": "Minimal spanning Tree (Algorithm R422) spanning tree, minimal spanning tree, Prim algorithm\n", "2473": "Hidden-Line Plotting Program (Algorithm R420) hidden-line plot, surface plot\n", "2474": "DIFSUB for Solution of Ordinary Differential Equations (Algorithm C407) differential equations, stiff differential\nequations, boundary value problems\n", "2475": "Solution of Linear Programming Problems linear programming, zero-one variable \n", "2476": "Equivalence Between AND/OR Graphs and Context-Free Grammars artificial intelligence, AND/OR graphs,\nlanguage theory, context-free grammars\n", "2477": "Multiple Exits from a Loop Without the GOTO control structures, goto free programming,\nmultiple exits from loops, exit statement\n", "2478": "Computer Science-Seminars for Undergraduates education, computer science, curriculum, imprecise\nsynthesis, fuzzy educational structure\n", "2479": "Curriculum Recommendations for Graduate Professional An addendum to the Report of the ACM Curriculum\nCommittee on Computer Education for Management \nis proposed. The proposed addendum is to include in the curriculum\na course on Information Systems administration. \nIt is important for two reasons: (1) the systems designer\nmust understand the administrative framework \nin which he must operate to work effectively, and (2) an\nimportant objective of the curriculum recommendations \nis to prepare the future manager of the computer activity.\n It is felt that the importance of these two \nreasons justifies the addition of the recommended course.\n The course is outlined in the format of the \noriginal report.\n education, management information systems, information\nsystems administration, information systems \nmanagement, computer management\n", "2480": "Teaching \"About Programming\" This paper presents the goals and organization\nof a course about programming designed to provide \nentering students in a graduate program with a cultural\nenrichment in their professional lives.  The \nstudents are expected to have taken at least two programming\ncourses prior to this one and, therefore, \nto be familiar with at least two programming languages,\nboth as students and users.  Teaching someone \nhow to program is similar to teaching him to play a musical\ninstrument: neither skill can be taught-they \nmust be learned.  However, the teacher still serves\nseveral vital purposes: to present a set of rules \nfor producing well-formed utterances; to offer numerous\ndemonstrations of his own skill; and to function \nas an involved critic.  Finally, the teacher is the\nsource of information about the process in which \nthe student is involved.\n education, programming concepts, professionalism\n", "2481": "The Distribution of a Program in Primary and Fast Buffer Storage A virtual memory computer system with a fast\nbuffer (cache) memory between primary memory and \nthe central processing unit is considered.  The optimal\ndistribution of a program between the buffer \nand primary memory is studied using the program's lifetime\nfunction.  Expressions for the distribution \nof a program which maximizes the useful fraction of\nthe cost-time integral of primary and fast buffer \nstorage are obtained for swapping and nonswapping buffer management policies.\n cache, virtual memory, lifetime function, cost-time integral, fast buffer\n", "2482": "Mixed Solutions for the Deadlock Problem Mixtures of detection, avoidance, and prevention\nprovide more effective and practical solutions \nto the deadlock problem than any one of these alone.  The\nindividual techniques can be tailored for subproblems \nof resource allocation and still operate together to\nprevent deadlocks.  This paper presents a method, \nbased on the concept of the hierarchical operating\nsystem, for constructing appropriate mixtures and \nsuggests appropriate subsystems for the most frequently\noccurring resource allocation problems\n deadlocks, resource allocation, operating systems,\nmultiprogramming, hierarchical systems\n", "2483": "COKO III: The Cooper-Koz Chess Program COKO III is a chess player written entirely\nin Fortran.  On the IBM 360-65, COKO III plays \na minimal chess game at the rate of .2 sec cpu time\nper move, with a level close to lower chess club \nplay.  A selective tree searching procedure controlled\nby tactical chess logistics allows a deployment \nof multiple minimal game calculations to achieve some optimal\nmove selection.  The tree searching algorithms \nare the heart of COKO's effectiveness, yet they are\nconceptually simple.  In addition, an interesting \nphenomenon called a tree searching catastrophe has plagued\nCOKO's entire development just as it troubles \na human player.  Standard exponential growth is curbed\nto a large extent by the definition and trimming \nof the Fischer set.  A clear distinction between tree\npruning and selective tree searching is also made. \n Representation of the chess environment is described\nalong with a strategical preanalysis procedure \nthat maps the Lasker regions.  Specific chess algorithms\nare described which could be used as a command \nstructure by anyone desiring to do some chess program\nexperimentation.  A comparison is made of some \nmysterious actions of human players and COKO III.\n artificial intelligence, selective searching, tree\nsearching, tree searching catastrophe, heuristic \nprogramming,chess algorithms, Lasker regions, Fischer\nset, minimal chess game, strategical, tactical, \ntactical control mode, game playing, alpha beta, machine\nlearning, concept formation, command structure, \nminimax, computer chess tournament, auxiliary minimal game\n", "2484": "A Note on Information Organization and Storage Since the logical structure of a data base\ncan be represented by a tree or graph, it is quite \nnatural for us to view the process of designing a data\nbase as that of constructing a tree or a graph. \n A general method for constructing such a tree or a graph\nis provided.  There are three important elements \nin this general construction method; namely, a set of\nbinary relations, an algorithm for constructing \nsubsets of a set, and an algorithm for selecting an\nelement from the given set of objects.  The use of \ndifferent relations and algorithms results in different\ninformation structures, as list, tree, ring, \netc.  Thus the problem of information organization and\nstorage is reduced to that of defining relations \nand formulating algorithms under a given set of constraints.\n The results presented may be valuable to \ndesigners as useful design concepts, and may serve as\na basis for developing a formal theory on the subject.\n data base, data-base management, information retrieval,\ninformation structure, file organization, \nstorage allocation, tree, graph\n", "2485": "Managing the Computer Resource: A Stage Hypothesis Based on the study of expenditures for data processing,\na descriptive stage hypothesis is presented. \n It is suggested that the planning, organizing, and controlling\nactivities associated with managing the \ncomputer resource will change in character over a period\nof time, and will evolve in patterns roughly \ncorrelated to four stages of the computer budget: Stage\nI (computer acquisition), Stage II (intense system \ndevelopment), Stage III (proliferation of controls), and\nStage IV (user/service orientation).  Each stage \nis described and related to individual tasks for managing the computer resource.\n computer management, computer budget, computer expenditures,\nstage hypothesis, planning, organizing, \ncontrol, computer resource\n", "2486": "Computer Photocomposition of Technical Text In computer assisted typesetting by means of\nphotocomposition, special problems arise in highly \ntechnical material such as mathematical formulas.  New\nsolutions to several of these problems have been \ndevised in the information system of the American Institute\nof Physics.  They include: the representation \nof special characters (foreign alphabets, mathematical\nsymbols, etc.) not available on input keyboards \nor on the photocomposer; the generation of such symbols,\ne.g. by overprinting; the precise positioning \nof accent marks (floating diacritics); line breaks,\ni.e. words or formulas placed partly at the end of \none line and partly at the beginning of the next;\nand certain aspects of error correction.\n photocomposition, typesetting, printing, graphics, text processing\n", "2487": "Cubic Spline solutions to Fourth-order Boundary Value Problems The cubic spline approximation to the fourth-order\ndifferential equation y''''+p(x)y''+q(x)y'+r(x)y=t(x) \nis shown to reduce to the solution of a five-term recurrence\nrelationship.  For some special cases the \napproximation is shown to be simply related to a finite\ndifference representation with a local truncation \nerror of order (y/720)delta^8.\n cubic spline, differential equations, boundary value problem\n", "2488": "Least Squares Piecewise Cubic Curve Fitting The matrices involved in a linear least squares\nformulation are determined for the problem \nof fitting piecewise cubic functions, those possessing\na continuous derivative, to arrays of planar data.\n curve fitting, data reduction, function\napproximation, approximation splines\n", "2489": "Number of Multiply-Restricted Partitions [A1] (Algorithm A448) partitions, enumeration, change making, energy-level\ndegeneracies, molecular vibrational energy-levels\n", "2490": "Efficient Algorithms for Graph Manipulation [H] (Algorithm A447) Efficient algorithms are presented for partitioning\na graph into connected components, biconnected \ncomponents and simple paths.  The algorithm for partitioning\nof a graph into simple paths is iterative \nand each iteration produces a new path between two\nvertices already on paths.  (The start vertex can \nbe specified dynamically.)  If V is the number of vertices\nand E is the number of edges, each algorithm \nrequires time and space proportional to max (V,E)\nwhen executed on a random access computer.\n graphs,analysis of algorithms, graph manipulation\n", "2491": "Threaded Code The concept of \"threaded code\" is presented as\nan alternative to machine language code.  Hardware \nand software realizations of it are given.  In software\nit is realized as interpretive code not needing \nan interpreter.  Extensions and optimizations are mentioned.\n interpreter, machine code, time tradeoff, space\ntradeoff, compiled code, subroutine calls, threaded \ncode\n", "2492": "The Development of Decision Tables via A new parsing technique is proposed which allows\nparsing based only on syntactical characteristics \nof the decision problem.  It requires a description\nof the problem in decision grid chart format and \nallows the development of decision tables within defined\nlimits by avoiding, or at least minimizing, \nrepetition of conditions and actions in the resulting tables.\n decision tables, parsing, decision grid chart,problem analysis\n", "2493": "Optimum Data Base Reorganization Points In certain data base organization schemes the\ncost per access may increase due to structural \ninefficiencies caused by updates.  By reorganizing\nthe data base the cost per access may be reduced. \n However, the high cost of a reorganization prohibits\nfrequent reorganizations.  This paper examines \nstrategies for selecting the optimum reorganization points.\n data base, reorganization, files, information retrieval\n", "2494": "A Computer Generated Aid for Cluster Analysis A computer generated graphic method, which\ncan be used in conjunction with any hierarchical \nscheme of cluster analysis, is described and illustrated.\n The graphic principle used is the representation \nof the elements of a data matrix of similarities or dissimilarities\nby computer printed symbols (of character \noverstrikes) of various shades of darkness, where a\ndark symbol corresponds to a small dissimilarity. \n The plots, applied to a data matrix before clustering\nand to the rearranged matrix after clustering, \nshow at a glance whether clustering brought forth any\ndistinctive clusters.  A well-known set of data \nconsisting of the correlations of 24 psychological tests\nis used to illustrate the comparison of groupings \nby four methods of factor analysis and two methods of cluster analysis.\n computer graphics, cluster analysis, numerical\ntaxonomy, hierarchical clustering, factor analysis\n", "2495": "Adapting Optimal Code Generation for Arithmetic arithmetic expressions, code generation, compilers,\nobject-code optimization, register assignment, \ntrees\n", "2496": "On the Near-Optimality of the Shortest-Latency-Time-First For computer systems in which it is practical\nto determine the instantaneous drum position, \na popular discipline for determining the sequence in which\nthe records are to be accessed is the so-called \nshortest-latency-time-first, SLTF, discipline.  When\na collection of varying-length records is to be \naccessed from specified drum positions, it is known that\nthe SLTF discipline does not necessarily minimize \nthe drum latency time.  However, we show that the total\ntime to access the entire collection for any \nSLTF schedule is never as much as a drum revolution\nlonger than a minimum latency schedule.\n drum scheduling, shortest-access-time-first, minimal\nlatency scheduling, shortest-latency-time-first\n", "2497": "Synchronizing Processors with Memory-Content-Generated Interrupts Implementations of the \"Lock-Unlock\" method\nof synchronizing processors in a multiprocessor \nsystem usually require uninterruptable, memory-pause type instructions.\n An interlock scheme called read-interlock, \nwhich does not require memory-pause instructions, has\nbeen developed for a dual DEC PDP-10 system with \nreal-time requirements.  The read-interlock method does\nrequire a special\"read-interlock\" instruction \nin the repertoire of the processors and a special \"read-interlock\"\ncycle in the repertoire of the memory \nmodules.  When a processor examines a \"lock\" (a memory\nlocation) with a read-interlock instruction, it \nwill be interrupted if the lock was already set; examining\na lock immediately sets it if it was not already \nset (this event sequence is a read-interlock cycle). \nWriting into a lock clears it.  Having the processor \ninterrupted upon encountering a set lock instead of\nbranching is advantageous if the branch would have \nresulted in an effective interrupt.\n interrupts,supervisors, monitors, debugging, parallel\nprocessing, associative memories, microprogramming\n", "2498": "Minimizing Wasted Space in Partitioned Segmentation A paged virtual memory system using a finite\nnumber of page sizes is considered.  Two algorithms \nfor assigning pages to segments are discussed.  Both\nof these algorithm are simple to implement.  The \nproblem of choosing the page sizes to minimize the expected\nvalue of total wasted space in internal fragmentation \nand in a page table, per segment, is then solved for a\nprobability density function of segment size which \nmay be expressed as a convex combination of Erlang densities.\n dynamic storage allocation, virtual memory, paging,\nmultiple page sizes, fragmentation, segmentation\n", "2499": "Efficient Multiprogramming Resource Allocation and Accounting Although sometimes thought of as only a component\nof time-sharing operation, multiprogramming \ncan involve broader questions of resource allocation,\nsince fairness is not required to meet a response \ncriterion.  In a multiprogrammed system, it may serve\nmaximal resource use to be unfair, for example \nby holding an input/output channel idle for a program\nwhile it completes a small amount of processor \nusage, enabling further use of the channel.  Several\napplications of this principle are given, and it \nis suggested that a multiprogramming executive might\ndynamically adjust its allocation algorithms to \ngain efficiency.  Allocation of resources is closely connected\nto accounting for those resources, raising \nthe problems of repeatability, minimal uncharged overhead,\nand relative weighting of charges for dependent \nresources.  Since weightings may depend on allocation\nalgorithms, these are not arbitrary accounting \nparameters.  Often the only repeatable accounting is\none which omits an extensive overhead will be paid, \nand should multiprogramming prove efficient, overcharges\nwill result.  Multiprogramming turns on allocation \nof the memory resource essential to control of other\nresources.  The general suggestions for allocation \nand accounting are applied to this question, and some\ndetails provided for the case of a monitor which \ncontrols a virtual-memory machine.\n monitor, executive, multiprogramming, efficiency,\nresource allocation, resource accounting\n", "2500": "A Practical Approach to Managing Resources and Avoiding Deadlocks Resource scheduling and allocation can be expensive\nwith regard to time and space in multiprogramming \nor time-sharing environments involving large numbers of\ntasks and resources with conflicting requirements. \n Detection and/or prevention of deadlocks can require\nmassive amounts of additional overhead if efficient \nusage of resources is to be maintained.  A resource\nmanagement program is described which uses linked \nlists along with other techniques to overcome a large\nportion of this overhead.  The program, which is \ncurrently running as part of a large scale general purpose\noperating system, keeps resources relatively \nactive but does not detect or prevent all deadlocks\nin its implemented state.  Certain changes, which \nwould permit more comprehensive levels of deadlock\nprevention/detection at additional cost, have not \nbeen incorporated in the running system due\nto the infrequency of deadlock situations.\n deadlock, resource allocation, scheduling, resource\nmanagement, multiprogramming, time-sharing, \nmultiprocessing, deadly embrace\n", "2501": "WYLBUR: An Interactive Text Editing and Remote Job Entry System WYLBUR is a comprehensive system for manipulating\nall kinds of text, such as computer programs, \nletters, and manuscripts, using typewriter terminals\nconnected to a computer.  It has facilities for \nremote job entry and retrieval as well as facilities\nfor text alignment and justification.  A powerful \nmethod for addressing text by content is provided.  This\npaper describes the external appearance of WYLBUR \nas well as its internal structure.  A short description\nof the major features of ORVYL, a general purpose \ntime-sharing system which operates in conjunction with WYLBUR, is also included.\n text editing, time-sharing, on-line text editing,\ninteractive text editing, terminal, remote terminal, \nterminal system, interactive terminal, remote job entry,\nremote job retrieval, program preparation, document \npreparation, data entry, content addressing\n", "2502": "A Comment on the Practical Aspects of Computer Science Education education, computer engineering, computer\nsciences curriculum, systems design\n", "2503": "Another Comment on Computer Music", "2504": "Concerning Music and Computer Composition in Computational Linguistics artificial intelligence, heuristic programming,\nmodels of cognitive processes, computer music, \ncomputer composition,music theory\n", "2505": "Reflection-Free Permutations, Rosary Permutations, permutation, permutation generation, scheduling, combinatorial analysis\n", "2506": "A Sparse Matrix Package (Algorithm R408) matrix, sparse matrix, matrix manipulation, Fortran standards\n", "2507": "Exact Solution of Linear Equations Using residue arithmetic, symmetric residue, modulus,\nmixed-radix representation, symmetric mixed-radix \nrepresentation, mixed radix conversion, prime number,\nlinear equations, Gaussian elimination, matrix \ninversion, determinant, adjoint matrix, ill-condition\n", "2508": "Increasing the Efficiency of Quicksort (Algorithm R402) sorting, quicksort\n", "2509": "Minit Algorithm for Linear Programming (Algorithm R333)", "2510": "Minit Algorithm for Linear Programming (Algorithm R333)", "2511": "Maxflow (Algorithm R324)", "2512": "Coulomb Wave Functions (Algorithm R300) Coulomb wave functions, wave functions,\nspecial functions, function evaluation\n", "2513": "A Nonrecursive List Moving Algorithm An efficient, nonrecursive algorithm is given\nfor moving any LISP-type list.  In particular, \nthe algorithm requires no storage other than the new\nnodes into which the list is to be moved, and no \nadditional bits per node for marking; the algorithm\nruns in time proportional to the number of nodes \nin the list.  The original list structure is destroyed as it is moved.\n list moving, list copying, list traversal, garbage collection LISP\n", "2514": "An Array Grammar Programming System A package of Fortran programs has been developed\nthat permits a user to interactively design \nand test array grammars.  The user can control the rule\nselection procedure in a derivation or parse, \nusing weighted programming matrices; he also has a choice\nof instance selection schemes (raster,random, \nparallel).  Examples are given involving array languages\nconsisting of simple geometrical patterns, as \nwell as a language of \"neuron pictures.\"\n picture grammars, array grammars\n", "2515": "Minimal Event-Node Network of Project Precedence Relations A procedure for constructing a minimal event-node\nnetwork to represent a set of precedence \nrelations without parallel activities is presented.  A\nminimal event-node network is an event-node network \nin which both the number of nodes and the number of arcs\nare the minima to preserve the given precedence \nrelations Counterexamples are given to show that the\nalgorithm presented by A. C. Fisher, J. S. Liebman, \nand G. L. Nemhauser (1968) produces event-node networks\nwhich are not minimal.  Since our procedure includes \nthe set-covering problem, the time required may grow\nexponentially with the number of given activities.\n network, project, event-node network, activity-node\nnetwork, minimal event-node network, dummy \nactivity, project precedence relations\n", "2516": "Hierarchical Storage in Information Retrieval A probabilistic analysis is employed to determine\nthe effect of hierarchical storage organizations \non information retrieval operations.  The data storage\nhardware is assumed to consist on n-levels of \nlinearly connected memory hardware with increasing data\naccess times and increasing data storage capabilities. \n A system might, for example, consist of fast semiconductor\nmemory, computer core memory, extended core \nstorage, disk memory, and data cells.  Equations are derived\nto predict the effect of such a system on \ndata access times using sequential files, random access files,\nand structured files employing multiple-hierarchical \nlinked lists.\n information retrieval, hierarchical storage\n", "2517": "Some Comments on the Use of Ambiguous Decision This paper comments upon recently published\nwork on decision table translation using methods \nsimilar to the rule-mask technique.  The applicability\nof these methods under various possible conventions \non overall table meaning is discussed, and it is argued\nthat there is a place both for the multi-rule \nand the single-rule (or action set) convention in decision tale usage.\n decision tables, systems analysis, programming\n", "2518": "Programming by Questionnaire: An Effective Way To Use Decision Tables Programming by questionnaire combines aspects\nof decision table programming and general purpose \nprogramming by using decision tables to construct an application\nprogram through the selection of certain \nsource statements from a predefined file.  It is proposed\nthat programming by questionnairies a useful \ncompromise between general and special purpose programming\nfor a significant class of large scale problems. \n The elements of the approach are discussed\nan existing application is described.\n customizing, modeling, applications development,\nprogrammer productivity, simulator generation, \nautomatic program generation, no reprogramming\n", "2519": "On the Problem of Communicating Complex Information The nature of the difficulty involved in communicating\nmathematical results between scientists \nusing a computer based information retrieval system\nis examined.  The problem is analyzed in terms of \npsychological and information-processing processes, and\nwhat turns out to be a vicious circle of effects \nis described.  These include ways of augmenting written\nnatural language by various notational and linguistic \ndevices, the exhibition of the structure inherent in the\ninformation we are communicating, and a sophisticated \ninteractive system controlled by computer.\n complex information, information, communication,\nmathematics, proof, interactive system, language\n", "2520": "Greatest Common Divisor of n Integers and Multipliers (Algorithm C386) proof of algorithms, greatest common divisor,\nEuclidean algorithm, inductive assertion method\n", "2521": "Ten Subroutines for the Manipulation Chebyshev series, differentiation, integration,\ncurve fitting,approximations, negative powers\n", "2522": "The Design, Implementation, and Evaluation of a Working Set Dispatcher The behavior of a computer system is largely\ndependent upon the algorithms employed to allocate \nthe system resources to the processes competing for them.\n Recent research in time-sharing paging systems \nhas developed the working set model for program behavior,\nand are source allocation strategy based on \nthis model has been proposed.  Two implementations\nalong these principles have been reported, but it \nseems that in neither case have further results been\nannounced.  This report discusses the design and \nimplementation of a dispatcher based on the working set\nprinciple, presents data to permit analysis of \nits behavior, and indicates future directions of research\non methods of controlling a computer system.\n working set, dispatcher, scheduler, time-sharing\nsystems, resource allocation, software evaluation, \noperating systems, supervisory systems\n", "2523": "A Region Coloring Technique for Scene Analysis A method of converting a picture into a \"cartoon\"\nor \"map\" whose regions correspond to differently \ntextured regions is described.  Texture edges in the\npicture are detected, and solid regions surrounded \nby these (usually broken) edges are \"colored in\" using\na propagation process.  The resulting map is cleaned \nby comparing the region colors with the textures of\nthe corresponding regions in the picture, and also \nby merging some regions with others according to criteria\nbased on topology and size.  The method has \nbeen applied to the construction of cloud cover maps\nfrom cloud cover pictures obtained by satellites.\n picture processing, scene analysis, edge detection\n", "2524": "Some Approaches to Best-Match File Searching The problem of searching the set of keys in\na file to find a key which is closest to a given \nquery key is discussed.  After \"closest,\" in terms of\na metric on the the key space, is suitably defined, \nthree file structures are presented together with their\ncorresponding search algorithms, which are intended \nto reduce the number of comparisons required to achieve\nthe desired result. These methods are derived \nusing certain inequalities satisfied by metrics and by\ngraph-theoretic concepts.  Some empirical results \nare presented which compare the efficiency of the methods.\n matching, file structuring, file searching, heuristics, best match\n", "2525": "A Statistical Study of the Accuracy of Floating Point Number Systems This paper presents the statistical results\nof tests of the accuracy of certain arithmetic \nsystems in evaluating sums, products and inner products,\nand analytic error estimates for some of the \ncomputations.  The arithmetic systems studied are 6-digit\nhexadecimal and 22-digit binary floating point \nnumber representations combined with the usual chop\nand round modes of arithmetic with various numbers \nof guard digits, and with a modified round mode with guard\ndigits.  In a certain sense, arithmetic systems \ndiffering only in their use of binary or hexadecimal number\nrepresentations are shown to be approximately \nstatistically equivalent inaccuracy.  Further, the\nusual round mode with guard digits is shown to be \nstatistically superior in accuracy to the usual chop\nmode in all cases save one.  The modified round \nmode is found to be superior to the chop mode in all cases.\n error analysis, floating point arithmetic,\nrounding, guard digits, number representation\n", "2526": "Asymmetric Memory Hierarchies  A study is presented of some of the system\nimplications of memory hierarchies in which the \nbacking or secondary store has a very small read time,\nrelative of both the time required for writing \nand to the read time of conventional backing storage\ndevices. Several analytic models are introduced, \nand it is shown that such hierarchies may operate in\nways which differ from those of more conventional \nhierarchies.  In particular, it is shown that it may not\nbe necessary to multiprogram in such a situation. \n In the past, backing storage devices have been roughly\nsymmetric with respect to their read and write \ntimes.  This situation may not continue, as several\ndevices are currently under development which may \nhave a very small read-time/write-time ratio.  This study\nplaces particular emphasis on one such system-the \nRCA read/write holographic optical memory.\n asymmetric memory hierarchy, demand paging, holographic\noptical memory, memory device, memory hierarchy, \npaging, storage device, storage hierarchy, virtual memory\n", "2527": "Implementation of High Level Language Machine Computing machines which directly execute\nthe statements of a high level language have been \nproposed in the past.  This report describes the actual\nimplementation of such a machine: it is a computer \nwhose \"machine language\" is APL.  The machine is fully\noperational and correctly executes almost all \nof the APL operations on scalars, vectors, and arrays.\n The machine automatically allocates memory, executes \nstatements, calls functions, converts numbers from one\ntype to another, checks subscripts, and automatically \ndetects many types of programmer errors.\n computer architecture, high level language machine,\nemulators, microprogramming, interpreters, \nexecution speed, APL\n", "2528": "Binary Pattern Reconstruction from Projections [Z] (Algorithm R445) pattern reconstruction, image reconstruction,\ndata compression, picture processing\n", "2529": "Binary Pattern Reconstruction from Projections [Z] (Algorithm A445) pattern reconstruction, image reconstruction,\ndata compression, picture processing \n", "2530": "An Algorithm for Extracting Phrases in information retrieval, coding, text compression\n", "2531": "Graduate Education: The Ph.D. Glut graduate education, Ph.D. production, accreditation\n", "2532": "On Harrison's Substring Testing Technique string, substring, hashing, information storage and retrieval\n", "2533": "Gray Code and the +- Sign Sequence when Gray code, sign sequences, ordering, positive\nmonotonic functions, binary system, Galois sum\n", "2534": "Design and Implementation of a Diagnostic Compiler for PL/I PL/C is a compiler for a dialect for PL/I.  The\ndesign objective was to provide a maximum degree \nof diagnostic assistance in a batch processing environment.\n For the most part this assistance is implicit \nand is provided automatically by the compiler. The most remarkable\ncharacteristic of PL/C is its perseverance-it \ncompletes translation of every program submitted and\ncontinues execution until a user-established error \nlimit is reached. This requires that the compiler repair\nerrors encountered during both translation \nand execution, and the design of PL/C is dominated by\nthis consideration.  PL/C also introduces several \nexplicit user-controlled facilities for program testing.\n To accommodate these extensions to PL/I without \nabandoning compatibility with IBM compiler PL/C permits\n\"pseudo comments\"-constructions whose contents \ncan optionally be considered either source test or comment.\n In spite of the diagnostic effort PL/C is \na fast and efficient processor.  It effectively demonstrates\nthat compilers can provide better diagnostic \nassistance than is customarily offered, even when a sophisticated\nsource language is employed, and that \nthis assistance need not be prohibitively costly.\n compilers, debugging, PL/I, programming languages\n", "2535": "The Effects of Multiplexing on a Computer-Communications System A study is made of the way in which asynchronous\ntime division multiplexing changes the stochastic \nnature of the arrival process from a user to the computer\nand, consequently, affects the performance \nof a time-shared computer-communications system.  It is\nconcluded that while, for certain values of system \nparameters, there is noticeable improvement in the\nperformance of the computer (model), in the sense \nthat time-shared scheduling delays are reduced, these\nimprovements are offset by the transmission delays \nimposed by multiplexing so that there may be little or\nno change in the computer-communications system \nperformance.  Analytical and simulation results are\nbased on the model of the computer-communications \nsystem being an M/D/1 queue (the multiplexor) in tandem\nwith a single exponential server (the computer). \n Analytical results include a general description of the\noutput process of an M/D/1 queue and the conditions \nunder which this output process is approximately Poisson.\n computer communications, time-sharing, multiplexing,\nscheduling algorithms, operating systems\n", "2536": "Telecommunications Using a Front-End Minicomputer The use of a front-end minicomputer to provide\nvaried remote terminal access to a large scale \ncomputer is considered.  The problems of embedding\ntelecommunications I/O within an operating system \nare discussed, and it is shown how the decentralization\nof intelligence acquired by front-end processing \nvastly simplifies the problem.  A specific implementation is\ndiscussed with emphasis on the main processor-minicomputer \nlink, the hardware-software implementation, the effect\nof the main processor operating system, and an \nassessment of the advantages over a hard wired line controller.\n telecommunications, minicomputer, front-end\nprocessor, remote job entry, remote terminals\n", "2537": "Common Phrases and Minimum-Space Text Storage A method for saving storage space for text\nstrings, such as compiler diagnostic messages, is \ndescribed.  The method relies on hand selection of a\nset of text strings which are common to one or more \nmessages.  These phrases are then stored only once. \nThe storage technique gives rise to a mathematical \noptimization problem: determine how each message should\nuse the available phrases to minimize its storage \nrequirement.  This problem is nontrivial when phrases\nwhich overlap exist.  However, a dynamic programming \nalgorithm is presented which solves the problem in time\nwhich grows linearly with the number of characters \nin the text.  Algorithm 444 applies to this paper.\n diagnostic messages, error messages, common phrases,\nminimum space, text storage, optimization, \ndynamic programming\n", "2538": "A Computer Science Course Program for Small Colleges The ACM Subcommittee on Small College Programs\nof the Committee on Curriculum in Computer Science \n(CCCS) was appointed in 1969 to consider the unique\nproblems of small colleges and universities, and \nto make recommendations regarding computer science programs\nat such schools.  This report, authorized \nby both the subcommittee and (CCCS), supplies a set of\nrecommendations for courses and necessary resources. \n Implementation problems are discussed, specifically\nwithin the constraints of limited faculty and for \nthe purposes of satisfying a wide variety of objectives.\n Detailed description of four courses are given; \nsuggestions are made for more advanced work;\nand an extensive library list is included.\n computer science education, course proposals, small\ncolleges, programming course, social implications \ncourse, computer organization course, file organization course, bibliographies\n", "2539": "Solution of the Transcendental Equation w*exp(w)=x [C5] (Algorithm A443) transcendental function evaluation, solution of transcendental equation\n", "2540": "Properties of the Working Set Model (Corrigendum)", "2541": "An Overview of the ISPL Computer System Design This paper explores the advantages of the concurrent\ndesign of the language, operating system, \nand machine (via microcode) to create an interactive programming\nlaboratory.  It describes the synergistic \neffect that the freedom to move and alter features from\none of these domains to another has had on the \ndesign of this system (which has not been implemented).\n This freedom simplified both incremental compilation \nand the system's addressing structure, and centralized the\ncommunication mechanisms enabling the construction \nof hierarchical subsystems.  It also suggested an important\nnew concept for operating systems: separation \nof the scheduling from the maintenance functions in resource\nallocation. This separation enables incorporation \nof new scheduling algorithms (decision of what to do) without\nendangering the system integration (correctly \nperforming the scheduling decisions).\n concurrent design, operating-system, scheduling,\ninterprogram communication, incremental compilation, \nvirtual addressing, debugging, hierarchical subsystems\n", "2542": "A Software Design and Evaluation System A critical failure of current software system\ndesign and implementation methodology is that \nthe performance of a proposed design is not evaluated\nbefore it is actually implemented.  In this paper \nthe reasons for this failure are explored, and a new methodology\nwhich overcomes many of the difficulties \nis proposed.  A system which integrates performance evaluation\nwith design and implementation is described. \n This system is based on a simple, high level language\nwhich is used to describe the evolving system \nat all stages of its development.  The source language\ndescription is used as direct input to performance \nanalysis and simulation routines.  Using the performance\ninformation obtained from these routines as \nfeedback, the problems which adversely affect performance\nare detected early enough so that they can \nbe corrected without costly major reimplementation of the proposed system.\n operating system development, language processing\nsoftware evaluation, compilers, system programming, \nsupervisory systems, debugging, program maintenance,\nmodeling, system integration, simulation\n", "2543": "Reducing the Retrieval Time of Scatter Storage Techniques A new method for entering and retrieving information\nin a hash table is described.  The method \nis intended to be efficient if most entries are looked\nup several times.  The expected number of probes \nto look up an entry, predicted theoretically and verified\nby Monte Carlo experiments, is considerably \nless than for other comparable methods if the table\nis nearly full.  An example of a possible Fortran \nimplementation is given.\n address calculation, content addressing, file searching,\nhash addressing, hash code, linear probing, \nlinear quotient method, scatter storage, searching, symbol table\n", "2544": "Automatic Error bounds for Simple Zeros of Analytic Functions The Cauchy-Ostrowski theorem on convergence\nof Newton iterates for an analytic function in \none variable is extended to include computational errors\nusing complex interval arithmetic. Several numerical \nexamples are given for polynomials with real and complex\nroots and one example for the Bessel function \nof the first kind.\n real intervals, complex intervals, real interval\narithmetic, complex interval arithmetic, Newton's \nmethod, Cauchy-Ostrowski theorem, zeros of\npolynomials, zeros of Bessel functions\n", "2545": "A Theory of Discrete Patterns and Their Implementation in SNOBOL4 The notion of a discrete pattern is formalized\nand certain properties deduced.  A pattern is \nshown to be a generalization of a formal language. \nAlgorithms for implementing the kinds of patterns \nin SNOBOL4 are given.  The general approach is to create,\nin-so-far as possible, a bottom-up parse from \na top-down specification.\n patterns, SNOBOL4, pattern theory, parsing, pattern matching,\nstring processing, pattern implementation\n", "2546": "The Use of Grammatical Inference for Designing Programming Languages Both in designing a new programming language\nand in extending an existing language, the designer \nis faced with the problem of deriving a \"natural\" grammar\nfor the language.  We are proposing an interactive \napproach to the grammar design problem wherein the designer\npresents a sample of sentences and structures \nas input to a grammatical inference algorithm.  The algorithm\nthen constructs a grammar which is a reasonable \ngeneralization of the examples submitted by the designer.\n The implementation is presently restricted \nto a subclass of operator precedence grammars, but\na second algorithm is outlined which applies to a \nlarger class of context-free grammars.\n grammar design, language definition, inference,\nidentification in the limit, extensible languages\n", "2547": "Representation of Contours ad Regions for Efficient Computer Search A novel computer-searchable representation\nfor the three basic pictorial features, contour \nmaps, region coverage, and line structures, is described.\n The representation, which has practical storage \nrequirements, provides a rapid mean of searching large\nfiles for data associated with geometric position \nas well as with attribute value.  An application of this\nrepresentation to handling terrain information \nillustrates its utility.  The algebraic properties\nof the data structure make it computationally easy \nto determine whether a point lies within a closed boundary;\ncompute the area contained by a closed boundary; \ngenerate the closed boundary representing the union or\nintersection of two closed boundaries; and determine \nthe neighboring boundaries to a point and the\nminimum distances between them and the point.\n contour map representation, region boundary representation,\ncomputer-search-able structure, graphic \ndata retrieval, graphic language, two-dimensional\npatterns, computer graphics, graphic display\n", "2548": "Normal Deviate [S14] (Algorithm A442) normal distribution inverse, probit\ntransform, Taylor series approximation\n", "2549": "Random Deviates from the Dipole Distribution [G5] (Algorithm A441) random number, probability density, probability distribution,\nDipole distribution, Cauchy distribution, \nsimulation, Monte Carlo\n", "2550": "A Multidimensional Monte Carlo Quadrature with Monte Carloquadrature, stratified sampling,\nadaptive quadrature, sequential stratification\n", "2551": "Mutual Recursion in Algol 60 Using Restricted Compilers Algol 60, mutual recursion, compiler restrictions\n", "2552": "A Note on When To Chain Overflow Items Within a Direct-Access Table hash code, open hash, chaining, information retrieval, collision\n", "2553": "The Practical Aspect of Computer Science Education-Discussion education, computer engineering, computer\nscience curriculum, systems design\n", "2554": "Reduction of a Band-Symmetric Generalized Eigenvalue Problem An algorithm is described for reducing the\ngeneralized eigenvalue problem Ax = lambda Bx to \nan ordinary problem, in case A and B are symmetric band\nmatrices with B positive definite.  If n is the \norder of the matrix and m the bandwidth, the matrices\nA and B are partitioned into m-by-m blocks; and \nthe algorithm is described in terms of these blocks.\n The algorithm reduces the generalized problem to \nan ordinary eigenvalue problem for a symmetric band\nmatrix C whose bandwidth is the same as A and B. \n The algorithm is similar to those of Rutishauser and\nSchwartz for the reduction of symmetric matrices \nto band form.  The calculation C requires order mn^2\noperation.  The round-off error in the calculation \nof C is of the same order as the sum of the errors at\neach of the n/m steps of the algorithm, the latter \nerrors being largely determined by the condition of B with respect to inversion.\n generalized eigenvalues, symmetric band matrices\n", "2555": "Variable-Precision Exponentiation A previous paper presented an efficient algorithm,\ncalled the Recomputation Algorithm, for \nevaluating a rational expression to within any desired tolerance\non a computer which performs variable-precision \narithmetic operations.  The Recomputation Algorithm can be\napplied to expressions involving any variable-precision \noperations having O(10^(-p) + SUM{|Ei|}) error bounds,\nwhere p denotes the operation's precision and \nEi denotes the error in the operation's ith argument.\n This paper presents an efficient variable-precision \nexponential operation with an error bound of the above\norder.  Other operations such as log, sin, and \ncos, which have simple series expansions, can be handled similarly.\n variable-precision, exponential function,\nerror analysis, interval arithmetic\n", "2556": "Adaptive Correction of Program Statements A method of analyzing statements in a programming\nlanguage which can tolerate a considerable \ninaccuracy in their specification is proposed. This method\ninvolves principles at present mainly confined \nto studies in the area of artificial intelligence such\nas feature extraction, approximate tree matching, \nand strategy improvement by feedback from the matching process.\n A pilot program incorporating the principles \nis described and preliminary operating results are presented.\n A final section surveys further principles \nwhich are currently being investigated.\n adaptive, linguistic pattern matching, automatic\nparsing, approximate match, compiler, program \nstatement analysis, syntax analysis\n", "2557": "On the Time Required for a Sequence of Matrix Products This paper discusses the multiplication of conformable\nsequences of row vectors, column vectors, \nand square matrices.  The minimum time required to evaluate\nsuch products on ordinary serial computers \nas well as parallel computers is discussed.  Algorithms\nare presented which properly parse such matrix \nsequences subject to the constraints of the machine organization.\n matrix expressions, matrix multiplication, operation\nminimization, parallel machine, time minimization\n", "2558": "Protection in Programming Languages Linguistic mechanisms which can be used to protect\none subprogram from another's malfunctioning \nare described.  Function-producing functions and various\ntype-tagging schemes are considered.  An attempt \nis made to distinguish between access limitation and authentication.\n protection, types, environments,trademarks, seals,\naccess keys, access control authentication, \nsecrecy\n", "2559": "The Reallocation of Hash-Coded Tables When the space allocation for a hash-coded table\nis altered, the table entries must be rescattered \nover the new space.  A technique for accomplishing\nthis rescattering is presented.  The technique is \nindependent of both the length of the table and the hashing\nfunction used, and can be utilized in conjunction \nwith a linear reallocation of the table being rescattered.\n Moreover, it can be used to eliminate previously \nflagged deletions from any hash-coded table, or to change\nfrom one hashing method to another.  The efficiency \nof the technique is discussed and theoretical statistics are given.\n reallocation, dynamic storage, hash code, scatter storage, deletions\n", "2560": "A Queuing Model of a Multiprogrammed The results are presented of an analysis of\na probabilistic model of a multiprogrammed computer \nsystem with a two-level storage system in which there\nis sequential dependency of accesses between the \ndevices.  Expressions are obtained for the long-run probability\nthat both the CPU and each of the storage \ndevices are busy.  Some numerical results are given which\nquantify the gains in CPU utilization obtainable \nby multiprogramming in the presence of this type of storage system.\n multiprogrammed computer system, storage system, hierarchical index sets\n", "2561": "A Heuristic Approach to Inductive Inference in Fact Retrieval Systems Heuristic procedures are presented which have\nbeen developed to perform inferences by generalizing \nfrom available information.  The procedures make use\nof a similarity structure which is imposed on the \ndata base using nonnumerical clustering algorithms.  They\nare implemented in a model fact retrieval system \nwhich uses a formal query language and a property-list data\nstructure.  A program of experiments is described \nwherein the procedures are used with test data bases\nwhich are altered by deleting part of the data and \nby purposely introducing false data.  It is found that\nthe system can infer the correct response under \na variety of conditions involving incomplete and inconsistent data.\n inference, inductive inference, clustering, fact retrieval, heuristics\n", "2562": "Routing Problem (Algorithm R456)", "2563": "Merge Sort Algorithm (R426)", "2564": "Hidden-Line Plotting Program (Algorithm R420)", "2565": "A Gaussian Pseudo-Random Number Generator (Algorithm 488) random numbers, pseudo-random numbers,\nGaussian distribution, normal distribution\n", "2566": "Exact Cumulative Distribution of the Kolmogorov-Smirnov Kolmogorov-Smirnov test, K-S statistic, goodness-of-fit testing\n", "2567": "An Exponential Method for the Solution of An explicit, coupled, single-step method for\nthe numerical solution of initial value problems \nfor systems of ordinary differential equations is presented.\n The method was designed to be general purpose \nin nature but to be especially efficient when dealing\nwith stiff systems of differential equations.  \nIt is, in general, second order except for the case\nof a linear system with constant coefficients and \nlinear forcing terms; in that case, the method is third\norder.  It has been implemented and put to routine \nusage in biological applications-where stiffness frequently\nappears-with favorable results.  When compared \nto a standard fourth order Runge-Kutta implementation,\ncomputation time required by this method has ranged \nfrom comparable for certain nonstiff problems to better\nthan two orders of magnitude faster for some \nhighly stiff systems.\n numerical solution, ordinary differential equations,\ninitial value problems, stiff systems\n", "2568": "A Graph Formulation of a School Scheduling Algorithm The problem classically titled \"The Examination\nSchedule Problem\" takes various forms in the \nliterature.  Most of these formulations can be presented\nin the terminology of classical Network Theory. \n One such formulation is:  Given a nondirected network,\npartition its nodes into a minimal number of \nsubsets such that no two members of the same subset\nare connected by anarc.  An obvious lower limit \nto this number is the size of the largest strongly connected\nsubgraph.  Kirchgassner proved that an upper \nlimit is this size plus one.  One logical extension of\nthe previous work is the introduction of variable \nlength examinations where W(I) is the number of periods\nfor exam I.  The object of this paper is to generalize \nthe definition of largest strongly connected subgraph\nto include the weighting of nodes, to present an \napproximate algorithm which usually finds the largest\nstrongly connected subgraph, and to discuss the \napplication of this algorithm to the solution of\nschool scheduling and exam scheduling problems.\n scheduling, school scheduling, examination scheduling,\nnondirected network, graph, subgraph, strongly \nconnected subgraph\n", "2569": "Computer Generation of Gamma Random Variates When the shape parameter, a, is integral,\ngenerating gamma random variables with a digital \ncomputer is straightforward.  There is no simple method\nfor generating gamma random variates with non-integral \nshape parameters.  A common procedure is to approximately\ngenerate such random variables by use of the \nso-called probability switch method.  Another procedure,\nwhich is exact, is due to Johnk.  This paper \npresents a rejection method for exactly generating\ngamma random variables when a is greater than 1.  \nThe efficiency of the rejection method is shown to\nbe better than the efficiency of Johnk's method.  \nThe paper concludes that when a is non-integral the following\nmix of procedures yields the best combination \nof accuracy and efficiency: (1) when a is less than\n1, use Johnk's method; (2) when 1 is less than a \nand a is less than 5, use the rejection method; (3) when\na is greater than 5, use the probability switch \nmethod.\n simulation, gamma random variables,\nprobability distribution, random numbers\n", "2570": "A Comparison of List Schedules for Parallel Processing Systems The problem of scheduling two or more processors\nto minimize the execution time of a program \nwhich consists of a set of partially ordered tasks\nis studied.  Cases where task execution times are \ndeterministic and others in which execution times are\nrandom variables are analyzed.  It is shown that \ndifferent algorithms suggested in the literature vary significantly\nin execution time and that the B-schedule \nof Coffman and Graham is near-optimal.  A dynamic programming\nsolution for the case in which execution \ntimes are random variables is presented.\n parallel processing, precedence graphs, scheduling,\nlist scheduling, optimization, dynamic programming\n", "2571": "An Analytic Model of the Hasp Execution Task Monitor The HASP Execution Task Monitor periodically\nrearranges the OS/360 dispatching chain to give \ntasks preemptive execution priority in inverse order to\nthat of their cpu utilization history.  The effect \nis to keep the I/O bound tasks active and to prevent\ncpu bound tasks from locking out other tasks.  This \npaper develops a simple model of the Execution Task\nMonitor and employs it to study the effectiveness \nof the monitor in improving system performance.  A\nmodified strategy monitor control is investigated \nfor the case of task execution in a memory hierarchy of varying speeds.\n Hasp, OS/360, dispatching, scheduling, modeling, performance evaluation\n", "2572": "Arguments for a Moratorium on the Construction In this article the author urges a prudent\nand decentralized approach to the question of the \ndesign and desirability of computerized community information\nutilities.  Before accepting the inevitability \nand desirability of this or any technology, we should:\n(1) be sure of the feasibility (internally and \nexternally) of what is proposed; (2) project and perhaps\nwait for changes in complementary techniques; \n(3) evaluate current and projected supplementary techniques;\n(4) establish the existence of demand for \nwhat is proposed; (5) take steps to involve a representative\ngroup of ultimate users in systems design, \nand (6) carefully think through possible side effects\non man and his world view.  Current proposals for \ncommunity information utilities are examined in this\nframework, and the conclusion is drawn that society \nis not yet in a position to justify either the construction\nof an information utility in a prototype \ncommunity or the acceptance of a policy in\nfavor of its widespread implementation.\n community information utilities, social implications, public policy\n", "2573": "Computer Programming as an Art", "2574": "Multiple Exists from a Loop Using Neither GO TO nor Labels goto free programming, control structures,\nmultiple exists from loops, exit statement\n", "2575": "The Best-Match Problem in Document Retrieval document retrieval, best match, clustering, file\nsearching, matching, dissimilarity, hierarchy, \nclassification\n", "2576": "A Simple Technique for Representing Strings in Fortran IV string processing, Fortran IV, string representation,structured\nprogramming, data structures\n", "2577": "An On-Site Data Management System Application in Field Archaeology APL-PLUS, archaeology, Koster prehistoric\nsite data management, retrieval systems\n", "2578": "Self-stabilizing Systems in Spite of Distributed Control multiprocessing, networks, self-stabilization, synchronization,\nmutual exclusion, robustness, sharing, \nerror recovery, distributed control, harmonious cooperation, self-repair\n", "2579": "Register Allocation Via Usage Counts This paper introduces the notion of usage counts,\nshows how usage counts can be developed by \nalgorithms that eliminate redundant computations, and\ndescribes how usage counts can provide the basis \nfor register allocation.  The paper compares register\nallocation based on usage counts to other commonly \nused register allocation techniques, and presents evidence\nwhich shows that the usage count technique \nis significantly better than these other techniques.\n optimization, redundant computations, common subexpressions,\nregister allocation, compilers, programming \nlanguages, virtual memory, demand paging\n", "2580": "A Method for Composing Simple Traditional Music by Computer A method is described for composing musical\nrounds by computer.  This method uses some music \ntheory plus additional heuristics.  Fundamental to the\nmethod is a set of productions together with sets \nof applicability rules and weight rules which operate\non the productions deciding when and to what extent \nthey are available for use.  Several rounds generated\nby the computer implementation of the method are \npresented.  Generally, the resultant music sounds mediocre\nto the professional although usually pleasing \nto the layman.  It appears that full-blown music theory\nis not needed for rounds--all the hardware required \nfor structural levels is not necessary for these pieces.\n The author has tried to address both musicians \nand computer scientists.\n artificial intelligence, heuristic programming,\nmodels of cognitive processes, computer music, \ncomputer composition, music theory, formal languages, probabilistic grammars\n", "2581": "A Locally-Organized Parser for Spoken Input This paper describes LPARS, a locally-organized\nparsing system, designed for use in a continuous \nspeech recognizer.  LPARS processes a string of phonemes\nwhich contains ambiguity and error. The system \nis locally-organized in the sense that it builds local\nparse structures from reliable word candidates \nrecognized anywhere in an input utterance.  These local\nstructures are used as \"islands of reliability\" \nto guide the search for more highly garbled\nwords which might complete the utterance.  \n parsing, speech recognition, speech understanding,\naugmented transition network, local parsing\n", "2582": "Improving Locality by Critical Working Sets A new approach to program locality improvement\nvia restructuring is described.  The method \nis particularly suited to those systems where primary memory\nis managed according to a working set strategy. \n It is based on the concept of critical working set, a\nworking set which does not contain the next memory \nreference.  The data the method operates upon are extracted from\na trace of the program to be restructured. \n It is shown that, except in some special cases, the\nmethod is not optimum.  However, the experimental \nresults obtained by using the method to restructure an\ninteractive text editor and the file system module \nof an operating system have shown its substantial superiority\nover the other methods proposed in the \nliterature.\n program restructuring, program segmentation, locality\nimprovement, memory hierarchies, virtual \nmemory, multiprogramming, restructuring techniques, static\nrestructuring, dynamic restructuring, working \nset strategy, critical working set\n", "2583": "Guidelines for Humanizing Computerized Information humanization, social implication, management, information\nsystems, regulations, social and behavioral \nsciences, philosophy\n", "2584": "Enumerating Full-Time Programmers Data from the 1970 Census and the Department\nof Labor's Area Wage Surveys are used to derive \nestimates of the number of full-time programmers employed\nduring the years 1969 through 1973.  The 1973 \nfigure of 180,000 is considerably less than suggested in\nearlier reports.  It is recommended that educational \nadministrators consider whether the many courses aimed\nat training programmers are justified on a vocational \nbasis.\n programmer, employment, 1970 Census, Area Wage Survey\n", "2585": "Efficient Implementation of a Variable Projection", "2586": "Adapting Optimal Code Generation for Arithmetic", "2587": "On the Construction of a Representative Synthetic Workload (Errata)", "2588": "Rosenbrock Function Minimization (Algorithm R450)", "2589": "A Computer Routine for Quadratic and Linear", "2590": "Hypergeometric (Algorithm C191)", "2591": "Numerical Inversion of Laplace Transform (Algorithm A486) Laplace transform inversion\n", "2592": "On Generation of Test Problems for Linear Programming Codes Users of linear programming computer codes have\nrealized the necessity of evaluating the capacity, \neffectiveness, and accuracy of the solutions provided\nby such codes.  Large scale linear programming \ncodes at most installations are assumed to be generating correct\nsolutions without ever having been \"bench-marked\" \nby test problems with known solutions.  The reason for\nthis failure to adequately test the codes is that \nrarely are there large problems with known solutions readily\navailable.  This paper presents a theoretical \njustification and an illustrative implementation of a method\nfor generating linear programming test problems \nwith known solutions.  The method permits the generation\nof test problems that are of arbitrary size \nand have a wide range of numerical characteristics.\n linear programming, test problem generation,\nLP program evaluation, LP program validation\n", "2593": "A Back-end Computer for Data Base Management It is proposed that the data base management\nfunction be placed on a dedicated back-end computer \nwhich accepts commands (in a relatively high level language\nsuch as the CODASYL Data Base Task Group, \nApril 1971 Report) from a host computer, accesses the\ndata base on secondary storage, and returns results. \n The advantages of such a configuration are discussed.  An\nexperimental implementation, called the experimental \nData Management System, XDMS, is described and certain\nconclusions about the back-end approach are drawn \nfrom this implementation.\n data base management, information retrieval, computer\nconfigurations, computer networks, Data Base \nTask Group Language, data base protection,\ndata base portability, back-end computer\n", "2594": "Structured Data Structures Programming systems which permit arbitrary\nlinked list structures enable the user to create \ncomplicated structures without sufficient protection.\n Deletions can result in unreachable data elements, \nand there is no guarantee that additions will be performed\nproperly.  To remedy this situation, this \npaper proposes a gauge which provides for the creation\nof a restricted class of data structures but ensures \nthe correctness of the program.  This is accomplished\nby an explicit structure declaration facility, \na restriction on the permissible operations, and execution-time checks.\n structured programming, data structures, data base management system\n", "2595": "A Note on the Calculation Working Set Size Finite-length reference string of arbitrary\nstructure are considered, and an exact expression \nfor average working set size in terms of \"corrected\"\ninterreference interval statistics is derived.  \nAn example is discussed; upper and lower bounds are obtained;\nand the average working set size function \nis shown to be efficiently obtained for a set of page\nsizes, in a single pass of the reference string. \n This work follows the developments of a paper by Denning\nand Schwartz, who consider infinite-length \nreference strings which satisfy certain statistical\nproperties and who derive an expression relating \nthe asymptotic average working set size to the asymptotic\nmissing page rate function under working set \nreplacement.\n working-set model, paging, program behavior\n", "2596": "A Weighted Buddy Method for Dynamic Storage Allocation An extension of the buddy method, called the weighted\nbuddy method, for dynamic storage allocation \nis presented.  The weighted buddy method allows block\nsizes of 2^k and 3(2^k), whereas the original buddy \nmethod allowed only block sizes of 2^k. This extension\nis achieved at an additional cost of only two \nbits per block.  Simulation results are presented which\ncompare this method with the buddy method.  These \nresults indicate that for a uniform request distribution,\nthe buddy system has less total memory fragmentation \nthan the weighted buddy algorithm.  However, the total\nfragmentation is smaller for the weighted buddy \nmethod when the requests are for exponentially distributed block sizes.\n weighted buddy algorithm, buddy systems,\nmemory allocation, dynamic storage allocation\n", "2597": "Monitors: An Operating System Structuring Concept This paper develops Brinch-Hansen's concept of\na monitor as a method of structuring an operating \nsystem.  It introduces a form of synchronization, describes\na possible method of implementation in terms \nof semaphores and gives a suitable proof rule.  Illustrative\nexamples include a single resource scheduler, \na bounded buffer, an alarm clock, a buffer pool, a\ndisk head optimizer, and a version of the problem \nof readers and writers.\n monitors, operating systems, scheduling, mutual\nexclusion, synchronization, system implementation \nlanguages, structured multiprogramming\n", "2598": "Extending the Information Theory Approach to Converting This paper modifies an earlier algorithm for\nconverting decision tables into flowcharts which \nminimize subsequent execution time when compiled into\na computer program.  The algorithms considered \nin this paper perform limited search and, accordingly,\ndo not necessarily result in globally optimal \nsolutions.  However, the greater search effort needed\nto obtain a globally optimal solution for complex \ndecision tables is usually not justified by sufficient\nsavings in execution time.  There is an analogy \nbetween the problem of converting decision tables into\nefficient flowcharts and the well-understood problem \nin information theory of noiseless coding.  The results\nof the noiseless coding literature are used to \nexplore the limitations of algorithms used to solve\nthe decision table problem.  The analogy between \nthe two problems is also used to develop improvements\nto the information algorithm in extending the depth \nof search under certain conditions and in proposing\nadditional conditions to be added to the decision \ntable.  Finally, the information algorithm is compared\nwith an algorithm proposed in a recent paper by \nVerhelst.\n coding, decision tables, flowcharting, information\ntheory, noiseless channel, sorting\n", "2599": " First Order Approximation to the Optimum Checkpoint Interval checkpoint, job failure, operations, programming\ncheckpoint, random failure, operations, programming\n", "2600": "Computation of g-Splines via a Factorization approximation, spline approximation\n", "2601": "Evaluation of the Modified Bessel Functions K0(Z) Bessel functions, Hankel functions, modified\nBessel functions, Gauss-Hermite quadrature\n", "2602": "Masked Three-Dimensional Plot Program plotting, three-dimensional plotting\n", "2603": "The Equivalence of Reducing Transition The class of reducing transition languages\nintroduced by Eickel, Paul, Bauer, and Samelson \nwas shown by Morris to be a proper superclass of the\nsimple precedence languages.  In this paper this \nresult is extended, showing that, in fact, the first class\nis equivalent to the class of deterministic \ncontext free languages.\n reducing transition languages, syntax controlled\ngenerators, deterministic context-free grammars\n", "2604": "An Interactive Graphic Display for Region Using linear programming, an interactive graphic\ndisplay system has been implemented to solve \nthe region design problem of partitioning a region into\nN nonoverlapping subregions in such a way that \ntheir areas are in specified proportions and that the\ntotal cost of servicing them is a minimum.  In \na conversational manner, a user can easily obtain different\npartitionings by specifying and modifying \nthe boundary, the service centers' locations, the area\nproportions, and the cost functions.  Examples \nare included.\n interactive graphic display, region partitioning,\narea specification, linear programming\n", "2605": "A Precise Numerical Analysis Program A description is given of a program for computing\nthe solution to a small number of standard \nnumerical analysis problems to any specified accuracy,\nup to a limit of 2000 correct decimal places. \n Each computed number is bounded in an interval with a\nmultiple precision midpoint.  Arithmetic operations \ninvolving these numbers are executed according to interval\narithmetic concepts, with non-significant \ndigits automatically discarded.  Details are supplied\nof problem specification and problem computation.\n interval arithmetic, multiple precision, list structure, error control\n", "2606": "A New Integration Algorithm for Ordinary Differential A new integration algorithm is found, and an\nimplementation is compared with other programmed \nalgorithms.  The new algorithm is a step-by-step procedure\nfor solving the initial value problem in ordinary \ndifferential equations.  It is designed to approximate\npoles of small integer order in the solutions \nof the differential equations by continued fractions obtained\nby manipulating the sums of truncated Taylor \nseries expansions.  The new method is compared with\nGragg-Bulirsh-Stoer, and the Taylor series method. \n The Taylor series method and the new method are shown\nto be superior in speed and accuracy, while the \nnew method is shown to be most superior when the solution\nis required near a singularity.  The new method \ncan finally be seen to pass automatically through singularities\nwhere all the other methods which are \ndiscussed will have failed.\n ordinary differential equations, initial value problem,\nintegration, Taylor series, singularities, \ncontinued fractions, program comparison\n", "2607": "A Problem-List of Issues Concerning Computers and Public Policy economic and sociological effects, the public and computers\n", "2608": "Recurrence Relations for the Fresnel Integral and Similar Integrals recurrence relations, Fresnel integral, exponential integral\n", "2609": "Interpolation with Rounded Ramp Functions A new interpolation function is introduced.\n It has infinitely many continuous derivatives \nand is a composition of ramp functions with smoothed bends\ncalled Rounded Ramp Functions.  How the interpolation \nfunction can be extended to more than one variable is\nshown.  An efficient Fortran program is given by \nwhich the interpolation function can be obtained for a given point set.\n interpolation, approximation, smooth interpolation,\nmulti variable interpolation, interpolation \nfunction, approximation function, spline-like function\n", "2610": "Gauss Harmonic Interpolation Formulas Let R be an open, bounded, simply connected\nregion in the (x,y)-plane and let (x*,y*) be a \npoint in R.  Assuming R is starlike with respect to\n(x*,y*), we discuss a method for computing Gauss \nharmonic interpolation formulas for R and the point (x*,y*).\n Such formulas approximate a harmonic function \nat (x*,y*) in terms of a linear combination of its\nvalues at certain selected points on the boundary \nof R.  Such formulas are useful for approximating\nthe solution of the Dirichlet problem for R.\n interpolation, quadrature, harmonic interpolation,\nharmonic quadrature, Dirichlet problem\n", "2611": "The Complex Method for Constrained Optimization (Algorithm R454)", "2612": "Rosenbrock Function Minimization (Algorithm R450)", "2613": "Transitivity Sets [G7] (Algorithm A482) transitivity, sets\n", "2614": "Arrow to Precedence Network Transformation [H] (Algorithm A481) critical path, networks, precedence networks\n", "2615": "Procedures for computing Smoothing and Interpolating approximation, interpolation, spline, natural spline, spline smoothing\n", "2616": "On the Conversion of Programs to Decision Tables: Method and Objectives The problems of converting programs to decision\ntables are investigated.  Objectives of these \nconversions are mainly program debugging and optimization\nin practice.  Extensions to the theory of computation \nand computability are suggested.\n decision tables, program optimization, debugging,\nsemantics, theory of programming, systems analysis\n", "2617": "A Note on Subexpression Ordering in", "2618": "A New Solution of Dijkstra's Concurrent Programming Problem A simple solution to the mutual exclusion problem\nis presented which allows the system to continue \nto operate despite the failure of any individual component.\n critical section, concurrent programming, multiprocessing, semaphores\n", "2619": "Graph Coloring Conditions for the Existence A necessary and sufficient condition is presented\nfor the existence of a solution to the Gotlieb \nclass-teacher timetable problem.  Several relationships\nare established between the class-teacher timetable \nproblem and graphs with preconditions.  These preconditions\nplace additional restrictions on the coloration \nof a graph.  The preconditions correspond to the unavailability\nconstraints and preassigned meetings \nin the class-teacher timetable problem.  Using some recent\nresults that convert graphs with preconditions \nto graphs without them, it is shown that the existence\nof a coloration of a graph is the required necessary \nand sufficient condition.\n graphs, coloration, preassignment, prevention\nof assignment, class-teacher timetables\n", "2620": "Execution Time Requirements for Encipherment Programs Although encipherment has often been discussed\nas a means to protect computer data, its costs \nare not well established.  Five experiments were conducted\nto measure the cpu time on a CDC 6400 required \nby additive ciphers programmed both in assembly language\nand in Fortran: a \"null transformation\" to measure \nthe time to move data without encipherment; encipherment\nwith one-word key; encipherment with a 125-word \nkey; double key encipherment; and encipherment using\na pseudo random key.  The results were analyzed \nfor consistency over 100 runs, and the effects of constant\nand intermittent errors were considered.  \nTiming rates for assembly language encipherment ranged\nfrom 498,800 characters per second for a pseudo \nrandom key cipher to 2,092,000 characters per second\nfor a constant one-word key cipher.  The latter \nis almost equivalent to the rate required simply to move\ndata without encipherment.  Fortran tests required \nover four times as much cpu time.  This paper introduces\nthe idea on enciphering time coefficient the \nratio of enciphering time to the time taken to\nfetch and store data without encipherment.\n encipherment, ciphers, security, privacy transformations,\nprotection, cryptography, cryptology\n", "2621": "A High Security Log-in Procedure The protection of time sharing systems from\nunauthorized users is often achieved by the use \nof passwords.  By using one-way ciphers to code the passwords,\nthe risks involved with storing the passwords \nin the computer can be avoided.  We discuss the selection\nof a suitable one-way cipher and suggest that \nfor this purpose polynomials over a prime modulus are\nsuperior to one-way ciphers derived from Sannon \ncodes.\n operating systems, time sharing systems, security, cryptography\n", "2622": "A User Authentication Scheme Not Requiring Secrecy in the Computer In many computer operating systems a user authenticates\nhimself by entering a secret password \nknown solely to himself and the system.  The system compares\nthis password with one recorded in a Password \nTable which is available to only the authentication\nprogram.  The integrity of the system depends on \nkeeping the table secret.  In this paper a password\nscheme is presented which does not require secrecy \nin the computer.    All aspects of the system, including\nall relevant code and data bases, may be known \nby anyone attempting to intrude.  The scheme is based\non using a function H which the would-be intruder \nis unable to invert.  This function is applied to the\nuser's password and the result compared to a table \nentry, a match being interpreted as authentication of\nthe user.  The intruder may know all about H and \nhave access to the table, but he can penetrate the system\nonly if he can invert H to determine an input \nthat produces a given output.  This paper discusses\nissues surrounding selection of a suitable H.  Two \ndifferent plausible arguments are given that penetration\nwould be exceedingly difficult, and it is then \nargued that more rigorous results are unlikely.  Finally,\nsome human engineering problems relating to \nthe scheme are discussed.\n operating system security, security, authentication,\npasswords, one-way encryption, cryptology\n", "2623": "A New Technique for Compression and Storage of Data The widespread tendency toward storage of\nlarge programs and blocks off text has produced a \nneed for efficient methods of compressing and storing\ndata.  This paper describes techniques that can, \nin most cases, decrease storage size by a factor of\nfrom two to four.  The techniques involve special \nhandling of leading and trailing blanks, and the encoding\nof other symbols in groups of fixed size as \nunique fixed point numbers.  The efficiency of the\nsystem is considered and pertinent statistics are \ngiven and compared with statistics for other information coding techniques.\n file maintenance, information retrieval, utility\nprograms, text compression, coding techniques, \ndata storage, data management\n", "2624": "Formal Requirements for Virtualizable Third Generation Architectures Virtual machine systems have been implemented\non a limited number of third generation computer \nsystems, e.g. CP-67 on the IBM 360/67.  From previous\nempirical studies, it is known that certain third \ngeneration computer systems, e.g. the DEC PDP-10, cannot\nsupport a virtual machine system.  In this paper, \nmodel of a third-generation-like computer system is\ndeveloped.  Formal techniques are used to derive \nprecise sufficient conditions to test whether such\nan architecture can support virtual machines.\n operating system, third generation architecture,\nsensitive instruction, formal requirements, abstract \nmodel, proof, virtual machine, virtual memory,\nhypervisor, virtual machine monitor\n", "2625": "Capability-Based Addressing Various addressing schemes making use of segment\ntables are examined.  The inadequacies of \nthese schemes when dealing with shared addresses are\nexplained. These inadequacies are traced to the \nlack of an efficient absolute address for objects in\nthese systems.  The direct use of a capability as \nan address is shown to overcome these difficulties\nbecause it provides the needed absolute address.  \nImplementation of capability-based addressing is discussed.\n It is predicted that the use of tags to \nidentify capabilities will dominate.  A hardware address\ntranslation scheme which never requires the \nmodification of the representation of capabilities is\nsuggested. The scheme uses a main memory hash table \nfor obtaining a segment's location in main memory given\nits unique code.  The hash table is avoided for\nrecently accessed segments by means of a set of associative\nregisters.  A computer using capability-based \naddressing may be substantially superior to present\nsystems on the basis of protection, simplicity of \nprogramming conventions, and efficient implementation.\n addressing, capabilities, addressing hardware,\nprotection, protection hardware, shared addresses, \ninformation sharing, operating systems, computer\nutility, segmentation, tagged architecture\n", "2626": "Protection and the Control of Information Sharing in Multics The design of mechanisms to control the sharing\nof information in the Multics system is described. \n Five design principles help provide insight into the\ntradeoffs among different possible designs.  The \nkey mechanisms described include access control lists,\nhierarchical control of access specifications, \nidentification and authentication of users, and primary\nmemory protection.  The paper ends with a discussion \nof several known weaknesses in the current protection mechanism design.\n Multics, protection, security, privacy, access control,\nauthentication, computer utilities, time-sharing \nsystems, proprietary programs, protected subsystems, virtual memory, descriptors\n", "2627": "Scheduling Independent Tasks to Reduce Mean Finishing Time Sequencing to minimize mean finishing time\n(or mean time in system) is not only desirable to \nthe user, but it also tends to minimize at each point\nin time the storage required to hold incomplete \ntasks.  In this paper a deterministic model of independent\ntasks is introduced and new results are derived \nwhich extend and generalize the algorithms known for\nminimizing mean finishing time.  In addition to \npresenting and analyzing new algorithms it is shown\nthat the most general mean-finishing-time problem \nfor independent tasks is polynomial complete, and hence unlikely\nto admit of a non-enumerative solution\n minimizing mean finishing time, minimizing mean flow\ntime, sequencing algorithms, optimal scheduling \nalgorithms, deterministic scheduling models\n", "2628": "Minimal-Total-Processing Time Drum and Disk Scheduling Disciplines This article investigates the application of\nminimal-total-processing-time (MTPT) scheduling \ndisciplines to rotating storage units when random arrival\nof requests is allowed.  Fixed-head drum and \nmoving-head drum and moving-head disk storage units are\nconsidered, and emphasis is placed on the relative \nmerits of the MTPT scheduling discipline with respect\nto the shortest-latency-time-first (SLTF) scheduling \ndiscipline.  The results of the simulation studies\npresented show that neither scheduling discipline \nis unconditionally superior to the other.  For most\nfixed-head drum applications, the SLTF discipline \nis preferable to MTPT, but for intra-cylinder disk scheduling\nthe MTPT discipline offers a distinct advantage \nover the SLTF discipline.  The computational requirements\nof an algorithm that implements the MTPT scheduling \ndiscipline are shown to be comparable to SLTF algorithms.\nIn both cases, the sorting procedure is the \nmost time-consuming phase of the algorithm.\n drum scheduling, disk scheduling, shortest-latency-time-first\n(SLTF), minimal-total-processing-time \n(MTPT), rotating storage units\n", "2629": "The UNIX Time-Sharing system  UNIX is a general-purpose, multi-user, interactive\noperating system for the Digital Equipment \nCorporation PDP-11/40 and 11/45 computers.  It offers\na number of features seldom found even in larger \noperating systems, including: (1) a hierarchical file system\nincorporating demountable volumes; (2) compatible \nfile, device, and inter-process I/O; (3) the ability to\ninitiate asynchronous processes; (4) system command \nlanguage selectable on a per-user basis; and (5) over\n100 subsystems including a dozen languages.This \npaper discusses the nature and implementation of the\nfile system and of the user command interface.\n time-sharing, operating system, file system, command language, PDP-11\n", "2630": "On Computing Sets of Shortest Paths in a Graph Two algorithms are presented that construct\nthe k shortest paths between every pair of vertices \nin a directed graph.  These algorithms generalize the Floyd\nalgorithm and the Dantzig algorithm for finding \nthe shortest path between every pair of vertices in a directed graph.\n graph, network, shortest path, algorithm\n", "2631": "An Information-Theoretic Approach to Using direct access computer files of bibliographic\ninformation, an attempt is made to overcome \none of the problems often associated with information\nretrieval, namely, the maintenance and use of large \ndictionaries, the greater part of which is used only\ninfrequently.  A novel method is presented, which \nmaps the hyperbolic frequency distribution.  This is\nmore suited to implementation on storage devices. \n This method treats text as a string of characters rather\nthan words bounded by spaces, and chooses subsets \nof strings such that their frequencies of occurrence are\nmore even than those of word types.  The members \nof this subset are then used as index keys for retrieval.\nThe rectangular distribution of key frequencies \nresults in a much simplified file organization\nand promises considerable cost advantages.\n text searching, information theory, file organization,\ndirect access, information retrieval, character \nstring, bit vector\n", "2632": "HYDRA: The Kernel of a Multiprocessor Operating System This paper describes the design philosophy of\nHYDRA-the kernel of an operating system for C.mmp, \nthe Carnegie-Mellon Multi-Mini-Processor.  This philosophy\nis realized through the introduction of a \ngeneralized notion of \"resource\", both physical and virtual,\ncalled an \"object\".  Mechanisms are presented \nfor dealing with objects, including the creation of new\ntypes, specification of new operations applicable \nto a given type, sharing, and protection of any reference\nto a given object against improper application \nof any of the operations defined with respect to that\ntype of object.  The mechanisms provide a coherent \nbasis for extension of the system in two directions: the\nintroduction of new facilities, and the creation \nof highly secure systems. \n operating system, kernel, nucleus, protection, security\n", "2633": "Compact Representation of Contour Plots for Phone Line Transmission Methods for the compact representation of contour\nplots are described and tested.  These are \nintended to reduce the cost of transmitting contour plots\nover phone lines.  We feel some of these methods \ncould be used to transmit contour plots over voice grade phone lines.\n contour plotting, data transmission, remote terminal, data compaction\n", "2634": "An Evaluation of Statistical Software in the Social Sciences  Several hundred college and university computer\ninstallations now offer various types of statistical \npackages for general use.  Among those most widely available\nare OSIRIS, SPSS, BMD, DATA-TEXT, and TSAR. \n In order to provide users with a basis for selection\nand use, tests were made for each of these systems, \nand the results are summarized as to cost and performance.\n statistical computation, statistical software,\ndescriptive statistics, bivariate tables, Pearson \ncorrelation, regression, factor analysis, one-way analysis of variance\n", "2635": "Exact Probabilities for R X C Contingency Tables (Algorithm R434)", "2636": "Generation of Random Correlated Normal Variables (Algorithm R425)", "2637": "Hidden-Line Plotting Program (Algorithm R420)", "2638": "Hidden-Line Plotting Program (Algorithm R420)", "2639": "Calculation of Fourier Integrals (Algorithm R418)", "2640": "Modified Havie Integration (Algorithm R400)", "2641": "A Minimal Spanning Tree clustering Method [Z] (Algorithm A479) clustering, pattern recognition, feature\nselection, minimal spanning trees\n", "2642": "Solution of an Overdetermined System of Equations L1 approximation, L1 norm, overdetermined system\nof equations, linear programming, simplex method \n", "2643": "The Minimization of Spatially-Multiplexed Character Sets The paper describes a technique for compacting\ncharacter sets in a digital computer while retaining \nfast access to individual bits.  It considers the problem\nof minimizing the storage needed to contain \nsuch tables.  Reduction techniques are developed, and\nthe problem is shown to reduce to a covering problem.\n parsing, lexical analysis,scanning,\nstring processing, spatial multiplexing\n", "2644": "A Theorem-Proving Language for Experimentation Because of the large number of strategies\nand inference rules presently under consideration \nin automated theorem proving, there is a need for developing\na language especially oriented toward automated \ntheorem proving.  This paper discusses some of the features\nand instructions of this language.  The use \nof this language permits easy extension of automated\ntheorem-proving programs to include new strategies \nand/or new inference rules.  Such extend ability will\npermit general experimentation with the various \nalternative systems.\n theorem proving, resolution, factoring,\nparamodulation, programming languages\n", "2645": "Two Languages for Estimating Program Efficiency Two languages enabling their users to estimate\nthe efficiency of computer programs are presented. \n The program whose efficiency one wishes to estimate is written\nin the first language, a go-to-less programming \nlanguage which includes most of the features of Algol\n60.  The second language consists of interactive \ncommands enabling its users to provide additional information\nabout the program written in the first \nlanguage and to output results estimating its efficiency.\n Processors for the two languages are also \ndescribed.  The first processor is a syntax-directed\ntranslator which compiles a program into a symbolic \nformula representing the execution time for that program.\n The sound processor is a set of procedures \nfor that program.  The second processor is a set of\nprocedures for algebraic manipulation which can be \ncalled by the user to operate on the formula produced\nby the first processor.  Examples of the usage \nof the two languages are included.  The limitations of\nthe present system, its relation to Knuth's work \non the analysis of algorithms, and some of the directions\nfor further research are also discussed.\n programming languages, syntax-directed translation,\nsymbolic manipulation, program efficiency, \nanalysis of algorithms\n", "2646": "A Model for Masking Rotational Latency by Dynamic Disk Allocation This paper presents the background and algorithms\nfor masking the rotational latency of a disk \nor drum.  It discusses the anticipatory input and output\nof blocks of data to buffer and primary memories \nfor a mono-programmed computer system.  A basic permutation\nalgorithm and several variations are given. \n  Because of the anticipatory nature of the I/O scheduling,\nthese algorithms are restricted to classes \nof programs with predictable behavior.  While the methods\nare not restricted to numerical computations, \nmatrix and partial differential equation methods are\ntypical examples of their use.  It is shown that \nlatency may be masked using a small amount of buffer\nmemory.  The methods discussed are independent of \nthe overall size of the data base being considered.\n buffer memory, memory hierarchy, permutation algorithm,\nrotational latency, staging, storage allocation\n", "2647": "More on Algorithms that Reveal Properties floating-point arithmetic, high-level\nlanguages, philosophy of language design\n", "2648": "A Design for a Number Theory Package A number theory package is described which uses\ndoubly linked list structures for storing multiprecise \nintegers.  The package has been coded in IBM's Basic\nAssembly Language and makes heavy use of the macro \nlanguage and conditional assembly.  An optimally coded\ntrial division routine is also described which \ncan be used to determine the unique factorization of large integers.\n number theory package, trial division, multiprecise\narithmetic, factorization, doubly linked lists, \npseudoprime\n", "2649": "On the Distributions of Significant Digits and Roundoff Errors Generalized logarithmic law is derived for\nthe distribution of the first t significant digits \nof a random digital integer.  This result is then used\nto determine the distribution of the roundoff \nerrors in floating-point operations, which is a mixture\nof uniform and reciprocal distributions.\n significant digits, floating-point operations,\nroundoff errors, uniform distribution, reciprocal \ndistribution, variance, mean valve\n", "2650": "Order-n Correction for Regular Languages A method is presented for calculating a string\nB, belonging to a given regular language L, \nwhich is \"nearest\" (in number of edit operations) to a\ngiven input string a.  B is viewed as a reasonable \n\"correction\" for the possibly erroneous string a, where\na was originally intended to be a string of L. \n The calculation of B by the method presented requires\ntime proportional to |a|, the number of characters \nin a.  The method should find applications in information\nretrieval, artificial intelligence, and spelling \ncorrection systems.\n error correction, regular languages, regular events,\nfinite state automata, compiler error recovery, \nspelling correction, string best match problem, correction,\ncorrector, errors, nondeterministic finite-state \nautomata\n", "2651": "The Treatment of Data Types in EL1 In constructing a general purpose programming\nlanguage, a key issue is providing a sufficient \nset of data types and associated operations in a manner\nthat permits both natural problem-oriented notation \nand efficient implementation.  The EL1 language contains\na number of features specifically designed to \nsimultaneously satisfy both requirements.  The resulting\ntreatment of data types includes provision for \nprogrammer-defined data types data types and generic\nroutines, programmer control over type conversion, \nand very flexible data type behavior, in a context that\nallows efficient compiled code and compact data \nrepresentation.\n data types, modes, mode unions, type conversion,\ncoercion, generic functions, extensible languages, \ndata type definition, data description language, compilation\n", "2652": "Reduction of Compilation Costs Through Language Contraction Programming languages tailored to particular\ngroups of users can often be constructed by removing\nunwanted features from a general purpose language.  This\npaper describes the use of simulation techniques \nto predict the savings in compilation cost achievable\nby such an approach.  The results suggest a function \nwhich describes the effect of changes in the power of\na language on the compilation cost of an algorithm \nexpressed in that language: when features not actually\nused by the algorithm are removed from the language, \nthe cost of compiling the algorithm decreases moderately,\nbut when features that are needed are removed, \nthe compilation cost increases sharply.\n design of programming languages, language contraction,\ncompiler design, compilation cost, Algol\n", "2653": "Solution of the Transcendental Equation w*exp(x)=x (Algorithm R443)", "2654": "Generator of Set-Partitions to Exactly R Subsets [G7] (Algorithm A477) partitions, subset generation, permutations\n", "2655": "Six Subprograms for Curve Fitting Using interpolation, splines, contouring, curve fitting\n", "2656": "Scalar- and Planar- Valued Curve Fitting Using Splines Under Tension The spline under tension was introduced by\nSchweikert in an attempt to imitate cubic splines \nbut avoid the spurious critical points they induce. \nThe defining equations are presented here, together \nwith an efficient method for determining the necessary\nparameters and computing the resultant spline. \n The standard scalar-valued curve fitting problem is discussed,\nas well as the fitting of open and closed \ncurves in the plane.  The use of these curves and the\nimportance of the tension in the fitting of contour \nlines are mentioned as application.\n interpolation, splines, contouring, curve fitting\n", "2657": "An Improved Program-Synthesizing Algorithm and Its Correctness An improved program-synthesizing algorithm\nbased on the algorithm proposed by Waldinger and \nLee in 1969 is given.  In the old algorithm, the program-synthesizing\nproblem is translated into a theorem-proving \nproblem, and a program is obtained by analyzing a proof.\n For the improved algorithm, the analysis is \nnot necessary, and a program is obtained as soon as\nthe proof is completed.  This is achieved by using \na modified variable tracing mechanism invented by Green\nin 1969.  The correctness of the improved algorithm \nis also proved; i.e. the program thus obtained\nalways satisfies the specification.\n program-synthesizing algorithms, theorem proving,\nconsequence finding, primitive resolutions\n", "2658": "An Alternative Approach to Mutual Recursion Algol 60, mutual recursion, compiler restrictions\n", "2659": "Some Remarks on Lookup of Structured Variables PL/1, symbol table, structured variables,\nqualified references, compilers \n", "2660": "Addendum to M. L. Patrick Paper parallelism, polynomial root finding, real zeros\n", "2661": "Ideal Teaching Machines-A Solution to the Pedagogic Language Problem education, programming languages, simulators\n", "2662": "Graduate Education: The Ph.D. Glut: Response and Rebuttal graduate education, Ph.D. production, accreditation\n", "2663": "A Study of Computer Use in a Graduate School of Business education, management, business schools\n", "2664": "Parallelism in Tape-Sorting Two methods for employing parallelism in tape-sorting\nare presented.  Method A is the natural \nway to use parallelism. Method B is new.  Both approximately\nachieve the goal of reducing the processing \ntime by a divisor which is the number of processors.\n tape sorting, parallelism, external sorting, queues, stacks\n", "2665": "Copying List Structures Using Bounded Workspace Two new algorithms are presented for list structure\ncopying using bounded workspace.  The first, \nof primarily theoretical interest, shows that without\ncell tag bits the task can be performed in time \nn^2.  The second algorithm, assuming one tag bit in\neach cell, delivers attractive practical speed.  \nAny noncyclic structure is copied in linear speed, while\ncyclic structures are copied in average time \nless than nlogn.  No foreknowledge of cycle absence\nis necessary to achieve linear speed.  A variation \nof the second algorithm solves an open problem concerning\nlist structure marking.  That result demonstrates \nthat marking can be done in average time nlogn without\nthe aid of supplemental tag bits or stacks.\n list processing, copying, marking, space complexity\n", "2666": "On Lions' Counter Example for Gotlieb's Method The timetable problem is an essentially discrete\nproblem. Although the discrete problem may \nhave no feasible solution, there may exist a solution\nto the equivalent continuous problem.  An example \nis given, for which the nondiscrete solution can be\ninterpreted as a set of timetables, differing from \nweek to week, which together satisfy the long-term\nrequirements of the timetable problem.\n combinatorial, multi-index problem, necessary\nconditions, schedule, school timetable, timetable\n", "2667": "Execution Characteristics of Programs in a Page-on-Demand System Data are presented which show the execution characteristics\nof two types of commonly used programs \nin a large-scale, time-shared computer system.  A software\nmonitoring facility built into the supervisor \nwas used for data collection during normal system operation.\n These data were analyzed, and results of \nthis analysis are presented for a Fortran compiler\nand an interactive line file editor.  Probability \ndistribution functions and other data are given for\nsuch things as CPU intervals, I/O intervals, and \nthe number of such intervals during execution.  Empirical\ndistributions are compared with simple theoretical \ndistributions (exponential, hyperexponential, and geometric).\n Other data show paging characteristics \nof tasks as a function of the number of pages those tasks have in core.\n program behavior, virtual memory, paging, demand paging,\nsoftware monitor, program execution characteristics, \ncompiler execution behavior, editor execution behavior\n", "2668": "Computation of Page Fault Probability from Program Transition Diagram An algorithm is given for calculating page fault\nprobability in a virtual memory system operating \nunder demand paging with various memory sizes and replacement\nrules.  A first order Markov model of program \nbehavior is assumed, and a representation of the system\nbased on memory states, control states, and memory \nsubstates is presented.  The algorithm is general in\nthe sense that the page fault probabilities can \nbe calculated for nonpredictive replacement rules applied\nto any program represented by a one-step Markov \nchain.  A detailed example is given to illustrate the\nalgorithm for Random and Least Recently Used (LRU) \nreplacement rules.\n virtual memory, demand paging, replacement rule,\nprogram model, program behavior, Markov model, \npage fault, page fault probability\n", "2669": "A Simple Linear Model of Demand Paging Performance Predicting the performance of a proposed automatically\nmanaged multilevel memory system requires \na model of the patterns by which programs refer to the\ninformation stored in the memory.  Some recent \nexperimental measurements on the Multics virtual memory\nsuggest that, for rough approximations, a remarkably \nsimple program reference model will suffice.  The simple\nmodel combines the effect of the information \nreference pattern with the effect of the automatic management\nalgorithm to produce a single, composite \nstatement: the mean number of memory references between\npaging exceptions increases linearly with the \nsize of the paging memory.  The resulting model is easy\nto manipulate, and is applicable to such diverse \nproblems as choosing an optimum size for a paging memory,\narranging for reproducible memory usage charges, \nand estimating the amount of core memory sharing.\n paging, demand paging, memory models, program models,\nperformance measurement, multilevel memory \nsystems, virtual memory, associative memory, memory usage accounting, Multics\n", "2670": "Efficient Implementation of a Variable Projection Nonlinear least squares frequently arise for which\nthe variables to be solved for can be separated \ninto a linear and a nonlinear part.  A variable projection\nalgorithm has been developed recently which \nis designed to take advantage of the structure of a problem\nwhose variables separate in this way.  This \npaper gives a slightly more efficient and slightly more\ngeneral version of this algorithm than has appeared \nearlier.\n nonlinear least squares, parameter estimation, variable projection\n", "2671": "A Note on a Combinatorial Problem of Burnett and Coffman memories, interleaving, derangements, rencontres, combinatorial analysis\n", "2672": "Emotional Content Considered Dangerous artificial intelligence, heuristic programming, models\nof cognitive processes, computer music, computer \ncomposition, music theory\n", "2673": "Quadratic Search for Hash Tables of Size p^n hashing, quadratic search\n", "2674": "Scan Conversion Algorithms for a Cell Organized Raster Display Raster scan computer graphics with \"real time\"\ncharacter generators have previously been limited \nto alphanumeric characters.  A display has been described\nwhich extends the capabilities of this organization \nto include general graphics.  Two fundamentally different\nscan conversion algorithms which have been \ndeveloped to support this display are presented.  One\nis most suitable to non-interactive applications \nand the other to interactive applications.  The algorithms\nwere implemented in Fortran on the CDC 6400 \ncomputer.  Results obtained from the implementations show\nthat the noninteractive algorithms can significantly \nreduce display file storage requirements at little cost\nin execution time over that of a conventional \nraster display.  The interactive algorithm can improve\nresponse time and reduce storage requirements.\n graphics, scan conversion, raster display, line\ndrawing, discrete image, dot generation, matrix\ndisplays\n", "2675": "A Computer Routine for Quadratic and Linear", "2676": "Zeros of a Complex Polynomial (Algorithm R419)", "2677": "Incomplete Beta Ratio (Algorithm R179)", "2678": "Visible Surface Plotting Program [J6] (Algorithm A475) hidden line problem, computer graphics, contour surface\n", "2679": "Some Performance Tests of \"quicksort\" and Descendants Detailed performance evaluations are presented\nfor six ACM algorithms: quicksort (No. 64), \nShellsort (No. 201), stringsort (No. 207), \"TREESORT3\"\n(No. 245), quickersort (No. 271), and qsort (No. \n402).  Algorithms 271 and 402 are refinements of algorithm\n64, and all three are discussed in some detail. \n The evidence given here demonstrates that qsort (No.\n402) requires many more comparisons than its author \nclaims.  Of all these algorithms, quickersort requires\nthe fewest comparisons to sort random arrays.\n sorting, in-place sorting, sorting efficiency,\nsorting performance tests, quicksort, quickersort, \nqsort, Shellsort, stringsort, TREESORT3,utility sort\nalgorithm, general-purpose sort algorithm, sorting \nalgorithm documentation\n", "2680": "Optimal Space Allocation on Disk Storage Devices When the amount of space required for file storage\nexceeds the amount which can be kept on-line, \ndecisions must be made as to which files are to be permanently\nresident and which mountable.  These decisions \nwill affect the number of mount requests issued to the\noperators.  This is often a bottleneck in a computing \nfacility, and reducing the number of mounts thus decreases\nturnaround time.  An optimization model for \nthe assignment of files to disk packs, and packs to either\nresident or nonresident status is presented. \n Heuristics are suggested for those cases in which\nit is inefficient to compute the actual optimum.\n disk analysis, disk optimization, disk files,file\nsystems, file scheduling, space allocation, \nmemory hierarchy\n", "2681": "Dynamic Memory Repacking A probabilistic model of a multiprogramming system\nis exercised in order to determine the conditions \nunder which the dynamic repacking of main memory is beneficial.\n An expression is derived for the maximum \ninterference that a repacking process may introduce\nbefore the original performance of the system is \ndegraded.  Alternative approaches to repacking are discussed,\nand the operating conditions that lead \nto improved system throughput through repacking are delineated.\n dynamic memory repacking, memory compaction,storage\nfragmentation, multiprogramming system model, \nprobabilistic model, central processor productivity,\nresource utilization, system throughput\n", "2682": "On the Construction of a Representative Synthetic Workload A general method of constructing a drive workload\nrepresentative of a real workload is described. \nThe real workload is characterized by its demands on the\nvarious system resources.  These characteristics \nof the real workload are obtained from the system accounting\ndata. The characteristics of the drive workload \nare determined by matching the joint probability density\nof the real workload with that of the drive \nworkload.  The drive workload is realized by using a\nsynthetic program in which the characteristics can \nbe varied by varying the appropriate parameters. Calibration\nexperiments are conducted to determine expressions \nrelating the synthetic program parameters with the workload\ncharacteristics.  The general method is applied \nto the case of two variables, cpu seconds and number\nof I/O activities; and synthetic workload with 88 \njobs is constructed to represent a month's\nworkload consisting of about 6000 jobs.\n benchmarks, calibration, drive workload, input to\nsimulation, probability distribution, representative \nworkload, synthetic workload, workload characteristics\n", "2683": "The Synthesis of Loop Predicates Current methods for mechanical program verification\nrequire a complete predicate specification \non each loop.  Because this is tedious and error prone,\nproducing a program with complete, correct predicates \nis reasonably difficult and would be facilitated by machine\nassistance.  This paper discusses techniques \nfor mechanically synthesizing loop predicates.  Two classes\nof techniques are considered: (1) heuristic \nmethods which derive loop predicates from boundary conditions\nand/or partially specified inductive assertions: \n(2) extraction methods which use input predicates and\nappropriate weak interpretations to obtain certain \nclasses of loop predicates by an evaluation on the weak interpretation.\n program verification, loop predicates, inductive\nassertions, synthesis of loop predicates, weak \ninterpretations, well-founded sets, property extraction, theorem proving\n", "2684": "Production Systems: or Can We Do Better than BNF? Since the development of BNF, the definition\nof the syntax of programming languages has been \nalmost universally associated with context-free requirements.\n Yet numerous interesting and difficult \nissues in syntax stem from the context-sensitive requirements,\nnotably the compatibility between the \ndeclaration of an identifier and its uses, the correspondence\nbetween actual and formal parameters, and \nissues arising from block structure.  This paper explores\nthe use of a formal notation called Production \nSystems in providing a readable and complete formal definition\nof syntax.  As a practical illustration, \na small but significant subset of PL/I is considered.  A\nmore detailed presentation, as well as the application \nto define abstract syntax and translations between languages,\nis given in a previous paper by the author.\n syntax, translation, context-sensitive grammars,\ncompilers, formal definition, PL/I standards\n", "2685": "The Parallel Execution of DO Loops Methods are developed for the parallel execution\nof different iterations of a DO loop.  Both \nasynchronous multiprocessor computers and array computers\nare considered.  Practical application to the \ndesign of compilers for such computers is discussed.\n parallel computing, multiprocessor computers,\narray computers, vector computers, loops\n", "2686": "An Approximate Method for Generating Asymmetric Random Variables Tukey's lambda distribution is generalized\nto provide an algorithm for generating values of \nunimodal asymmetric random variables.  This algorithm\nhas the same advantages as the symmetric random \nvariable generator previously given by the authors, except\nthat the addition of another parameter complicates\nthe problem of finding the parameter values to fit a distribution.\n simulation, Monte Carlo, probability, statistics,\napproximations, random variables, random numbers, \nmoments, distribution\n", "2687": "A Cell Organized Raster Display for Line Drawings Raster scan computer graphics displays with\n\"real time\" character generators have previously \nbeen limited to alphanumeric characters.  A display is\ndescribed which extends the capabilities of this \norganization to include general graphics.  The feasibility\nof such a display is shown by deriving the \nminimum number of patterns required in the read only\nmemory of the character generator to synthesize \nan arbitrary line.  The synthesis process does not compromise\npicture quality since the resulting dot \npatterns are identical with those of a conventional\nraster display.  Furthermore, the time constraints \nof a raster display are shown to be satisfied for\na typical design for very complex line drawings.\n graphics, raster display, line drawing, discrete\nimage, dot generation, matrix displays\n", "2688": "Attribute Based File Organization in a Paged Memory Environment The high cost of page accessing implies a need\nfor more careful data organization in a paged \nmemory than is typical of most inverted file and similar\napproaches to multi-key retrieval.  This article \nanalyses that cost and proposes a method called multiple\nkey hashing which attempts to minimize it.  \nSince this approach is not always preferable to inversion,\na combined method is described.  The exact \nspecifications of this combination for a file with given\ndata and traffic characteristics is formulated \nas a mathematical program.  The proposed heuristic solution\nto this program can often improve on a simple \ninversion technique by a factor of 2 or 3.\n file organization, paging, retrieval algorithm,\ninverted file, multiple key hashing\n", "2689": "A CRT Report Generating System report generation, automated systems design, data processing, management\n", "2690": "A Numbering Systems for Combinations combinatorics, coding system, storage mapping function\n", "2691": "Comments on the Algorithms of Verhelst for the decision table, flowcharting, preprocessor, optimal programs, search \n", "2692": "Reentrant Polygon Clipping A new family of clipping algorithms is described.\n These algorithms are able to clip polygons \nagainst irregular convex plane-faced volumes in three\ndimensions, removing the parts of the polygon which \nlie outside the volume.  In two dimensions the algorithms\npermit clipping against irregular convex windows. \n Polygons to be clipped are represented as an ordered\nsequence of vertices without repetition of first \nand last, in marked contrast to representation as a\ncollection of edges as was heretofore the common \nprocedure.  Output polygons have an identical format,\nwith new vertices introduced in sequence to describe \nany newly-cut edge or edges.  The algorithms easily handle\nthe particularly difficult problem of detecting \nthat a new vertex may be required at a corner of the\nclipping window.  The algorithms described achieve \nconsiderable simplicity by clipping separately against\neach clipping plane or window boundary.  Code \ncapable of clipping the polygon against a single boundary\nis reentered to clip against subsequent boundaries. \n Each such reentrant stage of clipping need store only\ntwo vertex values and may begin its processing \nas soon as the first output vertex from the proceeding\nstage is ready.  Because the same code is reentered \nfor clipping against subsequent boundaries, clipping\nagainst very complex window shapes is practical. \n For perspective applications in three dimentions, a six-plane\ntruncated pyramid is chosen as the clipping \nvolume.  The two additional planes parallel to the projection\nscreen serve to limit the range of depth \npreserved through the projection.  A perspective projection\nmethod which provides for arbitrary view \nangles and depth of field in spite of simple fixed clipping\nplanes is described.  This method is ideal \nfor subsequent hidden-surface computations.\n computer graphics, hidden-surface, clipping\n", "2693": "Bivariate Interpolation and Smooth Surface Fitting bivariate interpolation, interpolation, partial\nderivative, polynomial, smooth surface fitting\n", "2694": "Computation of Legendre Series Coefficients [C6] (Algorithm A473) Legendre series, Chebyshev series\n", "2695": "Tridiagonalization by Permutations Tridiagonalizing a matrix by similarity transformations\nis an important computational tool \nin numerical linear algebra. Consider the class of sparse\nmatrices which can be tridiagonalized using \nonly row and corresponding column permutations.  The\nadvantages of using such a transformation include \nthe absence of round-off errors and improved computation time\nwhen compared with standard transformations. \n A graph theoretic algorithm which examines an arbitrary\nn x n matrix and determines whether or not it \ncan be permuted into tridiagonal form is given.  The\nalgorithm requires no arithmetic while the number \nof comparisons, the number of assignments, and the number\nof increments are linear in n.  This compares \nvery favorably with standard transformation methods.\n If the matrix is permutable into tridiagonal form, \nthe algorithm gives the explicit tridiagonal form.\n Otherwise, early rejection will occur.\n tridiagonal matrix, permutation, algorithm,\neigenvalues, graph, bandwidth, sparse matrix\n", "2696": "A Method of Bivariate Interpolation and Smooth A method is designed for interpolating values\ngiven at points of a rectangular grid in a plane \nby a smooth bivariate function z=z(x,Y).  The interpolating\nfunction is a bicubic polynomial in each \ncell of the rectangular grid.  Emphasis is an avoiding\nexcessive undulation between given grid points. \nThe proposed method is an extension of the method of\nunivariate interpolation developed earlier by the \nauthor and is likewise based on local procedures.\n bivariate interpolation, interpolation, partial\nderivative, polynomial, smooth surface fitting\n", "2697": "A Fast Method for Solving a Class of Tridiagonal Linear Systems The solution of linear systems having real, symmetric,\ndiagonally dominant,tridiagonal coefficient \nmatrices with constant diagonals is considered.  It is\nproved that the diagonals of the LU decomposition \nconverges when floating-point precision.  It is also\nproved that the computed LU decomposition converges \nwhen floating-point arithmetic is used and that the limits\nof the LU diagonals using floating point are \nroughly within machine precision of the limits using\nreal arithmetic.  This fact is exploited to reduce \nthe number of floating-point operations required to\nsolve a linear system from 8n-7 to 5n+2k-3, where \nk is much less than n, the order of the matrix.  If the\nelements of the subdiagonals and superdiagonals \nare 1, then only 4n+2k-3 operations are needed.  The\nentire LU decomposition takes k words of storage, \nand considerable savings in array subscripting are achieved.\n Upper and lower bounds on k are obtained \nin terms of the ratio of the coefficient matrix diagonal\nconstants and parameters of the floating-point \nnumber system.  Various generalizations of these results are discussed.\n numerical linear algebra, linear systems,\nToeplitz matrices, tridiagonal matrices\n", "2698": "Syntax-Directed Least-Errors Analysis for A least-errors recognizer is developed informally\nusing the well-known recognizer of Earley, \nalong with elements of Bellman's dynamic programming.\n The analyzer takes a general class of context-free \ngrammars as drivers, and any finite string as input.\n Recognition consists of a least-errors count for \na corrected version of the input relative to the driver\ngrammar. The algorithm design emphasizes practical \naspects which help in programming it.\n arbitrary input strings, context-free grammars,\nparsing, dynamic programming, stored subanalyses, \nseparability, state merging, least-errors correction\n", "2699": "Automatic Data Structure Choice in a Language of Very High Level SETL is a set-theoretically oriented language\nof very high level whose repertoire of semantic \nobjects includes finite sets, ordered n-tuples, and\nsets of ordered n-tuples usable as mappings.  This \npaper describes the structure of an optimizer for this\nlanguage.  Among other methods of interest, the \noptimizer uses techniques which allow relations of inclusion\nand membership to be established, the domains \nand ranges of (tabulated) mappings to be estimated from\nabove and below, and the single-valuedness of \n(tabulated) mappings to be proved.  Once facts of this\nkind have been established, automatic choice of \ndata structures becomes possible. The methods employed\nare based upon, and extend, known techniques of \ndata flow analysis.\n program optimization, automatic programming, high-level\nlanguages, set-theoretic languages, data \nstructure choice\n", "2700": "Reduction: A Method of Proving Properties of Parallel Programs When proving that a parallel program has a\ngiven property it is often convenient to assume \nthat a statement is indivisible, i.e. that the statement\ncannot be interleaved with the rest of the program. \n Here sufficient conditions are obtained to show that\nthe assumption that a statement is indivisible \ncan be relaxed and still preserve properties such as\nhalting.  Thus correctness proofs of a parallel \nsystem can often be greatly simplified.\n deadlock free, reduction, interruptible, indivisible,\nparallel program, semaphore, verification \nmethod, process, computation sequence\n", "2701": "A Fast and Usually Linear Algorithm for Global A new algorithm for global flow analysis on\nreducible graphs is presented. The algorithm is \nshown to treat a very general class of function spaces.\n For a graph of e edges, the algorithm has a \nworst case time bound of O(e log e) function operations.\n It is also shown that in programming terms, \nthe number of operations is proportional to e plus the\nnumber of exits from program loops.  Consequently \na restriction to one-entry one-exit control structures\nlinearity.  The algorithm can be extended to yet \nlarger classes of function spaces and graphs by relaxing\nthe time bound.  Examples are given of code \nimprovement problems which can be solved using the algorithm.\n global flow analysis, data flow, code optimization,\ncommon subexpression elimination, live-dead \nanalysis, information propagation, flow graph, reducibility,\ngo-to-less programming, depth-first search, \npath compression\n", "2702": "On the Complexity of LR(k) Testing The problem of determining whether an arbitrary\ncontext-free grammar is a member of some easily \nparsed subclass of grammars such as the LR(k) grammars\nis considered.  The time complexity of this problem \nis analyzed both when k is considered to be a fixed\ninteger and when k is considered to be a parameter \nof the test.  In the first case, it is shown that for\nevery k there exists an O(n(k+2)) algorithm for \ntesting the LR(k) property, where n is the size of the\ngrammar in question.  On the other hand, if both \nk and the subject grammar are problem parameters, then\nthe complexity of the problem depends very strongly \non the representation chosen for k.  More specifically,\nit is shown that this problem is NP-complete \nwhen k is expressed in unary.  When k is expressed in\nbinary the problem is complete for nondeterministic \nexponential time.  These results carry over to many\nother parameterized classes of grammars, such as \nthe LL(k), strong LL(k), SLR(k), LC(k), and strong LC(k) grammars.\n computational complexity, context-free grammars,\nparsing, LR(k) grammars, NP-complete problems\n", "2703": "The Intrinsically Exponential Complexity of Attribute grammars are an extension of context-free\ngrammars devised by Knuth as a mechanism \nfor including the semantics of a context-free language\nwith the syntax of the language.  The circularity \nproblem for a grammar is to determine whether the semantics\nfor all possible sentences (programs) in \nfact will be well defined.  It is proved that this problem\nis, in general, computationally intractable. \n Specifically, it is shown that any deterministic algorithm\nwhich solves the problem must for infinitely \nmany cases use an exponential amount of time.An improved\nversion of Knuth's circularity testing algorithm \nis also given, which actually solves the problem within exponential time.\n attribute grammars, circularity problem, context-free\ngrammars, computational complexity, exponential \ntime, semantics\n", "2704": "Exception Handling: Issues and a Proposed Notation This paper defines exception conditions, discusses\nthe requirements exception handling language \nfeatures must satisfy, and proposes some new language\nfeatures for dealing with exceptions in an orderly \nand reliable way.  The proposed language features serve\nto highlight exception handling issues by showing \nhow deficiencies in current approaches can be remedied.\n multilevel exit, goto statement, error conditions,\nstructured programming, ON conditions, programming \nlanguages\n", "2705": "Programming Languages, Natural Languages, and Mathematics Some social aspects of programming are illuminated\nthrough analogies with similar aspects of \nmathematics and natural languages.  The split between\npure and applied mathematics is found similarly \nin programming. The development of natural languages toward\nflexion less, word-order based language types \nspeaks for programming language design based on general,\nabstract constructs.  By analogy with incidents \nof the history of artificial, auxiliary languages it\nis suggested that Fortran and Cobol will remain \ndominant for a long time to come.  The most promising\navenues for further work of wide influence are \nseen to be high quality program literature (i.e. programs)\nof general utility and studies of questions \nrelated to program style.\n analogies related to social aspects,pure and applied\nmathematics, language quality, language development, \nartificial auxiliary languages, literature, style,\ndescriptive and prescriptive attitudes\n", "2706": "A Note on the Set Basis Problem Related This note discusses the reduction of the\nset basis problem to the clique cover problem.\n compaction of character sets, set basis, set covering,\ncomputational complexity, polynomial completeness, \nclique cover \n", "2707": "Backtrack Programming Techniques The purpose of this paper is twofold.  First,\na brief exposition of the general backtrack technique \nand its history is given.  Second, it is shown how the use\nof macros can considerably shorten the computation \ntime in many cases.  In particular, this technique has allowed\nthe solution of two previously open combinatorial \nproblems, the computation of new terms in a well-known\nseries, and the substantial reduction in computation \ntime for the solution to another combinatorial problem.\n backtrack, depth-first search, exhaustive search,\nmacros, combinatorial computing, non-attacking \nqueen's problem, difference-preserving codes, pentominoes,\ntiling problems, squaring the square\n", "2708": "Practical Syntactic Error Recovery This paper describes a recovery scheme for syntax\nerrors which provides automatically-generated \nhigh quality recovery with good diagnostic information\nat relatively low cost. Previous recovery techniques \nare summarized and empirical comparisons are made.  Suggestions\nfor further research on this topic conclude \nthe paper.\n syntax errors, error recovery, error correction,\nparsing, simple precedence, compilers, debugging\n", "2709": "A Genealogy of Control Structures The issue of program control structures has\nhad a history of heated controversy.  To put this \nissue on a solid footing, this paper reviews numerous theoretical\nresults on control structures and explores \ntheir practical implications.  The classic result of\nBohm and Jacopini on the theoretical completeness \nof if-then-else and while-do is discussed. Several recent\nideas on control structures are then explored. \n These include a review of various other control structures,\nresults on time/space limitations, and theorems \nrelating the relative power of control structures under\nnotions of equivalence.  In conclusion, the impact \nof theoretical results on the practicing programmer and\nthe importance of one-in, one-out control structures \nas operational abstractions are discussed.  It is argued\nfurther that there is insufficient evidence \nto warrant more than if-then-else, while-do, and their variants.\n structured programming, control structures,\ngoto statements, language design, PASCAL\n", "2710": "Specifying Queries as Relational Expressions: This paper presents a data sublanguage called\nSQUARE, intended for use in ad hoc, interactive \nproblem solving by non-computer specialists. SQUARE\nis based on the relational model of data, and is \nshown to be relationally complete; however, it avoids\nthe quantifiers and bound variables required by \nlanguages based on the relational calculus.  Facilities\nfor query, insertion, deletion, and update on \ntabular data bases are described.  A syntax is given,\nand suggestions are made for alternative syntaxes, \nincluding a syntax based on English key words for\nusers with limited mathematical background.\n database, data sublanguages, relations, query languages,\ncasual user, relational data model, tabular \ndata, interactive problem solving, nonprocedural\nlanguages, relational completeness\n", "2711": "A Vector Space Model for Automatic Indexing In a document retrieval, or other pattern matching\nenvironment where stored entities (documents) \nare compared with each other or with incoming patterns\n(search requests), it appears that the best indexing \n(property) space is one where each entity lies as far away\nfrom the others as possible; in these circumstances \nthe value of an indexing system may be expressible\nas a function of the density of the object space; \nin particular, retrieval performance may correlate inversely\nwith space density.  An approach based on \nspace density computations is used to choose an optimum\nindexing vocabulary for a collection of documents. \n Typical evaluation results are shown, demonstrating\nthe usefulness of the model.\n automatic information retrieval, automatic\nindexing, content analysis, document space\n", "2712": "Horner's Rule for the Evaluation of General Closed Queueing Networks The solution of separable closed queueing networks\nrequires the evaluation of homogeneous multinomial \nexpressions.  The number of terms in those expressions\ngrows combinatorially with the size of\u0019 the network \nsuch that a direct summation may become impractical.  An\nalgorithm is given which does not show a combinatorial \noperation count.  The algorithm is based on a generalization\nof Horner's rule for polynomials.  It is \nalso shown how mean queue size and throughput an be obtained\nat negligible extra cost once the normalization \nconstant is evaluated.\n Queueing networks, queueing theory Horner's rule,\nevaluation of multinomial sums, load-dependent \nservice rate\n", "2713": "Remark on Stably Updating Mean and", "2714": "Merging with Parallel Processors Consider two linearly ordered sets A, B, |A|=m,\n|B|=n, m<=n, and p, p<=m, parallel processors \nworking synchronously.  The paper presents an algorithm\nfor merging A and B with the p parallel processors, \nwhich requires at most 2[log2 (2m+1)]+[3m/p] + [m/p][log2\n(n/m)] steps.  If n = (2^B)m (B an integer), \nthe algorithm requires at most 2[log2 (m+1)] + [m/p](2+B)\nsteps.  In the case where m and n are of the \nsame order of magnitude, i.e. n=km with k being a constant,\nthe algorithm requires 2[log2 (m+1)] + [m/p](3+k) \nsteps.  These performances compare very favorably with\nthe previous best parallel merging algorithm, \nBatcher's algorithm, which requires n/p + ((m+n)/2p)log2 m\nsteps in the general case and km/p + ((k+1)/2)(m/p)log2 \nm in the special case where n=km.\n parallel processing, parallel merging, parallel binary insertion\n", "2715": "Implementation of a Structured English Query Language The relational model of data, the XRM Relational\nMemory System, and the SEQUEL language have \nbeen covered in previous papers and are reviewed. \nSEQUEL is a relational data sublanguages intended \nfor the ad hoc interactive problem solving by non-computer\nspecialists.  A version of SEQUEL that has \nbeen implemented in a prototype interpreter is described.\n The interpreter is designed to minimize the \ndata accessing operations required to respond to an arbitrary\nquery.  The optimization algorithms designed \nfor this purpose are described.\n relational model, query language, nonprocedural language,\ndatabase, data structure, data organization\n", "2716": "Optimizing the Performance of a Relational Algebra Database Interface An approach for implementing a \"smart\" interface\nto support a relational view of data is proposed. \n The basic idea is to employ automatic programming techniques\nso that the interface analyzes and efficiently \nrefines the high level query specification supplied by\nthe user.  A relational algebra interface, called \nSQUIRAL, which was designed using this approach, is described\nin detail. SQUIRAL seeks to minimize query \nresponse time and space utilization by: (1) performing\nglobal query optimization, (2) exploiting disjoint \nand pipelined concurrency, (3) coordinating sort orders\nin temporary relations, (4) employing directory \nanalysis, and (5) maintaining locality in page references.\n Algorithms for implementing the operators \nof E. F. Codd's relational algebra are presented, and\na methodology for composing them to optimize the \nperformance of a particular user query is described.\n relational database, database optimization, inverted\nfile, automatic programming, query language, \ndata manipulation language, very high level language\n", "2717": "CONVERT: A High Level Translation This paper describes a high level and nonprocedural\ntranslation definition language, CONVERT, \nwhich provides very powerful and highly flexible data\nrestructuring capabilities. Its design is based \non the simple underlying concept of a form which enables\nthe users to visualize the translation processes, \nand thus makes data translation a much simpler task. \n\"CONVERT\" has been chosen for conveying the purpose \nof the language and should not be confused with any\nother language or program bearing the same name.\n data conversion, data restructuring, data translation,\ndatabase reorganization, translation definition, \nutility program, programming languages, nonprocedural languages\n", "2718": "A Preliminary System for the Design of DBTG Data Structures The functional approach to database design is\nintroduced.  In this approach the goal of design \nis to derive a data structure which is capable of supporting\na set of anticipated queries rather than \na structure which \"models the business\" in some other\nway. An operational computer program is described \nwhich utilizers the functional approach to design data\nstructures conforming to the Data Base Task Group \nspecifications.  The automatic programming technology\nutilized by this program, although typically used \nto generate procedure, is here used to generate declaratives.\n network model of databases, Data Base Task Group, database\ndesign, data structure, automatic programming, \ntranslation, nonprocedural languages\n", "2719": "Mechanical Program Analysis One means of analyzing program performance\nis by deriving closed-form expressions for their \nexecution behavior.  This paper discusses the mechanization\nof such analysis, and describes a system, \nMetric, which is able to analyze simple Lisp programs\nand produce, for example, closed-form expressions\nfor their running time expressed in terms of size of input.\n This paper presents the reasons for mechanizing \nprogram analysis, describes the operation of Metric, explains\nits implementation, and discusses its limitations.\n analysis of programs, performance analysis, execution\ntime, execution behavior, difference equations, \ngenerating functions, list processing, Lisp, algebraic\nmanipulation, programming languages, analysis \nof algorithms\n", "2720": "Optimal Balancing of I/O Requests to Disks Determining a policy for efficient allocation\nand utilization of a set of disk drives with \ndiffering operational characteristics is examined using\nanalytical techniques.  Using standard queueing \ntheory, each disk drive is characterized by a queueing\nmodel with service time of a disk drive represented \nby the probability density function of the sum of two\nuniform distributions. Total response time of the \nset of disk models is then minimized under varying\nload conditions. The results indicate that faster \ndevices should have higher utilization factors and that\nthe number of different device types utilized \ntends to decrease with decreasing load.  Specific examples\nusing 2314 and 3330 combinations are examined.\n disk drive hierarchies, system evaluation, input/output,\nmodeling, queueing theory, balancing, \nscheduling, device assignment\n", "2721": "The Digital Simulation of River Plankton Population Dynamics This paper deals with the development of a\nmathematical model for and the digital simulation \nin Fortran IV of phytoplankton and zooplankton population\ndensities in a river using previously developed \nrate expressions.  In order to study the relationships\nbetween the ecological mechanisms involved, the \nsimulation parameters were varied illustrating the\nresponse of the ecosystem to different conditions, \nincluding those corresponding to certain types of chemical\nand thermal pollution.  As an investigation \nof the accuracy of the simulation methods, a simulation\nof the actual population dynamics of Asterionella \nin the Columbia River was made based on approximations\nof conditions in that river. Although not totally \naccurate, the simulation was found to predict the general\nannual pattern of plankton growth fairly well \nand, specifically, revealed the importance of the annual\nvelocity cycle in determining such patterns. \n In addition, the study demonstrates the usefulness of\ndigital simulations in the examinations of certain \naquatic ecosystems, as well as in environmental\nplanning involving such examinations.\n digital simulation, mathematical modeling, plankton\npopulation dynamics, phytoplankton, zooplankton, \nriver ecosystems, ecological mechanisms, environmental simulation,\nmodeling ecosystems, pollution, environmental \nimpact, environmental planning\n", "2722": "Multidimensional Binary Search Trees Used for Associative Searching This paper develops the multidimensional binary\nsearch tree (or k-d tree, where k is the dimensionality \nof the search space) as a data structure for storage of\ninformation to be retrieved by associative searches. \nThe k-d tree is defined and examples are given. It\nis shown to be quite in its storage requirements. \n A significant advantage of this structure is that a single\ndata structure can handle many types of queries \nvery efficiently.  Various utility algorithms are developed;\ntheir proven average running times in an \nn record file are: insertion, O (log n); deletion of\nthe root, O (n^(k-1)/k); deletion of a random node, \nO (log n); and optimization (guarantees logarithmic performance\nof searches), O (n log n).  Search algorithms \nare given for partial match queries with t keys specified\n[proven maximum running time of O (n^(k-t)/k)] \nand for nearest neighbor queries [empirically observed average\nrunning time of O (log n).]  These performances \nfar surpass the best currently known algorithms for\nthese tasks.  An algorithm is presented to handle \nany general intersection query. The main focus of this\npaper theoretical.  It is felt, however, that \nk-d trees could be quite useful in many applications,\nand examples of potential uses are given.\n associative retrieval, binary search trees, key,\nattribute, information retrieval system, nearest \nneighbor queries, partial match queries, intersection\nqueries, binary tree insertion\n", "2723": "Multiprocessing Compactifying Garbage Collection Algorithms for a multiprocessing compactifying\ngarbage collector are presented and discussed. \n The simple case of two processors, one performing LISP-like\nlist operations and the other performing \ngarbage collection continuously, is thoroughly examined.\nThe necessary capabilities of each processor \nare defined, as well as interprocessor communication\nand interlocks. Complete procedures for garbage \ncollection and for standard list processing primitives\nare presented and thoroughly explained.  Particular \nattention is given to the problems of marking and relocating\nlist cells while another processor may be \noperating on them.  The primary aim throughout is to\nallow the list processor to run unimpeded while \nthe other processor reclaims list storage.  The more\ncomplex cases involving several list processors \nand one or more garbage collection processors are also briefly discussed.\n garbage collection, storage reclamation, reclaimer,\nstorage allocation, multiprocessing, synchronization, \nsemaphores, parallel processing, compactification, relocation,\nLISP, list processing, free storage, pointers, \ndata structures, gc processor\n", "2724": "The Lemniscate Constants (Corrigendum)", "2725": "A Comparison of Simulation Event List Algorithms (Corrigendum)", "2726": "Combining Decision Rules in a Decision Table The techniques for minimizing logic circuits\nare applied to the simplification of decision \ntables by the combining of decision rules. This method\nis logically equivalent to the Quien-McCluskey \nmethod for finding prime implicants.  If some of the\ndecision rules implied in the ELSE Rule occur with \nlow frequency, then the ELSE Rule can be used to further\nsimplify the decision table.  Several objectives \nmerit consideration in optimizing a decision table:(1)\nreducing machine execution time; (2) reducing \npreprocessing time; (3) reducing required machine memory;\n(4) reducing the number of decision rules. \n (This often improves the clarity of the decision table\nto a human reader.)  It will be shown that objectives \n(3) and (4) can be furthered with the above methods.\n Objective (1) is also attained if overspecified \ndecision rules are not combined.  Objective (2) must be\ncompared against the potential benefits of objectives \n(1), (3), and (4) in deciding whether to use the above methods.\n the Quine-McCluskey method, prime implicants, minimization,\nmaximization, logic circuit, boolean \nmethod, coding, decision tables, flowcharting, sorting\n", "2727": "Multiple Byte Processing with Full-Word Instructions A method is described which allows parallel\nprocessing of packed data items using only ordinary \nfull-word computer instructions, even though the processing\nrequires operations whose execution is contingent \nupon the value of a datum.  It provides a useful technique\nfor processing small data items such as alphanumeric \ncharacters.\n byte processing, character processing, packed data\n", "2728": "Consecutive Storage of Relevant Records with Redundancy This paper studies the properties of a new\nclass of file organizations (CRWR) where records \nrelevant to every query are stored in consecutive storage\nlocations but the organizations contain redundancy. \nSome theorems which provide tools for reducing redundancy\nin CRWR organizations have been also developed. \nRedundancies obtained by the application of these theorems\nare compared with that of query-inverted file \norganizations.  Some CRWR organization with minimum redundancy\nhave also been developed for queries which \nspecify sets of keys.\n consecutive, retrieval, storage, file, records, query, redundancy, key\n", "2729": "Comments on a Paper by T. C. Chen and I. T. Ho binary coded decimal digits, decimal data storage,\ndata compression, Huffman codes, variable length \ncodes\n", "2730": "Interactive Consulting via Natural Language Interactive programming systems often contain\nhelp commands to give the programmer on-line \ninstruction regarding the use of the various systems\ncommands.  It is argued that it would be relatively \neasy to make these help commands significantly more\nhelpful by having them accept requests in natural \nlanguage.  As a demonstration, Weizenbaum's ELIZA program\nhas been provided with a script that turns \nit into a natural language system consultant.\n interactive programming, time-sharing systems, natural\nlanguage processing, computer assisted instruction\n", "2731": "Remark on Stably Updating Mean and Standard Deviation of Data mean, standard deviation\n", "2732": "Guarded Commands, Nondeterminacy and Formal Derivation of Programs So-called \"guarded commands\" are introduced\nas a building block for alternative and repetitive \nconstructs that allow nondeterministic program components\nfor which at least the activity evoked, but \npossible even the final state, is not necessarily uniquely\ndetermined by the initial state.  For the \nformal derivation of programs expressed in terms\nof these constructs, a calculus will be shown.\n programming languages, sequencing primitives, program\nsemantics, programming language semantics, \nnondeterminacy, case-construction, repetition, termination,\ncorrectness proof, derivation of programs, \nprogramming methodology\n", "2733": "Deterministic Parsing of Ambiguous Grammars Methods of describing the syntax of programming\nlanguages in ways that are more flexible and \nnatural than conventional BNF descriptions are considered.\n These methods involve the use of ambiguous \ncontext-free grammars together with rules to resolve\nsyntactic ambiguities.  It is shown how efficient \nLR and LL parsers can be constructed directly from\ncertain classes of these specifications.  \n programming language specification, parser generation,\ntranslator writing systems, syntax analysis, \nLR parsing, LL parsing, ambiguous grammars\n", "2734": "On the External Storage Fragmentation Produced Published comparisons of the external fragmentation\nproduced by first-fit and best-fit memory \nallocation have not been consistent.  Through simulation,\na series of experiments were performed in order \nto obtain better data on the relative performance of\nfirst-fit and best-fit and a better understanding \nof the reasons underlying observed differences. The\ntime-memory-product efficiencies of first-fit and \nbest-fit were generally within 1 to 3 percent of each\nother.  Except for small populations, the size \nof the request population had little effect on allocation\nefficiency.  For exponential and hyperexponential \ndistributions of requests, first-fit outperformed best-fit;\nbut for normal and uniform distributions, \nand for exponential distributions distorted in various\nways, best-fit outperformed first-fit.  It is \nhypothesized that when first-fit outperforms best-fit,\nit does so because first-fit, by preferentially \nallocating toward one end of memory, encourages large blocks\nto grow at the other end.  Sufficient contiguous \nspace is thereby more likely to be available for relatively\nlarge requests.  Results of simulation experiments \nsupported this hypothesis and showed that the relative\nperformance of first-fit and best-fit depends \non the frequency of request.  When the coefficient of\nvariation of the request distribution is greater \nthan or approximately equal to unity, first-fit outperformed best-fit.\n storage fragmentation, dynamic memory allocation, first-fit, best-fit\n", "2735": "Discrimination in the Employment of Women in the Computer Industry discrimination against women, salaries, employment,\nprogrammers, systems analysis, keypunch operators, \nmachine operators\n", "2736": "A Note on Hash Linking hash search, address space extension,\nimplicit pointers, monitor conditions\n", "2737": "Determining the Minimum-Area Encasing This paper describes a method for finding the\nrectangle of minimum area in which a given arbitrary \nplane curve can be contained.  The method is of interest\nin certain packing and optimum layout problems. \n It consists of first determining the minimal-perimeter\nconvex polygon that encloses the given curve \nand then selecting the rectangle of minimum area capable\nof containing this polygon.  Three theorems \nare introduced to show that one side of the minimum-area\nrectangle must be colinear with an edge of the \nenclosed polygon and that the minimum-area encasing rectangle\nfor the convex polygon is also the minimum-area \nrectangle for the curve.\n enclosed curve, optimum layout, optimum\npacking, minimum-area encasing rectangle\n", "2738": "Use of the Concept of Transparency in the This paper deals with the design of hierarchically\nstructured programming systems.  It develops \na method for evaluating the cost of requiring programmers\nto work with an abstraction of a real machine. \n A number of examples from hardware and software\nare given as illustrations of the method.\n hierarchical systems, bottom up design, levels\nof abstraction, synchronization primitives\n", "2739": "The Restriction Language for Computer Grammars of Natural Language Over the past few years, a number of systems\nfor the computer analysis of natural language \nsentences have been based on augmented context-free\ngrammars: a context-free grammar which defines a \nset of parse trees for a sentence, plus a group of restrictions\nto which a tree must conform in order \nto be a valid sentence analysis.  As the coverage of the\ngrammar is increased, an efficient representation \nbecomes essential for further development.  This paper\npresents a programming language designed specifically \nfor the compact and perspicuous statement of restrictions\nof a natural language grammar.  It is based \non ten years' experience parsing text sentences with\nthe comprehensive English grammar of the N.Y.U. \nLinguistic String Project, and embodies in its syntax\nand routines the relations which were found to \nbe useful and adequate for computerized natural language\nanalysis.  The language is used in the current \nimplementation of the Linguistic String Parser.\n natural language, parsing, grammar, programming languages\n", "2740": "A Large Semaphore Based Operating System The paper describes the internal structure of\na large operating system as a set of cooperating \nsequential processes.  The processes synchronize by\nmeans of semaphores and extended semaphores (queue \nsemaphores).  The number of parallel processes is carefully\njustified, and the various semaphore constructions \nare explained.  The system is proved to be free of \"deadly\nembrace\" (deadlock).  The design principle \nis an alternative to Dijkstra's hierarchical structuring\nof operating systems.  The project management \nand the performance are discussed, too.  The operating\nsystem is the first large one using the RC 4000 \nmultiprogramming system.\n cooperating processes, operating system, semaphores,\nsemaphore applications, queue semaphores, \ndeadlock, deadly embrace, hierarchical structuring, multiprogramming,\noperating system structure, asynchronous \nstructuring, buffering, parallel processes, synchronizing\nprimitives, reentrant code, RC 4000, project \nmanagement, time schedule, debugging, project planning,\nproject scheduling, reliability, program proving, \ncoroutines, correctness, program maintenance, software paging\n", "2741": "Decomposability, Instabilities, and A step-by-step approach to model the dynamic\nbehavior and evaluate the performance of computing \nsystems is proposed.  It is based on a technique of variable\naggregation and the concept of nearly decomposable \nsystem, both borrowed from Econometrics.  This approach\nis taken in order to identify in multiprogramming \npaging systems (i) unstable regimes of operations and (ii)\ncritical computing loads which bring the system \ninto states of saturation.  This analysis leads to a\nmore complete definition of the circumstances in \nwhich \"thrashing\" can set in.\n multiprogramming, paging, performance evaluation,\nsaturation, instabilities, thrashing, aggregation, \nsystem levels, hierarchy,networks of queues\n", "2742": "Improved Event-Scanning Mechanisms for Discrete Event Simulation Simulation models of large, complex \"real-world\"\napplications have occasionally earned the \nreputation of eating up hours of computer time.  This\nproblem may be attributed in part to difficulties \nsuch as slow stochastic convergence.  However, an additional\nproblem lies in the fact that a significant \namount of bookkeeping time is required to keep future events\nin their proper sequence.  This paper presents \na method for significantly reducing the time spent scanning\nfuture event lists in discrete event simulations. \n There models are presented, all of which improve in effectiveness\nas the events-list scan problem becomes \nmore burdensome.\n discrete event simulation, simulation, event scanning mechanisms\n", "2743": "Sorting X + Y merge sorting, computational complexity, data\nmodeling, computing models, binary comparisons\n", "2744": "Addition in an Arbitrary Base Without Radix Conversion This paper presents a generalization of an\nold programming technique; using it,one may add \nand subtract numbers represented in any radix, including\na mixed radix, and stored one digit per byte \nin bytes of sufficient size.  Radix conversion is unnecessary,\nno looping is required, and numbers may \neven be stored in a display (I/O) format.  Applications\nto Cobol, MIX, and hexadecimal sums are discussed. \n addition, subtraction, decimal arithmetic, arbitrary\nradix arithmetic, radix conversion, MIX arithmetic, \nCobol display arithmetic, mixed radix arithmetic\n", "2745": "A Linear Space Algorithm for Computing Maximal Common Subsequences The problem of finding a longest common subsequence\nof two strings has been solved in quadratic \ntime and space.  An algorithm is presented which will\nsolve this problem in quadratic time and in linear \nspace.\n subsequence, longest common subsequence, string correction, editing\n", "2746": "Efficient String Matching: An Aid to Bibliographic Search This paper describes a simple, efficient algorithm\nto locate all occurrences of any of a finite \nnumber of keywords in a string of text.  The algorithm\nconsists of constructing a finite state pattern \nmatching machine from the keywords and then using the\npattern matching machine to process the text string \nin a single pass.  Construction of the pattern matching\nmachine takes time proportional to the sum of \nthe lengths of the keywords.  The number of state transitions\nmade by the pattern matching machine in \nprocessing the text string is independent of the number\nof keywords.  The algorithm has been used to \nimprove the speed of a library bibliographic\nsearch program by a factor of 5 to 10.\n keywords and phrases, string pattern matching, bibliographic\nsearch, information retrieval, text-editing, \nfinite state machines, computational complexity.\n", "2747": "A Simplified Recombination Scheme for the Fibonacci Buddy System A simplified recombination scheme for the Fibonacci\nbuddy system which requires neither tables \nnor repetitive calculations and uses only two\nadditional bits per buffer is presented.\n Fibonacci buddy system, dynamic storage allocation, buddy system\n", "2748": "Indirect Threaded Code An efficient arrangement for interpretive code\nis described.  It is related to Bell's notion \nof threaded code but requires less space and is more\namenable to machine independent implementations.\n threaded code, SNOBOL4, interpretors, code generation\n", "2749": "Significant Event Simulation This paper compares a new method of simulation\norganization, called the significant event method, \nwith an old one, called the clock pulse method, using\nas examples two automobile traffic models.  The \nsignificant event method is found to be more efficient\nthan the clock pulse method at low levels of system \ninteraction and less efficient at high levels.  A simple\nmathematical model for the trade-off in the \nrelative running time of the two methods is developed. \nThe model aids in choosing between the two simulation \nmethods for a particular experiment.  It is concluded\nthat the significant event method can be of value \nin the simulation of some systems when computational\nefficiency is of sufficient importance.\n simulation organization, event simulation, clock\npulse simulation, significant event simulation.\n", "2750": "A Cost Oriented Algorithm for Data Set Allocation in Storage Hierarchies Data set allocation in today's multilevel\nstorage systems is usually based on qualitative, \nad hoc decisions.  While it would be desirable to obtain\nan optimal solution to this allocation problem, \nit is clear that the number of parameters involved makes\nit intractable to straight-forward solution. \n In such a situation, we must find a set of assumptions\nwhich simplify the problem greatly, but which \nstill provide a basis for considering all significant\ncost elements. This paper presents such a first, \nquantitative allocation step.  It considers many of the\nsignificant detailed costs of system utilization, \ndata storage, data staging, and data migration.  Although\nmany avenues of further improvement are available, \nthe present algorithm seems to be usefully accurate.\nAs such, it can aid in quantifying the problems \nof data set allocation, storage system configuration, and new device designs.\n data set allocation, hierarchical storage, storage\nsystem configuration, data staging, data migration, \nstorage allocation analysis\n", "2751": "Illumination for Computer Generated Pictures The quality of computer generated images of\nthree-dimensional scenes depends on the shading \ntechnique used to paint the objects on the cathode-ray\ntube screen.  The shading algorithm itself depends \nin part on the method for modeling the object, which\nalso determines the hidden surface algorithm.  The \nvarious methods of object modeling, shading, and hidden\nsurface removal are thus strongly interconnected. \n Several shading techniques corresponding to different\nmethods of object modeling and the related hidden \nsurface algorithms are presented here.  Human visual\nperception and the fundamental laws of optics are \nconsidered in the development of a shading rule that\nprovides better quality and increased realism in \ngenerated images.\n computer graphics, graphic display, hidden surface removal.\n", "2752": "Generation of All the Cycles of a Graph from basic cycle, cycle, graph\n", "2753": "A Heuristic Problem Solving Design System The Designer Problem Solver (DPS) demonstrates\nthat the computer can perform simple design \ntasks.  In particular, it designs furniture and equipment\nlayouts.  This task was chosen because it is \nsimple, well defined, and characteristic of many design\ntasks in architecture, engineering, urban planning, \nand natural resource management.  These space planning\ntasks usually involve manipulating two-dimensional \nrepresentations of objects to create feasible or optimal\nsolutions for problems involving topological \nand metric spatial constraints.  The paper describes\nextensive tests performed on the program.  DPS is \na heuristic problem solver with a planning phase prefixed\nto it.  It uses the planning process to give \nit a sense of direction, diagnostic procedures to locate\ndifficulties, and remedial actions to recover \nfrom difficulties.  It uses a convex polygon representation\nto accurately describe the objects and the \nlayout.  This representation allows topological and\nmetric constraints to be tested and the design to \nbe easily updated.  DPS has been applied to 50 problems.\n While it is slow and limited in scope, the \nideas behind it are general.  It demonstrates the need\nfor selectivity in controlling search and the \nmethods used to achieve it: task-specific information,\nplanning, diagnostic procedures, remedial actions, \nand selective alternative generators.\n artificial intelligence, computer-aided design,\ndesign synthesis, diagnostic search, heuristics, \nplanning, problem solving, representations, search strategies,\nspace planning, spatial representations\n", "2754": "A Syntactic Algorithm for Peak Detection Peaks in a digitized waveform are detected by an\nalgorithm incorporating piecewise linear approximation \nand tabular parsing techniques.  Several parameters serve\nto identify the waveform context enabling accurate \nmeasurement of peak amplitude, duration, and shape.  The\nalgorithm is of sufficient speed to allow on-line \nreal-time processing.  An example of its application\nis demonstrated on an electrocardiogram.\n peak detection, digitized waveform, piecewise linear\napproximation, context-free grammar, bottom-up \nparsing, electrocardiogram.\n", "2755": "The New Math of Computer Programming (Corrigendum)", "2756": "A Problem-List of Public Policy Issues economic and social implications, the public\nand computing, medicine and health care\n", "2757": "More on kth Shortest Paths networks, kth shortest paths\n", "2758": "A Note on the LU Factorization of a Symmetric Matrix symmetric matrices, factorization, test matrices,\nmatrix inversion, separable systems\n", "2759": "Solution of an Overdetermined System of", "2760": "Visible Surface Plotting Program (Algorithm R475)", "2761": "Visible Surface Plotting Program (Algorithm R475)", "2762": "Ten Subroutines for the Manipulation", "2763": "Basic Cycle Generation [H] (Algorithm 491) Graph, basic cycles,fundamental cycle,\nspanning tree, vertex adjacency matrix\n", "2764": "An Intelligent Analyzer and Understander of English The paper describes a working analysis and generation\nprogram for natural language, which handles \nparagraph length input.  Its core is a system of preferential\nchoice between deep semantic patterns, \nbased on what we call \"semantic density.\"  The system\nis contrasted: (1) with syntax oriented linguistic \napproaches, and (2) with theorem proving\napproaches to the understanding problem.\n artificial intelligence, computational linguistics,\ntemplate, paraplate, stereotype, machine translation, \nunderstanding, natural language processing,\nsemantic preference, semantic density\n", "2765": "Analysis and performance of Inverted Data Base Structures The need to envision and architecture data base\nsystems in a hierarchical level by level framework \nis stressed. The inverted data base (file) organization\nis then analyzed, considering implementation \noriented aspects.  The inverted directory is viewed realistically\nas another large data base which itself \nis subjected to inversion.  Formulations are derived\nto estimate average access time (read only) and \nstorage requirements, formalizing the interaction of data\nbase content characteristics, logical complexity \nof queries, and machine timing and blocking specifications\nidentified as having a first-order effect \non performance.  The formulations presented are necessary\nto be used in conjunction with any index selection \ncriteria to determine the optimum set of index keys.\n data base architecture, inverted file organization,\ndata base performance and measurement, secondary \nindex organization, information storage and retrieval, query answering\n", "2766": "Copying Cyclic List Structures in Linear Time Using Bounded Workspace A bounded workspace copying algorithm for arbitrary\nlist structures is given.  This algorithm \noperates in linear time and does not require tag bits. \nThe best previous bounded workspace copying algorithms \nachieved n^2 time without tag bits and n log n time with\none tag.  The only restriction on the algorithm \ngiven here is that the copy must be placed into a contiguous\nsection of memory.  The method is applicable \nto fixed or variable size nodes.\n list processing, copying, linear time, space complexity\n", "2767": "A Comparison of Simulation Event List Algorithms Four algorithms are considered which can be used\nto schedule events in a general purpose discrete \nsimulation system.  Two of the algorithms are new, one\nis based on an end-order tree structure for event \nnotices, and another uses an indexed linear list. The algorithms\nare tested with a set of typical stochastic \nscheduling distributions especially chosen to show\nthe advantages and limitations of the algorithms. \n The end-order tree algorithm is shown to be an advantageous,\nimmediate replacement for the algorithm \nin use with current simulation languages.  The most\npromising algorithm uses the indexed list concept. \n It will require an adaptive routine before it can\nbe employed in general purpose simulators,but its \nperformance is such that further study would be fruitful.\n simulation, time flow mechanisms, event list algorithm,\nsimulation, time flow mechanisms, event \nlist algorithm, simulation executive, event scheduling\nroutine, discrete system simulation, sorting\n", "2768": "An Algorithm for Locating Adjacent Storage Blocks in the Buddy System A simple scheme for the determination of the\nlocation of a block of storage relative to other \nblocks is described.  This scheme is applicable\nto the buddy type storage allocation systems.\n dynamic storage allocation, buddy system, generalized Fibonacci sequences\n", "2769": "A Modification of Warshall's Algorithm for An algorithm is given for computing the transitive\nclosure of a binary relation that is represented \nby a Boolean matrix. The algorithm is similar to Warshall's\nalthough it executes faster for sparse matrices\non most computers, particularly in a paging environment.\n Warshall's algorithm, transitive closure, reachability\nmatrix, directed graph, digraph, Boolean \nmatrix, binary relation\n", "2770": "The Quadratic Hash Method When the Table Size Is Not a Prime Number Previous work on quadratic hash methods is\nlimited mainly to the case where the table size \nis a prime number.  Here, certain results are derived for\ncomposite numbers.  It is shown that all composite \nnumbers containing at least the square of one of the component\nprimes have full-period integer-coefficient \nquadratic hash functions.\n quadratic search, hash code, scatter storage, table size\n", "2771": "The Synthesis of Solids Bounded by Many Faces A technique is presented which allows a class\nof solid objects to be synthesized and stored \nusing a computer.  Synthesis begins with primitive solids\nlike a cube, wedge, or cylinder.  Any solid \ncan be moved, scaled, or rotated.  Solids may also be\nadded together or subtracted.  Two algorithms to \nperform addition are described.  For practical designers,\nthe technique has the advantage that operations \nare concise, readily composed, and are given in terms\nof easily imagined solids.Quite short sequences \nof operations suffice to build up complex solids bounded by many faces.\n computational geometry, computer-aided design,\ngraphics, machined components, polyhedra, shape \nsynthesis, three-dimensional modeling\n", "2772": "On Maintenance of the Opportunity List One of the principal components of procedures\nfor the solution of class-teacher timetable problems \nis that for maintenance of the opportunity list.  Opportunity\nlist maintenance methods are based on necessary \nconditions for the existence of a solution. A general\nframework for necessary conditions, together with \nfour specific sets of necessary conditions, is given.\n combinatorial, necessary conditions, opportunity\nlist, schedule,school timetable, timetable\n", "2773": "A Weighted Buddy Method for Dynamic Storage Allocation (Corrigendum)", "2774": "Remark on Algorithm 475", "2775": "The Dilogarithm Function of a Real Argument [S22] (Algorithm 490) dilogarithm\n", "2776": "Computer Networks in Higher Education: Socio-Economic-Political Factors This study presents the results of a nationwide\nsurvey of computer networks in higher education \nconducted during 1971-73.  Five major and 18 minor networks\nwere identified.  The five major networks \nincluded: the ARPA Net, the California State College network,\nthe University of Iowa/Iowa State University \nnetwork, the Michigan Educational Research Information Triad,\nInc., and the Triangle Universities Computation \nCenter network in North Carolina. In-depth studies were\nconducted of the latter two nets.  Based on the \nexperiences of these operating networks, a number of factors\nare identified for consideration in developing \nnetworks.  Finally, recommendations are advanced regarding\nthe development of networks in higher education \nin the future.\n networks, higher education\n", "2777": "On a Solution to the Cigarette Smoker's This report discusses a problem first introduced\nby Patil, who has claimed that the cigarette \nsmoker's problem cannot be solved using the P and V operations\nintroduced by Dijkstra unless conditional \nstatements are used.  An examination of Patil's proof\nshows that he has established this claim only under \nstrong restrictions on the use of P and V.  These restrictions\neliminate programming techniques used \nby Dijkstra and others since the first introduction\nof the semaphore concept.  This paper contains a \nsolution to the problem.  It also discusses the need\nfor the generalized operators suggested by Patil.\n operating systems, co-operating processes,process\nsynchronization primitives\n", "2778": "Perturbations of Eigenvalues of Non-normal Matrices (Corrigendum)", "2779": "Discrete Least Squares Polynomial Fits The recurrence relation between orthogonal polynomials\nis widely used for discrete least squares \ndata fitting.  A variant of the classical algorithm\nwhich has better numerical properties is presented \nand the reason for its improved performance is explained.\n orthogonal polynomials, data fitting, least squares,\nrecurrence relation between orthogonal polynomials, \nresidual\n", "2780": "On Computing Certain Elements of the Inverse of a Sparse Matrix A recursive algorithm for computing the inverse\nof a matrix from the LU factors based on relationships \nin Takahashi, et al., is examined.  The formulas for the\nalgorithm are given; the dependency relationships \nare derived; the computational costs are developed; and some\ngeneral comments on application and stability \nare made.\n sparse matrices, triangular factorization, elements\nof inverse, tridiagonal matrix, sensitivities\n", "2781": "The Algorithm Sequential Access Method: keys, direct access method, sequential access\nmethod, randomizing information retrieval\n", "2782": "A Reply to Gentleman and Marovich high-level languages, philosophy of language design\n", "2783": "The Algorithm SELECT-for Finding the ith selection, medians, quantiles\n", "2784": "Expected Time Bounds for Selection A new selection algorithm is presented which\nis shown to be very efficient on the average, \nboth theoretically and practically.  The number of comparisons\nused to select the ith smallest of n numbers \nis n+min(i,n-i)+o(n).  A lower bound within 9\npercent of the above formula is also derived.\n selection, computational complexity, medians, tournaments, quantiles\n", "2785": "Glypnir-A Programming Language for Illiac IV GLYPNIR is one of the earliest existing languages\ndesigned for programming the Illiac IV computer. \nThe syntax of the language is based on ALGOL 60, but has\nbeen extended to allow the programmer explicitly \nto specify the parallelism of his algorithm in terms of 64-word\nvectors.  This paper describes the characteristics, \ngoals and philosophy of the language, and discusses some\nof the problems associated with parallel computer \narchitectures.\n GLYPNIR, Illiac IV, Programming language,\nparallel computation, parallel architecture\n", "2786": "A System for Typesetting Mathematics This paper describes the design and implementation\nof a system for typesetting mathematics. \n The language has been designed to be easy to learn\nand to use by people (for example, secretaries and \nmathematical typists) who know neither mathematics nor\ntypesetting.  Experience indicates that the language \ncan be learned in an hour or so, for it has few rules\nand fewer exceptions.  For typical expressions, \nthe size and font changes, positioning, line drawing, and\nthe like necessary to print according to mathematical \nconventions are all done automatically.  For example,\nthe input sum from i=o to infinity x sub i=pi over \n2 produces (formula).  The syntax of the language is specified\nby a small context-free grammar; a compiler-compiler \nis used to make a compiler that translates this language\ninto typesetting commands.  Output maybe produced \non either a phototypesetter or on a terminal with forward\nand reverse half-line motions.  The system \ninterfaces directly with text formatting programs, so\nmixtures of text and mathematics may be handled \nsimply.  This paper was typeset by the authors using the system described \n typesetting, photocomposition,compiler-compiler,\ngraphics, printing, text processing.\n", "2787": "Matrix Reduction-An Efficient Method The paper describes an efficient method for\nreduction of the binary matrices which arise in \nsome school time-tabling problems.  It is a development\nof that described by John Lions.  It has been \ngeneralized and adapted to fit into the complete timetabling\nprocess; to use a more compact data representation \nand more efficient processing techniques; to take fuller\nadvantage of possible available previous knowledge \nabout the matrix.  And it is designed as a structured\nprogram, which can readily be coded by the reader \nin the high level or low level programming language\nof his choice.  Practical tests of the method have \nshown it to be a good basis for a realistic timetabling algorithm.\n binary matrices, matrix reduction, tight set, school\ntimetable construction, structured programming\n", "2788": "Finding Circles by an Array of Accumulators picture processing, pattern recognition, curve detection,line fitting\n", "2789": "A Minimal Spanning Tree Clustering Method (Algorithm R479)", "2790": "The Elementary Circuits of a Graph (Algorithm R459)", "2791": "Exact Probabilities for R x C Contingency Tables (Algorithm R434)", "2792": "Jacobi Polynomials (Algorithm R332)", "2793": "Chi-Square Quantiles (Algorithm C451)", "2794": "State-Space, Problem-Reduction, and Theorem Proving-Some Relationships This paper suggests a bidirectional relationship\nbetween state-space and problem-reduction \nrepresentations. It presents a formalism based on multiple-input\nand multiple-output operators which \nprovides a basis for viewing the two types of representations\nin this manner.  A representation of the \nlanguage recognition problem which is based on the Cocke\nparsing algorithm is used as an illustration. \n A method for representing problems in first-order logic\nin such a way that the inference system employed \nby a resolution-based theorem prover determines whether\nthe set of clauses is interpreted in the state-spacer \nmode or in the problem-reduction mode is presented.\n The analogous concepts in problem-reduction and \ntheorem proving, and the terminology used to refer to them,\nare noted.  The relationship between problem-reduction, \ninput resolution, and linear resolution is discussed.\n artificial intelligence, state-space representation,\nproblem-reduction representation, theorem \nproving, language recognition\n", "2795": "Sentence Paraphrasing from a Conceptual Base A model of natural language based on an underlying\nlanguage-free representation of meaning \nis described.  A program based on this model is able\nto produce sentence paraphrases which demonstrate \nunderstanding with respect to a given context.  This\ngenerator operates in conjunction with a natural \nlanguage analyzer and a combined memory and inference model.\n In generating sentences from meaning structures, \nthe program employs both the information retrieval and\ndeduction capabilities of the memory model.  The \nmodel encompasses several diverse classes of linguistic\nknowledge, which include: (1) executable tests \nof conceptual properties stored in discrimination nets;\n(2) information relating conceptual to syntactic \nroles, stored in a word-sense dictionary, and (3) surface\ngrammatical knowledge, stored in a formal grammar.\n artificial intelligence, natural language processing,\nlanguage generation, models of cognitive \nprocesses, semantic representation\n", "2796": "Monitors: An Operating System Structuring Concept (Corrigendum)", "2797": "A First Order Approximation to the Optimal", "2798": "Analysis of Interleaved Memory Systems Using Blockage Buffers A model of interleaved memory systems is presented,\nand the analysis of the model by Monte \nCarlo simulation is discussed.  The simulations investigate\nthe performance of various system structures, \ni.e. schemes for sending instruction and data requests\nto the memory system.  Performance is measured \nby determining the distribution of the number of memory\nmodules in operation during a memory cycle.  \nAn important observation from these investigations is that\nseparately grouping instruction and data requests \nfor memory can substantially increase the average number\nof memory modules in operation during a memory \ncycle.  Results of the simulations and an analytical\nstudy are displayed for various system structures.\n interleaved memory systems, modular memory systems,\nmemory performance analysis, blockage buffer, \nconflict buffer, simulation, Monte Carolo simulation\n", "2799": "Stably Updating Mean and Standard Deviation of Data By considering the (sample) mean of a set of\ndata as a fit to this data by a constant function, \na computational method is given based on a matrix formulation\nand Givens transformations. The (sample) \nmean and standard deviation can be updated as data\naccumulates.  The procedure is numerically stable \nand does not require storage of the data.  Methods for\ndealing with weighted data and data removal are \npresented.  When updating the mean and square of the\nstandard deviation, the process requires no square \nroots.\n mean, standard deviation, least squares, Givens\ntransformation, updating estimates, removing data\n", "2800": "Connections Between Accuracy and Stability This paper is concerned with stability and accuracy\nof families of linear k-step formulas depending \non parameters, with particular emphasis on the numerical\nsolution of stiff ordinary differential equations. \n An upper bound, p=k, is derived for the order of accuracy\nof A(inf)-stable formulas.  Three criteria \nare given for A(0)-stability.  It is shown that (1) for\np=k, k arbitrary, A(inf)-stability implies certain \nnecessary conditions for A(0)-stability and for strict\nstability (meaning that the extraneous roots of \np(psi) satisfy |psi|<1); (2) for p=k=2,3,4,and 5, A(inf)-stability\n(for k=5 together with another constraint) \nimplies strict stability; and (3) for certain one-parameter\nclasses of formulas with p=k=3,4,and/or 5, \nA(inf)-stability implies A(0)-stability.\n stiff equations, parametrized linear multistep formulas,\norder of accuracy, A(0)-stability, A(inf)-stability, \nstrict stability\n", "2801": "Storage-Efficient Representation of Decimal Data Usually n decimal digits are represented by\n4n bits in computers.  Actually, two BCD digits \ncan be compressed optimally and reversibly into 7 bits,\nand three digits into 10 bits, by a very simple \nalgorithm based on the fixed-length combination of two\nvariable field-length encodings.  In over half \nof the cases the compressed code results from the conventional\nBCD code by simple removal of redundant \n0 bits.  A long decimal message can be subdivided into\nthree-digit blocks, and separately compressed; \nthe result differs from the asymptotic minimum length\nby only 0.34 percent.  The hardware requirement \nis small, and the mappings can be done manually.\n binary-coded decimal digits, decimal data storage\n", "2802": "The New Math of Computer Programming Structured programming has proved to be an important\nmethodology for systematic program design \nand development.  Structured programs are identified\nas compound function expressions in the algebra \nof functions. The algebraic properties of these function\nexpressions permit the reformulation (expansion \nas well as reduction) of a nested subexpression independently\nof its environment, thus modeling what \nis known as stepwise program refinement as well as program\nexecution.  Finally, structured programming \nis characterized in terms of the selection and solution\nof certain elementary equations defined in the \nalgebra of functions.  These solutions can be given in\ngeneral formulas, each involving a single parameter, \nwhich display the entire freedom available\nin creating correct structured programs.\n structured programming, algebra of functions,\nstepwise refinement, program correctness\n", "2803": "Pseudoinverses and Conjugate Gradients This paper is devoted to the study of connections\nbetween pseudoinverses of matrices and conjugate \ngradients and conjugate direction routines.\n pseudoinverse, conjugate gradients, hermitian matrix, minimization\n", "2804": "Elementary Divisors of Tensor Products The elementary divisors of a tensor product\nof linear transformations have been known for 40 \nyears.  This paper provides a short, easily accessible\nproof of these results, and points out an interesting \ncombinatorial consequence of the proof.\n elementary divisors, tensor products, linear transformations\n", "2805": "Perturbations of Eigenvalues of Non-normal Matrices The problem considered is to give bounds for finite\nperturbations of simple and multiple eigenvalues \nof nonnormal matrices, where these bounds are in terms\nof the eigenvalues, the departure from normality, \nand the Frobenius norm of the perturbation matrix, but\nnot in terms of the eigen system.  The bounds which \nare derived are shown to be almost attainable for any set of matrices. \n perturbation of eigenvalues, non-normal matrices,\ndeparture from normality, Gershgorin circles\n", "2806": "Two Hadamard Numbers for Matrices A discussion is given of two functions of the entries\nof a square matrix, both related to Hadamard's \ndeterminant theorem, which have some merits as alternatives\nto norm-bound \"condition numbers.\"  One (for \nlinear systems) is known; the other (for eigen systems) seems to be new.\n matrices, eigenvalues, norms, condition numbers,\nerror analysis, Gram-Schmidt orthogonalization\n", "2807": "On the Stability of Gauss-Jordan Elimination with Pivoting The stability of the Gauss-Jordan algorithm\nwith partial pivoting for the solution of general \nsystems of linear equations is commonly regarded as suspect.\n It is shown that in many respects suspicions \nare unfounded, and in general the absolute error in the solution\nis strictly comparable with that corresponding \nto Gaussian elimination with partial pivoting plus back\nsubstitution.  However, when A is ill conditioned, \nthe residual corresponding to the Gauss-Jordan solution\nwill often be much greater than that corresponding \nto the Gaussian elimination solution.\n Gauss-Jordan algorithm, Gaussian elimination, back-substitution,\nbackward error analysis, bounds \nfor error in solution, bound for residual \n", "2808": "The Lemniscate Constants The lemniscate constants, and indeed some\nof the methods used for actually computing them, \nhave played an enormous part in the development of\nmathematics.  An account is given here of some of \nthe methods used-most of the derivations can be made\nby elementary methods.  This material can be used \nfor teaching purposes, and there is much relevant and\ninteresting historical material.  The acceleration \nmethods developed for the purpose of evaluating\nthese constants are useful in other problems.\n lemniscate, acceleration, elliptic functions, Euler transformation\n", "2809": "Positivity and Norms Following some lines of joint work with A.\nS. Householder, the character and use of algebraic \nmethods in the theory of norms is demonstrated.  New results\nconcerning norms with values in an Archimedian \nvector lattice (not necessarily being totally ordered)\nare given, in particular for the generalization \nof order unit norms, L-norms and M-norms.  An example\nof application to operator norms is given concerning \ncontraction properties of positive operators.\n matrices, norms, positivity, numerical range, positivity\ncones, vector lattice,absolute, monotonic\n", "2810": "Professionalism in the Computing Field The term professional means different things\nto different people; nevertheless, there are certain \ngeneral technical and social standards normally associated\nwith a professional.  Further, the term is \nmore generally applied to the practitioner rather than\nto the researcher.  But within the rather broad \ndefinition specified, the computing practitioner is,\nas yet, not regarded as a professional.  Each of \nthe four types of institutions-academic, industry, government,\nand the professional society- that educate,\nemploy, regulate, and mold the practitioner contributes\nto the \"nonprofessional\" status of the computing \npractitioner.  The roles of these institutions are examined,\nvarious shortcomings are noted, and recommended \nchanges are suggested.  In the last analysis, professional\nstatus is not bestowed; it is earned.  However, \nuniversities and industry, specifically, can make certain\n improvements to help the computing practitioner \nachieve professional status.\n professional aspects, educational programs, industry\nattitudes, professional societies, licensing \nand certification\n", "2811": "Structural Pattern Recognition Of Carotid Pulse A general waveform parsing system with application\nto structural pattern recognition of carotid \npulse waves is described.  The carotid arterial pulse\nwave is of medical importance because of variation \nin its structure induced by arterial aging and cardiovascular\ndisease.  The syntax-driven waveform analysis \nsystem has been applied with good results to these pulse\nwaves to detect and measure structural variations. \n The waveform parsing system is modeled on a compiler-compiler\nsystem and allows the user to enter application \nspecific information as data.  It is thus general\nenough to be applicable to other waveforms.\n structural pattern recognition, parsing, waveform analysis, pulse waves\n", "2812": "Computer-Aided Analysis and Design of Information Systems This paper describes the use of computer-aided\nanalysis for the design and development of an \nintegrated financial management system by the Navy Material\nCommand Support Activity (NMCSA).  Computer-aided \nanalysis consists of a set of procedures and computer\nprograms specifically designed to aid in the process \nof applications software design, computer selection\nand performance evaluation.  There are four major \ncomponents: Problem Statement Language, Problem Statement\nAnalyzer, Generator of Alternative Designs, \nand Performance Evaluator. The statement of requirements\nwas written in ADS (Accurately Defined Systems) \nand analyzed by a Problem Statement Analyzer for ADS.\n The ADS problem definition was supplemented with \nadditional information in order to create a complete\nproblem definition.  The analyzed problem statement \nwas translated to the form necessary for use by the\nSODA (Systems Optimization and Design Algorithm)\nprogram for the generation of alternative specifications\nof program modules and logical database structures.\n computer-aided analysis, information systems, logical\nsystem design, problem statement language, \nproblem statement analyzer, physical system design,\naccurately defined systems, systems optimization \nand design algorithm\n", "2813": "The Computer Science and Engineering Research Study (COSERS) The Computer Science and Engineering Research\nStudy (COSERS) is briefly described.  The motivation, \norganization, and schedule for this NSF supported study\nare given.  For possible further reference, the \nsubject area panel chairmen and the members\nof the Steering Committee are identified.\n computer science research, computer engineering\nresearch, national research study\n", "2814": "Roster of Programming Languages for 1974-75 ", "2815": "High-Level Binding with Low-Level Linkers An easy to implement scheme is described by\nwhich a compiler can enforce agreement between \ncomplex data types in separately compiled modules.\n The scheme is designed to work with any existing \nlink editor or linking loader, no matter how deficient.\n Obscure run-time errors caused by inconsistent \nusages are forestalled by static errors detected at linking time.\n separate compilation, binding, linking, strong typing\n", "2816": "Optimal Reorganization of Distributed Space Disk Files In most database organizations, the cost of accessing\nthe database will increase due to structural \nchanges caused by updates and insertions.  By reorganizing\nthe database,the access costs can be reduced. \n A basic problem is to establish the proper tradeoff between\nperformance, storage costs, and reorganization \ncosts.  This paper considers the optimum points at which\nto reorganize a database.  A disk file organization \nwhich allows for distributed free space is described.\n A cost function describing the excess costs due \nto physical disorganization is defined, and this function\nis minimized to obtain the optimum reorganization \npoints.  Numerical examples based on the characteristics\nof existing disk storage devices are given.\n disk file, free space,retrieval, insertion, deterioration, reorganization\n", "2817": "The Notions of Consistency and Predicate Locks in a Database System In database systems, users access shared data\nunder the assumption that the data satisfies \ncertain consistency constraints.  This paper defines the\nconcepts of transaction, consistency and schedule \nand shows that consistency requires that a transaction\ncannot request new locks after releasing a lock. \n Then it is argued that a transaction needs to lock a logical\nrather than a physical subset of the database. \n These subsets may be specified by predicates.  An\nimplementation of predicate locks which satisfies \nthe consistency condition is suggested.\n consistency, lock, database, concurrency, transaction\n", "2818": "Interference in Multiprocessor Computer", "2819": "Experiments in Text File Compression A system for the compression of data files,\nviewed as strings of characters, is presented. \n The method is general, and applies equally well to\nEnglish, to PL/I, or to digital data.  The system \nconsists of an encoder, an analysis program, and a decoder.\n  Two algorithms for encoding a string differ \nslightly from earlier proposals.  The analysis program attempts\nto find an optimal set of codes for representing \nsubstrings of the file.  Four new algorithms for this\noperation are described and compared.  Various \nparameters in the algorithms are optimized to obtain\na high degree of compression for sample texts.\n text compression, data file compaction, Huffman\ncodes, N-gram encoding, comparison of algorithms\n", "2820": "The Design and Implementation of a Table Driven, CAPS is a highly interactive diagnostic compiler/interpreter\nthat allows beginning programmers \nto prepare, debug, and execute fairly simple programs\nat a graphics display terminal.  Complete syntax \nchecking and most semantic analysis is performed as\nthe program is entered and as it is subsequently\nedited.  Analysis is performed character by character.\n The most remarkable feature of CAPS is its ability \nto automatically diagnose errors both at compile time\nand at run time.  Errors are not automatically \ncorrected.  Instead, CAPS interacts with the student to help\nhim find the cause of his error.  Most components \nof CAPS are table driven, both to reduce the space needed\nfor implementation and to increase the flexibility \nof the multilingual system.  Over 500 students have used\nCAPS to learn Fortran, PL/I, or Cobolin conjunction \nwith a computer assisted course on introductory computer science.\n interactive programming, table driven compilers,\nerror correction, interpreters, debugging, computer \nassisted instruction, computer science education\n", "2821": "Cobol Under Control A sample set of Cobol programming standards\nis offered.  These standards constrain code to \nbe developed in a \"structured\" form for both data and\ncontrol structures.  They do not require syntax \nbeyond the existing Cobol language and in fact utilize\na typical limited subset of the 1974 ANS Cobol \nstandard.  These standards have proved extremely valuable\nin practice and have reduced the cost and time \nto produce and maintain large software systems that have\nbeen deployed in live multiple customer environments.\n Cobol, structured programming,software development, program standards\n", "2822": "Homilies for Humble Standards Copyright 1976, Association for Computing\nMachinery, Inc. General permission to republish, \nbut not for profit, all or part of this material is granted\nprovided that ACM's copyright notice is given \nand that reference is made to the publication, to its\ndata of issue, and to the fact that reprinting \nprivileges were granted by permission of\nthe Association for Computing Machinery.\n standards, CASE Standards criteria for standards, standardization\n", "2823": "The Status of Women and Minorities in Academic Computer Science The results of a survey concerning women and\nminority students and faculty in computer science \nduring the years 1971 to 1975 are presented.  Analysis\nof the data indicated that effective affirmative \naction programs for recruitment into graduate degree\nprograms are needed to enlarge the number of women \nand minorities qualified for later employment in computer\nscience.  Also, possible discrimination in \nemployment of women and minority graduate students was revealed. \n discrimination against women, discrimination against\nminorities, graduate students, undergraduate \nstudents, academic employment, faculty, computer science\ndegree programs, affirmative action, Title VII, \nTitle IX\n", "2824": "An Improvement to Martin's Algorithm for syntax analysis, precedence functions, Boolean matrices\n", "2825": "The BMD and BMDP Series of Statistical Computer Programs analysis of variance, cluster analysis, contingency\ntables, data analysis, discriminant analysis, \nfactor analysis, graphics, outliers, regression, time series, transformations\n", "2826": "Interactive Skeleton Techniques for Enhancing A significant increase in the capability for\ncontrolling motion dynamics in key frame animation \nis achieved through skeleton control.  This technique\nallows an animator to develop a complex motion \nsequence by animating a stick figure representation\nof an image.  This control sequence is then used \nto drive an image sequence through the same movement.\n The simplicity of the stick figure image encourages \na high level of interaction during the design stage. \nIts compatibility with the basic key frame animation \ntechnique permits skeleton control to be applied selectively\nto only those components of a composite \nimage sequence that require enhancement.\n interactive graphics, computer generated animation,\nkey frame animation, interactive skeleton control, \nstick figure animation\n", "2827": "A Parametric Algorithm for Drawing Pictures An algorithm for drawing pictures of three-dimensional\nobjects, with surfaces made up of patches \nof quadric surfaces, is described.  The emphasis of\nthis algorithm is on calculating the intersections \nof quadric surfaces. A parameterization scheme is used.\n Each quadric surface intersection curve (QSIC) \nis represented as a set of coefficients and parameter\nlimits.  Each value of the parameter represents \nat most two points, and these may easily be distinguished.\n This scheme can find the coordinates of points \nof even quartic (fourth-order) intersection curves, using\nequations of no more than second order.  Methods \nof parameterization for each type of OSIC are discussed,\nas well as surface bounding and hidden surface \nremoval.\n computer graphics, hidden surface removal,\nquadric surface intersection curves\n", "2828": "Hierarchical Geometric Models for Visible Surface Algorithms The geometric structure inherent in the definition\nof the shapes of three-dimensional objects \nand environments is used not just to define their relative\nmotion and placement, but also to assist in \nsolving many other problems of systems for producing\npictures by computer.  By using an extension of \ntraditional structure information, or a geometric hierarchy,\nfive significant improvements to current \ntechniques are possible.  First, the range of complexity\nof an environment is greatly increased while \nthe visible complexity of any given scene is kept within\na fixed upper limit.  Second, a meaningful way \nis provided to vary the amount of detail presented in\na scene.  Third, \"clipping\" becomes a very fast \nlogarithmic search for the resolvable parts of the environment\nwithin the field of view.  Fourth, frame \nto frame coherence and clipping define a graphical\n\"working set,\" or fraction of the total structure \nthat should be present in primary store for immediate\naccess by the visible surface algorithm.  Finally, \nthe geometric structure suggests a recursive descent,\nvisible surface algorithm in which the computation \ntime potentially grows linearly with the visible complexity of the scene.\n visible surface algorithms, hidden surface algorithms,\nhierarchical data structures, geometric \nmodels\n", "2829": "Texture and Reflection in Computer Generated Images In 1974 Catmull developed a new algorithm\nfor rendering images of bivariate surface patches. \n This paper describes extensions of this algorithm in\nthe areas of texture simulation and lighting models. \n The parameterization of a patch defines a coordinate\nsystem which is used as a key for mapping patterns \nonto the surface.  The intensity of the pattern at each\npicture element is computed as a weighted average \nof regions of the pattern definition function. The shape\nand size of this weighting function are chosen \nusing digital signal processing theory.  The patch rendering\nalgorithm allows accurate computation of \nthe surface normal to the patch at each picture element,\npermitting the simulation of the mirror reflections. \n The amount of light coming from a given direction is\nmodeled in a similar manner to the texture mapping \nand then added to the intensity obtained from the texture\nmapping.  Several examples of images synthesized \nusing these new techniques are included.\n computer graphics, graphic display, shading, hidden surface removal\n", "2830": "A Practitioner's Guide to Addressing Algorithms (Corrigendum)", "2831": "Analysis of the PFF Replacement Algorithm", "2832": "Faster Retrieval from Context Trees (Corrigendum) Context trees provide a convenient way of\nstoring data which is to be viewed as a hierarchy \nof contexts.  This note presents an algorithm which improves\non previous context tree retrieval algorithms. \nIt is based on the observation that in typical uses context\nchanges are infrequent relative to retrievals, \nso that data can be cached to speed up retrieval.  A retrieval\nis started from the position of the previous \nretrieval and auxiliary structures are built up to make\nthe search rapid.  Algorithms for addition and \ndeletion of data and for garbage collection are outlined.\n context trees, frame problem, variable bindings, data structures\n", "2833": "An Efficient, Incremental, Automatic Garbage Collector This paper describes a new way of solving\nthe storage reclamation problem for a system such \nas Lisp that allocates storage automatically from a\nheap, and does not require the programmer to give \nany indication that particular items are no longer useful\nor accessible.  A reference count scheme for \nreclaiming non-self-referential structures, and a linearizing,\ncompacting, copying scheme to reorganize \nall storage at the users discretion are proposed.  The\nalgorithms are designed to work well in systems \nwhich use multiple levels of storage, and large virtual\naddress space.  They depend on the fact that \nmost cells are referenced exactly once, and that reference\ncounts need only be accurate when storage \nis about to be reclaimed.  A transaction file stores changes\nto reference counts, and a multiple reference \ntable stores the count for items which are referenced more than once.\n storage management, garbage collection, Lisp\n", "2834": "Efficient Generation of the Binary Algorithms are presented to generate the n-bit\nbinary reflected Gray code and codewords of \nfixed weight in that code.  Both algorithms are efficient\nin that the time required to generate the next \nelement from the current one is constant.  Applications\nto the generation of the combinations of n things\ntaken k at a time, the compositions of integers, and\nthe permutations of a multiset are discussed.\n Gray code, combinations, subsets, compositions, combinatorial computing\n", "2835": "Recursion Analysis for Compiler Optimization A relatively simple method for the detection\nof recursive use of procedures is presented for \nuse in compiler optimization.  Implementation considerations\nare discussed, and a modification of the \nalgorithm is given to further improve optimization.\n This analysis can also be used to determine what \npossible subset of values could be assumed by variables\nwhich can only take on a relatively small discrete \nset of values.  The most common are parameters of variables\nassuming values of label, procedure, or Pascal's \nenumerated type.\n recursion, compiler optimization\n", "2836": "Weighted Derivation Trees The nodes of a weighted derivation tree are associated\nwith weighting functions over the vocabulary \nof a context-free grammar.  An algorithm is presented\nfor constructing the optimal derivation tree having \nthe same structure as a given weighted derivation tree.\n In addition, the correctness of the algorithm \nis established.  The method may be applied to problems\ninvolving probabilistic parsing or combinatorial \noptimization.\n derivation tree, parse tree, probabilistic grammar,\nstructural ambiguity, combinatorial optimization\n", "2837": "New Upper Bounds for Selection The worst-case minimum number of comparisons\ncomplexity Vi(n) of the i-th selection problem \nis considered.  A new upper bound for Vi(n) improves the\nbound given by the standard Hadian-Sobel algorithm \nby a generalization of the Kirkpatrick-Hadian-Sobel\nalgorithm, and extends Kirkpatrick's method to a \nmuch wider range of application.  This generalization\ncompares favorably with a recent algorithm by Hyafil.\n selection problem, algorithms, comparison problems,\nconcrete computational complexity, upper bounds, \nworst-case analysis\n", "2838": "Analysis of an Algorithm for Real Time Garbage Collection A real time garbage collection system avoids\nsuspending the operations of a list processor \nfor the long times that garbage collection normally requires\nby performing garbage collection on a second \nprocessor in parallel with list processing operations,\nor on a single processor time-shared with them. \n Algorithms for recovering discarded list structures in\nthis manner are presented and analyzed to determine \nsufficient conditions under which the list processor never\nneeds to wait on the collector.  These techniques \nare shown to require at most twice as much processing\npower as regular garbage collectors, if they are \nused efficiently.  The average behavior of the program\nis shown to be very nearly equal to the worst-case \nperformance, so that the sufficient conditions are also\nsuitable for measuring the typical behavior of \nthe algorithm.\n garbage collection, storage reclamation, list\nprocessing, Lisp, time-sharing, multiprocessing, \nparallel processing, real time, data structures, analysis of algorithms\n", "2839": "An Insertion Technique for One-Sided Height-Balanced Trees A restriction on height-balanced binary trees\nis presented.  It is seen that this restriction \nreduces the extra memory requirements by half (from\ntwo extra bits per node to one) and maintains fast \nsearch capabilities at a cost of increased\ntime requirements for inserting new nodes.\n balanced, binary, search, trees\n", "2840": "Protection in Operating Systems A model of protection mechanisms in computing\nsystems is presented and its appropriateness \nis argued.  The \"safety\" problem for protection systems\nunder this model is to determine in a given situation \nwhether a subject can acquire a particular right to\nan object.   In restricted cases, it can be shown \nthat this problem is decidable, i.e. there is an algorithm\nto determine whether a system in a particular \nconfiguration is safe.  In general, and under surprisingly\nweak assumptions, it cannot be decided if \na situation is safe. Various implications of this fact are discussed.\n protection, protection system, operating\nsystem, decidability, Turing machine\n", "2841": "Designing Surfaces in 3-D An experimental system for computer-aided\ndesign of free-form surfaces in three dimensions \nis described. The surfaces are represented in the system\nas parametric basis splines. The principal features \nof the system are: (1) the surfaces are rendered as isoparametric\nline drawings on a head-mounted display, \nand they are designed with the aid of a three-dimensional\n\"wand,\" which allows 3-D movements of the points \ncontrolling the shapes of the surfaces, (2) all of the\ninteractions with the surfaces are in real-time, \nand (3) the mathematical formulations used assume no\nknowledge of them by the user of the system.  Also \nexamined are some of the features that should be part\nof a practical 3-D system for designing space-forms.\n real-time graphics, computer-aided design,\npicture processing, B-splines, 3-D displays\n", "2842": "The Denotational Semantics of Programming Languages This paper is a tutorial introduction to the\ntheory of programming language semantics developed \nby D. Scott and C. Strachey.  The application of the theory\nto formal language specification is demonstrated \nand other applications are surveyed. The first language\nconsidered, LOOP, is very elementary and its \ndefinition merely introduces the notation and methodology\nof the approach.  Then the semantic concepts\nof environments, stores, and continuations are introduced\nto model classes of programming language features \nand the underlying mathematical theory of computation\ndue to Scott is motivated and outlined.  Finally, \nthe paper presents a formal definition of the language GEDANKEN.\n semantics, programming language, applicative, imperative,\nenvironment, store, continuation, theory \nof computation, higher-order function, recursive definition, LOOP, GEDANKEN\n", "2843": "Tools and Philosophy for Software Education  This paper describes a set of tools and a philosophy\nfor teaching software that have been found \nvery useful in course at MIT over the past seven years.\n The tools include programs such as simulators, \ngraders, compilers, and monitor.  These allow the instructor\nto augment the basic concepts with relevant, \nexciting, and economical student project activities. \n software education, simulators, grading programs, student assignments\n", "2844": "Heaps Applied to Event Driven Mechanisms discrete event simulation, event-scanning\nmechanisms, priority queues, heaps\n", "2845": "A Buddy System Variation for Disk Storage Allocation A generalization of the buddy system for storage\nallocation is described. The set of permitted \nblock sizes {SIZE(i)}, i=0,n, must satisfy the condition\nSIZE(i)=SIZE(i-1)+SIZE(i-k(i)) where k may be \nany meaningful integral-valued function.  This makes it\npossible to force logical storage blocks to coincide \nwith physical storage blocks, such as tracks and cylinders.\n buddy system, dynamic storage allocation\n", "2846": "Compressed Tries This paper presents a new data structure,\ncalled a compressed trie or C-trie, to be used in \ninformation retrieval systems.  It has the same underlying\nm-ary tree structure as a trie, where m is \na parameter of the trie, but whereas the fields of the\nnodes in a trie have to be large enough to hold \na key or at least a pointer, the fields in a C-trie are\nonly one bit long.  In the analysis part of the \npaper it will be shown that for a collection of n keys the\nretrieval time, measured in terms of bit inspections \nof one key, is of the order logm(n) and the storage\nrequirement of the order n*(m+log2 n) bits.  This \nimprovement in storage requirements and retrieval time\nis achieved at the cost of decreasing the flexibility \nof the structure, and therefore updating costs are increased.\n First the C-trie is analyzed as a data \nstructure, and then several methods of its use\nfor relatively static databases are discussed.\n data structure, database, m-ary tree, trie,\nretrieval time, storage requirement, keys\n", "2847": "Sampling from the Gamma Distribution on a Computer This paper describes a method of generating\ngamma variates that appears to be less costly than \nWallace's recently suggested method.  For large shape parameter\n(a); the cost of computation is proportional \nto (a), whereas Wallace's method is proportional to (a).\n Experimentation by Robinson and Lewis indicates \nthat for small (a) the method suggested here also dominates\nmethods recently suggested by Dieter and \nAhrens, albeit those methods dominate for large (a).  The\nmethod suggested here uses the rejection technique.\n gamma variates, reflection method, sampling\n", "2848": "Synthesis of Decision Rules Decision tables can be used as an effective\ntool during an interview to record the logic of \nprocesses to be automated.  The result of such an interview\nis not a structure of complete decision tables \nbut rather sets of decision rules.  The purpose of this\npaper is to provide a procedure for synthesizing \nthe decision rules and thus provide an aid in developing\na structure of complete decision tables.\n decision rules, decision tables, logical tables,\nlogical design, system design, specification language\n", "2849": "Ethernet: Distributed Packet Switching for Local Computer Networks Ethernet is a branching broadcast communication\nsystem for carrying digital data packets among \nlocally distributed computing stations. The packet\ntransport mechanism provided by Ethernet has been \nused to build systems which can be viewed as either local\ncomputer networks or loosely coupled multiprocessors. \n An Ethernet's shared communication facility, its Ether,\nis a passive broadcast medium with no central \ncontrol.  Coordination of access to the Ether for packet\nbroadcasts is distributed among the contending \ntransmitting stations using controlled statistical arbitration.\n Switching of packets to their destinations \non the Ether is distributed among the receiving stations\nusing packet address recognition.  Design principles \nand implementation are described, based on experience\nwith an operating Ethernet of 100 nodes along a \nkilometer of coaxial cable.  A model for estimating performance\nunder heavy loads and a packet protocol \nfor error controlled communication are included for completeness.\n computer networks, packet switching, multiprocessing,\ndistributed control, distributed computing, \nbroadcast communication, statistical arbitration\n", "2850": "Symbolic Execution and Program Testing This paper describes the symbolic execution of\nprograms.  Instead of supplying the normal inputs \nto a program (e.g. numbers) one supplies symbols representing\narbitrary values.  The execution proceeds \nas in a normal execution except that values may be symbolic\nformulas over the input symbols.  The difficult, \nyet interesting issues arise during the symbolic execution\nof conditional branch type statements.  A \nparticular system called EFFIGY which provides symbolic\nexecution for program testing and debugging is \nalso described.  It interpretively executes programs written\nin a simple PL/I style programming language. \n It includes many standard debugging features, the ability\nto manage and to prove things about symbolic \nexpressions, a simple program testing manager, and a program\nverifier.  A brief discussion of the relationship \nbetween symbolic execution and program proving is also included.\n symbolic execution, program testing, program debugging,\nprogram proving, program verification, \nsymbolic interpretation\n", "2851": "Formal Verification of Parallel Programs Two formal models for parallel computation\nare presented: an abstract conceptual model and \na parallel-program model.  The former model does not\ndistinguish between control and data states.  The \nlatter model includes the capability for the representation\nof an infinite set of control states by allowing \nthere to be arbitrarily many instruction pointers (or\nprocesses) executing the program.  An induction \nprinciple is presented which treats the control and\ndata state sets on the same ground.  Through the \nuse of \"place variables,\" it is observed that certain\ncorrectness conditions can be expressed without \nenumeration of the set of all possible control states.\n Examples are presented in which the induction \nprinciple is used to demonstrate proofs of mutual exclusion.\n It is shown that assertions-oriented proof \nmethods are special cases of the induction principle.\nA special case of the assertions method, which \nis called parallel place assertions, is shown to be\nincomplete.  A formalization of \"deadlock\" is then \npresented. The concept of a \"norm\" is introduced, which\nyields an extension, to the deadlock problem, \nof Floyd's technique for proving termination.  Also discussed\nis an extension of the program model which \nallows each process to have its own local variables\nand permits shared global variables.  Correctness \nof certain forms of implementation is also discussed.\n An Appendix is included which relates this work \nto previous work on the satisfiability of certain logical formulas.\n parallel program, correctness, verification,\nassertions, deadlock, mutual exclusion, Petrinet\n", "2852": "The Technology of Computer Center Management: A McFarlan and Nolan have made a strong case for\nadding a course on information systems administration \nto the 13 courses proposed by the ACM Curriculum Committee\non Computer Education for Management for Graduate \nProfessional Programs in Information Systems.  This paper\nis a report on a course entitled, \"The Technology \nof Computer Center Management,\" which has been offered\nat Purdue for the past four years.  The course \nis suitable either for graduate professional programs\nin information systems or for graduate professional \nprograms in computer science.\n education, information systems administration, computer\ncenter management, computer system performance\n", "2853": "A Numbering System for Permutations of Combinations combinatorics,coding systems, storage mapping functions\n", "2854": "Multiprocessing Compactifying Garbage Collection (Corrigendum)", "2855": "An Efficient List-Moving Algorithm Using Constant Workspace An efficient algorithm is presented for moving\narbitrary list structures, using no storage \n(apart from program variables) other than that required\nto hold the original list and the copy.  The \noriginal list is destroyed as it is moved.  No mark\nbits are necessary, but pointers to the copy must \nbe distinguishable from pointers to the original.  The\nalgorithm is superior in execution speed to previous \nalgorithms for the same problem.  Some variations\nand extensions of the algorithm are discussed.\n list moving, list copying, LISP, space complexity, constant workspace\n", "2856": "The Synthetic Approach to Decision Table Conversion Previous approaches to the problem of automatically\nconverting decision tables to computer \nprograms have been based on decomposition.  At any\nstage, one condition is selected for testing, and \ntwo smaller problems (decision tables with one less\ncondition) are created.  An optimal program (with \nrespect to average execution time or storage space, for\nexample) is located only through implicit enumeration \nof all possible decision trees using a technique such\nas branch-and-bound.  The new approach described \nin this paper uses dynamic programming to synthesize\nan optimal decision tree from which a program can \nbe created.  Using this approach, the efficiency of creating\nan optimal program is increased substantially, \npermitting generation of optimal programs for decision\ntables with as many as ten to twelve conditions.\n decision tables, decision trees, dynamic programming, optimal programs\n", "2857": "Referencing Lists by an Edge An edge reference into a list structure is a pair\nof pointers to adjacent nodes.  Such a reference \noften requires little additional space, but its use can\nyield efficient algorithms. For instance, a circular \nlink between the ends of a list is redundant\u0019 if the list\nis always referenced by that edge, and list traversal \nis easier when that link is null.  Edge references also\nallow threading of nonrecursive lists, can replace \nsome header cells, and enhance the famous\nexclusive-or-trick to double-link lists\n list processing, circular, doubly linked, overlapping\nsublist, header cell, pointer, cursor\n", "2858": "A Process for the Determination of An algorithm is presented for the assignment\nof instruction addresses and formats under the \nfollowing conditions: (1) the length of the instruction varies\nas a function of the distance of the instruction \nfrom its target; (2) there exists an optimality criterion\nwhich implies some preferential choices subject \nto the addressing constraints.  This may be, for example,\nachieving the smallest number of long instructions, \nin which case the total code length is minimized, or\nminimizing the assigned address of a specified point \nin the program.  The algorithm is suitable for arbitrary\nprogram structure and a choice of optimization \ncriteria.\n variable length addressing, assembler, paging\n", "2859": "Interference in Multiprocessor Computer Systems with Interleaved Memory This paper analyzes the memory interference\ncaused by several processors simultaneously using \nseveral memory modules.  Exect results are computed for\na simple model of such a system.   The limiting \nvalue is derived for the relative degree of memory interference\nas the system size increases.  The model \nof the limiting behavior of the system yields approximate\nresults for the simple model and also suggests \nthat the results are valid for a much larger class of models,\nincluding those more nearly like real systems \nthat the simple model are tested against some measurements\nof program behavior and simulations of systems \nusing memory references from real programs.  The model\nresults provide a good indication of the performance \nthat should be expected from real system of this type.\n memory, memory interference, multiprocessing,\ninterleaved memory, trace driven simulation\n", "2860": "A Practitioner's Guide To Addressing Algorithms This paper consolidates a number of popular\nrules of thumb which have been suggested for the\ndesign of record addressing algorithms, and discusses\nthe applicability of these rules to large commercial \ndatabases.  Guidelines for selecting identifier transformations,\noverflow techniques, loading factors, \nbucket sizes, and loading order and considered.  Particular\nattention is focused on the reasonableness \nof common heuristics for determining primary or secondary\nbucket sizes. A mathematical model which explicitly \nconsiders storage device characteristics and time/space\ncost tradeoffs is used to analyze the effect \nof design parameters on overall system costs.  A\nspecific design example is presented and solved.\n data management, file retrieval, searching, addressing\ntechniques, hashing functions, synonym resolution, \nloading factor, bucket size, heuristic design, rules of thumb\n", "2861": "Production and Employment of Ph.D.'s in Computer Science", "2862": "Analysis of the PFF Replacement Algorithm via a Semi-Markov Model An analytical model is presented to estimate\nthe performance of the Page Fault Frequency (PFF) \nreplacement algorithm.  In this model, program behavior\nis represented by the LRU stack distance model \nand the PFF replacement algorithm is represented by a semi-Markov\nmodel.  Using these models, such parameters \nas the inter-page-fault interval distribution, the\nprobability of the number of distinct pages being \nreferenced during an inter-page-fault interval, etc. are\nable to be analytically determined.  Using these \nmodels to evaluate these parameter values permits study\nof the performance of the replacement algorithm \nby simulating the page fault events rather than every\npage reference event.  This significantly reduces \nthe required computation time in estimating\nthe performance of the PFF algorithm.\n PFF replacement algorithm, semi-Markov\nmodel, simulation of replacement algorithm\n", "2863": "VMIN-An Optimal Variable-Space Page Replacement Algorithm A criterion for comparing variable space page\nreplacement algorithms is presented.  An optimum \npage replacement algorithm, called VMIN, is described and\nshown to be optimum with respect to this criterion. \nThe results of simulating VMIN, Denning's working set,\nand the page partitioning replacement algorithms \non five virtual memory programs are presented to demonstrate\nthe improvement possible over the known \nrealizable variable space algorithms.\n demand paging, performance measurement, multilevel\nmemory systems, virtual memory, working set, \npage replacement algorithms, optimal page replacement\n", "2864": "Characteristics of Program Localities The term \"locality\" has been used to denote that\nsubset of a program's segments which are referenced \nduring a particular phase of its execution.  A program's\nbehavior can be characterized in terms of its \nresidence in localities of various sizes and lifetimes,\nand the transitions between these localities. \n In this paper the concept of a locality is made more explicit\nthrough a formal definition of what constitutes \na phase of localized reference behavior, and by a corresponding\nmechanism for the detection of localities \nin actual reference strings.  This definition provides\nfor the existence of a hierarchy of localities \nat any given time, and the reasonableness of the definition\nis supported by examples taken from actual \nprograms.  Empirical data from a sample of production\nAlgol 60 programs is used to display distributions \nof locality sizes and lifetimes, and these results are\ndiscussed in terms of their implications for the \nmodeling of program behavior and memory management in virtual memory systems.\n program behavior, memory management, locality\n", "2865": "Verifying Properties of Parallel Programs: An Axiomatic Approach An axiomatic method for proving a number\nof properties of parallel programs is presented.  \nHoare has given a set of axioms for partial correctness,\nbut they are not strong enough in most cases. \n This paper defines a more powerful deductive system which\nis in some sense complete for partial correctness. \n A crucial axiom provides for the use of auxiliary variables,\nwhich are added to a parallel program as \nan aid to proving it correct.  The information in a partial\ncorrectness proof can be used to prove such \nproperties as mutual exclusion, freedom from deadlock,\nand program termination.  Techniques for verifying \nthese properties are presented and illustrated by\napplication to the dining philosophers problem.\n structured multiprogramming correctness proofs, program\nverification, concurrent processes, synchronization, \nmutual exclusion, deadlock\n", "2866": "Proving Monitors Interesting scheduling and sequential properties\nof monitors can be proved by using state variables \nwhich record the monitor's history and by defining extended\nproof rules for their wait and signal operations. \n These two techniques are defined, discussed, and applied\nto examples to prove properties such as freedom \nfrom indefinitely repeated overtaking or unnecessary waiting\nupper bounds on queue lengths, and historical \nbehavior.\n monitors, correctness, proof rules, historical variables,\nconcurrency, scheduling, bounded buffer, \nsemaphores, alarm clock, disk head\n", "2867": "Modularization and Hierarchy in a Family of Operating Systems This paper describes the design philosophy\nused in the construction of a family of operating \nsystems. It is shown that the concepts of module and\nlevel do not coincide in a hierarchy of functions. \n Family members can share much software as a result\nof the implementation of run-time modules at the \nlowest system level.\n incremental machine design, module,\ndata type, address space, virtual memory\n", "2868": "Reflections on an Operating System Design The main features of a general purpose multiaccess\noperating system developed for the CDC 6400 \nat Berkeley are presented, and its good and bad points are\ndiscussed as they appear in retrospect.  Distinctive \nfeatures of the design were the use of capabilities\nfor protection, and the organization of the system \ninto a sequence of layers, each building on the facilities\nprovided by earlier ones and protecting itself \nfrom the malfunctions of later ones. There were serious\nproblems in maintaining the protection between \nlayers when levels were added to the memory hierarchy;\nthese problems are discussed and a new solution \nis described.\n operating system, protection, capabilities,\nlayering domains, memory hierarchy, faults\n", "2869": "Security Kernel Validation in Practice A security kernel is a software and hardware\nmechanism that enforces access controls within \na computer system. The correctness of a security kernel\non a PDP-11/45 is being proved.  This paper describes \nthe technique used to carry out the first step of the\nproof: validating a formal specification of the \nprogram with respect to a axioms for a secure system.\n validation, verification, correctness, security\nkernel, formal specification, protection\n", "2870": "A Lattice Model of Secure Information Flow This paper investigates mechanisms that guarantee\nsecure information flow in a computer system. \nThese mechanisms are examined within a mathematical framework\nsuitable for formulating the requirements \nof secure information flow among security classes. The\ncentral component of the model is a lattice structure \nderived from the security classes and justified by the semantics\nof information flow.  The lattice properties \npermit concise formulations of the security requirements\nof different existing systems and facilitate \nthe construction of mechanisms that enforce security.\n The model provides a unifying view of all systems \nthat restrict information flow, enables a classification\nof them according to security objectives, and \nsuggests some new approaches.  It also leads to the construction\nof automatic program certification mechanisms \nfor verifying the secure flow of information through a program.\n protection, security, information flow, security\nclass, lattice, program certification\n", "2871": "Logical Analysis of Programs Most present systems for verification of computer\nprograms are incomplete in that intermediate \ninductive assertions must be provided manually by the\nuser, termination is not proven, and incorrect \nprograms are not treated.  As a unified solution to\nthese problems, this paper suggests conducting a \nlogical analysis of programs by using invariants which\nexpress what is actually occurring in the program. \n The first part of the paper is devoted to techniques\nfor the automatic generation of invariants.  The \nsecond part provides criteria for using the invariants\nto check simultaneously for correctness (including \ntermination) or incorrectness.  A third part examines\nthe implications of the approach for the automatic \ndiagnosis and correction of logical errors.\n logical analysis, invariants, program verification,\ncorrectness, incorrectness, termination, automatic \ndebugging\n", "2872": "A Counterintuitive Example of Computer Paging (Corrigendum)", "2873": "LG: A Language for Analytic Geometry A conversational programming language for analytic\ngeometry is described, together with some \naspects of its implementation.  The language allows\nthe flexible definition of geometric objects and \nelements, computes their parameters, and displays the results.\nIt also provides the capability of specifying \na geometric figure via a collection of parameters and\ndisplaying various loci corresponding to these \nparameters. A third characteristic consists of the possibility\nof using this language to design other \nuser oriented languages.  LG has been specifically designed\nfor use by nonprogrammers; it is easy to \nlearn and very close to the natural language used in geometry.\n interactive programming, problem oriented languages,\ncomputer graphics, interpreters, analytic \ngeometry\n", "2874": "A Comparative Evaluation of Versions of BASIC From its inception, The BASIC language has\ngrown in terms of its usage, scope of usage, and \nits features.  This article compares ten of the current\nversions of BASIC with each other, with two earlier \nversions, and with the proposed standard for minimal\nBASIC. The comparison is arranged by the features \nof the versions and by computational comparison\nof computation and times and processing costs.\n BASIC, interpretive language summary\n", "2875": "Development of an International System copyright of software, patenting of\nsoftware, legal protection of software\n", "2876": "Intentional Resolution of Privacy Protection in Database Systems Traditionally, privacy protection in database\nsystems is understood to be the control over \nwhat information a given user can get from a database.\n This paper is concerned with another, independent, \ndimension of privacy protection, the control over what\na user is allowed to do with a piece of information \nsupplied to him by the database.  The ability to condition\nthe supply of information on its intended \nuse is called here \"intentional resolution\" of privacy\nprotection.  The practical importance of intentional \nresolution is demonstrated by several examples, and its realization\nis discussed.  It is shown that intentional \nresolution can be achieved, but that it involves a radical\nchange from the traditional approach to the \nprocess of user-database interaction.  In particular,\nit appears to be necessary for the database to \nimpose a certain amount of control over the internal\nbehavior of users' programs which interact with \nit.  A model for user-database interaction\nwhich admits such a control is developed.\n protection in database, protection in programming\nlanguages, privacy, security, intentional resolution \nof privacy, interaction with databases\n", "2877": "A Program Data Flow Analysis Procedure The global data relationships in a program\ncan be exposed and codified by the static analysis \nmethods described in this paper.  A procedure is given\nwhich determines all the definitions which can\npossibly \"reach\" each node of the control flow graph\nof the program and all the definitions that are \n\"live\" on each edge of the graph.  The procedure uses\nan \"interval\" ordered edge listing data structure \nand handles reducible and irreducible graphs indistinguishably.\n program optimization, data flow analysis,\nflow graphs, algorithms, compilers\n", "2878": "Joining Policies in a Multipriority Multiclass Batch Computer System Consider a multipriority batch computer system\nwhich users from several different classes may \njoin, its toll, service, and waiting charges.  Such a\nsystem is formulated here as a semi-Markov decision \nprocess, in which the aim of arriving users is to minimize\ntheir expected loss.  The optimal joining \npolicy is one of arriving users who may join the system\nat some of its queues is a control limit policy, \nwith a single control number for any possible queue\nand the user's class; a newly arriving user will \njoin a queue that is not filled up to the control number\ncorresponding to this queue and the user's class. \n In this paper control numbers, as well as lower and upper\nbounds for the control numbers and the capacities \nof the system's queues, are derived.\n priority queues, semi-Markov process, price scheduling, operating system\n", "2879": "Computer Science as Empirical Inquiry: Symbols and Search symbols, search, science, computer science, empirical,\nTuring, artificial intelligence, intelligence, \nlist processing, cognition, heuristics, problem solving\n", "2880": "A Fast Division Technique for Constant Divisors A fast algorithm for division by constant divisors\nis presented.  The method has proved very \nuseful implemented as microcode ona binary machine,\nand can be adapted directly into hardware.  The \nmathematical foundations of the algorithm are presented\nas well as some performance measures.\n constant divisors, division algorithms,\nbit addressable memory, microprogram\n", "2881": "A Counterintuitive Example of Computer Paging A counterexample is exhibited to a natural conjecture\nconcerning the optimal way to group records \ninto pages in the independent reference model of computer\npaging (an organization is said to be optimal \nif the \"least recently used\" miss ratio is minimized).\n least recently used, most likely together, independent\nreference model, storage organization, record \nallocation\n", "2882": "A Stochastic Evaluation Model for Database Experimental work in the valuation of large\nscale data retrieval systems has been scarce due \nto its difficulty and prohibitive cost. This paper\ndiscusses a simulation model of a data retrieval \nsystem which has the effect of significantly reducing\nthe cost of experimentation and enabling research \nnever attempted before.  The model is designed to estimate\nthe retrieval workload of alternative data \nretrieval systems.  These data retrieval systems can\nbe organized under several database organizations, \nincluding inverted list, threaded list, and cellular\nlist organizations and hybrid combinations of these \nsystems.  Effectiveness of the methodology is demonstrated\nby using the model to study the effect of \ndatabase organizations in data retrieval systems.  In particular,\nthe impact of query complexity is analyzed.\n database architecture, database performance and\nevaluation, invented list, threaded list, cellular \nlist, information retrieval, database organizations,\nquery complexity, stochastic model, Monte Carlo \nsimulation\n", "2883": "An Application of Heuristic Search Methods to Edge and Contour Detection This paper presents a method for detecting edges\nand contours in noisy pictures.  The properties \nof an edge are embedded in a figure of merit and the edge\ndetection problem becomes the problem of minimizing \nthe given figure of merit.  This problem can be represented\nas a shortest path problem on a graph and \ncan be solved using well-known graph search algorithms.\n The relations between this representation of \nthe minimization problem and a dynamic programming approach\nare discussed, showing that the graph search \nmethod can lead to substantial improvements in computing\ntime.  Moreover, if heuristic search methods \nare used, the computing time will depend on the amount\nof noise in the picture.  Some experimental results \nare given; these show how various information about the\nshape of the contour of an object can be embedded\nin the figure of merit, thus allowing the extraction\nof contours from noisy picture and the separation \nof touching objects.\n picture processing, pattern recognition, edge\ndetection, contour detection, contour following, \noptimization problems, dynamic programming, shortest\npath, heuristic search methods, problem solving \nmethods\n", "2884": "Permutation Enumeration: Four New Permutation Algorithms Classical permutation enumeration algorithms encounter\nspecial cases requiring additional computation \nevery nth permutation when generating the n! permutations\non n marks.  Four new algorithms have the attribute \nthat special cases occur every n(n-1)permutations. \nTwo of the algorithms produce the next permutation \nwith a single exchange of two marks.  The other two algorithms\ninfrequently exchange more than two marks, \nbut the rules for generating the next permutation are\nvery simple.  Performance tests which have counted \nexecution of assignment statements, comparisons, arithmetic\noperations, and subscripted array references \nhave shown superiority of the new algorithms compared to\nBoothroyd's implementation of M. B. Well's algorithm \nand Ehrlich's implementation of the Johnson-Trotter algorithm.\n permutations, loop-free algorithms\n", "2885": "On Self-Organizing Sequential Search Heuristics This paper examines a class of heuristics for\nmaintaining a sequential list in approximately \noptimal order with respect to the average time required\nto search for a specified element, assuming that \neach element is searched for with a fixed probability\nindependent of previous searches performed.  The \n\"move to front\" and \"transposition\" heuristics are shown\nto be optimal to within a constant factor, and \nthe transposition rule is shown to be the more efficient\nof the two. Empirical evidence suggests that \ntransposition is in fact optimal for any distribution of search probabilities.\n searching, self-organizing, list-processing, heuristics\n", "2886": "Semantic Evaluation from Left to Right This paper describes attribute grammars and their\nuse for the definition of programming languages \nand compilers; a formal definition of attribute grammars\nand a discussion of some of its important aspects \nare included. The paper concentrates on the evaluation\nof semantic attributes in a few passes from left \nto right over the derivation tree of a program.  A\ncondition for an attribute grammar is given which \nassures that the semantics of any program can be evaluated\nin a single pass over the derivation tree, \nand an algorithm is discussed which decides how many\npasses from left to right are in general necessary, \ngiven the attribute grammar. These notions are explained\nin terms of an example grammar which describes \nthe scope rules of Algol 60.  Practical questions, such\nas the relative efficiency of different evaluation \nschemes, and the ease of adapting the attribute grammar\nof a given programming language to the left-to-right \nevaluation scheme are discussed.\n attribute grammars, semantics of programming languages,\nsemantic attributes, left-to-right parsing, \nmultipass compilers, semantic evaluation, semantic conditions\n", "2887": "A Study of Errors, Error-Proneness, and Error Diagnosis in Cobol This paper provides data on Cobol error frequency\nfor correction of errors in student-oriented \ncompilers, improvement of teaching, and changes in programming\nlanguage.  Cobol was studied because of \neconomic importance, widespread usage, possible error-including\ndesign, and lack of research.  The types \nof errors were identified in a pilot study; then, using\nthe 132 error types found, 1,777 errors were \nclassified in 1,4000 runs of 73 Cobol students.  Error\ndensity was high: 20 percent of the types contained \n80 percent of the total frequency, which implies high\npotential effectiveness for software based correction \nof Cobol.  Surprisingly, only four high-frequency errors\nwere error-prone, which implies minimal error \ninducing design. 80 percent of Cobol misspellings were classifiable\nin the four error categories of previous \nresearchers, which implies that Cobol misspellings\nare correctable by existent algorithms.  Reserved \nword usage was not error-prone, which implies minimal\ninterference with usage of reserved words.  Over \n80 percent of error diagnosis was found to be inaccurate.\n Such feedback is not optimal for users, particularly \nfor the learning user of Cobol.\n errors in programming, error correction, Cobol, programming\nlanguage errors, error analysis, diagnostics, \nerror-proneness, error frequency, spelling errors, syntactic\nerrors, learning of programming, teaching \nof programming\n", "2888": "Information Reference Coding Items in business systems have to be identified\nby reference codes, which can later be used \nas data codes and file keys in an associated data processing\nsystem.  In business systems associated \nwith large collections of integrated files (database)\nit is vital to assign codes in a methodical way \nso as to control future extension and changes while maintaining\ncorrect program action. The principles \nof methodical coding are discussed, and the way in\nwhich logical connections between data items must \nbe reflected in the reference code framework is shown\nthrough a set-theoretic information model.\n data, file, reference code, systems\nanalysis, information modeling, database\n", "2889": "Performance of Height-Balanced Trees This paper presents the results of simulations\nthat investigate the performance of height-balanced \n(HB[k]) trees.  It is shown that the only statistic\nof HB[1] trees (AVL trees) that is a function of \nthe size of the tree is the time to search for an item\nin the tree.  For sufficiently large trees, the \nexecution times of all procedures for maintaining HB[1]\ntrees are independent of the size of the tree. \n In particular, an average of .465 restructures are required\nper insertion, with an average of 2.78 nodes \nrevisited to restore the HB[1] property; an average of\n .214 restructures are required per deletion, with \nan average of 1.91 nodes revisited to restore the HB[1]\nproperty.  Moreover,the execution times of procedures \nfor maintaining HB[k] trees, for k>1, are also independent\nof the size of the tree except for the average \nnumber of nodes revisited on a delete operation in\norder to restore the HB[k] property on trace back. \n The cost of maintaining HB[k] trees drops sharply as the\nallowable imbalance (k) increases.  Both analytical \nand experimental results that show the cost of maintaining\nHB[k] trees as a function of k are discussed.\n HB[k] trees, balanced trees, AVL trees,\ninformation storage and retrieval, searching\n", "2890": "On Quadratic Adaptive Routing Algorithms Two analytic models of a store-and-forward communications\nnetwork are constructed, one to find \nthe optimal message routing and the other to illustrate\nthe equilibrium (stationary state) maintained \nby an adaptive routing algorithm.  These models show that\nadaptive routing does not satisfy the necessary \nconditions for an optimal routing,  Adaptive routing tends\nto overuse the direct path and underuse alternate \nroutes because it does not consider the impact of its\ncurrent routing decision on the future state of \nthe network.  The form of the optimality conditions suggests\nthat a modification of the adaptive algorithm \nwill result in optimality.  The modification requires\nthe substitution of a quadratic bias term instead \nof a linear one in the routing table maintained at each\nnetwork node.  Simulation results are presented \nwhich confirm the theoretical analysis for a simple network.\n routing algorithms, adaptive routing, quadratic routing,\nalternate routing, store-and-forward network, \ndistributed network, computer network, message switching\n", "2891": "An Anomaly in Disk Scheduling: A Comparison of A model for disk accesses based on published\nmeasurements is developed.  The model is used \nto show that under highly probable conditions, FCFS\nseek scheduling is superior to SSTF scheduling in \nthe sense of having a lower mean queue length.  A simple\nexample of an arrival sequence illustration \nthis anomaly is presented.\n disks, disk scheduling, seek scheduling\n", "2892": "A Study of Line Overhead in the Arpanet The form, extent, and effect of the communication line\noverhead in the ARPANET are considered. \n The source of this over head is separated into various\nlevels of protocol hierarchy and the characteristics \nof each level are summarized.  Then the line efficiency\nfor various models of system use is studied. \n Some measurements of line efficiency for the ARPANET are\npresented and by extrapolation these measurements \nare used to anticipate overhead in a heavily loaded network.\nSimilar results are derived for a recently \nproposed network protocol and compared with those for the current system.\n ARPANET, computer communication networks, interprocess\ncommunication, measurement, packet switching, \nperformance evaluation and efficiency, resource sharing\n", "2893": "Computers as an Innovation in American Local Governments Computers and electronic data processing are\na major technological innovation in the operations \nof American local government. This paper establishes that\nthere is substantial variation among the larger \nlocal governments in the rate at which they adopt computer\ntechnology, in the level of financial support \nthey provide for EDP, and in the extensiveness and sophistication\nof their automated applications.  The \ncentral question addressed is: What might explain the\ndifferences between governments in the extent to \nwhich they adopt and use computers?  Hypotheses are\ntested for several streams of explanatory factors, \nusing data from more than 500 city and county governments.\n The findings identify certain local government \nmilieus which are particularly conducive to higher levels\nof computer innovation.  Somewhat unexpected \nfindings reveal the significant impact of the distribution\nof control over EDP decisions and the dominant \npolitical values within the government. Other important\nfactors include the measured need for computer \napplications and the presence of external funding support\nfor computing.  Finally, the paper suggests \na framework for identifying the key determinants\nof other technological innovations.\n innovation, technological innovation, computer utilization,\ncomputer adoption, American local government, \ncity government computers, county government computers.\n", "2894": "A Methodology for Interactive Computer Service Measurement A measurement methodology applicable to in teractive\ncomputer service is described.  Its primary \npurpose is to enable external, user-oriented assessment\nof computer performance, instead of the more \nfrequently used in ternal system measurement techniques.\n The NBS Network Measurement System is employed \nas the external measurement tool.  Example data have\nbeen collected and analyzed.  A demonstration of \nthe methodology, leading to a pragmatic figure-of-merit\nevaluation of results, is included.\n in teractive system, computer service, measurement,\nperformance, external measurement, methodology, \nmeasurement model,network measurement system, measures, figure-of-merit.\n", "2895": "A Language for Formal Problem Specification A language for specifying the in tended behavior\nof communicating parallel processes is described. \n The specifications are constrain ts on the order in which\nevents of a computation can occur.  The language \nis used to write specifications of the readers/writers\nproblem and the writer priority of the second \nreaders/writers problem.\n formal specifications,program correctness, parallel\nprocessing, synchronization, readers/writers \nproblem\n", "2896": "An Exercise in Proving Parallel Programs Correct A parallel program, Dijkstra's on-the-fly garbage\ncollector, is proved correct using a proof \nmethod developed by Owicki.  The fine degree of in terleaving\nin this program makes it especially difficult \nto understand, and complicates the proof greatly.  Difficulties\nwith proving such parallel programs correct \nare discussed.\n garbage collection, multiprocessing, program\ncorrectness for multiprocessing tasks\n", "2897": "A Case Study of a New Code Generation Technique for Compilers Recent developments in optimizing techniques\nhave allowed a new design for compilers to emerge. \n Such a compiler translates the parsed source code into\nlower level code by a sequence of steps.  Each \nstep expands higher level statements into blocks of\nlower level code and then performs optimizations \non the result.  Each statement has only one possible\nexpansion-the task of tailoring this code to take \nadvantage of any special cases is done by the optimizations.\n This paper provides evidence that this \nstrategy can indeed result in good object code.  The\ntraditionally difficult PL/I concatenate statement \nwas investigated as a detailed example.  A set of fairly\nsimple optimizations was identified which allow \nthe compiler to produce good code. More elaborate optimizations\ncan further improve the object code. \n For most contexts of the concatenate statement, the code\nproduced by a compiler using the expansion-optimization \nstrategy described above compares favorably with the\ncode produced by a conventional PL/I optimizing \ncompiler.\n compiler structure, optimizing compiler, code\ngeneration, PL/I compiler, concatenation, program \noptimization, optimization techniques, data flow analysis\n", "2898": "A Conceptual Framework for a Nonprocedural Programming Language A sequential programming language forces the\nprogrammer to prescribe explicitly the order in \nwhich the operations in his program have to be executed,\neven if the order is not relevant to the solution \nof his problem.  The requirement to indicate irrelevant\nsequencing can be removed if the language provides \nfacilities for specifying a task in a nonprocedural\nmanner.  In general, a program specified in this \nway will allow concurrent evaluation.  This paper describes\na conceptual framework for a high level programming \nlanguage providing both nonprocedural and sequential\nfacilities.  Within a program, nonprocedural and \nsequential program modules may be nested freely.\n parallel programming, descriptive programming,\nnonprocedural programming, definitional language, \ndata flow programming, applicative programming\n", "2899": "A Survey of Computer Science Offerings In Small Liberal Arts Colleges. Recent curricular development in computer science\ntogether with student in terest in pursuing \ntopics in computer science beyond the usual programming\ncourses have encouraged small liberal arts colleges \nto expand their offerings.  This paper summarizes the\nresults of a survey taken to determine the type \nof computer science programs being offered in these\ncolleges.  The results indicate that over half of \nthese colleges either have no computer science\nprogram or offer only programming courses.\n computer science, education, curricula, small colleges\n", "2900": "Some Theorems to Aid in Solving the File Allocation Problem The file allocation problem-i.e. the problem\nof finding the optimal set of network sites at \nwhich to locate copies of a file-is known to be, in general,\npolynomial complete.  Heuristics and other \naids to finding optimal, or near-optimal, solutions are\ntherefore much needed.  In this paper we present \nthree theorems which can be applied a priori to indicate\nthat certain sites should (or should not) be \nincluded in an optimal allocation.\n File allocation, computer networks, distributed data management\n", "2901": "An Encoding Method for Multifield Sorting and Indexing Sequences of character strings with an order\nrelation imposed between sequences are considered. \n An encoding scheme is described which produces a single,\norder-preserving string from a sequence of \nstrings.  The original sequence can be recovered from\nthe encoded string, and one sequence of strings \nprecedes another if and only if the encoding of the first\nprecedes the encoding of the second.  The strings \nmay be variable length, without a maximum length restriction,\nand no symbols need be reserved for control \npurposes.  Hence any symbol may occur in any string.  The\nscheme is useful for multifield sorting, multifield \nindexing, and other applications where ordering\non more than one field is important.\n Sorting multifield indexes, lexicographic order, searching, encoding\n", "2902": "Dynamic Memory Allocation in Computer Simulation This paper investigates the performance of\n35 dynamic memory allocation algorithms when used \nto service simulation programs as represented by 18\ntest cases.  Algorithm performance was measured in\nterms of processing time, memory usage, and external memory\nfragmentation.  Algorithms main taining separate \nfree space lists for each size of memory block used\ntended to perform quite well compared with other \nalgorithms.  Simple algorithms operating on memory ordered\nlists (without any free list) performed surprisingly \nwell.  Algorithms employing power-of-two block sizes\nhad favorable processing requirements but generally \nunfavorable memory usage.  Algorithms employing LIFO, FIFO,\nor memory ordered free lists generally performed \npoorly compared with others.\n algorithm performance,dynamic memory allocation, dynamic\nmemory management, dynamic storage allocation, \ngarbage collection, list processing, memory allocation,\nmemory management, programming techniques, simulation, \nsimulation memory management, simulation techniques,\nspace allocation, storage allocation\n", "2903": "Improving Programs by the Introduction of Recursion A new technique of program transformation,\ncalled \"recursion in troduction,\" is described and \napplied to two algorithms which solve pattern matching problems.\n By using recursion in troduction, algorithms \nwhich manipulate a stack are first translated into\nrecursive algorithms in which no stack operations \noccur.  These algorithms are then subjected to a second\ntransformation, a method of recursion elimination \ncalled \"tabulation,\" to produce programs with a very\nefficient running time.  In particular, it is shown \nhow the fast linear pattern matching algorithm of Knuth,\nMorris, and Pratt can be derived in a few steps \nfrom a simple nonlinear stack algorithm.\n program transformation, optimization of programs,\nrecursion elimination, pattern matching algorithms, \nstacks, computational induction\n", "2904": "An Algorithm for Reduction of Operator Strength A simple algorithm which uses an indexed temporary\ntable to perform reduction of operator strength \nin strongly connected regions is presented.  Several extensions,\nincluding linear function test replacement, \nare discussed.  These algorithms should fit well into an\nintegrated package of local optimization algorithms.\n compilers, optimization of compiled code, program analysis,\noperator strength reduction, test replacement, \nstrongly connected region\n", "2905": "Perfect Hashing Functions: A Single A refinement of hashing which allows retrieval\nof an item in a static table with a single probe \nis considered.  Given a set I of identifiers, two methods\nare presented for building, in a mechanical \nway, perfect hashing functions, i.e. functions transforming\nthe elements of I into unique addresses. \n The first method, the \"quotient reduction\" method, is\nshown to be complete in the sense that for every \nset I the smallest table in which the elements of I\ncan be stored and from which they can be retrieved \nby using a perfect hashing function constructed by this\nmethod can be found.  However, for nonuniformly \ndistributed sets, this method can give rather sparse tables.\n The second method, the \"remainder reduction\" \nmethod, is not complete in the above sense, but it seems\nto give minimal (or almost minimal) tables for \nevery kind of set.  The two techniques are applicable\ndirectly to small sets.  Some methods to extend \nthese results to larger sets are also presented.  A rough\ncomparison with ordinary hashing is given which \nshows that this method can be used conveniently\nin several practical applications.\n hashing, hashing methods, hash coding, direct addressing,\nidentifier-to-address transformations, \nperfect hashing functions, perfect hash coding, reduction, scatter storage\n", "2906": "A Very High Level Programming Language for Data Processing Applications Application development today is too labor-in tensive.\n In recent years, very high-level languages \nhave been increasingly explored as a solution to this\nproblem.  The Business Definition Language (BDL) \nis such a language, one aimed at business data processing\nproblems.  The concepts in BDL mimic those \nwhich have evolved through the years in businesses using\nmanual methods.  This results in three different \nsublanguages or components: one for defining the business\nforms, one for describing the business organization, \nand one for writing calculations.\n very high level language, nonprocedural language,\ndata flow language, business application, business \ndata processing, structured programming, modular programming,\nformat specification, and design methodology\n", "2907": "The Optimal Approach to Recursive Programs The classical fixed poin t approach toward recursive\nprograms suggests choosing the \"least defined \nfixed poin t\" as the most appropriate solution to a recursive\nprogram.  A new approach is described which \nin troduction an \" optimal fixed point,\" which, in contrast\nto the least defined fixed poin t, embodies the \nmaximal amount of valuable information embedded in the\nprogram.  The practical implications of this approach \nare discussed and techniques for proving properties\nof optimal fixed poin t are given.  The presentation \nis informal, with emphasis on examples.\n recursive programs, fixed poin ts, least fixedpoints,\noptimal fixed poin ts, proof techniques\n", "2908": "A Note On Reflection-Free Permutation Enumeration permutations, reflection-free generation\n", "2909": "What Can We Do about the Unnecessary Diversity syntactic description language, extended BNF\n", "2910": "Equivalence of Hough Curve Detection to Template Matching picture processing, pattern recognition, curve\ndetection, Hough transformation, template matching\n", "2911": "Anomalous Behavior of the Fifty-Percent This paper reports simulation data showing\nthat, in dynamic memory allocation, the average \nfree-to-allocated-block ratio can differ considerably\nand in both directions from the predictions of \nthe 50 percent rule.  A new derivation is given, and it\nis shown that previous derivations make an assumption \nthat may be violated frequently.  On the basis of the simulation\ndata and the derivation, it is hypothesized \nthat the anomalous behavior results from the combined\neffects of systematic placement and the statistics \nof the release process.  Additional simulations support\nthis hypothesis.  Systematic placement, which \nrefers to the natural convention of always allocating\nstorage requests against the same end of the free \nblock selected by the allocation strategy, tends to\norder blocks within contiguous groups according to \ntheir allocation time.  The degree of anomalous behavior\ndepends on the extent to which allocated blocks \nare released in the order of their allocation.  For\nnon-Markovian release processes, the extent of the \ncorrelation between allocation order and release order\nvaries approximately inversely with the coefficient \nof variation of the memory residence time distribution.\n The simulations show that allocation efficiency \ndepends strongly on the residence time distribution; efficiency\ndecreases as the distribution's coefficient \nof variation increases.  Some practical implications are briefly discussed.\n dynamic memory allocation, storage fragmentation,\nfifty-percent rule, first-fit, simulation\n", "2912": "Concurrent Reading and Writing The problem of sharing data among asynchronous\nprocess is considered.  It is assumed that only \none process at a time can modify the data, but concurrent\nreading and writing is permitted.  Two general \ntheorems are proved, and some algorithms are presented\nto illustrate their use.  These include a solution \nto the general problem in which a read is repeated if\nit might have obtained an incorrect result, and \ntwo techniques for transmitting messages between processes.\n These solutions do not assume any synchronizing \nmechanism other than data which can be written\nby one process and read by other processes.\n asynchronous multiprocessing, multiprocess synchronization,\nreaders/writers problem, shared data\n", "2913": "The Aliasing Problem in Computer-Generated Shaded Images Certain defects, such as jagged edges and\ndisappearing detail, have long been an annoyance \nin digitally generated shaded images.  Although increasing\nthe resolution or defocusing the display can \nattenuate them, an understanding of these defects leads\nto more effective methods.  This paper explains \nthe observed defects in terms of the aliasing phenomenon\ninherent in sampled signals and discusses prefiltering \nas a recognized cure.  A method for evaluating filters\nis presented, the application of prefiltering \nto hidden-surface algorithms is discussed, and an implementation\nof a filtering tiler is shown accompanied \nby examples of its effectiveness.\n aliasing, computer graphics, convolutional\nfiltering, hidden-surface removal, sampling\n", "2914": "Use of the LRU Stack Depth Distribution Two families of probability distributions were\nneeded for use by a virtual memory simulation \nmodel: headway between page fault distributions, and\nworking set size distributions.  All members of \nboth families can be derived from the LRU stack depth distribution.\n Simple expressions for the computation \nof both kinds of distributions are given.  Finally, examples\nare given of both families of distributions \nas computed from a published stack depth distribution.\n virtual memory, paging, LRU stack, working set, headway\nbetween page faults, computer system simulation\n", "2915": "Considerations for Future Programming Language Standards Activities This paper reviews the current state of programming\nlanguage standards activities with respect \nto the anomalies which exist between the various published\nand proposed standards for Fortran, Cobol, \nPL/I, and Basic.  Proposals are made for the inclusion\nof formalisms within future standards and the \nextension of the standards to include additional items\nsuch as error conditions and documentation.\n programming languages, standards, formalisms,\nformal descriptions, Fortran, Cobol, PL/I, Basic, \nVienna Definition Language (VDL)\n", "2916": "A Fast String Searching Algorithm An algorithm is presented that searches for\nthe location, \"i,\" of the first occurrence of a \ncharacter string, \"pat,\" in another string, \"string.\"\n During the search operation, the characters of \npat are matched starting with the last character of\npat.  The information gained by starting the match \nat the end of the pattern often allows the algorithm\nto proceed in large jumps through the text being \nsearched.  Thus the algorithm has the unusual property that,\nin most cases, not all of the first i characters \nof string are inspected.  The number of characters actually\ninspected (on the average) decreases as a \nfunction of the length of pat.  For a random English\npattern of length 5, the algorithm will typically \ninspect i/4 characters of string before finding a match at\ni.  Furthermore, the algorithm has been implemented \nso that (on the average) fewer than i+patlen machine\ninstructions are executed.  These conclusions are \nsupported with empirical evidence and a theoretical\nanalysis of the average behavior of the algorithm. \n The worst case behavior of the algorithm is linear in\ni+patlen, assuming the availability of array space \nfor tables linear in patlen plus the size of the alphabet.\n bibliographic search, computational complexity,\ninformation retrieval, linear time bound, pattern \nmatching, text editing\n", "2917": "SITAR: An Interactive Text Processing", "2918": "Multiprocessor Memory Organization and Memory Interference The structure of shared memory in a multiprocessor\ncomputer system is examined with particular \nattention to nonin terleaved memory.  Alternative memory\norganizations are compared and it is shown that \na home memory organization, in which each processor\nis associated with one or more memories in which \nits address space is concentrated, is quite effective in\nreducing memory in terference.  Home memory organization \nis shown to be particularly suited to certain specialized\ncomputation problems as well as to possess \nadvantages in terms of in terference and reliability for\ngeneral purpose computation.  Results for in terleaved \nmemory are drawn from previous work and are used for\ncomparison.  Trace-driven simulations are used to \nverify the conclusions of the analysis.\n memory in terference, interleaving, multiprocessing,\ntrace-driven simulation, queueing theory, shared \nmemory\n", "2919": "The Programmer's Workbench-A Machine for Software Development On almost all software development projects the\nassumption is made that the program development \nfunction will be done on the same machine on which the\neventual system will run.  It is only when this \nproduction machine is unavailable or when its programming\nenvironment is totally inadequate that alternatives \nare considered.  In this paper it is suggested that\nthere are many other situations where it would be \nadvantageous to separate the program development and\nmain tenance function onto a specialized computer \nwhich is dedicated to that purpose.  Such a computer\nis here called a Programmer's Workbench.  The four \nbasic sections of the paper in troduce the subject,outline\nthe general concept, discuss areas where such \nan approach may prove beneficial, and describe\nan operational system utilizing this concept.\n computer configurations, computer networks, software\ndevelopment, software engineering, software \nmain tenance, UNIX\n", "2920": "Game Interpretation of the Deadlock Avoidance Problem The deadlock avoidance problem may be defined\ninformally as the determination, from some a \npriori information about the processes, resources, operating\nsystem, etc., of the \"safe situations\" which \nmay be realized without endangering the smooth running\nof the system.  When each process specifies its \nfuture needs by a flowchart of need-defined steps, a global\napproach to the phenomenon and its in terpretation \nas a game between the operating system and the processes\nallows formalization of risk and safety concepts. \n The bipartite graph representation of this game may\nthen be used to construct explicitly the set of safe \nstates and to study their properties.\n operating system, multiprogramming, time-sharing,\nresource allocation, deadlock, in terlock, deadly \nembrace, deadlock avoidance, flowchart\n", "2921": "Regular Right Part Grammars and Their Parsers This paper in troduces an alternative to context-free\ngrammars called regular right part (RRP) \ngrammars, which resemble PASCAL syntax diagrams.  Formally,\nRRP grammars have production right parts, \nwhich are nondeterministic finite state machines (FSMs),\nand, as a special case, regular expressions, \nsince these can be converted to FSMs.  RRP grammars\ndescribe the syntax of programming languages more \nconcisely and more understandably than is possible with\nCF grammars.  Also in troduced is a class of parsers, \nRRP LR(m, k) parsers, which includes the CF LR(k) parsers\nand provides the same advantages.  Informally, \nan RRP LR(m, k) parser can determine the right end of\neach handle by considering at most k symbols to \nthe right of the handle and the left end, after the\nright end has been found, by considering at most \nm symbols to the left of the handle.  A mechanism for\ndetermining the left end is required because there \nis no bound on the length of the handle.\n finite state machines (automata), regular expressions,\nsyntax diagrams,LR(k) grammars, parser construction, \nparsing, programming languages, language generation,\nformal definition, compilers, translators, scanners\n", "2922": "Two-Level Control Structure for Nondeterministic Programming The basic ideas of nondeterministic programming\nare critically reconsidered to single out a \nproper attitude and programming style for language allowing\ndirect control of nondeterministic features. \n The proposed attitude aims at retaining the purity of\nthe nondeterministic formulation of search processes \non one level (the attempt level), deferring the coordination\nof problem solving efforts to another (the \nchoice level).  The feasibility of recognizing these two\nlevels is discussed, stressing that the structure \nto be managed at the choice level is a free of contexts.\n The leaves are computational environments, \neach holding an alternative under inspection, while\nthe other nodes are associated with choice poin ts. \n According to the proposed programming style, a generative\nfunction is associated with each choice poin t, \nwhich expresses the desired choice strategy. The main\nadvantage on this approach is the localization \nof the search strategies: Each nonterminal node of the\ntree keeps track of the state of the computation \nas it was when the choice poin t was last interrogated,\nholding at the same time the strategy to coordinate \nthe available alternatives.  Examples are given in\nterm of ND-Lisp, an extension of Lisp designed and \nimplemented according to these guidelines.\n nondeterministic programming, artificial in telligence,\ncontrol structures, backtracking, search \nstrategy planning, context tree\n", "2923": "High-Level Data Flow Analysis In contrast to the predominant use of low-level\nin termediate text, high-level data flow analysis \ndeals with programs essentially at source level and\nexploits the control flow information implicit in \nthe parse tree.  The need for high-level flow analysis\narises from several aspects of recent work on \nadvanced methods of program certification and optimization.\n This paper proposes a simple general method \nof high-level data flow analysis that allows free use\nof escape and jump statements, avoids large graphs \nwhen compiling large programs, facilitates updating of\ndata flow information to reflect program changes, \nand derives new global information helpful in solving\nmany familiar global flow analysis problems.  An \nillustrative application to live variable analysis is presented.\n Many of the graphs involved are constructed \nand analyzed before any programs are compiled, thus avoiding\ncertain costs that low-level methods incur \nrepeatedly at compile time.\n data flow analysis, high-level language, control\nflow graph, structured programming, escapes, exits, \njumps, goto statements\n", "2924": "An Interactive Computer Graphics Approach to Surface Representation An in teractive computer graphics method has been\ndeveloped for the rapid generation of arbitrary \nshaped three-dimensional surfaces.  The method is a synthesis\nof spline theory and algorithms, an in teractive \nmeans for man-machine communication, and software for\nstatic or dynamic graphics display.  The basic \ntechnique employed is a modified lofting method on\nwhich sectional curves are represented by uniform \nB-splines and the surface is in terpolated between sections\nby Cardinal splines.  Among the features of \nthis method are algorithms which enable in teractive\nmodification of the B-spline representation of the \nsectional curves.  At all stages of the process, the\nspatial information is graphically displayed to \nthe user.  Complex surfaces can be created by the combination\nof a number of shapes that have been separately \ngenerated and automatically joined.  The system has been\nsuccessfully in terfaced to a variety of analytical \nroutines for structural, medical and graphical applications.\n computer graphics, three-dimensional surface representation,\nsplines, lofting,finite element input \nmethods\n", "2925": "Optimal Surface Reconstruction from Planar Contours In many scientific and technical endeavors,\na three-dimensional solid must be reconstructed \nfrom serial sections, either to aid in the comprehension\nof the object's structure or to facilitate its \nautomatic manipulation and analysis.  This paper presents\na general solution to the problem of constructing \na surface over a set of cross-sectional contours. \nThis surface, to be composed of triangular tiles, \nis constructed by separately determining an optimal\nsurface between each pair of consecutive contours.\n Determining such a surface is reduced to the problem\nof finding certain minimum cost cycles in a directed \ntoroidal graph.  A new fast algorithm for finding such\ncycles is utilized.  Also developed is a closed-form \nexpression, in term of the number of contour poin ts, for\nan upper bound on the number of operations required \nto execute the algorithm.  An illustrated example which\ninvolves the construction of a minimum area surface \ndescribing a human head is included.\n surface reconstruction, contour data, serial sections,\nthree-dimensional computer graphics, minimum \ncost paths, continuous tone displays\n", "2926": "Pagination of B*-Trees with Variable-Length Records A strategy is presented for pagination of B*-trees\nwith variable-length records.  If records \nof each length are uniformly distributed within the\nfile, and if a wide distribution of record lengths \nexists within the file, then this strategy results in shallow\ntrees with fast access times.  The performance \nof this strategy in an application is presented, compared\nwith that of another strategy, and analyzed.\n B-tree, index, database, tree storage structure, searching\n", "2927": "Some New Upper Bounds on the Generation of Prime Numbers Given an integer N, what is the computational\ncomplexity of finding all the primes less than \nN?  A modified sieve of Eratosthenes using doubly linked\nlists yields an algorithm of O(N) arithmetic \ncomplexity.  This upper bound is shown to be equivalent\nto the theoretical lower bound for sieve methods \nwithout preprocessing.  Use of preprocessing techniques\ninvolving space-time and additive-multiplicative \ntradeoffs reduces this upper bound to O(N/log logN)\nand the bit complexity to O(N logN log log logN). \n A storage requirement is described using O(N logN/log logN) bits as well.\n computational complexity, sieve, prime number generation,\nnumber theory, linked list, preprocessing, \nbalancing\n", "2928": "Hardware Estimation of a Process' Primary Memory Requirements A minor hardware extension to the Honeywell\n6180 processor is demonstrated to allow the primary \nmemory requirements of a process in Multics to be approximated.\n The additional hardware required for \nthis estimate to be computed consists of a program accessible\nregister containing the miss rate of the \nassociative memory used for page table words.  This\nprimary memory requirement estimate was employed \nin an experimental version of Multics to control the\nlevel of multiprogramming in the system and to bill \nfor memory usage.  The resulting system's tuning parameters\ndisplay configuration insensitivity, and\nit is conjectured that the system would also track shifts\nin the referencing characteristics of its workload \nand keep the system in tune.\n primary memory requirement, virtual memory, level\nof multiprogramming, associative memory, working \nset, resource allocation, LRU stack model, referencing characteristics\n", "2929": "An Analysis of Inline Substitution for a Structured Programming Language An optimization technique known as inline substitution\nis analyzed.  The optimization consists \nof replacing a procedure invocation by a modified copy\nof the procedure body.  The general problem of \nusing inline substitution to minimize execution time\nsubject to size constrain ts is formulated, and an \napproximate algorithmic solution is proposed.  The algorithm\ndepends on run-time statistics about the \nprogram to be optimized.  Preliminary results for the\nCLU structured programming language indicate that, \nin programs with a low degree of recursion, over 90\npercent of all procedure calls can be eliminated, \nwith little increase in the size of compiled code and a\nsmall savings in execution time.  Other conclusions \nbased on these results are also presented.\n inline substitution, open coding, open compilation,\nprogram optimization, compilers, structured \nprogramming languages, run-time statistics\n", "2930": "The GRE Advanced Test in Computer Science This report describes the Advanced Test in\nComputer Science which was recently in troduced in \nthe Graduate Record Examination Program.  The GRE program\nis described in general, and, the events leading \nto the establishment of the Advanced Computer Science\nTest are discussed.  Content specifications and \ntheir rationale are given.  A set of sample questions is included.\n education, computer science, graduate school\nadmissions, test development examinations\n", "2931": "Logic and Programming Languages Logic has been long in terested in whether answers\nto certain questions are computable in principle, \nsince the outcome puts bounds on the possibilities of\nformalization.  More recently, precise comparisons \nin the efficiency of decision methods have become available\nthrough the developments in complexity theory. \n These, however, are applications to logic, and a big question\nis whether methods of logic have significance \nin the other direction for the more applied parts of\ncomputability theory.  Programming languages offer \nan obvious opportunity as their syntactic formalization\nis well advanced; however, the semantical theory \ncan hardly be said to be complete.  Though we have\nmany examples, we have still to give wide-ranging \nmathematical answers to these queries:  What is a machine?\n What is a computable process?  How (or how \nwell) does a machine simulate a process?  Programs naturally\nenter in giving descriptions of processes. \n The definition of the precise meaning of a program\nthen requires us to explain what are the objects \nof computation (in a way, the statics of the problem)\nand how they are to be transformed (the dynamics). \n So far the theories of automata and of nets, though\nmost in teresting for dynamics, have formalized only \na portion of the field, and there has been perhaps too\nmuch concentration on the finite-state and algebraic \naspects.  It would seem that the understanding of higher-level\nprogram features involves us with infinite \nobjects and forces us to pass through several levels\nof explanation to go from the conceptual ideas to \nthe final simulation on a real machine.  These levels\ncan be made mathematically exact if we can find \nthe right abstractions to represent the necessary structures.\n The experience of many independent workers \nwith the method of data types as lattices (or partial\norderings) under an information content ordering, \nand with their continuous mappings, has demonstrated the\nflexibility of this approach in providing definitions \nand proofs, which are clean and without undue dependence\non implementations.  Nevertheless much remains \nto be done in showing how abstract conceptualizations\ncan (or cannot) be actualized before we can say \nwe have a unified theory.\n logic, programming languages, automata, denotational\nsemantics, a-calculus models, computability, \npartial functions, approximation, function spaces\n", "2932": "Complexity of Computations The framework for research in the theory of complexity\nof computations is described, emphasizing \nthe in terrelation between seemingly diverse problems\nand methods.  Illustrative examples of practical \nand theoretical significance are given.  Directions\nfor new research are discussed.\n complexity of computations, algebraic complexity,\nin tractable problems, probabilistic algorithms\n", "2933": "Another Advantage of Keyword Notation for Keyword notation, positional notation, parameters,\ntransmission, subprograms, readability, call \nby value, call by reference, call by name, compile-time errors\n", "2934": "Comment on Computing the k Shortest Paths in a Graph graph, network, shortest path, algorithm, ranking\n", "2935": "Production and Employment of Ph.D.'s", "2936": "An Efficient Data Structure for the Simulation Event Set Recently algorithms have been presented for the\nrealization of event scheduling routines suitable \nfor general purpose discrete event simulation systems.\n Several exhibited a performance superior to that \nof commonly used simple linked list algorithms.  In this\npaper a new event scheduling algorithm is presented \nwhich improves on two aspects of the best of the previously\npublished algorithms.  First, the new algorithm's \nperformance is quite insensitive to skewed distributions,\nand second, its worst-case complexity is O( \nn), where n is the number of events in the set.  Furthermore,\ntests conducted to estimate the average \ncomplexity showed it to be nearly independent of n.\n simulation, time flow mechanisms, event\nscanning mechanisms, multilinked lists\n", "2937": "An Experimental Evaluation of Data Type Conventions The language in which programs are written\ncan have a substantial effect on the reliability \nof the resulting programs.  This paper discusses an experiment\nthat compares the programming reliability \nof subjects using a statically typed language and a \"typeless\"\nlanguage.  Analysis of the number of errors \nand the number of runs containing errors shows that, at\nleast in one environment, the use of a statically \ntyped language can increase programming reliability. \nDetailed analysis of the errors made by the subjects \nin programming solutions to reasonably small problems\nshows that the subjects had difficulty manipulating \nthe representation of data.\n data types, experimentation, language\ndesign, redundancy, reliable software\n", "2938": "Toward a Discipline of Real-Time Programming Programming is divided into three major categories\nwith increasing complexity of reasoning \nin program validation: sequential programming, multiprogramming,\nand real-time programming.  By adhering \nto a strict programming discipline and by using a suitable\nhigh-level language molded after this discipline, \nthe complexity of reasoning about concurrency and execution\ntime constrain ts may be drastically reduced. \n This may be the only practical way to make real-time\nsystems analytically verifiable and ultimately \nreliable.  A possible discipline is outlined and\nexpressed in terms of the language Modula.\n multiprogramming, real-time programming, process synchronization,\nprocessor sharing, program validation, \nModula\n", "2939": "Abstraction Mechanisms in CLU CLU is a new programming language designed to support\nthe use of abstractions in program construction. \n Work in programming methodology has led to the realization\nthat three kinds of abstractions-procedural, \ncontrol, and especially data abstractions-are useful\nin the programming process.  Of these, only the \nprocedural abstraction is supported well by conventional\nlanguages, through the procedure or subroutine. \n CLU provides, in addition to procedures, novel linguistic\nmechanisms that support the use of data and \ncontrol abstractions.  This paper provides an in troduction\nto the abstraction mechanisms in CLU.  By \nmeans of programming examples, the utility of the three\nkinds of abstractions in program construction \nis illustrated, and it is shown how CLU programs may\nbe written to use and implement abstractions.  The \nCLU library, which permits incremental program development\nwith complete type checking performed at compile \ntime, is also discussed.\n programming languages, data types, data abstractions,\ncontrol abstractions, programming methodology, \nseparate compilation\n", "2940": "Abstraction and Verification in Alphard: Defining The Alphard \"form\" provides the programmer with\na great deal of control over the implementation \nof abstract data types.  In this paper the abstraction techniques\nare extended from simple data representation \nand function definition to the iteration statement, the\nmost important poin t of interaction between data \nand the control structure of the language itself.  A\nmeans of specializing Alphard's loops to operate \non abstract entities without explicit dependence on the\nrepresentation of those entities is in troduced. \n Specification and verification techniques that allow\nthe properties of the generators for such iterations \nto be expressed in the form of proof rules are developed.\n Results are obtained that for common special \ncases of these loops are essentially identical to the\ncorresponding constructs in other languages.  A \nmeans of showing that a generator will terminate is also provided.\n abstraction and representation, abstract data types,\nassertions, control specialization, correctness, \ngenerators,invariants, iteration statements, modular\ndecomposition, program specifications, programming \nlanguages, programming methodology, proofs of correctness, types, verification\n", "2941": "Early Experience with Mesa The experiences of Mesa's first users-primarily\nits implementers-are discussed, and some implications \nfor Mesa and similar programming languages are suggested.\nThe specific topics addressed are: module structure \nand its use in defining abstractions, data-structuring\nfacilities in Mesa, an equivalence algorithm for \ntypes and type coercions, the benefits of the type system\nand why it is breached occasionally, and the \ndifficulty of making the treatment of variant records safe.\n programming languages, types, modules,\ndata structures, systems programming\n", "2942": "An Algol-Based Implementation of SNOBOL 4 Patterns patterns SNOBOL 4, pattern matching, string processing,\npattern implementation, algorithms in Pascal\n", "2943": "Lucid, a Nonprocedural Language with Iteration Lucid is a formal system in which programs\ncan be written and proofs of programs carried out. \n The proofs are particularly easy to follow and straightforward\nto produce because the statements in \na Lucid program are simply axioms from which the proof\nproceeds by (almost) conventional logical reasoning, \nwith the help of a few axioms and rules of inference\nfor the special Lucid functions.  As a programming \nlanguage, Lucid is unconventional because, among other\nthings, the order of statements is irrelevant \nand assignment statements are equations.  Nevertheless,\nLucid programs need not look much different than \niterative programs in a conventional structured programming\nlanguage using assignment and conditional \nstatements and loops.\n program proving, formal systems, semantics,\niteration, structured programming\n", "2944": "Shifting Garbage Collection Overhead to Compile Time This paper discusses techniques which enable automatic\nstorage reclamation overhead to be partially \nshifted to compile time.  The paper assumes a transaction\noriented collection scheme, as proposed by \nDeutsch and Bobrow, the necessary features of which are\nsummarized.  Implementing the described optimizations \nrequires global flow analysis to be performed on the\nsource program.  It is shown that at compile time \ncertain program actions that affect the reference counts\nof cells can be deduced.  This information is \nused to find actions that cancel when the code is executed\nand those that can be grouped to achieve improved \nefficiency.\n garbage collection, global flow analysis, list processing,\noptimization, reference counts, storage \nmanagement\n", "2945": "Certification of Programs for Secure Information Flow This paper presents a certification mechanism\nfor verifying the secure flow of information \nthrough a program.  Because it exploits the properties\nof a lattice structure among security classes, \nthe procedure is sufficiently simple that it can easily\nbe included in the analysis phase of most existing \ncompilers.  Appropriate semantics are presented and\nproved correct.  An important application is the \nconfinement problem: The mechanism can prove that a program\ncannot cause supposedly nonconfidential results \nto depend on confidential input data.\n protection, security, information flow, program certification,\nlattice, confinement, security classes\n", "2946": "An Alternative to Event Queues for Synchronization in Monitors In the monitor concept, as proposed by Brinch\nHansen and Hoare, event are used for synchronization.\n  This paper describes another synchronizing primitive\nwhich is nearly as expressive as the conditional \nwait, but can be implemented more efficiently.  An implementation\nof this primitive in terms of P and \nV operations is given together with a correctness proof.\n Two examples are presented: the readers and \nwriters problem and the problem of information\nstreams sharing a finite buffer pool.\n monitor, operating system, mutual exclusion, synchronization,\nconditional critical region, structuring \nconcept\n", "2947": "SITAR: An Interactive Text Processing System for Small Computers SITAR, a low-cost in teractive text handling\nand text analysis system for nontechnical users, \nis in many ways comparable to in teractive bibliographical\nsearch and retrieval systems, but has several \nadditional features. It is implemented on a PDP/11 time-sharing\ncomputer invoked by a CRT with microprogrammed \nediting functions.  It uses a simple command language designating\na function, a file, and a search template \nconsisting of the textual string desired and strings\ndelimiting the context in which the hit is to be \ndelivered.  Extensive experience with SITAR shows that\nthe combined powers of simple commands, string \norientation, circular file structure, a CRT with local\nmemory, and conversational computing produce a \nsystem much more powerful than the sum of its parts.\n information retrieval, text editing, minicomputers,\nCRTs,time sharing, bibliographic search and \nretrieval, literary analysis, linguistic analysis, command languages\n", "2948": "A Terminal-Oriented Communication System This paper describes a system for full-duplex\ncommunication between a time-shared computer \nand its terminals.  The system consists of a communications\ncomputer directly connected to the time-shared \nsystem, a number of small remote computers to which\nthe terminals are attached, and connecting medium \nspeed telephone lines.  It can service a large number\nof terminals of various types.  The overall system \ndesign is presented along with the algorithms used to\nsolve three specific problems: local echoing, error \ndetection and correction on the telephone lines,\nand multiplexing of character output.\n terminal system, error correction, multiplexing,\nlocal echoing, communication system, network\n", "2949": "A Correctness Proof of a Topology Information In order for the nodes of a distributed computer\nnetwork to communicate, each node must have \ninformation about the network's topology.  Since nodes\nand links sometimes crash, a scheme is needed \nto update this information.  One of the major constrain ts\non such a topology information scheme is that \nit may not involve a central controller.  The Topology\nInformation Protocol that was implemented on the \nMERIT Computer Network is presented and explained; this\nprotocol is quite general and could be implemented \non any computer network.  It is based on Baran's \"Hot\nPotato Heuristic Routing Doctrine.\"  A correctness \nproof of this Topology Information Protocol is also presented.\n distributed computer network, correctness proofs,\ncomputer networks, distributed control, network \ntopology, routing problem in networks, distributed operating\nsystem, store and forward packet switching, \nstore and forward message switching, traffic control\n", "2950": "A Unifying Approach to Scheduling This paper presents a scheme for classifying\nscheduling algorithms based on an abstract model \nof a scheduling system which formalizes the notion of\npriority.  Various classes of scheduling algorithms\nare defined and related to existing algorithms.  A\ncriterion for the implementation efficiency of an \nalgorithm is developed and results in the definition\nof time-invariant algorithms, which include most \nof the commonly implemented ones.  For time-invariant\nalgorithms, the dependence of processing rates \non priorities is derived.  The abstract model provides\na framework for implementing flexible schedulers \nin real operating systems.  The policy-driven scheduler\nof Bernstein and Sharp is discussed as an example \nof such an implementation\n scheduling algorithms, scheduling models, priority,\noperating systems,processor sharing, implementation \nefficiency\n", "2951": "Dynamic Response Time Prediction for Computer Networks If the ultimate aim of a computing network\nis resource sharing, then the human component as \nwell as the technical component of networking must\nbe fully investigated to achieve this goal.  This \nresearch is a first step toward assisting the user in participating\nin the vast store of resources available \non a network. Analytical, simulation, and statistical performance\nevaluation tools are employed to investigate \nthe feasibility of a dynamic response time monitor\nthat is capable of providing comparative response \ntime information for users wishing to process various\ncomputing applications at some network computing \nnode.  The research clearly reveals that sufficient\nsystem data are currently obtainable, at least for \nthe five diverse ARPA network systems studied in detail,\nto describe and predict the response time for \nnetwork time-sharing systems as it depends on some\nmeasure of system activity or load level.\n response time monitor, computer networks, time-sharing\nsystems, comparative response time, ARPA \nnetwork, anlytic modeling, simulation, benchmark jobs, system measurement\n", "2952": "Functions Realizable with Word-Parallel Logical Boolean functions, two's-complement, sign propagation\n", "2953": "Notes on Recursion Elimination Various methods of recursion elimination are\napplied to the schematic recursive procedure: \nproc S(x); px then N(x); S(fx); S(gx); M(x) fi.  Procedures\nwith this general form arise in connection \nwith tree traversal and sorting algorithms.  Each method\nof recursion removal involves the use of one \nor more stacks, and the solutions are compared\non the basis of their running time.\n recursion elimination, optimization of programs,\nstacks, trees, sorting algorithms, computational \ninduction\n", "2954": "A Bounded Storage Algorithm for Copying Cyclic Structures A new algorithm is presented which copies cyclic\nlist structures using bounded workspace and \nlinear time. Unlike a previous similar algorithm, this\none makes no assumptions about the storage allocation \nsystem in use and uses only operations likely to be available\nin a high-level language.  The distinctive \nfeature of this algorithm is a technique for traversing\nthe structure twice, using the same spanning \ntree in each case, first from left to right and then from right to left.\n copying, shared subtrees, cyclic structures\n", "2955": "Buddy Systems Two algorithms are presented for implementing\nany of a class of buddy systems for dynamic storage \nallocation.  Each buddy system corresponds to a set of\nrecurrence relations which relate the block sizes \nprovided to each other. Analyses of the in ternal fragmentation\nof the binary buddy system, the Fibonacci \nbuddy system, and the weighted buddy system are given.\nComparative simulation results are also presented \nfor in ternal, external, and total fragmentation.\n dynamic storage allocation, buddy system, fragmentation,\nFibonacci buddy system, weighted buddy \nsystem\n", "2956": "Some Ideas on Data Types in High-Level Languages A number of issues are explored concerning the\nnotion that a data type is a set of values together \nwith a set of primitive operations on those values.  Among\nthese are the need for a notation for iterating \nover the elements of any finite set (instead of the\nmore narrow for i:= 1 to n notation), the use of \nthe domain of an array as a data type, the need for\na simple notation for allowing types of parameters \nto be themselves parameters (but in a restrictive fashion),\nand resulting problems with conversion of \nvalues from one type to another.\n data types, generic procedures, programming languages\n", "2957": "Database Abstractions: Aggregation Aggregation is in troduced as an abstraction\nwhich is important in conceptualizing the real \nworld.  Aggregation transforms a relationship between\nobjects into a higher-level object.  A new data \ntype, called aggregation, is developed which, under\ncertain criteria of \"well-definedness,\" specifies \naggregation abstractions.  Relational databases defined\nas collections of aggregates are structured as \na hierarchy on n-ary relations.  To main tain well-definedness,\nupdate operations on such databases must \npreserve two invariants.  Well-defined relations are\ndistinct from relations in third normal form.  It \nis shown that these notions are complementary and both are\nimportant in database design.  A top-down \nmethodology for database design is described which separates\ndecisions concerning aggregate structure \nfrom decisions concerning key identification.  It is\nsuggested that aggregate types, and other types \nwhich support real-world abstractions without in troducing\nimplementation detail, should be incorporated \ninto programming languages.\n data abstraction, relational database, data type,\naggregation, database design, data structure, \nknowledge representation, data definition language\n", "2958": "Abstract Data Types and the Development of Data Structures Abstract data types can play a significant role\nin the development of software that is reliable, \nefficient, and flexible.  This paper presents and discusses\nthe application of an algebraic technique \nfor the specification of abstract data types.  Among\nthe examples presented is a top-down development \nof a symbol table for a block structured language; a discussion\nof the proof of its correctness is given. \n The paper also contains a brief discussion of the problems\ninvolved in constructing algebraic specifications \nthat are both consistent and complete.\n abstract data type, correctness proof, data type,\ndata structure, specification, software specification\n", "2959": "The System for Business Automation (SBA): Programming Language The system for business automation (SBA) is a system\nwithin which application experts-nonprogrammers-can \ndescribe and execute their applications on a computer. \nThe user of SBA views his application as manipulation \nof information in two-dimensional pictures of tables,\nbusiness forms, and reports on a display terminal. \n He can gradually automate this application by giving \"examples\"\nto the system of how he manually manipulates \nthe information.  The Query-by-Example database language\nis a subset of the SBA programming language.\n programming language, graphics, user in terface,\ndata flow, forms flow, data abstraction, database, \nquery, data processing, business system specification, application programming\n", "2960": "Two Views of Data Abstraction", "2961": "Experimental Investigations of the Utility This paper describes previous research on\nflowcharts and a series of controlled experiments \nto test the utility of detailed flowcharts as an aid\nto program composition, comprehension, debugging, \nand modification.  No statistically significant difference\nbetween flowchart and nonflowchart groups \nhas been shown, thereby calling into question the utility\nof detailed flowcharting.  A program of further \nresearch is suggested.\n flowcharts, program composition, program comprehension,\ndebugging, modification, experimental testing, \nhuman factors\n", "2962": "Production and Employment of Ph.D.'s in Computer Science-1976 Statistics are presented on the production\nand employment of Ph.D.'s in computer science for \nthe calendar year 1975-76.  Data include profiles of graduate\nstudents and of faculty at 60 Ph.D.-producing \ndepartments as well as a breakdown of degrees granted\nby specialty areas.  Significant trends are noted \nand comparisons with comparable data gathered\nfor the 1974-75 calendar year are made.\n computer science, production of Ph.D.'s, employment, students\n", "2963": "A Fast Algorithm for Computing Longest Common Subsequences Previously published algorithms for finding\nthe longest common subsequence of two sequences \nof length n have had a best-case running time of O(n^2).\n An algorithm for this problem is presented \nwhich has a running time of O((r + n)log n), where r\nis the total number of ordered pairs of positions \nat which the two sequences match.  Thus in the worst\ncase the algorithm has a running time of O(n^2 log \nn).  However, for those applications where most positions\nof one sequence match relatively few positions \nin the other sequence, a running time of O(n log n) can be expected.\n Longest common subsequence, efficient algorithms\n", "2964": "An Approach to Optimal Design of Storage Parameters in Databases database organization, storage parameter\noptimization, resident, overflow storage\n", "2965": "An Optimal Evaluation of Boolean Expressions in an Online Query System query, Boolean expression, information retrieval, file organization\n", "2966": "The Choice of Reference Poin ts in Best-Match File Searching Improvements to the exhaustive search method\nof best-match file searching have previously been \nachieved by doing a preprocessing step involving the\ncalculation of distances from a reference poin t. \n  This paper discusses the proper choice of reference\npoin ts and extends the previous algorithm to use \nmore than one reference poin t.  It is shown that reference\npoin ts should be located outside of data clusters. \n The results of computer simulations are presented which\nshow that large improvements can be achieved \nby the proper choice and location of multiple reference poin ts.\n matching, file searching, best match, nearest-neighbor classification\n", "2967": "A Comparison of Hardware and Software Associative The Associative Processing of Line Drawings (APLD)\nSystem utilizes a hardware associative memory \nand creates, modifies, deletes, stores, and retrieves\ntwo-dimensional line drawings consisting of poin ts,\nlines, rectangles, and triangles. The APLD functions\nwere duplicated on the TX-2 computer at M.I.T.'s \nLincoln Laboratory under the LEAP Language and Data\nStructure,  A comparison of the hardware approach \nwith the software simulation illustrates the advantages\nof the hardware associative memory in three areas: \n(1) processing speed, (2) storage requirements, and (3)\nflexibility.  The major problem areas of hardware \nassociative memory technology, namely input/output\nand cost effectiveness, are also addressed.\n associative memory, associative processor, content-addressable\nmemory, graphics, information retrieval, \ndata structures, software evaluation, hardware evaluation,\nparallel processing, database management\n", "2968": "A Comparison of Tree-Balancing Algorithms Several algorithms-height-balance (i.e. AVL\nand extensions), weight-balance (i.e. BB and WB), \nand total restructuring-for building balanced binary search\ntrees are compared.  The criteria for comparison \nencompass theoretical aspects (e.g. path lengths) and implementation\nindependent and machine/algorithm-dependent \nmeasures (e.g. run time).  A detailed analysis of code is\nalso presented at a level believed to be language-and \ncompiler-independent.  The quality of the resulting\ntrees and the overhead spent on building them are \nanalyzed, and some guidelines are given for an efficient\nuse of the methods.  If insertion and subsequent \nqueries are the only operations of in terest, then \"pure\"\nAVL trees present the overall best qualities.\n binary search trees, AVL trees, weight-balanced trees,\npath length, analysis of algorithms, information \nstorage and retrieval\n", "2969": "Optimal Program and Data Locations in Computer Networks An optimization procedure for the allocation\nof program and data files in a computer network \nis presented.  This algorithm takes into account the\ndependencies between files and programs such as \noccur in real heterogeneous computer networks.  Insights\ninto whether or not to convert programs from \none computer to another can also be gained from the\nmodel.  A search procedure for the file location \nproblem is described, along with an example\nand a possible application of the model.\n computer networks, databases, distributed\ndatabases, optimal file location\n", "2970": "Achieving Specific Accuracy in Simulation Output Analysis This paper extends the use of the regenerative\nproperty of queueing systems in the analysis \nof simulation output.  In particular, it describes a\nsequential estimation method which when used with \nthe regenerative property allows results to be obtained\nwith specified statistical accuracy.  This method \nincludes a test to check the normality assumption on\nwhich the sequential procedure relies.  The paper \nillustrates the method using the empty and idle state\nas the regenerative state.  A second example then \ndescribes how using the most frequently entered state\nas the regenerative state reduces the chance of \nmaking a costly error in a preliminary simulation run.\n The paper also described how a variance reduction \nmethod due to Page [9] can be used to obtain a specified\naccuracy with considerably fewer job completions \nthan are required when no variance reduction technique is applied.\n confidence in terval, ratio estimator, regenerative\nproperty, sequential estimator, simulation, \nstopping rule, variance reduction\n", "2971": "SP/k: A System for Teaching Computer Programming SP/k is a compatible subset of the PL/I  language\nthat has been designed for teaching programming. \nThe features of the SP/k language were chosen to encourage\nstructured problem solving by computers, to \nmake the language easy to learn and use, to eliminate\nconfusing and redundant constructs, and to make \nthe language easy to compile.  The resulting language\nis suitable for in troducing programming concepts \nused in various applications, including business data\nprocessing, scientific calculations and non-numeric \ncomputation.  SP/k is actually a sequence of language\nsubsets called SP/1, SP/2,...SP/8.  Each subset \nin troduces new programming language constructs while\nretaining all the constructs of preceding subsets. \nEach subset is precisely defined and can be learned\nor implemented without the following subsets.\n programmer education, universities, community colleges,\nhigh schools, PL/I, SP/k, minicomputers, \nprogramming language design, teaching programming, in troductory computing\n", "2972": "Proof Techniques for Hierarchically Structured Programs A method for describing and structuring programs\nthat simplifies proofs of their correctness \nis presented.  The method formally represents a program\nin terms of levels of abstraction, each level \nof which can be described by a self-contained nonprocedural\nspecification.  The proofs, like the programs, \nare structured by levels.  Although only manual proofs\nare described in the paper, the method is also \napplicable to semi-automatic and automatic proofs.  Preliminary\nresults are encouraging, indicating that \nthe method can be applied to large programs, such as operating systems.\n hierarchical structure, program verification, structured\nprogramming, formal specification, abstraction, \nand programming methodology\n", "2973": "Sorting on a Mesh-Connected Parallel Computer Two algorithms are presented for sorting n^2\nelements on an n X n mesh-connected processor \narray that require O(n) routing and comparison steps.\n The best previous algorithm takes time O(n log \nn).  The algorithms of this paper are shown to be optimal\nin time within small constant factors.  Extensions \nto higher-dimensional arrays are also given.\n parallel computer, parallel sorting, parallel merge,\nrouting and comparison steps, perfect shuffle. \nprocessor in terconnection pattern\n", "2974": "Comment on Weighted Increment Linear Search for Scatter Tables hash address, primary clustering, index,\nsequence, complementary relation, search\n", "2975": "Remark on Uniform Insertion in Structured Data Structures data structures, directed graphs, uniform insertion\n", "2976": "Approximating Block Accesses in Database Organizations database, inverted file organization, database performance\nand measurement, information retrieval, \nquery answering\n", "2977": "The Stage Hypothesis and the S-Curve: Some Contradictory Evidence This paper presents the results of a study\ntesting the s-shaped budget curve of Nolan's stage \nmodel of computer development in an organization.  Research\non the data processing budgets of California \ncounties fails to support the s-shaped curve or the use\nof budgets as a basis for a stage model.  However, \nthe results do not invalidate the concept of a stage\nmodel.  The analysis suggests an alternative model \nof budget growth and a separation between models of budgeting\ngrowth and growth stages in the development \nof the computer resource.\n budgets, stage theories, stage hypothesis\n", "2978": "Analysis of Design Alternatives for Virtual Memory Indexes A class of index structures for use in a virtual\nmemory environment is described.  Design alternatives \nwithin this class of index structures are analyzed.  These\nalternatives include a choice of search strategy, \nwhether or not pages in the index are structured, and\nwhether or not keys are compressed.  The average \ncost of retrieving entries from these indexes is expressed\nas a wieghted sum of the cost of a basic key \ncomparison and the cost of crossing a page boundary in\nthe index structure.  Formulas for the retrieval \ncosts for possible combinations of design alternatives\nare given.  These are used in numerical case studies \nwhich compare the retrieval costs of the alternatives.\n Qualitative comparisons of the main tenance costs \n(insertion, deletion, reorganization) of the\ndesign alternatives are also included.\n index, index structure, pages, virtual memory,\nfiles, retrieval, main tenance, search strategy, \nkey compression\n", "2979": "Studies in Machine Cognition Using The Game of Poker A progress report is presented of on-going\nresearch efforts concerning human decision making \nunder uncertainly and risk and human problem solving\nand learning processes on the one hand, and machine \nlearning, large scale programming systems, and novel\nprogramming techniques on the other.  There has \nalso been in terest in how humans make deductive and inductive\ninferences and form and optimize heuristic \nrules, and how machines can reach similar results.\n Although the vehicle of these investigations has \nbeen the game of poker, a conceptual framework has been\nprovided that should have a fairly wide range \nof applicability.  The models of human judgment, choice,\nand decision making are incorporated in a large \nscale complex program.  They represent both descriptive\nand normative theories of behavior. An in teractive \ngame environment has been recently established which,\nbesides its usefulness for experiments in game \nplaying, enables humans to construct machine strategies\n\"on-line\" in a question answering, advice taking \nmode.\n machine learning, game playing programs, decision\nmaking under uncertain ty and risk, automatic \nforming and optimizing of heuristic rules, automatic\ninductive and deductive inference making, models \nof game learning, poker, gambling and bluffing\n", "2980": "The Editing  of Picture Segmentations Using Local Analysis of Graphs A major problem in picture processing is the\nelimination of the large number of spurious regions \nthat result from an initial segmentation by region growing\ntechniques.  Such regions have been eliminated \neither on the basis of semantic information or on the\nbasis of size and contrast.  A scheme is presented \nwhich performs eliminations on the basis of local properties\nof the region adjacency graph.  The scheme \nis based on definitions of graph properties which are\nsatisfied when a spurious region is present; then \nediting is equivalent to fast graph operations.  A number of examples are shown.\n picture processing, pattern recognition, segmentation, region editing \n", "2981": "Subgoal Induction A proof method, subgoal induction, is presented\nas an alternative or supplement to the commonly \nused inductive assertion method.  Its major virtue is that\nit can often be used to prove a loop's correctness \ndirectly from its input-output specification without the\nuse of an invariant.  The relation between subgoal \ninduction and other commonly used induction rules is explored\nand, in particular, it is shown that subgoal \ninduction can be viewed as a specialized form of computation\ninduction.  A set of sufficient conditions \nare presented which guarantee that an input-output specification\nis strong enough for the induction steps \nof a proof by subgoal induction to be valid.\n program verification, proving programs correct,\ninduction rule, computation induction, inductive \nassertions, structural induction, proof rule,\nrecursive programs, iterative programs\n", "2982": "The Storage Requirement in Precedence Parsing precedence parsing, storage requirement, value table\n", "2983": "A Comparison of Next-fit, First-fit, and Best-fit memory allocation, first-fit, best-fit, next-fit\n", "2984": "Cost/Utilization: A Measure of System Performance A method is presented for evaluating computer\nsystem performance in terms of a cost/utilization \nfactor and a measure of imbalance.  These coefficients\nindicate the extent to which the total system \ncost is effectively utilized.  The method includes a\ntechnique for the visual representation of system \nperformance.\n computer system, performance evaluation, cost/utilization, system balance\n", "2985": "Effects of Chargeout on User/Manager Attitudes The relationship of in ternal pricing systems\nfor computer services (chargeout systems) and \nuser management attitudes about their computer-based\ninformation systems is investigated. Evidence is \nprovided that the relationship conforms to a general\npattern that would be expected from the hypothesis \nof the four stages of EDP growth [15].  The results also\nindicate that the chargeout systems characteristic \nof advanced EDP stage environments are associated with\nrelatively high levels of positive user attitudes \nand marked increases in EDP training for users. Both factors\nare important to the user/manager involvement \nnecessary for effective control of computer-based systems.\n Development and main tenance of computer-based \nsystems is asserted to be a category of organizational\nchange.  A \"felt need\" for the change on the part \nof the user/manager is prerequisite to any change taking\nplace.  The research methods of behavioral science \nare applied to investigate the user/manager\nenvironment and the effects of chargeout.\n computer management, computer budget,\nchargeout, stage hypothesis, control\n", "2986": "Operations on Sparse Relations Various computations on relations, Boolean matrices,\nor directed graphs, such as the computation \nof precedence relations for a context-free grammar, can be\ndone by a practical algorithm that is asymptotically \nfaster than those in common use.  For example, how to compute\noperator precedence or Wirth-Weber precedence \nrelations in O(n^2) steps is shown, as well as how to\ncompute linear precedence functions in O(n^2) steps \nis shown, as well as how to compute linear precedence\nfunctions in O(n) steps, where n is the size of \na grammer.  The heart of the algorithms is a general\ntheorem giving sufficient conditions under which \nan expression whose operands are sparse relations and\nwhose operators are composition, transitive closure, \nunion, and inverse, can be computed efficiently.\n computational complexity, sparse relation, Boolean\nmatrix, directed graph, Wirth-Weber precedence \nrelation, linear precedence function, SLR\ngrammar, T-canonical precedence relation\n", "2987": "Representation of Many-Sided Polygons A representation for polygons and polygonal\nlines is described which allows sets of consecutive \nsides to be collectively examined.  The set of sides are\narranged in a binary tree hierarchy by inclusion. \n A fast algorithm for testing the inclusion of a poin t\nin a many-sided polygon is given.  The speed of \nthe algorithm is discussed for both ideal and practical\nexamples.  It is shown that the poin ts of intersection \nof two polygonal lines can be located by what is essentially\na binary tree search.  The algorithm and \na practical example are discussed.  The representation\novercomes many of the disadvantages associated \nwith the various fixed-grid methods for representing curves and regions\n boundary line representation, cartography, computer\ngraphics computer-searchable structures, contour \nrepresentation, geographic information processing, graphic\ndata retrieval, in tersection of curves, line-drawing \nprocessing, poin ts in polygons, regional boundary\nrepresentation, spatial information\n", "2988": "Memory Management and Response Time This paper presents a computationally tractable\nmethodology for including accurately the effects \nof finite memory size and workload memory requirements\nin queueing network models of computer systems. \n Empirical analyses and analytic studies based on applying\nthis methodology to an actual multiaccess \nin teractive system are reported.  Relations between workload\nvariables such as memory requirement distribution \nand job swap time, and performance measures such as response\ntime and memory utilization are graphically \ndisplayed. A multiphase, analytically soluble model is\nproposed as being broadly applicable to the analysis \nof in teractive computer systems which use nonpaged memories.\n memory management, system performance, queueing\nnetwork models, in teractive computer systems\n", "2989": "Empirical Evaluation of Some Features This paper presents methods for empirical evaluation\nof features of Instruction Set Processors \n(ISPs).  ISP features are evaluated in terms of the time\nused or saved by having or not having the feature. \n The methods are based on analysis of traces of program\nexecutions.  The concept of a register life is \nin troduced, and used to answer questions like: How many\nregisters are used simultaneously? How many would \nbe sufficient all of the time? Most of the time? What\nwould the overhead be if the number of registers \nwere reduced? What are registers used for during their\nlives? The paper also discusses the problem of \ndetecting desirable but non-existing instructions. Other\nproblems are briefly discussed.  Experimental \nresults are presented, obtained by analyzing 41\nprograms running on the DEC system 10 ISP.\n computer architecture, program behavior, instruction\nsets, op code utilization, register structures, \nregister utilization, simultaneous register\nlives, instruction tracing, execution time\n", "2990": "Effective Information Retrieval Using Term Accuracy The performance of information retrieval systems\ncan be evaluated in a number of different \nways.  Much of the published evaluation work is based\non measuring the retrieval performance of an average \nuser query.  Unfortunately, formal proofs are difficult\nto construct for the average case.  In the present \nstudy, retrieval evaluation is based on optimizing the\nperformance of a specific user query.  The concept \nof query term accuracy is in troduced as the probability\nof occurrence of a query term in the documents \nrelevant to that query.  By relating term accuracy\nto the frequency of occurrence of the term in the \ndocuments of a collection it is possible to give formal\nproofs of the effectiveness with respect to a \ngiven user query of a number of automatic indexing systems\nthat have been used successfully in experimental \nsituations.  Among these are inverse document frequency\nweighting, thesaurus construction, and phrase \ngeneration.\n information retrieval, automatic indexing, content\nanalysis, term accuracy, frequency weighting, \nthesaurus and phrase transformations\n", "2991": "Improving the Access Time for Random Access Files Clustering in the key set is decreased by\nsmoothing the key-to-address transformation, and \nby adding shadow buckets to an open chaining file.  The\nkeys are pre-hashed before the address division, \nto remove the effect of sequential properties in the\nkey set.  Shadow buckets in the key search sequence \nreduce the effect of nonuniformity in file loading,\nand decrease the number of maximum probes needed \nto locate a record.  The combined effects of these techniques\nlead to improved file performance for secondary \nstorage devices, as shown by empirical studies.\n hashing, hashing techniques, hashing methods, hash\ncoding, keys, key transformation, key-to-address \ntransformation, direct addressing, direct access, direct\naccess method, randomizing, random access, file \naddressing, file organizations, file structures, scatter\nstorage, search method, collisions, synonyms, \nclustering, information retrieval, open addressing, open\nchaining, buckets, bucket size, shadow buckets, \ncombinatorics\n", "2992": "A Numbering System for Binary Trees binary trees, permutations, binary search trees, ranking function\n", "2993": "Occurrences of Cycling and Other Phenomena An investigation into the average queue size\nfor a certain class of queues has resulted in \nthe formulation of linear programming problems which\nare ill-conditioned in some cases.  In attempting \nto solve these linear programming models, using IBM's\nMPS package, instances of cycling were encountered. \n Small perturbations in the input data resulted in problems\nwhich did not cycle.  This fact, plus several \nother observed phenomena suggest that the primary reason\nthat cycling is not known to occur more frequently \nis the round-off errors in the computations perturb\nthe problem sufficiently to prevent cycling (or at \nleast to prevent indefinite cycling).  In one case maximizing\nand minimizing an objective function subject \nto the same constrain t set was attempted, but MPS solved\nonly one of these while giving an indication \nof infeasibility for the other.\n linear programming, cycling, queueing models\n", "2994": "A Linear Algorithm for Incremental Digital Display of Circular Arcs Circular arcs can be drawn on an incremental\ndisplay device such as a cathode ray tube, digital \nplotter, or matrix prin ter using only sign testing and\nelementary addition and subtraction.  This paper \ndescribes methodology for producing dot or\nstep patterns closet to the true circle.\n graphics, circle drawing, step generation, dot\ngeneration, incremental digital plotting, raster \ndisplay, integer arithmetic, circle algorithm\n", "2995": "Decomposability, Instabilities, and Saturation", "2996": "Transient-Free Working-Set Statistics Transient-free average working set size and transient-free\nmissing-page rate for a finite sample \nof a reference string are defined.  Use of these statistics\nis appropriate if the contents of the working \nset at the start of the recorded string are unknown.\n If a certain stationarity condition holds, these \nstatistics provide unbiased estimates of expected working-set\nsizes, missing-page probabilities, and \nin terreference distance probabilities.  Two other pairs\nof estimators are shown to be biased.  Expressions \nfor the transient-free statistics are obtained in terms\nof in terval statistics. Several methods of computation \nare discussed, the usefulness of each depending on length\nof the sample, number of distinct references, \nand the amount of main storage available to the computer\nperforming the calculations.  In particular, \nmethods are described for handling long strings\ncontaining many distinct page names.\n working set, estimation program behavior\n", "2997": "Convex Hulls of Finite Sets of Poin ts in Two and Three Dimensions The convex hulls of sets of n poin ts in two\nand three dimensions can be determined with O(n \nlog n) operations.  The presented algorithms use the \"divide\nand conquer\" technique and recursively apply \na merge procedure for two nonin tersecting convex hulls.\n Since any convex hull algorithm requires at \nleast O(n log n) operations, the time complexity of the\nproposed algorithms is optimal within a multiplicative \nconstant.\n computational complexity, convex hull, optimal algorithms,\nplanar set of poin ts, spatial set of \npoin ts\n", "2998": "An Empirical Study of List Structure in Lisp Static measurements of the list structure of\nfive large Lisp programs are reported and analyzed \nin this paper.  These measurements reveal substantial\nregularity, or predictability, among poin ters to \natoms and especially among poin ters to lists.  Pointers\nto atoms are found to obey, roughly, Zipf's law, \nwhich governs word frequencies in natural languages; poin ters\nto lists usually poin t to a location physically \nnearby in memory.  The use of such regularities in the\nspace-efficient representation of list structure \nis discussed.  Linearization of lists, whereby successive\ncdrs (or cars) are placed in consecutive memory \nlocations whenever possible, greatly strengthens the\nobserved regularity of list structure.  It is shown \nthat under some reasonable assumptions, the entropy or\ninformation content of a car-cdr pair in the programs \nmeasured is about 10 to 15 bits before linearization,\nand about 7 to 12 bits after.\n list structure measurement, Lisp, list structure\nregularity, poin ter compression, Zipf's law, list \nlinearization, poin ter entropy\n", "2999": "An Approach to Multidimensional Data Array Processing by Computer Some recent work on the development of general-purpose\ncomputer-based statistical and data \nprocessing capabilities for handling multidimensional\narrays of data is presented. Attention is first \ngiven to some of the general problems of multidimensional\ntable and array processing.  This is followed \nby a summary of some recent developments in array processing\ncapabilities at the World Bank, in particular, \nthe system identified as WRAPS(World Bank\nRetrieval and Array Processing System).\n array processing, table processing, statistical\nanalysis, data retrieval, data processing, syntax \nfor data structures, computing techniques, time series, cross tabulation\n", "3000": "Segment Sizes and Lifetimes in Algol 60 Programs The characteristics of the virtual memory requirements\nof a sample of Algol 60 programs have \nbeen measured.  Distributions are presented for thesizes\nof memory requests and for their holding times \n(lifetimes).  The results are presented in terms of Johnston's\ncontour model and a simple abstract machine. \n They provide new empirical evidence of certain aspects\nof the construction and behavior of real programs, \nand some of their implications for the design of virtual\nmemory systems are presented and discussed.\n virtual memory, program behavior, segmentation,\nstorage allocation, Algol 60, contour model\n", "3001": "Detection of Combined Occurrences In this paper it is supposed that the variables\nX1,...,Xn each have finite range with the variable \nXi taking on Pi possible values and that the values of the\nvariables are changing with time.  It is supposed \nfurther that it is desired to detect occurrences in which\nsome subset of the variables achieve particular \nvalues.  Finally, it is supposed that the problem involves\nthe detection of a large number of combined \noccurrences for a large number of changes of values of\nvariables.  Two efficient solutions for this problem \nare described.  Both methods have the unusual property\nof being faster for systems where the sum P1 + ... \n+ Pn is larger. The first solution is error-free\nand suitable for most cases.  The second solution \nis slightly more elegant and allows negation as well\nas conjunction, but is subject to the possibility \nof errors.  An error analysis is given for the second\nmethod and an empirical study is reported.\n coding, hash coding, retrieval, secondary keys, pattern\nrecognition, artificial in telligence, demons, \nn-tuples, sorting, chess\n", "3002": "A Record and File Partitioning Model One of the main objectives in the design of\na file system is the reduction of storage and data \ntransfer costs.  This paper presents a model in which\nseveral  requests access the file system, and each \nrequest requires information from one or more variable\nlength data-items.  The probabilities of access \nand the distribution of each data-item's length are assumed\nto be known, and to be mutually independent. \nThe file system uses one or more storage devices, and\neach record may be partitioned into subrecords \nthat are stored on different devices.  One of the subrecords\nis designated as the primary record; when \na request for a record is made, the primary record is\nfirst accessed, and other subrecords are accessed \nonly if the pertinent information is not stored in the\nprimary record.  The model that is presented in \nthis paper, both as a nonlinear programming model and\na mixed integer programming model, is a very general \none; several types of file systems may be derived from\nit by an appropriate selection of its parameters. \n This model has already been used in the optimization of\nlibrary routines' storage at a large scale operating \nsystem.\n file system, file design, file partitioning, record partitioning\n", "3003": "A Survey of the Literature in Computer A bibliography of approximately two hundred\nreferences in computer science education appearing \nin the literature since the publication of \"Curriculum\n'68\" is presented.  The bibliography itself is \npreceded by brief descriptive materials organizing the\nreferences into the categories of survey reports, \nactivities of professional organizations, philosophy\nof programs, description of  programs, description \nof courses and other materials.\n education, computer science, curricula\n", "3004": "Structured Programming in Cobol: An Approach for Application Programmers Techniques for designing and writing Cobol programs\nare presented.  Previous work in structured \nprogramming is drawn upon and adapted.  The presentation\nis informal: the terminology is nonmathematical \nas far as possible, no theorems are proved, and examples\nare used frequently.  Top-down program design \nis implemented through the use of structured flowcharts,\ndisciplined specifications, and step by step \nverification.  A well-formed Cobol program is defined.\n The proper use of the GO TO and other Cobol coding \npractices are discussed.\n structured programming, top-down, well-formed program,\nGO TO statement, repeat statement, flowchart, \napplication programming, Cobol, software reliability, program verification\n", "3005": "Implications of Structured Programming for Machine Architecture Based on an empirical study of more than 10,000\nlines of program text written in a GOTO-less \nlanguage, a machine architecture specifically designed for\nstructured programs is proposed.  Since assignment, \nCALL, RETURN, and IF statements together account for\n93 percent of all executable statements, special \ncare is given to ensure that these statements can be implemented\nefficiently.  A highly compact instruction \nencoding scheme is presented, which can reduce program\nsize by a factor of 3.  Unlike a Huffman code, \nwhich utilizes variable length fields, this method uses\nonly fixed length (1-byte) op code and address \nfields.  The most frequent instructions consist of a\nsingle 1-byte field.  As a consequence, instruction \ndecoding time is minimized, and the machine is\nefficient with respect to both space and time.\n machine architecture, computer architecture, computer\norganization, instruction set design, program \ncharacteristics\n", "3006": "Anomalies with Variable Partition Paging Algorithms Five types of anomalous behavior which may\noccur in paged virtual memory operating systems \na redefined.  One type of anomaly, for example, concerns\nthe fact that, with certain reference strings \nand paging algorithms, an increase in mean memory allocation\nmay result in an increase in fault rate. \n Two paging algorithms, are examined in terms of their\nanomaly potential, and reference string examples \nof various anomalies are presented.  Two paging algorithm\nproperties, the inclusion property and the \ngeneralized inclusion property, are discussed and the\nanomaly implications of these properties presented.\n anomaly, memory management, program behavior, stack\nalgorithms, virtual memory, working set, page \nfault frequency, paging algorithms\n", "3007": "Complexity of Computations (Corrigendum)", "3008": "Preserving Average Proximity in Arrays Programmers and data structure designers are often\nforced to choose between alternative structures. \n In storing these structures, preserving logical adjacencies\nor \"proximity\" is usually an important consideration. \n The combinatorial problem of storing arrays as various\nkinds of list structures is examined.  Embeddings \nof graphs are used to model the loss of proximity involved\nin such storage schemes, and an elementary \nproof that arrays cannot be stored as linear lists with\nbounded loss of proximity is presented.  Average \nloss of proximity is then considered, and it is shown\nthat arrays cannot be stored as linear lists with \nonly bounded loss of average proximity, but can be so\nstored in binary trees.  The former result implies, \nfor instance, that row major order is an asymptotically\noptimal storage strategy for arrays.\n arrays, graph embedding, linear lists,\nproximity, average proximity, trees\n", "3009": "Insertions and Deletions In One-Sided Height-Balanced Trees Recently Hirschberg has established that insertions\ninto one-sided height-balanced trees can \nbe done in 0(log^2N) steps.  It is proved here that deletions\ncan also be performed in 0(log^2N) steps, \nwhich answers the open problem posed by Hirschberg.\n AVL trees, balanced trees, binary search, dynamic balancing\n", "3010": "Value Orientation of Computer Science Students Technological and nontechnological value orientations\nare investigated with special attention \nto the complexity of value structures.  Computer science\nstudents, who are closely associated with technology, \ncontrast with social science students, who are often\ntechnologically aloof.  This is confirmed by the \nvalue ratings of 313 students at the University of Minnesota\nin 1972.  Computer science majors were found \nto have a more complex value structure than social science majors.\n values, attitudes, students, public, social effects\n", "3011": "Management Utilization of Computers in American Local Governments Traditional concepts of management information\nsystems (MIS) bear little relation to the information \nsystems currently in use by top management in most US local\ngovernments.  What exists is management-oriented \ncomputing, involving the use of relatively unsophisticated\napplications.  Despite the unsophisticated \nnature of these systems, management use of computing is\nsurprisingly common, but also varied in its extent \namong local governments.  Management computing is most\nprevalent in those governments with professional \nmanagement practices where top management is supportive\nof computing and tends to control computing decisions \nand where department users have less control over design\nand implementation activities.  Finally, management \ncomputing clearly has impacts for top managers, mostly\ninvolving improvements in decision information.\n computer utilization, management information system,\nAmerican local government, city government \ncomputers, county government computers, computer impacts, management computing\n", "3012": "The Use of an Interactive Information Storage This paper presents the results of a study\nof the use of an interactive computerized storage \nand retrieval system.  A monitor built into the computer\nsystem provided usage data for the study.  Additional \ndata on user reactions were gathe red from a questionnaire.\n The results show the important role played \nby frequently chosen laboratory reference leaders in influencing\nthe use of this system.  The implications \nof the study for the design of similar systems are discussed.\n implementation, system use, information storage and retrieval system\n", "3013": "Some New Methods of Detecting Step Edges in Digital Pictures This note describes two operators that respond\nto step edges, but not to ramps.  The first \nis similar to the digital Laplacian, but uses the max, rather\nthan the sum, of the x and y second differences. \n The second uses the difference between the mean and\nmedian gray levels in a neighborhood.  The outputs \nobtained from these operators applied to a set of test\npictures are compared with each other and with \nthe standard digital Laplacian and gradient.  A third\noperator, which uses the distance between the center \nand centroid of a neighborhood as an edge value, is also\nbriefly considered; it turns out to be equivalent \nto one of the standard digital approximations to the gradient.\n image processing, pattern recognition, edge detection\n", "3014": "Is \"Sometime\" Sometimes Better than \"Always\"? (Intermittent This paper explores a technique for proving the\ncorrectness and termination of programs simultaneously. \n This approach, the intermittent-assertion method, involves\ndocumenting the program with assertions that \nmust be true at some time when control passes through\nthe corresponding point, but that need not be true \nevery time.  The method, introduced by Burstall, promises\nto provide a valuable complement to the more \nconventional methods.  The intermittent-assertion method\nis presented with a number of examples of correctness \nand termination proofs.  Some of these proofs are markedly\nsimpler than their conventional counterparts. \n On the other hand, it is shown that a proof of correctness\nor termination by any of the conventional \ntechniques can be rephrased directly as a proof using\nintermittent assertions.  Finally, it is shown \nhow the intermittent-assertion method can be applied\nto prove the validity of program transformations \nand the correctness of continuously operating programs.\n intermittent assertions, correctness of programs,\ntermination of programs, program verification, \nprogram transformation, continuously operating programs.\n", "3015": "Relaxation Methods for Image Reconstruction The problem of recovering an image (a function\nof two variables) from experimentally available \nintegrals of its grayness over thin strips is of great\nimportance in a large number of scientific areas. \n An important version of the problem in medicine is\nthat of obtaining the exact density distribution \nwithin the human body from X-ray projections.One approach\nthat has been taken to solve this problem \nconsists of translating the available information into\na system of linear inequalities.  The size and \nthe sparsity of the resulting system (typically, 25,000\ninequalities with fewer than 1 percent of the \ncoefficients nonzero) makes methods using successive\nrelaxations computationally attractive, as compared \nto other ways of solving systems of inequalities. \nIn this paper, it is shown that, for a consistent \nsystem of linear inequalities, any sequence of relaxarion parameters\nlying strictly between 0 and 2 generates \na sequence of vectors which converges to a solution.\n Under the same assumptions, for a system of linear \nequations, the relaxation method converges to the minimum\nnorm solution.  Previously proposed techniques\nare shown to be special cases of our procedure with\ndifferent choices of relaxation parameters.  The \npractical consequences for image reconstruction of the\nchoice of the relaxation parameters are discussed.\n biomedical image processing, image reconstruction,\nX-ray tomography, mathematical programming, \nlinear inequalities, relaxation techniques\n", "3016": "A Comparison of Numerical Techniques in Markov Modeling This paper presents several numerical methods which\nmay be used to obtain the stationary probability \nvectors of Markovian models.  An example of a nearly\ndecomposable system is considered, and the results \nobtained by the different methods examined.  A post\nmortem reveals why standard techniques often fail \nto yield the correct results.  Finally, a means of estimating\nthe error inherent in the decomposition \nof certain models is presented.\n Markov models, numerical techniques, simultaneous\niteration, near-decomposability\n", "3017": "B-trees Re-examined The B-tree and its variants have, with increasing\nfrequency, been proposed as a basic storage \nstructure for multiuser database applications.  Here,\nthree potential problems which must be dealt with \nin such a structure that do not arise in more traditional\nstatic directory structures are indicated. \n One problem is a possible performance penalty.\n B-tree, directory, static directory, dynamic\ndirectory, index sequential access method\n", "3018": "Covering Edges by Cliques with Regard to Kellerman has presented a method for determining\nkeyword conflicts and described a heuristic \nalgorithm which solves a certain combinatorial optimization\nproblem in connection with this method.  \nThis optimization problem is here shown to be equivalent\nto the problem of covering the edges of a graph \nby complete subgraphs with the objective of minimizing\nthe number of complete subgraphs.  A relationship \nbetween this edge-clique-cover problem and the graph coloring\nproblem is established which allows algorithms \nfor either one of these problems to be constructed\nfrom algorithm for the other.  As consequences of \nthis relationship, the keyword conflict problem and the\nedge-clique-cover problem are shown to be NP-complete, \nand if P=/NP then they do not admit polynomial-time approximation\nalgorithms which always produce solutions \nwithin a factor less than 2 from the optimum.\n keyword conflicts, intersection graphs, node clique\ncover, edge clique cover, computational complexity, \nNP-complete problems, polynomial-time heuristics\n", "3019": "The GRE Advanced Test in Computer Science", "3020": "Systematic Recursion Removal The recursion removal algorithm presented\nby Strong and Walker is amplified and applied to \na relatively complex PL/I program.  The aim is to demonstrate\nsystematic recursion-removal techniques \non something more complex than Knuth's \"sturdy toddler\"\nand to obtain measurements of the cost of procedure \nlinkage in PL/I and the savings achievable via procedure\nintegration in the presence of recursion.  First, \nthe paper describes the recursion-removal process and the\nexample on which it will be illustrated.  Recursion \nremoval is then applied to the two major parts of this\nexample and the final result of the process is \ndisplayed.  Our performance comparison results are presented\nand our conclusions are briefly discussed. \n recursion removal, recursion elimination, optimization,\nprocedure linkage, procedure integration\n", "3021": "A Method for Obtaining Digital Signatures and Public-Key Cryptosystems An encryption method is presented with the novel\nproperty that publicly revealing an encryption \nkey does not thereby reveal the corresponding decryption\nkey.  This has two important consequences: (1) \nCouriers or other secure means are not needed to transmit\nkeys, since a message can be enciphered using \nan encryption key publicly revealed by the intended recipient.\n Only he can decipher the message, since \nonly he knows the corresponding decryption key.  (2)\nA message can be \"signed\" using a privately held \ndecryption key.  Anyone can verify this signature using\nthe corresponding publicly revealed encryption \nkey.  Signatures cannot be forged, and a signer cannot\nlater deny the validity of his signature.  This \nhas obvious applications in \"electronic mail\" and \"electronic\nfunds transfer\" systems.  A message is \nencrypted by representing it as a number M, raising\nM to a publicly specified power e, and then taking \nthe remainder when the result is divided by the publicly\nspecified product, n, of two large secret prime \nnumbers p and q.  Decryption is similar;only a different,\nsecret, power d is used, where e * d = 1 (mod(p-1) \n* (q-1)).  the security of the system rests in part on\nthe difficulty of factoring the published divisor, \nn.\n digital signatures, public-key cryptosystems,\nprivacy, authentication, security, factorization, \nprime number, electronic mail, message-passing,\nelectronic funds transfer, cryptography.\n", "3022": "Computer Science Faculties: The Current Status of Minorities and Women The results of a survey conducted in the fall\nof 1975 to determine the status of women and \nminority faculty members in academic computer science\nare presented.  Faculty members were compared with \nrespect to professional background, salaries, teaching\nload, publication records, and research grants. \n Analysis of the data indicated that the over-all verdict\nis one of general equality among women, minorities, \nand men.\n discrimination against women, discrimination against\nminorities, faculty, computer science degree \nprograms, affirmative action, teaching loads, salaries, publications\n", "3023": "Architecture of the IBM System/370 This paper discusses the design considerations\nfor the architectural extensions that distinguish \nSystem/370 from System/360.  It comments on some experiences\nwith the original objectives for System/360 \nand on the efforts to achieve them, and it describes the\nreasons and objectives for extending the architecture. \nIt covers virtual storage, program control, data-manipulation\ninstructions, timing facilities, multiprocessing, \ndebugging and monitoring, error handling, and input/output\noperations.  A final section tabulates some \nof the important parameters of the various IBM\nmachines which implement the architecture.\n computer systems, architecture, instruction\nsets, virtual storage, error handling\n", "3024": "The CRAY-1 Computer System This paper describes the CRAY-1, discusses\nthe evolution of its architecture, and gives an \naccount of some of the problems that were overcome during\nits manufacture.  The CRAY-1 is the only computer \nto have been built to date that satisfies ERDA's Class\nVI requirement (a computer capable of processing \nfrom 20 to 60 million floating point operations per\nsecond) [1].  The CRAY-1's Fortran compiler (CFT) \nis designed to give the scientific user immediate access\nto the benefits of the CRAY-1's vector processing \narchitecture.  An optimizing compiler, CFT, \"vectorizes\"\ninnermost DO loops.  Compatible with the ANSI \n1966 Fortran Standard and with many commonly supported\nFortran extensions, CFT does not require any source \nprogram modifications or the use of additional nonstandard\nFortran statements to achieve vectorization. \n Thus the user's investment of hundreds of man months\nof effort to develop Fortran programs for other \ncontemporary computers is protected.\n architecture, computer systems\n", "3025": "The Evolution of the DEC system 10 The DEC system 10, also known as the PDP-10, evolved\nfrom the PDP-6 (circa 1963) over five generations \nof implementations to presently include systems covering\na price range of five to one.  The origin and \nevolution of the hardware, operating system, and languages\nare described in terms of technological change, \nuser requirements, and user developments. The PDP-10's\ncontributions to computing technology include: \naccelerating the transition from batch oriented to time\nsharing computing systems; transferring hardware \ntechnology within DEC (and elsewhere) to minicomputer\ndesign and manufacturing; supporting minicomputer \nhardware and software development; and serving as a\nmodel for single user and timeshared interactive \nminicomputer/microcomputer systems.\n computer structures, architecture, operating system, timesharing\n", "3026": "The Evolution of the Sperry Univac 1100 The 1100 series systems are Sperry Univac's\nlarge-scale main frame computer systems.  Beginning \nwith the 1107 in 1962, the 1100 series has progressed\nthrough a succession of eight compatible computer \nmodels to the latest system, the 1100/80, introduced\nin 1977.  The 1100 series hardware architecture \nis based on a 36-bit word, ones complement structure\nwhich obtains one operand from storage and one from \na high-speed register, or two operands from high-speed\nregisters.  The 1100 Operating System is designed \nto support a symmetrical multiprocessor configuration\nsimultaneously providing multiprogrammed batch, \ntimesharing, and transaction environments.\n 1100 computer series, computer architecture, multiprocessing\nlanguages, data management systems, \nend user facilities, executive control software\n", "3027": "The Development of the MU5 Computer System Following a brief outline of the background\nof the MU5 project, the aims and ideas for MU5 \nare discussed.  A description is then given of the instruction\nset, which includes a number of features \nconducive to the production of efficient compiled code\nfrom high-level language source programs.  The \ndesign of the processor is then traced from the initial\nideas for an associatively addressed \"name store\" \nto the final multistage pipeline structure involving\na prediction mechanism for instruction prefetching \nand a function queue for array element accessing.  An\noverall view of the complete MU5 complex is presented \ntogether with a brief indication of its performance.\n architecture, naming, virtual storage, instruction\nset, descriptor, pipeline, instruction buffering, \nassociative storage, function queue, computer complex\n", "3028": "The Manchester Mark I and Atlas: A His torical Perspective In 30 years of computer design at Manchester University\ntwo systems stand out: the Mark I (developed \nover the period 1946-49) and the Atlas (1955-62). \nThis paper places each computer in its his torical \ncontext and then describes the architecture and system\nsoftware in present-day terminology.  Several \ndesign concepts such as address-generation and store\nmanagement have evolved in the progression from \nMark I to Atlas.  The wider impact of Manchester innovations\nin these and other areas is discussed, and \nthe contemporary performance of the Mark I and Atlas is evaluated.\n architecture, index registers, paging, virtual\nstorage, extra codes, compilers, operating systems, \nFerranti, Manchester Mark I, Atlas, ICL\n", "3029": "Foreword to the Special Issue on Computer Architecture", "3030": "An Example of Hierarchical Design and Proof Hierarchical programming is being increasingly\nrecognized as helpful in the construction of \nlarge programs.  Users of hierarchical techniques claim\nor predict substantial increases in productivity \nand in the reliability of the programs produced.  In this\npaper we describe a formal method for hierarchical \nprogram specification, implementation, and proof.  We\napply this method to a significant list processing \nproblem and also discuss a number of extensions to current\nprogramming languages that ease hierarchical \nprogram design and proof.\n Program verification, specification, data abstraction,\nsoftware modules, hierarchical structures\n", "3031": "Abstract Data Types and Software Validation A data abstraction can be naturally specified\nusing algebraic axioms.  The virtue of these \naxioms is that they permit a representation-independent\nformal specification of a data type.  An example \nis given which shows how to employ algebraic axioms at\nsuccessive levels of implementation.  The  major \nthrust of the paper is twofold.  First, it is shown how\nthe use of algebraic axiomatizations can simplify \nthe process of proving the correctness of an implementation\nof an abstract data type.  Second, semi-automatic \ntools are described which can be used both to automate\nsuch proofs of correctness and to derive an immediate \nimplementation from the axioms.  This implementation\nallows for limited testing of programs at design \ntime, before a conventional implementation is accomplished.\n Abstract data type, correctness proof,\ndata type, data structure, specification \n", "3032": "Reverse Path Forwarding of Broadcast Packets A broadcast packet is for delivery to all\nnodes of a network.  Algorithms for accomplishing \nthis delivery through a store-and-forward packet switching\n computer network include (1) transmission \nof separately addressed packets. (2) multidestination\naddressing, (3) hot potato forwarding,(4) spanning \ntree forwarding, and (5) source based forwarding.  To\nthis list of algorithms we add (6) reverse path \nforwarding, a broadcast routing method which exploits\nrouting procedures and data structures already \navailable for packet switching.  Reverse path forwarding\nis a practical algorithm for broadcast routing \n in store-and-forward packet switching computer networks.\n The algorithm is described as being practical \n because it is not optimal according to metrics developed\nfor its analysis in this paper, and also because \nit can be implemented in existing networks with less complexity\nthan that required for the known alternatives. \n Reverse path forwarding, broadcast packets, routing,\ncomputer networks, store-and-forward packet \nswitching, broadcast protocols\n", "3033": "Optimizing Decision Trees Through Heuristically Guided Search Optimal decision table conversion has been\ntackled in the literature using two approaches, \ndynamic programming and branch-and-bound.  The former\ntechnique is quite effective, but its time and \nspace requirements are independent of how \"easy\" the\ngiven table is.  Furthermore, it cannot be used \nto produce good, quasi optimal solutions.  The branch-and-bound\ntechnique uses a good heuristic to direct \nthe search, but is cluttered up by an enormous search\nspace, since the number of solutions increases \nwith the number of test variables according to a double \nexponential.  In this paper we suggest a heuristically \nguided top-down search algorithm which, like dynamic\nprogramming, recognizes identical subproblems but \nwhich can be used to find both optimal and quasi optimal\nsolutions.  The heuristic search method introduced \nin this paper combines the positive aspects of the above\ntwo techniques.  Compressed tables with a large \nnumber of variables can be handled without deriving expanded tables first. \n Decision table, optimal decision table conversion,\ndecision tree, heuristic search, AND/OR graphs, \ndynamic programming, branch-and-bound\n", "3034": "Detection of Logical Errors in Decision Table Programs In this paper an algorithm to detect logical\nerrors in a limited-entry decision table and in \nloop-free programs with embedded decision tables is developed.\n All the conditions in the decision tables \nare assumed to be inequalities or equalities relating\nlinear expressions.  It is also assumed that actions \nin a decision table are linear in variables which occur\nin the condition stub of the decision table (or \ntables) to which control is transferred from the table.\n The algorithm is based on determining whether \na set of linear inequalities has or does not have a\nsolution.  The algorithm described in the paper is \nimplemented in Fortran IV.\n Error diagnostics, decision tables\n", "3035": "A Strategic Planning Methodology for the Computing The findings of a study designed to address\nthe pressing problems associated with the strategic \nplanning of the computing effort in higher education\nare presented here.  A planning methodology was \ndeveloped and tested through implementation at a university.\n Two years after the methodology was implemented, \nthe effectiveness of the planning methodology was assessed\nin terms of the improvement of the delivery \nof computing services to the major institutional roles\nof instruction, research, and administration. \n Two control institutions were employed to contrast the\nimprovements at the test institution.  The results \nof the research indicate the planning methodology significantly\nenhanced the delivery of computing services. \n Computer management, computer budget,\nuniversity computing, computer planning\n", "3036": "The Selection of Optimal Tab Settings A new generation of computer terminals allows\ntab settings to be selected and set by the computer. \n This feature can be used to reduce the number of characters\nthat are needed to represent a document \nfor transmission and printing.  In this note, an algorithm\nis given for selecting the optimal set of \ntab stops for minimizing the number of characters transmitted.\n An implementation of the algorithm has \nreduced the number of characters transmitted by from\n7 to 30 percent, but requires a prepass through \nthe document to compute a matrix used in determining\nthe optimal set tab stops.  The use of fixed tab \nstops, as a heuristic alternative, can achieve\nabout 80 percent of optimal with no prepass. \n Tabs, word processing, dynamic programming\n", "3037": "A Linear Sieve Algorithm for Finding Prime Numbers A new algorithm is presented for finding all\nprimes between 2 and n.  The algorithm executes \nin time proportional to n (assuming that multiplication\nof integers not larger than n can be performed \nin unit time).  The method has the same arithmetic complexity\nas the algorithm presented by Mairson [6]; \nhowever, our version is perhaps simpler and more elegant.\n It is also easily extended to find the prime \nfactorization of all integers between 2 and n in time proportional to n.   \n Primes, algorithms, data structures\n", "3038": "Using Encryption for Authentication in Large Networks of Computers Use of encryption to achieve authenticated\ncommunication in computer networks is discussed. \n Example protocols are presented for the establishment\nof authenticated connections, for the management \nof authenticated mail, and for signature verification\nand document integrity guarantee.  Both conventional \nand public-key encryption algorithms are considered as the basis for protocols.\n Encryption, security, authentication, networks, protocols,\npublic-key cryptosystems, data encryption \nstandard\n", "3039": "On-the-Fly Garbage Collection: An Exercise in Cooperation As an example of cooperation between sequential\nprocesses with very little mutual interference \ndespite frequent manipulations of a large shared data\nspace,  a technique is developed which allows nearly \nall of the activity needed for garbage detection and collection\nto be performed by an additional processor \noperating con-currently with the processor devoted to the\ncomputation proper.  Exclusion and synchronization \nconstraints have been kept as weak as could be achieved;\nthe severe complexities engendered by doing \nso are illustrated. \n Multiprocessing, fine-grained interleaving, cooperation\nbetween sequential processes with minimized \nmutual exclusion, program correctness for multiprogramming\ntasks, garbage collection \n", "3040": "Synthesizing Constraint Expressions A constraint network representation is presented\nfor a combinatorial search problem: finding \nvalues for a set of variables subject to a set of constraints.\n A theory of consistency levels in such \nnetworks is formulated, which is related to problems\nof backtrack tree search efficiency.  An algorithm \nis developed that can achieve any level of consistency\ndesired, in order to preprocess the problem for \nsubsequent backtrack search, or to function as an alternative\nto backtrack search by explicitly determining \nall solutions.\n Backtrack, combinatorial algorithms, constraint\nnetworks, constraint satisfaction, graph coloring, \nnetwork consistency, relaxation, scene labeling, search\n", "3041": "Median Split Trees: A Fast Lookup Technique for Frequently Occuring Keys Split trees are a new technique for searching sets\nof keys with highly skewed frequency distributions. \n A split tree is a binary search tree each node of which\ncontains two key values-a node value which is \na maximally frequent key in that subtree, and a split\nvalue which partitions the remaining keys (with \nrespect to their lexical ordering) between the left and\nright subtrees.  A median split tree (MST) uses \nthe lexical median of a node's descendents as its split\nvalue to force the search tree to be perfectly \nbalanced, achieving both a space efficient representation\nof the tree and high search speed.  Unlike \nfrequency ordered binary search trees, the cost of a\nsuccessful search of an MST is log n bounded and \nvery stable around minimal values.  Further, an MST\ncan be built for a given key ordering and set of \nfrequencies in time n log n, as opposed to n2 for an\noptimum binary search tree.  A discussion of the \napplication of MST's to dictionary lookup for English is\npresented, and the performance obtained is contrasted \nwith that of other techniques.\n Tree search, dictionary lookup, binary search, heaps,\nbalanced trees, Zipf's Law, information retrieval\n", "3042": "Power Trees The new class of Pk trees is presented, where\nheight balance is maintained for the nodes Iying \non particular paths.  The number of nodes of a Pk tree\nasymptotically grows as a power of the height, \nin the worst case.  A procedure for node insertion is given,\nand the class of trees  considered is restricted \nto IPk trees, which are buildable by such a procedure.\n The average behavior of such trees, studied by \nan extensive set of simulation runs, is close to that\nof AVL trees.  In particular, the family of IPO \ntrees whose main advantage is the reduced number of\nrestructurings required after node insertion, is \nanalyzed.\n Binary search trees, Pk trees, IPk trees, search\nlength, node insertion, subtree rotation\n", "3043": "Distributed Processes: A Concurrent Programming Concept A language concept for concurrent processes\nwithout common variables is introduced.  These \nprocesses communicate and synchronize by means of procedure\ncalls and guarded regions.  This concept \nis proposed for real-time applications controlled by\nmicrocomputer networks with distributed storage. \n The paper gives several examples of distributed processes\nand shows that they include procedures, coroutines, \nclasses, monitors, processes, semaphores, buffers, path\nexpressions, and input/output as special cases.\n Concurrent programming, distributed processes,\nmicroprocessor networks, nondeterminism, guarded \nregions, programming languages, process communication\nand scheduling, sorting arrays, coroutines, classes, \nmonitors, processes, semaphores, buffers, path expressions, input/output \n", "3044": "A Note on Conditional Expressions Evaluation of a conditional expression may succeed\neven when the \"deciding predicate\" diverges \nand the alternatives are records (or nodes) whose fields have different content.\n Parallel evaluation, suspending cons, Lisp, conditional\nforms, if-then-else, ambiguous function,\ninfinite structures\n", "3045": "A Simple Recovery-Only Procedure For SImple Precedence Parsers A simple method is described enabling simple\nprecedence parsers to recover from syntax errors. \n No attempt to repair errors is made, yet parsing and\nmost semantic processing can continue.  The result \nis a good \"first approximation\" to syntax error handling\nwith negligible increase in parsing time, space, \nand complexity of both the parser and its table generator. \n Syntax errors, error recovery, parsing,\nsimple precedence, compilers, debugging\n", "3046": "Computer Generation of Gamma Random Variables - II A rejection method is proposed for generating\ngamma variates with nonintegral shape parameter \na, a > 1. This method is similar to other methods given\nby Fishman, Wallace, and Tadikamalla and is faster \nthan these methods for a> 2.  The core storage requirements\nand the programming effort for the proposed \nmethod are similar to those of Wallace's or Tadikamalla's\nmethods.  The computational times for the proposed \nmethod remain fairly constant for medium and large\nvalues of a and are superior to times obtained by \nAhrens and Dieter's method for all values of a.  The\nproposed method is simpler than Ahrens and Dieter's \nmethod.\n Gamma variables, rejection method, computer methods\n", "3047": "Using Synthetic Images to Register Real Images with Surface Models A number of image analysis tasks can benefit\nfrom registration of the image with a model of \nthe surface being imaged.  Automatic navigation using visible\nlight or radar images requires exact alignment \nof such images with digital terrain models.  In addition,\nautomatic classification of terrain, using \nsatellite imagery, requires such alignment to deal correctly\nwith the effects of varying sun angle and \nsurface slope.  Even inspection techniques for certain\nindustrial parts may be improved by this means. \nWe achieve the required alignment by matching the real\nimage with a synthetic image obtained from a surface \nmodel and known positions of the light sources.  The\nsynthetic image intensity is calculated using the \nreflectance map, a convenient way of describing surface reflection\nas a function of surface gradient. \n We illustrate the technique using LANDSAT images and digital terrain models.\n Image registration, synthetic images, surface models,\nautomatic hill shading, digital terrain models, \nimage transformation, image matching, shaded images \n", "3048": "Performance Evaluation of Highly Concurrent Simulation is presented as a practical technique\nfor performance evaluation of alternative \nconfigurations of highly concurrent computers.  A technique\nis described for constructing a detailed \ndeterministic simulation model of a system.  In the model\na control stream replaces the instruction and \ndata streams of the real system.  Simulation of the\nsystem model yields the timing and resource usage \nstatistics needed for performance evaluation, without\nthe necessity of emulating the system.  As a case \nstudy, the implementation of a simulator of a model\nof the CPU-memory subsystem of the IBM 360/91 is \ndescribed.  The results of evaluating some alternative\nsystem designs are discussed.  The experiments \nreveal that, for the case study, the major bottlenecks\nin the system are the memory unit and the fixed \npoint unit.  Further, it appears that many of the sophisticated\npipelining and buffering technique simplemented \nin the architecture of the IBM 360/91 are of little\nvalue when high-speed (cache) memory is used, as \nin the IBM 360/195.\n Performance evaluation, deterministic simulation,\ncontrol stream, concurrent computers\n", "3049": "A Simply Extended and Modified Batch SEMBEGS is a complete batch environment graphical\nsystem containing components for handling \ngraphical data files, for displaying the contents of\nthese files on a variety of graphical hardware, \nand for performing graphical batch input operations.\n SEMBEGS is easy to extend and modify to meet the \ngrowing needs of a large batch environment, and is even\nextendable to a fully interactive system.  The \npaper presents the conceptual view of graphics leading\nto the design of SEMBEGS and outlines the major \ncomponents of the system.  The design of SEMBEGS is founded\nupon the basic assumption that the true aim \nof computer graphics is to describe graphical entities,\nrather than, as commonly held, to provide graphical \ninput and output functional capabilities.  SEMBEGS\nis built around a Basic Graphical Data Management \nSystem (BAGDAMS) which provides a common means of communicating\nthe descriptions of graphical entities \n between the various components of SEMBEGS.  BAGDAMS\nprovides facilities for storing, retrieving, and \nmanipulating the descriptions of graphical entities\nprovided by, and received by application programs,\ngraphics packages, and graphical devices. \n Computer graphics, data structures, graphic display,\ngraphic input, graphical database, device \nindependent graphics\n", "3050": "Systems Design Education: A Gaming Approach One of the problems facing managers of computer\ninstallations is the problem of configuring \nthe computer system to meet the demands made by the\nmix of jobs that the computer center must service. \n This paper presents a management game that allows\nthe player to configure a computer system to meet \na hypothetical job mix is under the control of a game administrator\nand can be varied to simulate a variety \nof real-world situations (I/O bound jobs, compute bound\njobs, etc.).  The player of the game receives \na set of detailed reports on the cost of his choices\nand a simulated run of the center operating under \nhis choices. \n System design, configuration, management game\n", "3051": "A Comparison of Heaps and the TL Structure for the SImulation Event Set None\n Simulation,event set, heaps, TL structure\n", "3052": "Cold-Start vs. Warm-Start Miss Ratios In a two-level computer storage hierarchy, miss\nratio measurements are often made from a \"cold \nstart,\" that is made with the first-level  store initially\nempty.  For large capacities the effect on \nthe measured miss ratio of the misses incurred while\nfilling the first-level store can be significant, \neven for long reference strings.  Use of \"warm-start\"\nrather than \"cold-start\" miss ratios cast doubt \non the widespread belief that the observed \"S-shape\" of\nlifetime (reciprocal of miss ratio) versus capacity \ncurve indicates a property of behavior of programs that\nmaintain a constant number of pages in main storage. \n On the other hand, if cold-start miss ratios are measured\nas a function of capacity and measurement \nlength, then they are useful in studying systems in which\noperation of a program is periodically interrupted \nby task switches.  It is shown how to obtain, under simple\nassumptions, the cache miss ratio for multiprogramming \nfrom cold-start miss ratio values and how to obtain\napproximate cold-start miss ratios from warm-start \nmiss ratios.\n Miss ratio, cold start, warm start, storage hierarchy,\nlifetime function, multiprogramming, S-shape\n", "3053": "Packed Scatter Tables Scatter tables for open addressing benefit\nfrom recursive entry displacements, cutoffs for \nunsuccessful searches, and auxiliary cost functions.  Compared\nwith conventional methods, the new techniques \nprovide substantially improved tables that resemble exact-solution\noptimal packings.  The displacements \nare depth-limited approximations to an enumerative\n(exhaustive) optimization, although packing costs \nremain linear-O(n)-with table size n.  The techniques are\nprimarily suited for important fixed (but possibly \nquite large) tables for which reference frequencies may\nbe known: op-code tables,spelling dictionaries, \naccess arrays.  Introduction of frequency weights further\nimproves retrievals, but the enhancement may \ndegrade cutoffs.  \n Assignment problem, backtrack programming, hashing, open\naddressing, recursion, scatter table rearrangements \n", "3054": "Implementing Quicksort Programs This paper is a practical study of how to\nimplement the Quicksort sorting algorithm and its \nbest variants on real computers, including how to apply\nvarious code optimization techniques.  A detailed \nimplementation combining the most effective improvements\nto Quicksort is given, along with a discussion \nof how to implement it in assembly language.  Analytic\nresults describing the performance of the programs \nare summarized.  A variety of special situations are considered\nfrom a practical standpoint to illustrate \nQuicksort's wide applicability as an internal sorting\nmethod which requires negligible extra storage. \n Quicksort, analysis of algorithms, code optimization, sorting\n", "3055": "An Analysis of Algorithms for the Dutch National Flag Problem Solutions to the Dutch National Flag Problem\nhave been given by Dijkstra [1] and Meyer [3]. \n Dijkstra starts with a simple program and arrives at\nan improved program by refinement.  Both of the \nalgorithms given by Dijkstra are shown to have an expected number\nof swaps which is 2/3N + 0(1) and that \nthese values differ at most by 1/3 of a swap and asymptotically\nby 1/4 of a swap.  The algorithm of Meyer \nis shown to have expected swap complexity 5/9N.\n Algorithmic analysis, Dutch National Flag\nProblem, refinement, structured programming\n", "3056": "Counting Large Numbers of Events in Small Registers It is possible to use a small counter to keep\napproximate counts of large numbers.  The resulting \nexpected error can be rather precisely controlled.  An\nexample is given in which 8-bit counters (bytes) \nare used to keep track of as many as 130,000 events with\na relative error which is substantially independent \nof the number n of events.  This relative error can\nbe expected to be 24 percent or less 95 percent of \nthe time (i.e.o = n/8).  The techniques could be used\nto advantage in multichannel counting hardware \nor software used for the monitoring of experiments or processes.\n Counting\n", "3057": "Optimal His togram Matching by Monotone Gray Level Transformation This paper investigates the problem of optimal\nhis togram matching using monotone gray level \ntransformation, which always assigns all picture points\nof a given gray level i to another gray level \nT(i) such that if i > j, then T(i) > T(j).  The objective\nis to find a transformed digital picture of \na given picture such that the sum of absolute errors\nbetween the gray level his togram of the transformed \npicture and that of a reference picture is minimized.\n This is equivalent to placing k1 linearly ordered \nobjects of different sized one by one into k2 linearly ordered\nboxes of assorted sizes, such that the \naccumulated error of space under packed or overpacked\nin the boxes is minimized; the placement function \nis monotonic, which ensures a polynomial time solution\nto this problem.  A tree search algorithm for \noptimal his togram matching is presented which has time\ncomplexity O(k1 x k2).  If the monotone property \nis dropped, then the problem becomes NP-complete,\neven if it is restricted to k2 = 2. \n Optimal his togram matching, gray level transformation,\npacking problem, tree searching algorithm, \npicture processing\n", "3058": "Jump Searching: A Fast Sequential Search Technique When sequential file structures must be used\nand binary searching is not feasible, jump searching \nbecomes an appealing alternative.  This paper explores\nvariants of the classic jump searching scheme \nwhere the optimum jump size is the square root of the\nnumber of records.  Multiple level and variable \nsize jump strategies are explored, appropriate applications\nare discussed and performance is evaluated.\n Jump searching, sequential files, file management,\nsearch strategies, database structures, index \nsearching\n", "3059": "Models for Parallel Processing WIthin Programs: Approximate queueing models for internal parallel\nprocessing by individual programs in a multiprogrammed \nsystem are developed in this paper.  The solution technique\nis developed by network decomposition.  The \nmodels are formulated in terms of CPU:I/O and I/O:I/O overlap\nand applied to the analysis of these problems. \n The percentage performance improvement from CPU:I/O\noverlap is found to be greatest for systems which \nare in approximate CPU:I/O utilization balance and for\nlow degrees of multiprogramming.  The percentage \nimprovement from I/O:I/O overlap is found to be greatest\nfor systemtems in which the I/O system is more \nutilized than the CPU.\n Multiprogramming, parallel processing, queueing\nnetwork models, multiprocessing of computation \nand I/O \n", "3060": "Fortran 77 There is a new standard Fortran.  The official\ntitle is \"American National Standard Programming \nLanguage Fortran, X3.9-1978,\" but it is more commonly\nreferred to as \"Fortran 77,\" since its development \nwas completed in 1977.  It replaces the Fortran standard\ndesignated X3.9-1966.  This paper describes \nmany of the features of Fortran 77 and also provides\nsome information about how and why the standard \nwas developed. \n None\n", "3061": "Simulations of Dynamic Sequential Search Algorithms None\n Searching, list processing, sequential\nsearching, dynamic reordering, simulation \n", "3062": "Real Time Plotting of Approximate Contour Maps None\n Contour map, digital plotting, graphical characters\n", "3063": "A Note on Virtual Memory Indexes None\n Index, B-tree, pages, file organization,\nlinked representation, maintenance costs \n", "3064": "Event Manipulation for Discrete Simulations The event-manipulation system presented here consists of\ntwo major parts.  The first part addresses \nthe familiar problem of event scheduling efficiency\nwhen the number of scheduled events grows large. \n The second part deals with the less apparent problem\nof providing efficiency and flexibility as scheduled \nevents are accessed to be executed.  Additional features\nand problems dealt with include the proper handling \nof simultaneous events; that certain events must be created,\nscheduled, and executed at the same points \nin simulated time; that infinite loops caused by the concatenation\nof such \"zero-time\" events are possible \nand must be diagnosed; that maintaining various event\ncounts is practical and economical; and that a \ncapability for handling  \"time-displaceable\" events is desirable and possible.  \n Simulation, discrete systems simulation, discrete\nevent simulation, time-flow mechanisms\n", "3065": "Right Brother Trees Insertion and deletion are provided for the\nclass of right (or one-sided) brother trees which \nhave O (log n) performance.  The importance of these\nresults stems from the close relationship of right \nbrother trees which have an insertion algorithm operating\nin O (log2 n).  Further, although both insertion \nand deletion can be  carried out in O (log n) time for\nright brother trees, it appears that the insertion \nalgorithm is inherently much more difficult than the\ndeletion algorithm-the reverse of what one usually \nobtains.  \n Dictionary problem, search trees, AVL trees, brother\ntrees, right-balanced trees,one-sided height-balanced \ntrees, insertion and deletion algorithms\n", "3066": "A Controlled Experiment in Program Testing This paper describes an experiment in program\ntesting, employing 59 highly experienced data \nprocessing professionals using seven methods to test\na small PL/I program.  The results show that the \npopular code walk through/inspection method was as effective\nas other computer-based methods in finding \nerrors and that the most effective methods (in terms of\nerrors found and cost) employed pairs of subjects \nwho tested the program independently and then pooled\ntheir findings.  The study also shows that there \nis a tremendous amount of variability among subjects\nand that the ability to detect certain types of \nerrors varies from method to method.\n Software reliability, program verification, debugging,\ntesting, code walkthroughs, code inspections, \npersonnel selection\n", "3067": "Generalized Working Sets for Segment Reference Strings The working-set concept is extended for programs\nthat reference segments of different sizes. \n The generalized working-set policy (GWS) keeps as its\nresident set those segments whose retention costs \ndo not exceed their retrieval costs.  The GWS is a model\nfor the entire class of demand-fetching memory \npolicies that satisfy a resident-set inclusion property.\n A generalized optimal policy (GOPT) is also \ndefined; at its operating points it minimizes aggregated\nretention and swapping costs.  Special cases \nof the cost structure allow GWS and GOPT to simulate\nany known stack algorithm, the working set, and \nVMIN.  Efficient procedures for computing demand curves\nshowing swapping load as a function of memory \nusage are developed for GWS and GOPT policies.  Empirical\ndata from an actual system are included.\n Database referencing, memory management, optimal\nmemory policies, paging, program behavior, program \nmeasurement, segmentation, working sets\n", "3068": "A Model for Verification of Data Security in Operating Systems Program verification applied to kernel architectures\nforms a promising method for providing \nuncircumventably secure, shared computer systems.  A\nprecise definition of data security is developed \nhere in terms of a general model for operating systems.\n This model is suitable as a basis for verifying \nmany of those properties of an operating system which\nare necessary to assure reliable enforcement of \nsecurity.  The application of this approach to the\nUCLA secure operating system is also discussed. \n Operating systems, security, protection, program verification\n", "3069": "A Practical Interprocedural Data Flow Analysis Algorithm A new interprocedural  data flow analysis algorithm\nis presented and analyzed.  The algorithm \nassociates with each procedure in a program information\nabout which variables may be modified, which \nmay be used, and which are possibly preserved by a call\non the procedure, and all of its subcalls.  The \nalgorithm is sufficiently powerful to be used on recursive\nprograms and to deal with the sharing of variables \nwhich arises through reference parameters.  The algorithm\nis unique in that it can compute all of this \ninformation in a single pass, not requiring a prepass to\ncompute calling relationships or sharing patterns. \n The algorithm is asymptotically optimal in time complexity.\n It has been implemented and is practical \neven on programs which are quite large.\n Data flow analysis, global flow analysis, optimization,\nside effects, relations, reference parameters, \nincarnations\n", "3070": "Hybrid Simulation Models of Computer Systems This paper describes the structure and operation\nof a hybrid simulation model in which both \ndiscrete-event simulation and analytic techniques are\ncombined to produce efficient yet accurate system \nmodels.  In an example based on a simple hypothetical\ncomputer system, discrete-event simulation is used \nto model the arrival and activation of jobs, and a\ncentral-server queueing network models the use of \nsystem processors.  The accuracy and efficiency of the\nhybrid technique are demonstrated by comparing \nthe result and computational costs of the hybrid model of\nthe example with those of an equivalent simulation-only \nmodel.  \n Performance evaluation, simulation, queueing\nnetwork models, central server model\n", "3071": "An Algorithm Using Symbolic Techniques for the In this note, an algorithm is presented for the\nsymbolic calculation of certain algebraic invariants \nof the Weyl tensor which permits the determination\nof the Bel-Petrov types of a gravitational field. \n This algorithm, although more specialized than that\nof D'Inverno and Russell-Clark, requires neither \nthe use of a special coordinate system nor the spin coefficient\nformalism.  The algorithm has been implemented \nin FORMAC and is designed to complete the classification\nscheme proposed by Petrov in his book.  An appendix \ncontains examples illustrating the use of the algorithm.\n General relativity, Bel-Petrov types,\nFORMAC, symbolic manipulation, tensors\n", "3072": "Feedback Coupled Resource Allocation Policies Model studies of some integrated, feedback-driven\nscheduling systems for multiprogrammed- multiprocessor \ncomputer systems are presented.  The basic control variables\nused are the data-flow rates for the processes \nexecuting on the CPU.  The model systems feature simulated\ncontinuous-flow and preempt-resume scheduling \nof input-output activity.  Attention is given to the\namount of memory resource required for effective \nprocessing of the I/O activity (buffer space assignment).\n The model studies used both distribution-driven \nand trace-driven techniques.  Even relatively simple dynamic\nschedulers are shown to improve system performance \n(as measured by user CPU time) over that given by optimal\nor near-optimal static schedulers imbeded \nin identical system structures and workload environments.\n The improvement is greatest under a heavy \nI/O demand workload.\n Integrated schedulers, feedback scheduling,\nmultiprogramming systems, I/O system scheduling\n", "3073": "Communicating Sequential Processes This paper suggests that input and output are\nbasic primitives of programming and that parallel \ncomposition of communicating sequential processes is\na fundamental program structuring method.  When \ncombined with a development of Dijkstra's guarded command,\nthese concepts are surprisingly versatile. \n Their use is illustrated by sample solutions of\na variety of familiar programming exercises.\n Programming, programming languages, programming primitives,\nprogram structures, parallel programming, \nconcurrency, input, output, guarded commands, nondeterminacy,\ncoroutines, procedures, multiple entries, \nmultiple exits, classes, data representations, recursion,\nconditional critical regions, monitors, iterative \narrays\n", "3074": "A Time- and Space- Efficient Garbage Compaction Algorithm Given an area of storage containing scattered,\nmarked nodes of differing sizes, one may wish \nto rearrange them into a compact mass at one end of the\narea while revising all pointers to marked nodes \nto show their new locations.  An algorithm is described\nhere which accomplishes this task in linear time \nrelative to the size of the storage area, and in a space\nof the order of one bit for each pointer.  The \nalgorithm operates by reversibly encoding the situation\n(that a collection of locations point to a single \nlocation) by a linear list, emanating from the pointed-to\nlocation, passing through the pointing locations, \nand terminating with the pointed-to location's transplanted contents.\n Garbage collection, compaction, compact ification,\nstorage reclamation, storage allocation, record \nstructures, relocation, list processing, free storage, pointers, data structures\n", "3075": "Fast Parallel Sorting Algorithms A parallel bucket-sort algorithm is presented\nthat requires time O(log n) and the use of n \nprocessors.  The algorithm makes use of a technique that\nrequires more space than the product of processors \nand time.  A realistic model is used model is used in which\nno memory contention is permitted.  A procedure \nis also presented to sort n numbers in time O(k log\nn) using n 1 + 1/k processors, for k an arbitrary \ninteger.  The model of computation for this procedure\npermits simultaneous fetches from the same memory \nlocation.\n Parallel processing, sorting, algorithms, bucket sort\n", "3076": "Value Conflicts and Social Choice in Electronic During the last few years, computer-based\nsystems which automate the transfer and recording \nof debits and credits have begun to be implemented on\na large scale.  These systems promise both financial \nbenefits for the institutions that use them and potential\nconveniences to their customers.  However, \nthey also raise significant social, legal, and technical\nquestions that must be resolved if full scale \nsystems for Electronic Funds Transfer (EFT) are not\nto cause more problems for the larger public than \nthey solve.  This paper examines the incentives for EFT\ndevelopments and the social problems they raise \nin the context of conflicts between five different value\npositions that are often implicit in analyses \nof proposed EFT arrangements.  These conflicts reflect\nthe relative importance of certain problems for \nspecific groups.  The value positions implicit in EFT proposals\nhelp to organize analyses of market arrangements, \nsystem reliability, and privacy of transactions.  These\ntopics are analyzed in this article and related \nto the value positions held by concerned parties.  Last,\nthe ways in which the public can learn about \nthe social qualities of different EFT arrangements and\nthe pace of EFT developments are both discussed \nin the context of social choice. \n Electronic funds transfer systems, social impacts\nof computing, privacy, social choice, computer \nnetworks, network reliability, security, social values\n", "3077": "Can Programming Be Liberated from the von Neumann Conventional programming languages are growing\never more enormous, but not stronger.  Inherent \ndefects at the most basic level cause them to be both\nfat and weak: their primitive word-at-a-time style \nof programming inherited from their common ancestor-the\nvon Neumann computer, their close coupling off \nsemantics to state transitions, their division of programming\ninto a world of expressions and a world \nof statements, their inability to effectively use powerful\ncombining forms for building new programs \nfrom existing ones, and their lack of useful mathematical\nproperties for reasoning about programs. An \nalternative functional style of programming is founded\non the use of combining forms for creating programs. \n Functional programs deal with structured data, are often\nnonrepetitive and nonrecursive, are hierarchically \nconstructed, do not name their arguments, and do not require\nthe complex machinery of procedure declarations \nto become generally applicable.  Combining forms can\nuse high level programs to build still higher level\nones in a style not possible in conventional languages.\n Associated with the functional style of programming \nis an algebra of programs whose variables range over\nprograms and whose operations are combining forms. \n This algebra can be used to transform programs and\nto solve equations whose \"unknowns\" are programs \nin much the same way one transforms equations in high\nschool algebra.  These transformations are given \nby algebraic laws and are carried out in the same language\nin which programs are written.  Combining \nforms are chosen not only for their programming power\nbut also for the power of their associated algebraic \nlaws.  General theorems of of the algebra give the detailed\nbehavior and termination conditions for large \nclasses of programs.  A new class of computing systems\nuses the functional programming style both in \nits programming language and in its state transition\nrules.  Unlike von Neumann languages, these systems \nhave semantics loosely coupled to states-only one\nstate transition occurs per major computation. \n Functional programming, algebra of programs, combining\nforms, functional forms, programming languages, \nvon Neumann computers, von Neumann languages, models of\ncomputing systems, applicative computing systems, \napplicative state transition systems, program transformation,\nprogram correctness, program termination, \nmetacomposition\n", "3078": "Analysis of the Availability of Computer Analytical results, related to the availability\nof a computer system constructed of unreliable \nprocessors, are presented in this paper.  These results\nare obtained by using various computer-aided \nalgebraic manipulation techniques.  A major purpose of\nthis paper is to demonstrate that the difficulties \nof obtaining analytical solutions to Markov processes\ncan be considerably reduced by the application \nof symbol manipulation programs.  Since many physical\nsystems can be modeled by Markov and semi-Markov \nprocesses, the potential range of application of these techniques\nis much wider than the problem of availability \nanalyzed here.\n Computer-aided algebra, symbol manipulation, Markov\nprocess, reliability, redundant structures, \non-line computer system.\n", "3079": "An Algorithm for Reasoning About Equality A simple technique for reasoning about equalities\nthat is fast and complete for ground formulas \nwith function symbols and equality is presented.\n A proof of correctness is given as well. \n Theorem proving, deduction, program verification, equality\n", "3080": "Proving the Correctness of Heuristically Optimized Code  A system for proving that programs written\nin a high level language are correctly translated \nto a low level language is described.  A primary use of\nthe system is as a post optimization step in code \ngeneration.  The low level language programs need not\nbe generated by a compiler and in fact could be \nhand coded.  Examples of the usefulness of such a system\nare given.  Some interesting results are the \nability to handle programs that implement recursion by\nbypassing the start of the program, and the detection \nand pinpointing of a wide class of errors in the low\nlevel language programs.  The examples demonstrate \nthat optimization of the genre of this paper can result\nin substantially faster operation and the saving \nof memory in terms of program and stack sizes.\n Compilers, correctness, code optimization,\ndebugging, program verification, Lisp\n", "3081": "Shallow Binding in Lisp 1.5 Shallow binding is a scheme which allows the\nvalue of a variable to be accessed in a bounded \namount of computation.  An elegant model for shallow binding\nin  Lisp 1.5 is presented in which context-switching \nis an environment tree transformation called rerooting.\n Rerooting is completely general and reversible, \nand is optional in the sense that a Lisp 1.5 interpreter\nwill operate correctly whether or not rerooting \nis invoked one very context change.   Since rerooting\nleaves assoc [v, a] invariant, for all variables \nv and all environments a, the programmer can have access\nto a rerooting primitive, shallow[], which gives \nhim dynamic control over whether accesses are shallow or\ndeep, and which affects only the speed of execution \nof a program, not its semantics.  In addition, multiple\nprocesses can be active in the same environment \nstructure, so long as rerooting is an indivisible operation.\n Finally, the concept of rerooting is shown \nto combine the concept of shallow binding in Lisp with\nDijkstra's display for Algol and hence is a general \nmodel for shallow binding.\n Lisp 1.5, environment trees, FUNARG'S, shallow binding,\ndeep binding, multiprogramming, Algol display\n", "3082": "Time, Clocks, and the Ordering of Events in a Distributed System The concept of one event happening before\nanother in a distributed system is examined, and\nis shown to define a partial ordering of the events.\n A distributed algorithm is given for synchronizing \na system of logical clocks which can be used to totally\norder the events.  The use of the total ordering \nis illustrated with a method for solving synchronization\nproblems.  The algorithm is then specialized \nfor synchronizing physical clocks, and a bound is derived\non how far out of synchrony the clocks can \nbecome.  \n Distributed systems, computer networks,\nclock synchronization, multiprocess systems\n", "3083": "Pseudochaining in Hash Tables This paper presents pseudochaining as a new\ncollision-resolution method.  Pseudochaining is \nhalf way between open addressing and chaining.  It owes\nits name to the fact that link fields are present \nin each cell of the hash table which permits \"chaining\"\nof the first overflow items in the table.  The \nefficiency of the method is derived and a tradeoff analysis is given.\n Hash code, scatter storage, open addressing, chaining,\npseudochaining, collision resolution, searching, \nuniform probing.\n", "3084": "Interpolation Search -A Log LogN Search Interpolation search is a method of retrieving\na desired record by key in an ordered file by \nusing the value of the key and the statistical distribution\nof the keys.  It is shown that on the average \nlog logN file accesses are required to retrieve a key,\nassuming that the N keys are uniformly distributed. \n The number of extra accesses is also estimated and shown\nto be very low.  The same holds if the cumulative \ndistribution function of the keys is known.  Computational\nexperiments confirm these results.  \n Average number of accesses, binary search, database,\ninterpolation search, retrieval, searching, \nuniform distribution \n", "3085": "An O(n) Algorithm for Determining a Near-Optimal This paper discusses the computation of matrix\nchain products of the form M1 x M2 x ... x Mn \nwhere Mi's are matrices.  The order in which the matrices\nare computed affects the number of operations. \n A sufficient condition about the association of the\nmatrices in the optimal order is presented.  An \nO(n) algorithm to find an order of computation which\ntakes less than 25 percent longer than the optimal \ntime Topt is also presented.  In most cases, the algorithm\nyields the optimal order or an order which \ntakes only a few percent longer than Topt (less than 1 percent on the average).\n Approximate algorithm, heuristic algorithm,\nmatrix multiplication, matrix chain product\n", "3086": "On the Complexity of Computing the Measure of U[ai, bi] The decision tree complexity of computing the\nmeasure of the union of n (possibly overlapping) \nintervals is shown to be  (n log n), even if comparisons\nbetween linear functions of the interval endpoints \nare allowed.  The existence of an   (n log n) lower bound\nto determine whether any two of n real numbers \nare within   of each other is also demonstrated.  These\nproblems provide an excellent opportunity for \ndiscussing the effects of the computational model on\nthe ease of analysis and on the results produced.\n Analysis of algorithms, combinatorial problems,\ncomputational complexity, computational models, \ndecision tree programs, lower bounds\n", "3087": "An English Language Question Answering System By typing requests in English, casual users\nwill be able to obtain explicit answers from a \nlarge relational database of aircraft flight and maintenance\ndata using a system called PLANES.  The \ndesign and implementation of this system is described and\nillustrated with detailed examples of the operation \nof system components and examples of overall system\noperation.  The language processing portion of the \nsystem uses a number of augmented transition networks,\neach of which matches phrases with a specific \nmeaning, along with context registers (his tory keepers)\nand concept case frames; these are used for judging \nmeaningfulness of questions, generating dialogue for clarifying\npartially understood questions, and resolving \nellipsis and pronoun reference problems.  Other system components\nconstruct a formal query for the relational \ndatabase, and optimize the order of searching relations.\n Methods are discussed for handling vague or \ncomplex questions and for providing browsing ability.\n Also included are discussions of important issues \nin programming natural language systems for limited domains,\nand the relationship of this system to others. \n Question answering, relational database, natural language,\ndatabase front end, artificial intelligence, \ndialogue, query generation, information retrieval, natural language programming \n", "3088": "General Equations for Idealized CPU-I/O Overlap Configurations General equations are derived for estimating\nthe maximum possible utilization of main storage \npartitions, CPU and I/O devices under different conditions\nin an idealized CPU-I/O overlap model of multiprogrammed \ncomputer systems.  The equations are directly applicable\nto any configuration consisting  of sets of \nidentical CPU's I/O processors, main storage partitions\nand user tasks.  Examples are provided to illustrate \nthe use of the equations to compute effective processing\ntime per record and expected timesharing response \ntime under both balanced and unbalanced resource utilization conditions. \n Blocking, buffering, input/output, overlap, performance,\nresource allocation, throughput, timesharing\n", "3089": "Performance of Rollback Recovery Systems under Intermittent Failures A mathematical model of a transaction-oriented\nsystem under intermittent failures is proposed. \n The system is assumed to operate with a checkpointing\nand rollback/recovery method to ensure reliable \ninformation processing.  The model is used to derive the\nprincipal performance measures, including availability, \nresponse time, and the system saturation point.   \n Database reliability, file systems, checkpoints, recovery\nprocedures, checking techniques, reliability \nand system performance evaluation\n", "3090": "Automated Welfare Client-Tracking and Service The impacts of an automated client-tracking\nsystem on the clients, caseworkers, administrators, \nand operations of the welfare agencies that use it are\nreported.  The major impact of this system was \nto enhance the administrative  attractiveness of the\nusing agencies in the eyes of funders rather than \nto increase their internal administrative efficiency. \nThis impact is a joint product of both the technical \nfeatures of the computer-based system and of the organizational\ndemands placed upon different agencies, \nadministrators, and caseworkers.  It illustrates the\nway \"successful\" automated information systems fit \nthe political economies of the groups that use them.    \n Social impacts of computing, organizational impacts\nof computing, management information systems, \nsociology of computing, information systems and\nservice integration, urban information systems\n", "3091": "Some Basic Determinants of Computer Programming Productivity The propose of this research was to examine\nthe relationship between processing characteristics \nof programs and experience characteristics of programmers\nand program development time.  The ultimate \nobjective was to develop a technique for predicting\nthe amount of time necessary to create a computer \nprogram.  The fifteen program characteristics hypothesized\nas being associated with an increase in programming \ntime required are objectively measurable from preprogramming\nspecifications.  The five programmer characteristics \nare experience-related and are also measurable before a programming\ntask is begun.  Nine program characteristics \nemerged as major influences on program development time,\neach associated with increased program development \ntime.  All five programmer characteristics were found\nto be related to reduced program development time. \n A multiple regression  equation which contained one programmer\ncharacteristic and four program characteristics \ngave evidence of good predictive power for\nforecasting program development time.   \n Programmer performance standards, predicting program\ndevelopment time, program estimation techniques, \nprogram development equation, value of programming experience,\nprogrammer evaluation, programmer scheduling, \nprogrammer productivity, programming management, Cobol programming\n", "3092": "Characteristics of Application Software Maintenance Maintenance and enhancement of application\nsoftware consume a major portion of the total life \ncycle cost of a system.  Rough estimates of the total\nsystems and programming resources consumed range \nas high as 75-80 percent in each category.  However,\nthe area has been given little attention in the \nliterature.  To analyze the problems in this area a\nquestionnaire was developed and pretested.  It was \nthen submitted to 120 organizations.  Respondents totaled\n69.  Responses were analyzed with the SPSS \nstatistical package.  The results of the analysis indicate\nthat: (1) maintenance and enhancement do consume \nmuch of the total resources of systems and programming\ngroups; (2) maintenance and enhancement tend to \nbe viewed by management as at least somewhat more important\nthan new application software development; \n(3) in maintenance and enhancement, problems of a management\norientation tend to be more significant \nthan those of a technical orientation; and (4) user\ndemands for enhancements and extension constitute \nthe most important management problem area.\n Software maintenance, use of productivity\naids, management and technical issues \n", "3093": "Automatic Error Recovery for LR Parsers In this paper we present a scheme for detecting\nand recovering from syntax errors in programs. \n The scheme, which is based on LR parsing, is driven\nby information which is directly and automatically \nobtainable from the information that is already present\nin an LR parser.  The approach, which is patterned \nafter that of Levy and Graham and Rhodes, appears to\nprovide error recovery which is both simple and \npowerful.\n Programming languages, error correction, automatic\ncorrection, parsing, LR, syntax errors, compilers\n", "3094": "Analyses of Deterministic Parsing Algorithms This paper describes an approach for determining\nthe minimum, maximum, and average times to \nparse sentences acceptable by a deterministic parser.\n These quantities are presented in the form of \nsymbolic formulas, called time-formulas.  The variables\nin these formulas represent not only the length \nof the input string but also the time to perform elementary\noperations such as pushing, popping, subscripting, \niterating, etc.  By binding to the  variables actual numerical\nvalues corresponding to a given compiler-machine \nconfiguration, one can determine the execution time\nfor that configuration.  Time-formulas are derived \nby examining the grammar rules and the program representing\nthe algorithm one wishes to analyze.  The \napproach is described by using a specific grammar that defines\nsimple arithmetic expressions.  Two deterministic\nparsers are analyzed: a top-down recursive descent\nLL(1) parser, and a bottom-up SLR(1) parser.  The \npaper provides estimates for the relative efficiencies\nof the two parsers.  The estimates applicable \nto a specific machine, the PDP-10, are presented and\nsubstantiated buy benchmarks.  Finally, the paper \nillustrates the proposed approach by applying it to\nthe analyses of parsers for a simple programming \nlanguage.  \n Syntactic analysis, analysis of algorithms,top-down\nand bottom-up parsing, relative efficiencies.\n", "3095": "A Selective Traversal Algorithm for Binary Search Trees The problem of selecting data items from\na binary search tree according to a list of range \nconditions is considered.  The process of visiting a\nminimal number of nodes to retrieve data satisfying \nthe range conditions is called selective traversal.  Presented\nin this paper is an algorithm for selective \ntraversal which uses a tag field for each node in the\ntree.  The algorithm is particularly useful and \nefficient when examination of data is more time\nconsuming than examination of a tag field. \n Data retrieval, range conditions, binary search\ntree, tree traversal, selective traversal\n", "3096": "An Optimal Method for Deletion in One-Sided Height-Balanced Trees A one-sided height-balanced tree is a binary\ntree in which every node's right subtree has a \nheight which is equal to or exactly one greater than the\nheight of its left subtree.  It has an advantage \nover the more general AVL tree in that only one bit\nof balancing information is required (two bits are \nrequired for the ACL tree).  It is shown that deletion of\nan arbitrary node of such a tree can be accomplished \nin O(logn) operations, where n is the number of nodes\nin the tree.  Moreover the method is optimal in \nthe sense that its complexity cannot be reduced in order\nof magnitude.  This result, coupled with earlier \nresults by Hirschberg, indicates that, of the three basic\nproblems of insertion, deletion, and retrieval, \nonly insertion is adversely affected by this modification of an AVL tree.   \n Balanced, binary, search, trees\n", "3097": "Optimal Shift Strategy for a Block-Transfer CCD Memory For the purposes of this paper, a block-transfer\nCCD memory is composed of serial shift registers \nwhose shift rate can vary, but which have a definite minimum\nshift rate (the refresh rate) and a definite \nmaximum shift rate.  The bits iin the shift registers\nare numbered 0 to N - 1, and blocks of N bits are \nalways transferred, always starting at bit 0.   What\nis the best shift strategy so that a block transfer \nrequest occurring at a random time will have to wait the\nminimal amount of time before bit 0 can be reached? \n The minimum shift rate requirement does not allow one\nto  simply \"park\" at bit 0 and wait for a transfer \nrequest.  The optimal strategy involves shifting as slowly\nas possible until bit 0 is passed, then shifting \nas quickly as possible until a critical boundary is\nreached, shortly before bit 0 comes around again. \n This is called the \"hurry up and wait\" strategy and is well\nknown outside the computer field.  The block-transfer \nCCD memory can also be viewed as a paging drum\nwith a variable (bounded) rotation speed.\n Paging drum, charge coupled devices, shift register\nmemory, memory hierarchy, electronic drum, \nlatency\n", "3098": "Computer Generation of Gamma Random Variables A new method for generating random variables\nfrom the gamma distribution with nonintegral shape \nparameter a is proposed.  This method is similar to two\nother methods recently given by Wallace and Fishman. \n It is compared with Fishman's and Ahrens and Dieter's methods.\n The core storage requirements and programming \neffort for this method are similar to those of Fishman's\nmethod.  The proposed method is the same as \nFishman's method for 1 < a < 2 and is faster than Fishman's\nmethod for 3 < a < 19.  Also, the proposed \nmethod is much simpler than Ahrens and Dieter's method and is faster for a < 8. \n Gamma variables, rejection method, computer methods\n", "3099": "New Sufficient Optimality Conditions for The purpose of this report is to present a\nnew class of sufficient optimality conditions for \npure and mixed integer programming problems.  Some of\nthe sets of sufficient conditions presented can \nbe thought of as generalizations of optimality conditions\nbased on primal-dual complementarity in linear \nprogramming.  These sufficient conditions are particularly\nuseful for the construction of difficult integer \nprogramming problems with known optimal solutions.  These\nproblems may then be used to test and/or \"benchmark\" \ninteger programming codes.\n Integer programming, optimality conditions, test\nproblem construction, Kuhn-Tucker conditions, \ngreatest common divisor \n", "3100": "An Interference Matching Technique for Inducing Abstractions A method for inducing knowledge by abstraction\nfrom a sequence of training examples is described. \n The proposed method, interference matching, induces abstractions\nby finding relational properties common \nto two or more exemplars.  Three tasks solved by a program\nthat uses an interference-matching algorithm \nare presented.  Several problems concerning the description\nof the training examples and the adequacy \nof interference matching are discussed, and directions\nfor future research are considered.\n Rule induction, knowledge acquisition, partial\nmatching, interference, graph matching, learning, \ninduction, knowledge representation, informal retrieval,\nabstraction, generalization, language learning, \ncomplexity, predicate discovery.\n", "3101": "The SL5 Procedure Mechanism This paper describes an integrated procedure\nmechanism that permits procedures to be used as \nrecursive functions or as coroutines.  This integration\nis accomplished by treating procedures and their \nactivation records (called environments) as data objects\nand by decomposing procedure invocation into \nthree separate components at the source-language level.\n In addition, argument binding is under the control \nof the programmer, permitting the definition of various\nmethods of argument transmission in the source \nlanguage itself.  The resulting procedure mechanism,which\nis part of the SL5 programming language, is \nwell suited to goal-oriented problems and to other problems\nthat are more readily programmed by using \ncoroutines. Several examples are given. \n Procedures, coroutines, programming languages,\ninterpreters, SNOBOL 4, backtracking\n", "3102": "Incorporation of Units into Programming Languages The issues of how a programming language might\naid in keeping track of physical units (feet, \nsec, etc.) are discussed.  A method is given for the\nintroduction of relationships among units (a watt \nis volts*amps, a yard is three feet) and subsequent automatic\nconversion based upon these relationships.\n Various proposals for syntax are considered.\n Units, language design, compiler construction, language syntax\n", "3103": "Automatic Data Structure Selection: An Example and Overview The use of several levels of abstraction has\nproved to be very helpful in constructing and \nmaintaining programs.  When programs are designed with abstract\ndata types such as sets and lists, programmer \ntime can be saved by automating the process of filling\nin low-level implementation details.  In the past, \nprogramming systems have provided only a single general\npurpose implementation for an abstract type. \n Thus the programs produced using abstract types were\nthen inefficient in space or time.  In this paper \na system for automatically choosing efficient implementations\nfor abstract types from a library of implementations \nis discussed.  This process is discussed in detail for\nan example program.  General issues in data structure \nselection are also reviewed. \n Abstract data types, automatic programming, data\nstructures, optimizing compilers, sets, lists\n", "3104": "Test Data as an Aid in Proving Program Correctness Proofs of program correctness tend to be long\nand tedious, whereas testing, though useful in \ndetecting errors, usually does not guarantee correctness.\n This paper introduces a techniques whereby \ntest data can be used in proving program correctness.\n In addition to simplifying the process of proving \ncorrectness, this method simplifies the process of providing\naccurate specification for a program.  The \napplicability of this technique to procedures\nand recursive programs is demonstrated.\n Program verification, program testing, recursive programs\n", "3105": "A Language Extension for Expressing Constraints on Data Access Controlled sharing of information is needed and\ndesirable for many applications and is supported \nin operating systems by access control mechanisms.  This\npaper shows how to extend programming languages \nto provide controlled sharing.  The extension permits\nexpression of access constraints on shared data. \n Access constraints can apply both to simple objects, and\nto objects that are components of larger objects, \nsuch as bank account records in a bank's data base.\n The constraints are stated declaratively, and can \nbe enforced by static checking similar to type checking.\n The approach can be used to extend any strongly-typed \nlanguage, but is particularly suitable for extending\nlanguages that support the notion of abstract data \ntypes. \n Programming languages, access control, data types,\nabstract data types, type checking, capabilities\n", "3106": "A Fast Algorithm for Copying List Structures An algorithm is presented for copying an arbitrarily\nlinked list structure into a block of \ncontiguous storage locations without destroying  the original\nlist.  Apart from a fixed number of program \nvariables, no auxiliary storage, such as a stack, is used.\n The algorithm needs no mark bits and operates \nin linear time.  It is shown to be significantly faster\nthan Fisher's algorithm, the fastest previous \nlinear-time algorithm for the same problem.  Its speed\ncomes mainly from its efficient list-traversal \ntechnique, which folds the processing stack into the\nstructure being built, and from its classification \nof list cells into nine types, which enables processing\noperations to be optimized for each type.\n List copying, Lisp, space complexity, constant workspace\n", "3107": "Generating Beta Variates with Nonintegrel Shape Parameters A new rejection method is described for generating\nbeta variates.  The method is compared with \npreviously published methods both theoretically and through\ncomputer timings.  It is suggested that the \nmethod has advantages in both speed and programming\nsimplicity over previous methods, especially for \n\"difficult\" combinations of parameter values.\n Beta variates, random numbers, simulation\n", "3108": "Economical Encoding of Commas Between Strings A method for insertion of delimiters between\nstrings without using new symbols is presented. \n As the lengths of the strings increase, the extra cost,\nin terms of prolongation, becomes vanishingly \nsmall compared to the lengths of the strings.\n String transmission, delimiters, commas, encoding of the integers\n", "3109": "A Data Structure for Manipulating Priority Queues A data structure is described which can be used\nfor representing a collection of priority queues. \n The primitive operations are insertion, deletion,\nunion, update, and search for an item of earliest \npriority.\n Data structures, implementation of set operations,priority\nqueues, mergeable heaps, binary trees\n", "3110": "Assembling Code for Machines with Span-Dependent Instructions Many modern computers contain instructions\nwhose lengths depend on the distance from a given \ninstance of such an instruction to the operand of that\ninstruction.  This paper considers the problem \nof minimizing the lengths of programs for such machines.\n An efficient solution is presented for the \ncase in which the operand of every such \"span-dependent\"\ninstruction is either a label or an assembly-time \nexpression of a certain restricted form.If this restriction\nis relaxed by allowing these operands to \nbe more general assembly-time expressions, then\nthe problem is shown to be NP-complete.\n Span-dependent instructions, variable-length addressing,\ncode generation, assemblers, compilers, \nNP-complete, computational complexity.\n", "3111": "Secure Communications Over Insecure Channels According to traditional conceptions of cryptographic\nsecurity, it is necessary to transmit \na key, by secret means, before encrypted messages can\nbe sent securely.  This paper shows that it is \npossible to select a key over open communications channels\nin such a fashion that communications security \ncan be maintained.  A method is described which forces\nany enemy to expend an amount of work which increases \nas the square of the work required of the two communicants\nto select the key.  The method provides a \nlogically new kind of protection against the passive\neaves dropper.  It suggests that further research \non this topic will be highly rewarding, both\nin a theoretical and a practical sense.\n Security, cryptography, cryptology, communications\nsecurity, wiretap, computer network security, \npassive eavesdropping, key distribution, public key cryptosystem\n", "3112": "List Processing in Real Time on a Serial Computer A real-time list processing system is one\nin which the time required by the elementary list \noperations (e.g. CONS, CAR, CDR, RPLACA, REPLACD, EQ,\nand ATOM in LISP) is bounded by a (small) constant. \n Classical implementations of list processing systems\nlack this property because allocating a list cell \nfrom the heap may cause a garbage collection, which process\nrequires time proportional to the heap size \nto finish.  A real-time list processing system is presented\nwhich continuously reclaims garbage, including \ndirected cycles, while linearizing and compacting the\naccessible cells into contiguous locations to avoid \nfragmenting the free storage pool.  The program is small\nand requires no time-sharing interrupts, making \nit suitable for microcode.  Finally, the system requires\nthe same average time, and not more than twice \nthe space, of a classical implementation, and those\nspace requirements can be reduced to approximately \nclassical proportions by compact list representation.\n Arrays of different sizes, a program stack, and \nhash linking are simple extensions to our system, and\nreference counting is found to be inferior for \nmany applications.\n Real-time, compacting,garbage collection, list processing,\nvirtual memory, file or database management, \nstorage management, storage allocation, LISP, CDR-coding, reference counting.  \n", "3113": "Optimal Conversion of Extended-Entry A general dynamic programming algorithm for converting\nlimited, extended, or mixed entry decision \ntables to optimal decision trees is presented which can\ntake into account rule frequencies or probabilities, \nminimum time and/or space cost criteria, common action\nsets, compressed rules and ELSE rules, sequencing \nconstraints on condition tests, excludable combinations\nof conditions, certain ambiguities, and interrupted \nrule masking. \n Decision table, optimal programs, dynamic programming\n", "3114": "A Technique for Isolating Differences Between Files A simple algorithm is described for isolating\nthe differences between two files.  One application \nis the comparing of two versions of a source program\nor other file in order to display all differences. \n The algorithm isolates differences in a way that corresponds\nclosely to our intuitive notion of difference, \nis easy to implement, and is computationally efficient,\nwith time linear in the file length.  For most \napplications the algorithm isolates differences similar\nto those isolated by the longest common subsequence. \n Another application of this algorithm merges files\ncontaining independently generated changes into a \nsingle file.  The algorithm can also be used to generate\nefficient encodings of a file in the form of \nthe differences between itself and a given \"datum\" file,\npermitting reconstruction of the original file \nfrom the difference and datum files.   \n Difference isolation, word processing, text editing,\nprogram maintenance, hash coding, file compression, \nbandwidth compression, longest common subsequence,\nfile comparison, molecular evolution\n", "3115": "Orderly Enumeration of Nonsingular Binary Nonsingular binary matrices of order N, i.e.,\nnonsingular over the field {0, 1}, and an initial \nsegment of the natural numbers are placed in one-to-one\ncorrespondence.  Each natural number corresponds \nto two intermediate vectors.  These vectors are mapped into\na nonsingular binary matrix.  Examples of \ncomplete enumeration of all 2 x 2 and 3 x 3 nonsingular\nbinary matrices were produced by mapping the \nintermediate vectors to the matrices.  The mapping\nhas application to the Vernam encipherment method \nusing pseudorandom number sequences.  A bit string formed\nform bytes of text of a data encryption key \ncan be used as a representation of a natural number. \nThis natural number is transformed to a nonsingular \nbinary matrix.  key leverage is obtained by using the\nmatrix as a\"seed\" in a shift register sequence \npseudorandom number generator.  \n Binary matrices, combinatorics, combinations, nonsingular\nmatrices, encryption, Vernam, pseudorandom \nnumbers, feedback shiftregister sequences, random numbers.\n", "3116": "Interference Detection Among Solids and Surfaces In many industrial environments it is necessary to determine whether\nr there is interference among components.  There are many potential\ninterference problems in products made up of assemblies of components \nand in product manufacturing and testing.  Typically, drawings\nare used in an attempt to detect such unwanted interferences,\nbut the two-dimensional, static drafting medium does not always show\ninterferences among three-dimensional, moving parts.  This paper\n presents a computer representation for solids and surfaces and algorithms\nwhich carry out interference checking among objects so represented.  \nObjects are represented as polyhedra or as piecewise planar\nsurfaces.  Two types of interference checking are discussed:\ndetection of intersections among objects in fixed positions and detection\nof collisions among objects moving along specified trajectories.\n Interference checking, intersection detection, collision detection, solid\nrepresentation, polyhedral representation, graphics, polygons, surfaces\n", "3117": "The Impact and Use of Computer Technology by the Police Over the past decade there has been a significant growth\nin the use of computer technology by U.S. police departments.  This\ngrowth, however, has been at a slower rate than predicted in the\nearly 1970's.  Further, when computer applications extend\nbeyond \"routine\" uses to \"nonroutine\" efforts, such as resource allocation\nor computer-aided-dispatch systems where the machine begins to become\na tool for decision making, strategic planning and person/machine\ninteraction, the results of the technology to date have been\nmixed.  This paper reports on case studies and surveys which provinsights \non the implementation and impact of police computer technology\nand the relationship of this technology to law enforcement and society.\n Computer technology, innovation, police resource allocation, police command \nand control, computer aided dispatch,\nlaw enforcement, technology transfer\n", "3118": "Permutation of Data Blocks in a Bubble Memory A common internal organization of bubble memories consists of a set of (minor) \nloops, connected through another (major) loop.  The problem of obtaining any \ngive n permutation of the minor loop contents in minimum time is studied\nin this paper.  A lower bound to the number of steps required buy\na permutation algorithm is derived, and the class of optimum algorithms is \nidentified.\n Bubble memory, memory loops, permutation algorithm, data block shift\n", "3119": "The Impact of Distributions and Disciplines Simple queueing models are used to study the performance tradeoffs of \nmultiple processor systems.  Issues considered include the impact of CPU\nservice disciplines and distributions, level of multiprogramming,\nmultitasking, and job priorities. \n Multiprogramming, multiprocessing, scheduling disciplines,\nperformance evaluation, queueing models\n", "3120": "An Event-Driven Compiling Technique Due to the linear structure of source text, difficulties may arise in a \none-pass compilation process.  These difficulties occur when an entity\ncannot be processed because of a forward reference to information\nonly obtainable from subsequent entities.  Classic solutions\nask for data structures appropriate for each case.  A technique is\npresented here which uses instead control structures, namely events\nand processes.  The work of the compiler-writer becomes easier both\nconceptually and in practice because he can forget these problems\nat the outset and he avoids special processing for each problem.\nThis technique has been applied to the construction of an Algol\n68 compiler.  Three examples from that implementation\nare described and discussed here.\n Compiling technique, one-pass compilation, semantic\nanalysis, event, process, parallelism\ncategories--4.12\n.N\nCA790105 DH April 10, 1979  12:26 PM\n.X\n3120\t5\t3120\n3120\t5\t3120\n3120\t5\t3120\n", "3121": "Syntactic Source to Source Transforms and Program Manipulation Syntactic transforms are the source to source program transformations\nwhich preserve the history of computation, and thus do not\nmodify the execution time.  Combined with a small number of primitive\nsemantic transforms, they provide a powerful tool for program\nmanipulation.  A catalogue of syntactic transforms, and its use for\nsolution of a system of program equations, is given.  Examples of\nderivation of more complex source to source transformations are also\npresented.  Two case studies illustrate the way in which syntactic \nand semantic source to source transformations may be used for\ndevelopment of clear, simple, and reasonably efficient programs.\n Structured programming, program transforms, control structures\n", "3122": "Production and Employment of Ph.D.'s in Computer Science - 1977 and 1978 Computer science, production of Ph.D.'s, employment, students\n", "3123": "Employment Characteristics of Doctoral Level Computer Scientists Employment characteristics, manpower utilization,occupational trends\n", "3124": "Recursive Data Structures in APL A mathematical study of three approaches for defining nested\narrays in APL is presented.  Theorems exhibiting the relationships\nbetween the definitional systems are given and illustrated through graph\nrepresentations.  One of the approaches is used to define an\nAPL array to be a recursive data structure equivalent to a tree structure\nin which all data is stored at the leaves as homogeneous\narrays of numbers and characters.  An extension of APL is proposed that\nincludes new primitive functions to manipulate the nesting\nlevel of arrays and new operators to assist in the\nconstruction of data-driven algorithms.  \n Nested arrays, APL arrays, recursive data structures,\ntrees, data-driven algorithms, theory of arrays\n", "3125": "Global Optimization by Suppression of Partial Redundancies The elimination of redundant computations and the moving of invariant\ncomputations out of loops are often done separately, with invariants \nmoved outward loop by loop.  We propose to do both at once and\nto move each expression directly to the entrance of the outermost\nloop in which it is invariant.  This is done by solving a more\ngeneral problem, i.e. the elimination of computations performed\ntwice on a given execution path.  Such computations are termed partially\nredundant.  Moreover, the algorithm does not require any graphical\ninformation or restrictions on the shape of the program graph.\nTesting this algorithm has shown that its execution cost is nearly\nlinear with the size of the program, and that it leads\nto a smaller optimizer that requires less execution time.\n Optimizer, optimization, compiler, compilation,\nredundancy elimination, invariant\n computation elimination, partial redundancy,\ndata flow analysis, Boolean systems\n", "3126": "Comments on Perfect Hashing Functions: A Single Hashing, hashing methods, hash coding, direct addressing, identifier-\nto-address transformations, perfect hashing functions, perfect\nhash coding, reduction, retrieving, scatter storage, searching\n", "3127": "Thoth, a Portable Real-Time Operating System  Thoth isa real-time operating system which is designed to be portable\nover a large set of machines.  It is currently running on two minicomputers\nwith quite different architectures.  Both the system and application\nprograms which use it are written in a high-level language.\nBecause the system is implemented by the same software on different\nhardware, it has the same interface to user programs.  Hence,\napplication programs which use Thoth are  highly portable.  Thoth\nencourages structuring programs as networks of communicating processes \nby providing efficient interprocess communication primitives.\n Portability, real time, operating systems, minicomputer\n", "3128": "Synchronization with Eventcounts and Sequencers Synchronization of concurrent processes requires controlling the relative \nordering of events in the processes.\nA new synchronization mechanism is proposed, using \nabstract objects called eventcounts and sequencers, that allows processes\nto control the ordering of events directly, rather than using mutual\nexclusion to protect manipulations of shared variables that control\nordering of events.  Direct control of ordering seems to simplify\ncorrectness arguments and also simplifies implementation in distributed\nsystems.  The mechanism is defined formally, and then several\nexamples of its use are given.  The relationship of the mechanism\nto protection mechanisms in the system is explained; in particular,\neventcounts are shown to be applicable to situations where confinement\nof information matters.  An implementation of eventcount\ns and sequencers in a system with shared memory is described.\n Process synchronization, interprocess communication, distributed\nsystems, security models, mutual exclusion, semaphores\n", "3129": "Optimal Storage Allocation for Serial Files A computer system uses several serial files.  The files reside on a \ndirect-access storage device in which storage space is limited.  Records are \nadded to the files either by jobs in batch processing mode, or by on-line \ntransactions. Each transaction (or job) generates a demand vector which \ndesignates the space required in each file for record addition. Whenever one \nfile runs out of space, the system must be reorganized.  This paper considers \nseveral criteria for best allocating storage space to the files.\n Serial files, storage allocation, reorganization, partitioned dataset\n", "3130": "CURRICULUM '78 - Recommendations for the Contained in this report are the recommendations for\nthe undergraduate degree program in Computer Science of the\nCurriculum Committee on Computer Science (C3S) of the Association\nfor Computing Machinery (ACM).   The core curriculum common to all\ncomputer science undergraduate programs is presented in terms of\nelementary level topics and courses, and intermediate level courses.\nElective courses, used to round out an undergraduate program,\nare then discussed, and the entire program including the computer\nscience component and other material is presented.  Issues related\nto undergraduate computer science education, such as service\ncourses, supporting areas, continuing education, facilities,\nstaff, and articulation are presented.\n Computer sciences courses, computer science curriculum, computer\nscience education, computer science undergraduate degree\nprograms, service courses, continuing education\n", "3131": "FOCUS Microcomputer Number System FOCUS is a number system and supporting computational\nalgorithms especially useful for microcomputer control and other\nsignal processing applications.  FOCUS has the wide-ranging\ncharacter of floating-point numbers with a uniformity of state distributions\nthat give FOCUS better than a twofold accuracy advantage\nover an equal word length floating-point system.  FOCUS computations\nare typically five times faster than single precision fixed-point\nor integer arithmetic for a mixture of operations, comparable in\nspeed with hardware arithmetic for many applications.  Algorithms\nfor 8-bit and 16-bit implementations of FOCUS are included.\n Number representation, logarithmic arithmetic, computational\nspeed, computational accuracy, microcomputer applications  \n", "3132": "Experiments with Some Algorithms that Find In two-class pattern recognition, it is a standard\ntechnique to have an algorithm finding hyperplanes\nwhich separates the two classes in a linearly separable training\nset.  The traditional methods find a hyperplane which separates all\npoints in the other, but such a hyperplane is not necessarily centered\nin the empty space between the two classes.  Since a central\nhyperplane does not favor one class or the other, it should have\na lower error rate in classifying new points and is therefore better\nthan a noncentral hyperplane.  Six algorithms for finding central\nhyperplanes are tested on three data sets.  Although frequently\nused practice, the modified relaxation algorithm is very poor. \nThree algorithms which are defined in the paper are found to be\nquite good.\n Pattern recognition, pattern classification, linear discriminants, central\nhyperplanes, centering, centrality criteria, dead zone, hyperplane,\nlinearly separable, relaxation algorithm, accelerated relaxation\n", "3133": "Logic and Semantic Networks An extended form of semantic network is defined, which can\nbe regarded as a syntactic variant of the clausal form of logic.\nBy virtue of its relationship with logic, the extended\nsemantic network is provided with a precise semantics,\ninference rules, and a procedural interpretation.  On\nthe other hand, by regarding semantic networks as an \nabstract data structure for the representation of clauses, we provide a\ntheorem-prover with a potentially useful indexing scheme and path-following\nstrategy for guiding the search for a proof.\n Logic, semantic networks, theorem-proving, indexing, resolution, deduction, \nlogic programming\n", "3134": "The Use of Normal Multiplication Tables This paper describes a method for the organization and retrieval of attribute \nbased information systems, using the normal multiplication table as a directory\nfor the information system.  Algorithms for the organization an\nd retrieval of information are described.  This method is particularly\nsuitable for queries requesting a group of information items,\n all of which possess a particular set of attributes (and possibly\nsome other attributes as well).  Several examples are given; the\nresults with respect to the number of disk accesses and disk space\nare compared to other common approaches.  Algorithms evaluating\nthe appropriateness of the above approach to a given information system\nare described.  For a certain class of information systems,\nthe normal multiplication table method yields far more rapid retrieval\nwith a more economical space requirement than conventional systems.  \nMoreover this method incorporates an improved modification of the inverted \nfile technique.\n Information retrieval, inverted files, multiattribute retrieval,\nmultilist file, normal multiplication table, queries,\nrapid retrieval, space economy\n", "3135": "Detection of Three-Dimensional Patterns of Atoms in Chemical Structures An algorithm for detecting occurrences of a three-dimensional pattern of\nobjects within a larger structure is presented.  The search technique\npresented uses the geometric structure of the pattern to define\ncharacteristics demanded of candidates for matching. This is useful\nin cases where the properties of each atom, considered individually,\ndo not adequately limit the number of sets of possible matchings.\nSeveral applications of this technique in the field of chemistry\nare: (1) in pharmacology: searching for a common constellation\nof atoms in molecules possessing similar biological activities;\n(2) in X-ray crystallography: fitting a structure or a structural fragment\nto a set of peaks in the electron-density distribution of\na Fourier map; (3) in chemical documentation; retrieving from\na file the structures containing specified substructures.\n Three-dimensional pattern recognition, chemical\nstructure search, information retrieval, crystal\n-structure analysis, drug analysis and design\n", "3136": "Price/Performance Patterns of U.S. Computer Systems Econometric models of the U.S. computer market have been developed to study \nthe relationships between system price and hardware performance.  Single\nmeasures of price/performance such as \"Grosch's Law\" are shown to\nbe so over simplified as to be meaningless.  Multiple-regression models\npredicting system cost as a function of several hardware\ncharacteristics do, however, reveal a market dichotomy.  On one hand there\nexists a stable, price predictable market for larger, general\npurpose computer systems.  The other market is the developing one\nfor small business computer systems, a market which is relatively\nunstable with low price predictability. \n Price/performance, Grosch's law, U.S. computer market\n", "3137": "A Methodology for the Design of Distributed Information Systems A macro model of a distributed information system in presented.  The model\ndescribes the major costs of using an information\nsystem from the perspective of the end-user.  The making evident the effect of\nvarious design and operating parameters on overall cost per transaction.\n The technique is illustrated by application to the design\nof an interactive transaction processing system.\n Distributed processing, system design, cost minimization, distributed\ndatabase, interactive computing, economic modeling, transaction processing\n", "3138": "A Mathematical Programming Updating Method Using Modified An efficient and numerically stable method is presented for the problem of\nupdating an orthogonal decomposition of a matrix of column (or row) vectors.\nThe fundamental idea is to add a column (or row) analogous\nto adding an additional row of data in a linear least squares problem.\nA column (or row) is dropped by a formal scaling with the\nimaginary unit,  -1, followed by least squares addition of the column\n(or row).  The elimination process for the procedure is successive\nssive application of the Givens transformation in modified (more efficient)\nform.  These ideas are illustrated with an implementation\nof the revised simplex method.  The algorithm is a general purpose\none that does not account for any particular structure or sparsity\nin the equations.  Some suggested computational tests for determining\nsigns of various controlling parameters in the revised simplex\nalgorithm are mentioned.  A simple means of constructing\ntest cases and some sample computing times are presented. \n Linear programming, numerical linear algebra, modified Givens transformations,\nlinear programming test cases\n", "3139": "New Methods to Color the Vertices of a Graph This paper describes efficient new heuristic\nmethods to color the vertices of a graph which rely\nupon the comparison of the degrees and structure of a graph.  A method\nis developed which is exact for bipartite graphs and is an\nimportant part of heuristic procedures to find maximal cliques in general\ngraphs.  Finally an exact method is given which performs better\nthan the Randall-Brown algorithm and is able to color larger\ngraphs, and the new heuristic methods, the classical methods, and\nthe exact method are compared.  \n NP-complete, graph structure, balancing, graph\ncoloring, scheduling, comparison of the methods\n", "3140": "Social Processes and Proofs of Theorems and Programs It is argued that formal verifications of\nprograms, no matter how obtained, will not play the\nsame key role in the development of computer science and software\nengineering as proofs do in mathematics.  Furthermore the absence\nof continuity, the inevitability of change, and the complexity of\nspecification of significantly many real programs make the form\nal verification process difficult to justify and manage.  It is felt\nthat ease of formal verification should not dominate program\nlanguage design.\n Formal mathematics, mathematical proofs,\nprogram verification, program specification\n", "3141": "An Improved Algorithm for Decentralized Extrema-Finding This note presents an improvement to LeLann's\nalgorithm for finding the largest (or smallest) of a set of uniquely\nnumbered processes arranged in a circle, in which no central\ncontroller exists and the number of processes is not known a priori.\nThis decentralized algorithm uses a technique of selective\nmessage extinction in order to achieve an average number of\nmessage passes of order (n log n) rather than O(n2).  \n Decentralized algorithms, distributed systems, operating systems\n", "3142": "Consumer Difficulties With Computerized Transactions:  The prevalence with which errors may be encountered by the \nend targets of a computerized process is assessed.  How many and\nwhat type of errors occur?  How easily are they corrected?  What\nis the reaction of consumers to errors-to a failure to correct\nthem?  What can be learned by designers of large management packages\nfrom such data? Results show that with the present state of the\nart, approximately 40 percent of individuals (or households) having\naverage contacts with different types of accounts experience one\nor more errors per year.  Eighty percent relate to billing.  Attempts\nto correct errors often turned out to be difficult and not always\nsuccessful. There appears to be some conflict between computer-using\norganizations and their public.  Also the role of poor man\nagement packages including poor software is indicated.  While most\nmanagement systems may be adequate, results of the survey raise\nconcerns about the timeliness and the number of designs of very\nlarge linked program packages (as EFT for instance).  \n Errors, systems errors, billing errors, management systems, consumers\n", "3143": "Reasoning About Arrays A variety of concepts, laws, and notations are presented which facilitate\nreasoning about arrays.  The basic concepts include intervals and their\npartitions, functional restriction, images, pointwise extension of relations,\nordering, single-point variation of functions, various equivalence relations \nfor array values, and concatenation.  The effectiveness\nof these ideas is illustrated by informal descriptions of\nalgorithms for binary search and merging, and by a short formal proof.\n Arrays, assertions, program proving, intervals, partitions, pointwise\nextension, ordering, concatenation, binary search, merging\n", "3144": "A Model for and DIscussion of Multi-Interpreter Systems A multi-interpreter system is a system in which programs execute\nby virtue of being interpreted by other programs, which themselves may\neither be interpreted (i.e. nested interpreters) or run directly on\nthe host machine.  The model reveals the anatomy of interpreters\nand how these differ from procedures, and exhibits links\nto protection domains and multiprocessor architectures.\n Interpreters, transfer-of-control, hierarchies\n", "3145": "An Implementation of Structured Walk-Throughs The effectiveness of structured\nwalk-throughs in teaching introductory Cobol programming was empirically\nassessed with a sample of 215 under-graduate business administration\nmajors.  Cobol proficiency was measured by a final examination\ntesting (a) knowledge of language rules, (b) ability to read\nand debug a program, and (c) the ability to write a program.  Analysis\nof multiple covariance was used to statistically adjust test\nscores for age and conditional reasoning scores. The findings provide\nempirical support for incorporating structured walk-throughs\ninto the programming learning process more effectively\ndevelop student proficiency in writing Cobol programs.\n Structured walk-throughs, Cobol programming, teaching\nof programming, testing programming proficiency\n", "3146": "An Academic Program Providing Realistic Training in Software Engineering An academic program at Harvey Mudd College, called\nthe Clinic program, brings projects from industry on\n campus to be studied and solved by student teams.  The objective of\nthe Clinic is to provide students, working as small teams under\n careful faculty supervision, an opportunity to work on real world\nproblems of sufficient magnitude and complexity.  Under this program,\nstudents can acquire essential skills of software engineering,\nsuch as team work, software project management, software design\nmethodology, and communication skills, in a realistic environment.\nSample software projects undertaken by the Clinic are described.\n Experience so far has shown that the program is a viable\ntransition from an academic to industrial world.\n Software engineering, software engineering education, software\nprojects, student teams, software engineering skills\n", "3147": "A Model for Automating File and Program Design in Business Application Systems This paper discusses a model for finding an efficient implementation of a \nbusiness application system whose logical specifications have been determined\nin advance.  The model views file and program design as a problem\nof systematically coordinating the configurations of datasets and\ncomputations.  It uses a straight forward search technique to\ndetermine aggregations of computations, aggregations of datasets, device,\norganization, and key order for each data set, key order for\n each computation, and access method  for each dataset-computation\npair.  Although computational results are presented for a sample\nproblem involving 54 computations and 49 datasets, the main point of\nthe paper is that the underlying model works computationally an\nd is simple enough to be adapted to many file design situations.\n System design, automatic programming, search\nmethods, system configurations, design choices\n", "3148": "High Level Programming for Distributed Computing Programming for distributed and other loosely coupled systems\nis a problem of growing interest.  This paper describes an approach\nto distributed computing at the level of general purpose programming\nlanguages.  Based on primitive notions of module, message,\nand transaction key, the methodology is shown to be independent\nof particular languages and machines.  It appears to be useful for\nprogramming a wide range of tasks.  This is part of an ambitious\nprogram of development in advanced programming languages, and relations\nwith other aspects of the project are also discussed.\n Distributed computing, modules, messages, assertions\n", "3149": "The Cyclic Order Property of Vertices as an Aid in Scene Analysis A cyclic-order property is defined for bodies bounded by smooth-curved faces.\nThe property is shown to be useful for analyzing pictures of such bodies,\nparticularly when the line data extracted from the pictures are imperfect.\nThis property augments previously known grammatical rules that\ndetermine the existence of three-dimensional bodies corresponding\nto given two-dimensional line-structure data.\n Scene analysis, cyclic order, artificial intelligence,\nthree-dimensional reconstruction\n, picture processing, computer graphics, pattern recognition.\n", "3150": "Beyond Programming Languages As computer technology matures, our growing ability to create large systems is \nleading to basic changes in the nature of programming.  Current programming \nlanguage concepts will not be adequate for building and maintaining\nsystems of the complexity called for by the tasks we attempt.  Just\nas high level languages enabled the programmer to escape from the\nintricacies of a machine's order code, higher level programming systems\ncan provide the means to understand and manipulate complex\nsystems and components.  In order to develop such systems, we need\nto shift our attention away from the detailed specification of\nalgorithms, towards the description of the properties of the packages\nand objects with which we build.  This paper analyzes some of the\nshortcomings of programming languages as they now exist,\nand lays out some possible directions for future research.\n Programming, programming languages, programming systems, systems development\n", "3151": "An Optimal Real-Time Algorithm for Planar Convex Hulls An algorithm is described for the construction in real-time of the\nconvex hull of a set of n points in the plane.   Using an appropriate data\nstructure, the algorithm constructs the convex hull by successive\nupdates, each taking time O(log n), thereby achieving a total\nprocessing time O(n log n).  \n Computational geometry, convex hull, planar set of\npoints, real-time algorithms, on-line algorithms.  \n", "3152": "Storage Reorganization Techniques for In order to multiply matrices while minimizing\nthe number of page fetches required, it is often more efficient to\nreorganize the data into submatrix form and to use block multiplication \nrather than to use the best known algorithms which leave the\nmatrices stored in row-(or column-)oriented form.  An efficient\nmethod for accomplishing this reorganization is given.  This also\nmakes possible the derivation of an asymptotically better bound\nfor multiplication of matrices given in row-oriented form by adapting\nthe technique of Strassen to the reorganized data.  The reorganization/block \nmultiplication scheme is shown to be advantageous for\nmatrices and pages of realistic size; the Strassen adaptation is\nnot.  The former scheme is also shown to be advantageous even if\nthe transpose of one of the matrices is available at no additional cost.\n Matrix multiplication, paging, virtual memory,\ndata reorganization, pagination, transpose.\n", "3153": "The Control of Response Times in Multi-Class The possibility of giving different quality of service to jobs of different\nclasses by regulating their memory allocation is examined in\nthe context of a paged computer system.  Two parameterized algorithms\nwhich partition the main memory between two classes of jobs are\nconsidered.  Initially, a closed system consisting of a process\nor and paging and file devices, with fixed numbers of jobs, is studied\nto determine optimal degrees of multiprogramming and the proportion\nof processor time devoted to each class.  Applying a decomposition\napproach and treating the closed system as a single server,\nthe response times in an open system with external arrivals are\nstudied.  The object is to investigate the effect of the memory\nalocation parameters on the expected response times under the two algorithms.\nNumerical solutions and economical lower bounds for the\nexpected response times as functions of the control parameters\nare obtained.  A way of applying the results to systems with more\nthan two job classes is indicated.\n Queueing networks, paging, virtual memory, performance control\n", "3154": "Algorithm = Logic + Control An algorithm can be regarded as consisting of a logic component,\nwhich specifies the knowledge to be used in solving problems,\nand a control component, which determines the problem-solving\nstrategies by means of which that knowledge is used.  The logic component\ndetermines the meaning of the algorithm whereas the control\ncomponent only affects its efficiency.  The efficiency of an\nalgorithm can often by improving the control component without changing\nthe logic of the algorithm.  We argue that computer programs would\nbe more often correct and more easily improved and modified if\ntheir logic and control aspects were identified and separated in\nthe program text. \n Control language, logic programming, nonprocedural language, programming\nmethodology, program specification, relational data structures \n", "3155": "The Paradigms of Programming", "3156": "Computing Connected Components on Parallel Computers We present a parallel algorithm which uses n2 processors to find the connected\ncomponents of an undirected graph with n vertices in time O(log2n).  An\nO(log2n) time bound also can be achieved using only n$n/$log2n)) processors.\nThe algorithm can be used to find the transitive closure\nof a symmetric Boolean matrix.  We assume that the processors have\naccess to a common memory.  Simultaneous access to the same location\nis permitted for fetch instructions but not for store instructions.\n Graph theory, parallel processing, algorithms,\ntransitive closure, connected component\n", "3157": "Proving Termination with Multiset Orderings A common tool for proving the termination of programs is the well-founded\nset, a set ordered in such a way as to admit no infinite descending sequences.\nThe basic approach is to find a termination function  that maps\nthe values of the program variables into some well-founded set,\nsuch that the value of the termination function is repeatedly reduced\nthroughout the computation.  All too often, the termination functions required \nare difficult to find and are of a complexity out\nof proportion to the program under consideration. Multisets (bags)\nover a given well-founded set S are sets that admit multiple occurrences\nof elements taken from S.  The given ordering on S induces\nan ordering on the finite multisets over S.  This multiset ordering\nis shown to be well-founded.  The multiset ordering enables the\nuse of relatively simple and intuitive termination functions in otherwise\ndifficult termination proofs.  In particular, the multiset\nordering is used to prove the termination of production systems,\nprograms defined in terms of sets of rewriting rules. \n Program correctness, program termination, program verification, well-founded\norderings, well-founded sets, multisets, bags, production systems,\nterm rewriting systems, tree replacement systems, reduction rules\n", "3158": "Secure Personal Computing in an Insecure Network A method for implementing secure personal computing in a network\nwith one or more central facilities is proposed.  The method employs a\npublic-key encryption device and hardware keys.  Each user is responsible \nfor his own security and need not rely on the security of\nthe central facility or the communication links.  A user can safely\nstore confidential files in the central facility or transmit confidential \ndata to other users on the network. \n Personal computing, security, privacy, networks, public-key encryption\n", "3159": "Further Remark on Stably Updating Mean and Standard Deviation Estimates Mean, standard deviation\n", "3160": "Rejuvenating Experimental Computer Science This report is based on the results of an NSF sponsored\nworkshop held in Wasington, D.C. on November 2, 1978.  The co-authors of the \nreport are: Gordon Bell, Digital Equipment Corporation; Bernard A. Galler,\nUniversity of Michigan; Patricia Goldberg, IBM Corporation; John\nHamblen, University of Missouri at Rolla; Elliot Pinson, Bell Telephone\nLaboratories; and Ivan Sutherland, California Institute of\nTechnology.  Also participating in the workshop were representatives\nof NSF and other government agencies.  In addition to the authors,\na number of other people have contributed to the contents of this\nreport.  In preparation for the original workshop, all doctorate-granting \ncomputer science departments in the nation were asked\nfor comments and suggestions on the problems of experimental computer science.\nA version of the current report dated January 15 was circulated to these \ndepartments and to a number of industrial and government groups for criticism.\nThe editors and authors of this final version gratefully acknowledge the \ncontribution of a large number of other people at all stages in the preparation \nof the report.\n$Note: Following this presentation of the report, there is a\nposition paper on the crisis in experimental computer\nscience written by the ACM Executive Committee.)  \n", "3161": "An ACM Executive Committee Position on the Crisis ", "3162": "On Improving the Worst Case Running Time It is shown how to modify the Boyer-Moore string matching algorithm so that\nits worst case running time is linear even when multiple occurrences of the \npattern are present in the text.\n Computational complexity, linear time, worst case, string matching, periodicity\n", "3163": "An Optimal Insertion Algorithm for One-Sided An algorithm for inserting an element into a one-sided height-balanced\n(OSHB) binary search tree is presented.  The algorithm operates in time \nO(log n), where n is the number of nodes in\nthe tree.  This represents an improvement over the best previous\nly known insertion algorithms of Hirschberg and Kosaraju, which require\ntime O(log 2n).  Moreover, the O(log n) complexity is optimal. Earlier \nresults have shown that deletion in such a structure can\nalso be performed in O(log n) time.  Thus the result of this paper\ngives a negative answer to the question of whether such trees should\nbe the first examples of their kind, where deletion has a smaller time \ncomplexity than insertion.  Furthermore, it can now be concluded\nthat insertion, deletion, and retrieval in OSHB trees can\nbe performed in the same time as the corresponding operations for\nthe more general AVL trees, to within a constant factor.  However,\nthe insertion and deletion algorithms for OSHB trees appear much\nmore complicated than the corresponding algorithms for AVL trees.\n Insertion, one-sided height-balanced trees, height-balanced\ntrees, binary trees, search trees.\n", "3164": "Progressive Acyclic Digraphs-A Tool for Database Integrity A progressive acyclic digraph (PAD) algorithm accepts are requests and\nmaintains a graph in an acyclic state.  When a request creates a cycle,\nnodes are, \"detached\" until the new are can be entered acyclically\nThis process is important in certain areas of database implementation\nin which there are constraints on the permissible sequences\nof actions. Two PAD algorithms are presented; one uses a simple\npath matrix representation and the other uses a list with an\n\"artificial gradient.\"  Experiments suggest that for large N the second\nis considerably faster, though both are asymptotically O(NR),\nwhere N is the number of nodes and R is the expected number\nof nodes reachable along paths from any given node.\n List processing, data structures, topological sort,\nacyclic digraph, database integrity, network, deadlock\n", "3165": "Approximation of Polygonal Maps by Cellular Maps The approximation of polygonal thematic maps by cellular\nmaps, an important operation in geographical data processing,\nis analyzed.  The data organization used for representing the polygonal\nmaps is a widely used segment-based data structure, where class\nlabels identify the regions bordering each segment on either side.\nThe approximation algorithm presented operates on such an\norganization, eliminating the need for the recognition of region boundaries.\nEach segment is examined only once.  The versatility of\nthe new organization is further illustrated by the outline of algorithms\nfor area computation and point inclusion.  The algorithm is\napplied to a set of soil maps converted to computer-readable\nform by means of a coordinate digitizer.\n Polygon maps, cellularization, gridding, geographic data structures,\ncomputational geometry, computer cartography, automated cartography\n", "3166": "Computing Standard Deviations: Accuracy Four algorithms for the numerical computation\nof the standard deviation of (unweighted) sampled data\nare analyzed.  Two of the algorithms are well-known in the statistical\nand computational literature; the other two are new algorithms\nspecifically intended for automatic computation.  Our discussion is \nexpository, with emphasis on reaching a suitable definition of\n\"accuracy.\"  Each of the four algorithms is analyzed for the conditions\nunder which it will be accurate.  We conclude that all four\nalgorithms will provide accurate answers for many problems, but two\nof the algorithms, one new, one old, are substantially more accurate\non difficult problems than are the other two.\n Mean, standard deviation, least squares, updating\nestimates, rounding error analysis, condition number.\n", "3167": "Updating Mean and Variance Estimates: An Improved Method A method of improved efficiency\nis given for updating the mean and variance of weighted sampled data\nwhen an additional data value is included in the set.  Evidence\nis presented that the method is stable and at least\nas accurate as the best existing updating method. \n Mean, standard deviation, variance, updating estimates, removing data\n", "3168": "Comment on \"An Optimal Evaluation of Boolean Query, Boolean expression, information retrieval, file organization\n", "3169": "Note on \"An Optimal Evaluation of Boolean Expressions  Query, Boolean expression, optimal evaluation, information retrieval\n", "3170": "On the Proof of Correctness of a Calendar Program A formal specification is given for a simple calendar\nprogram, and the derivation and proof of correctness of the program are \nsketched.  The specification is easy to understand, and its correctness is \nmanifest to humans.\n Program specification, program verification, inductive assertions\n", "3171": "Line Numbers Made Cheap A technique is described for run-time line number administration\nto be used for implementations of high level languages.  Under suitable\ncircumstances, this method requires absolutely no overhead,\nin either time or space, during execution of the program. \n Line number administration, diagnostic messages, abstract machine code \n", "3172": "An Algorithm for Planning Collision-Free This paper describes a collision avoidance algorithm\nfor planning a safe path for a polyhedral object moving among\nknown polyhedral objects.  The algorithm transforms the obstacles\nso that they represent the locus of forbidden positions for an arbitrary\nreference point on the moving object.  A trajectory of this\nreference point which avoids all forbidden regions is free of collisions.\nTrajectories are found by searching a network which indicates, for each vertex \nin the transformed obstacles, which other vertices can be reached safely.\n Path finding, collision-free paths, polyhedral objects,\npolyhedral obstacles, graph searching, growing objects\n", "3173": "A Psychology of Learning BASIC This paper addresses the question: What does a person know\nfollowing learning of BASIC programming?  Several underlying conceptual\nstructures are identified: (1) a transaction is an event that\noccurs in the computer and involves some operation on some object\nat some location, (2) a prestatement is a set of transactions corresponding\nto a line of code, (3) chunks are frequently occurring\n configurations of prestatements corresponding to several lines of code.\n BASIC, Learning, instruction\n", "3174": "Password Security: A Case History This paper describes the history of the design of the password\nsecurity scheme on a remotely accessed time-sharing system.\nThe present design was the result of countering observed attempts\nto penetrate the system.  The result is a compromise between\nextreme security and ease of use.\n Operating systems, passwords, computer security\n", "3175": "Breaking Substitution Ciphers Using a Relaxation Algorithm Substitution ciphers are codes in which each letter\nof the alphabet has one fixed substitute, and the word divisions \ndo not change.  In this paper the problem of breaking substitution\nciphers is represented as a probabilistic labeling problem.\nEvery code letter is assigned probabilities of representing plain text\nletters.  These probabilities are updated in parallel for all\ncode letters, using joint letter probabilities.  Iterating the updating\nscheme results in improved estimates that finally lead to\nbreaking the cipher.  The method is applies successfully to two examples.\n Cryptography, substitution ciphers,\nprobabilistic classification, relaxation\n", "3176": "Storing a Sparse Table The problem of storing and searching large sparse tables is ubiquitous in \ncomputer science.  The standard technique for storing such tables is\nhashing, but hashing has poor worst-case performance.  We propose\na good worst-case method for storing a static table of n entries,\neach an integer between 0 and N - 1.  The method requires 0(n) w\nwords of storage and allows O(logn N) access time.  Although our method\nis a little complicated to use in practice, our analysis shows\nwhy a simpler algorithm used for compressing LR parsing tables works so well.\n Gaussian elimination, parsing, searching,\nsparse matrix, table compression, table lookup\n", "3177": "How to Share a Secret In this paper we show how to divide data D into\nn pieces in such a way that D is easily reconstructable from any\nk pieces, but even complete knowledge of k - 1 pieces reveals\nolutely no information about D.  This technique enables the construction\nof robust key management schemes for cryptographic systems\nthat can function securely and reliably even when misfortunes destroy\nhalf the pieces and security breaches expose all but one of the\nremaining pieces.\n Cryptography, key management, interpolation\n", "3178": "Introduction to the EFT Symposium", "3179": "Overview of the EFT Symposium It is increasingly recognized that large-scale technologies such as EFT\nhave the potential for aiding in the solution of current societal problems.\nYet, these technologies also generate problems.  This symposium\npresents selected papers from a conference that sought to discover\nwhat is currently known about EFT impacts in society\nand what research is needed in the future.   \n EFT's, research agenda, conference results, public policy\n", "3180": "Costs of the Current U.S. Payments System Neither the banking industry nor\npublic policy makers have good information on the comparative costs\nof alternative payment systems such as cash, checks, credit cards,\nand EFT transactions.  As a result, EFT systems and services are\nlikely to be implemented without a valid assessment of whether they\nare cost-justified, lst alone justified in terms of other criteria.\n EFT's,payment system costs, payment system volumes\n", "3181": "Public Protection and Education with EFT Research has revealed the existence of widespread\nmisinformation and lack of knowledge about EFT among\nbusiness and government as well as consumers.  As a result, any effort\nto stimulate meaningful public participation in decisions on\nthe introduction of EFT systems will require a coordinated educational\neffort of considerable scale.  In addition, research has revealed \nshortcomings in the present system for defining responsibilities,\nliabilities, and avenues of recourse.  THis article presents\nseveral possible alternatives for improving the current system, but\nongoing research is also needed to assure that actions taken will\nbe responsive to the changing environment and consumer needs.\n Electronic funds transfer systems, consumer education, security\nand fraud, privacy, system reliability, EFT ombudsman \n", "3182": "Vulnerabilities of EFTs to Intentionally Caused Losses The hypothesis that consumers\nare provided greater accuracy and freedom from error and fraud with\nelectronic funds transfer systems (EFTs) is discussed in light\nof the technical capabilities and potential of the computer to protect\nagainst both accidentally and intentionally caused losses.\nAlthough the nomenclature for business crimes remains the same as for\nmanual depository and other financial service systems - for example, \nfraud, theft, embezzlement - the characteristics of the crimes\nare new. The changes resulting from the accelerating use of EFTs and \nits continual technological advances broaden the scope of security\nissues to be examined.  Factors such as backup requirements, \nregulatory and legislative actions, and economics give rise to\nthe urgency for immediate research into solutions for emerging\nEFTs - related vulnerabilities.\n EFTs, computer abuse, crime, security, errors,\nlosses, positions of trust, legislation\n", "3183": "Policy, Values, and EFT Research: Anatomy of a Research Agenda There is an emerging recognition that EFT systems have the potential to\nvastly alter the payment and fund transfer system in American society.\nA number of forces and actors are involved in this evolution,\nand the values vary significantly depending on individual and institutional \nperspectives. These value conflicts are highlighted\nin a six-part research agenda: technological issues in EFT, EFT impacts \non people, economic impact of EFT, regulation and control of\nEFT, and evaluating and monitoring EFT systems.\n EFTs, research agenda, value conflicts, impacts on people,\neconomic impacts, regulation and control, monitoring EFT\n", "3184": "   Revised Report on the Algorithmic Language ALGOL 60    The report gives a complete defining description of the international\nalgorithmic language ALGOL 60. This is a language suitable for expressing \na large class of numerical processes in a form sufficiently concise for \ndirect automatic translation into the language of programmed automatic\ncomputers.\n", "3185": "   The Humble Programmer    We shall do a much better programming job, provided that we approach the\ntask with a full appreciation if its tremendous difficulty, provided that we \nstick to modest and elegant programming languages, provided that we respect\nthe intrinsic limitations of the human mind and approach the task as Very\nHumble Programmers.\n", "3186": "   GO TO Statement Considerd Harmful go to statement, jump instruction, branch instruction, conditional clause,\nrepetitive clause, program intelligibility, program sequencing\n", "3187": "   Certification of Algorithm 271 (QUICKERSORT)    QUICKERSORT compiled and run without correction through the ALDEP translator\nfor the CDC 1604A. Comparison of average sorting items with other recently\npublished algorithms demonstrates QUICKERSORT's superior performance.\n", "3188": "   Semiotics and Programming Languages    I have based my paper on semiotics and its three dimension. I should insert\nat this point that language has many aspects and that pragmatics, semantics and\nsyntactics do not necessary cover all of them. One can, however, project most \naspects into the three semiotic dimension and there seems to be a strong \ntendency to do so today.\n", "3189": "   An Algebraic Compiler for the FORTRAN Assembly Program    An algebraic compiler has been written which may be added to the FORTRAN \nAssembly Program. This compiler will expand all algebraic statements with the \nfollowing operations: addition, subtraction, multiplication and division. It\nwill compile multi-level expressions in floating-point arithmetic (this is\neasily be revised to fixed-point).\n", "3190": "   Correction to Economies of Scale and the IBM System/360    On page 439, a \"typical\" instruction mix id discussed and the timing computed\nas outlined in that page. Through an undetected programming error, the times and\nthe resulting regression equation are slightly in error.\n", "3191": "   Generating Permutations by Nested Cycling    The purpose of this letter is two_fold: first to give due credit to the\nTompkins-Paige algorithm, and second to clarify a comment by Hill, CR Review\n13891 on \"Programs for Permutations\".\n permutations\n", "3192": "The Lincoln Keyboard - a Typewriter Keyboard Designed     A new typewriter keyboard, for direct and punched paper tape computer input\nwill replace the usual commercial keyboard with 88 characters chosen for the \nconvenience  of programmers. The Lincoln Keyboard is expected to facilitate\nthe programming of algorithmic process and should allow considerable \nflexibility in assembly and utility routines.\n", "3193": ".W    Work is in progress on a formula coding technique allowing direct entry\ninto the computer of formulae typed on an 84 character Flexo-writer. This\nFlexo-writer will be modified for automatic half-line advance and retract,\nwithout carriage return, to permit completely general sub and superscripting.\n", "3194": "   A Non-heuristic Program for Proving Elementary Logical Theorems    The paper discusses problems involved in designing a device capable of\ndistinguishing among speech events that are normally recognized as different \nby native speakers of a particular language. Parallels between these problems\nand those of chemical analysis are pointed out.\n", "3195": "   Reiteration of ACM Policy Toward Standardization    The periodic change in officers, chairman and editors which usually follows\nas election occasionally results in a change in policy. In the case of this \ndepartment there is no radical change, but this is nevertheless the proper time\nto reiterate ans underline ACM's policy with respect to standardization in the \ncomputer area.\n", "3196": "   The Reactive Typewriter Program    84-character keyboard including alphabetical upper and lower case for good\nreadability. If the machine is restricted to only a single case, the lower case\nis preferred. The reactive typewriter should be portable. the reactive \ntypewriter should operate over any commercially used, dial-type telephone\n(voice) or telegraph (Telex) line or over leased (nondial) telegraph lines\ninterchangeably.\n", "3197": "   Structures of Standards-Processing Organizations in the Computer Area    In line with the ACM's policy statement [Comm. ACM 5 (Nov. 1962), 547-549],\nthe following organizational descriptions have been provided in order to\ndescribe standardization activities pertinent to computers and information\nprocessing.\n", "3198": "   Microprogramming, Emulators and Programming Languages   The problem we have been concerned with is that of converting language to\naction - or intellectual energy to mechanical energy. The medium that we use \nfor this purpose is language and therefore we are preoccupied with the subject\nof language. In the areas of language investigation we have concentrated first \non formalizing syntax and then on semantics.\n", "3199": "   ALGEM - An Algebraic Manipulator    ALGEM is a package of subprograms written in Slip, FORTRAN IV and MAP 7094 \nII to manipulate algebraic expressions. Algem's basic algebraic operations are \nadditions, subtractions, multiplications, division and exponentiation. It is \ncapable of handling any number of single letter variables, variable exponents, \nand of finding the highest common factor of two polynomials. Also included are\nsuch functions as substitution, differentiation, determining coefficients of\nspecified variables, solving a linear equation, basic I/O routines plus other\nspecial purpose and arithmetic routines. The major innovation of Algem over \nother manipulators is the assignment of types to all expressions and the use \nof a standard ordering procedure.\n", "3200": "   A FORMAC Program for the Solution of Linear Boundary and Initial Value    A computer program is described which has been developed for obtaining\napproximate solutions to linear initial and boundary-value problems involving \ndifferential equations. For each problem, input to the program includes:\n   1. The equations (in symbolic form) to be satisfied  -  the differential\nequations, equations describing auxiliary conditions such as boundary \nconditions, etc.\n   2. A numerical description of the regions in which each of the equations\nare to be satisfied.\n   3. Sets of functions (in symbolic form) to be used in linear combinations\nto approximate the solution functions. Give the above input, the program\ngenerates an approximation to the solutions of the specified problemm in terms \nof the specified functions which is optimum in the least-squares sense.\n", "3201": "   Symbolic Manipulation of Poisson Series    Poisson series of three variables are manageable symbolically through as a \nset of formal subroutines written partially in the IBM 7094 machine language,\nbut to be called in the FORTRAN language for use in Fortran  programs. An \neffort has been made to supply those operations which are most required by\ncelestial mechanics. The routines are entirely self-contained subroutines\nand require only standard Fortran input/output units 5 and 6; they are design\nto avoid waste and overflow of core storage space.\n", "3202": "   MANIP: A Computer System for Algebra and Analytic Differentiation    A mathematical expression to be operated upon is written in FORTRAN-like \nnotation and stored in the computer as a string of BCD characters with all\nblanks removed. It may be as complicated as desired (parentheses nested without\nrestriction, etc.) so long as the entire expression (or any subsequent form)\ndoes not exceed 5000 characters. The problemm of performing algebraic operations\nand obtaining analytic derivatives was translated into that of identifying and\nmanipulating character sequences. Programs which resulted were written in\nFORTRAN IV for a CDC 3600 and are discussed in detail.\n", "3203": "   GRAD Assistant - A Program for Symbolic Algebraic Manipulation and     The General Recursive Algebra and Differentiation Assistant (GRAD Assistant)\nnow under development is a set of LISP functions which symbolically manipulate\nabd differentiate algebraic expressions. It is designed for use with problemms \nin which a large amount of routine manipulation is to be done by a program \nwithout human intervention. Thus, GRAD must recognize necessary simplifications\nwithout external guidance. While some complicated expressions (notably ones\ninvolving nested radicals and trigonometric functions) do not yield completely\nto the present version, it has proved quite useful indeed.\n", "3204": "   An On-Line Program for Non-Numerical Algebra    The goal of this program is to make a step toward te design of an automated\nmathematical assistant. Some requirements for such a program are: it must be\neasy to access, and that the result must be obtained in a reasonably short\ntime. Accordingly the program is written for a time-shared computer. The Q-32\ncomputer as System Development Corporation, Santa Monica, California, was \nchosen because it also had a LISP 1.5 compiler. Programming and debugging was\ndone from a remote teletype console at Stanford University.\n"}